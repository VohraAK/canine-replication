{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.8368951191081089,
  "eval_steps": 500,
  "global_step": 7000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0029889111396718174,
      "grad_norm": 4.664714336395264,
      "learning_rate": 2.9913927077106994e-05,
      "loss": 5.9394,
      "step": 25
    },
    {
      "epoch": 0.005977822279343635,
      "grad_norm": 4.6591949462890625,
      "learning_rate": 2.982426778242678e-05,
      "loss": 5.8818,
      "step": 50
    },
    {
      "epoch": 0.008966733419015452,
      "grad_norm": 4.387139797210693,
      "learning_rate": 2.9734608487746562e-05,
      "loss": 5.8175,
      "step": 75
    },
    {
      "epoch": 0.01195564455868727,
      "grad_norm": 4.054754734039307,
      "learning_rate": 2.964494919306635e-05,
      "loss": 5.7637,
      "step": 100
    },
    {
      "epoch": 0.014944555698359088,
      "grad_norm": 3.8591437339782715,
      "learning_rate": 2.9555289898386134e-05,
      "loss": 5.701,
      "step": 125
    },
    {
      "epoch": 0.017933466838030904,
      "grad_norm": 4.375348091125488,
      "learning_rate": 2.946563060370592e-05,
      "loss": 5.6423,
      "step": 150
    },
    {
      "epoch": 0.020922377977702723,
      "grad_norm": 4.744508266448975,
      "learning_rate": 2.9375971309025702e-05,
      "loss": 5.591,
      "step": 175
    },
    {
      "epoch": 0.02391128911737454,
      "grad_norm": 4.605898857116699,
      "learning_rate": 2.9286312014345486e-05,
      "loss": 5.529,
      "step": 200
    },
    {
      "epoch": 0.02690020025704636,
      "grad_norm": 4.188354969024658,
      "learning_rate": 2.9196652719665274e-05,
      "loss": 5.4671,
      "step": 225
    },
    {
      "epoch": 0.029889111396718175,
      "grad_norm": 4.483104228973389,
      "learning_rate": 2.9106993424985058e-05,
      "loss": 5.4146,
      "step": 250
    },
    {
      "epoch": 0.032878022536389995,
      "grad_norm": 3.746946334838867,
      "learning_rate": 2.9017334130304842e-05,
      "loss": 5.3471,
      "step": 275
    },
    {
      "epoch": 0.03586693367606181,
      "grad_norm": 4.39648962020874,
      "learning_rate": 2.8927674835624626e-05,
      "loss": 5.2967,
      "step": 300
    },
    {
      "epoch": 0.03885584481573363,
      "grad_norm": 4.34638786315918,
      "learning_rate": 2.8838015540944414e-05,
      "loss": 5.2435,
      "step": 325
    },
    {
      "epoch": 0.04184475595540545,
      "grad_norm": 4.189818859100342,
      "learning_rate": 2.8748356246264198e-05,
      "loss": 5.1977,
      "step": 350
    },
    {
      "epoch": 0.044833667095077266,
      "grad_norm": 4.193456172943115,
      "learning_rate": 2.865869695158398e-05,
      "loss": 5.1273,
      "step": 375
    },
    {
      "epoch": 0.04782257823474908,
      "grad_norm": 4.287274360656738,
      "learning_rate": 2.8569037656903766e-05,
      "loss": 5.0829,
      "step": 400
    },
    {
      "epoch": 0.0508114893744209,
      "grad_norm": 4.363275051116943,
      "learning_rate": 2.847937836222355e-05,
      "loss": 5.0267,
      "step": 425
    },
    {
      "epoch": 0.05380040051409272,
      "grad_norm": 4.160948276519775,
      "learning_rate": 2.8389719067543338e-05,
      "loss": 4.9804,
      "step": 450
    },
    {
      "epoch": 0.05678931165376453,
      "grad_norm": 4.112051963806152,
      "learning_rate": 2.8300059772863122e-05,
      "loss": 4.9438,
      "step": 475
    },
    {
      "epoch": 0.05977822279343635,
      "grad_norm": 3.8612821102142334,
      "learning_rate": 2.8210400478182906e-05,
      "loss": 4.8765,
      "step": 500
    },
    {
      "eval_edit_distance": 0.499224006996317,
      "eval_exact_match": 0.484,
      "eval_f1": 0.48614873390136554,
      "step": 500
    },
    {
      "epoch": 0.06276713393310816,
      "grad_norm": 4.288654804229736,
      "learning_rate": 2.812074118350269e-05,
      "loss": 4.8183,
      "step": 525
    },
    {
      "epoch": 0.06575604507277999,
      "grad_norm": 4.068612098693848,
      "learning_rate": 2.8031081888822474e-05,
      "loss": 4.787,
      "step": 550
    },
    {
      "epoch": 0.0687449562124518,
      "grad_norm": 4.133265018463135,
      "learning_rate": 2.7941422594142262e-05,
      "loss": 4.7346,
      "step": 575
    },
    {
      "epoch": 0.07173386735212361,
      "grad_norm": 3.6100070476531982,
      "learning_rate": 2.7851763299462043e-05,
      "loss": 4.6729,
      "step": 600
    },
    {
      "epoch": 0.07472277849179544,
      "grad_norm": 3.9019646644592285,
      "learning_rate": 2.776210400478183e-05,
      "loss": 4.6161,
      "step": 625
    },
    {
      "epoch": 0.07771168963146725,
      "grad_norm": 4.092576026916504,
      "learning_rate": 2.7672444710101614e-05,
      "loss": 4.5974,
      "step": 650
    },
    {
      "epoch": 0.08070060077113908,
      "grad_norm": 4.288166046142578,
      "learning_rate": 2.7582785415421402e-05,
      "loss": 4.5265,
      "step": 675
    },
    {
      "epoch": 0.0836895119108109,
      "grad_norm": 4.1215596199035645,
      "learning_rate": 2.7493126120741183e-05,
      "loss": 4.4717,
      "step": 700
    },
    {
      "epoch": 0.0866784230504827,
      "grad_norm": 3.5653364658355713,
      "learning_rate": 2.7403466826060967e-05,
      "loss": 4.4256,
      "step": 725
    },
    {
      "epoch": 0.08966733419015453,
      "grad_norm": 3.5655412673950195,
      "learning_rate": 2.7313807531380754e-05,
      "loss": 4.3724,
      "step": 750
    },
    {
      "epoch": 0.09265624532982634,
      "grad_norm": 3.333911180496216,
      "learning_rate": 2.722414823670054e-05,
      "loss": 4.3468,
      "step": 775
    },
    {
      "epoch": 0.09564515646949816,
      "grad_norm": 3.8427631855010986,
      "learning_rate": 2.7134488942020326e-05,
      "loss": 4.2868,
      "step": 800
    },
    {
      "epoch": 0.09863406760916998,
      "grad_norm": 3.825943946838379,
      "learning_rate": 2.7044829647340107e-05,
      "loss": 4.2752,
      "step": 825
    },
    {
      "epoch": 0.1016229787488418,
      "grad_norm": 3.7298505306243896,
      "learning_rate": 2.6955170352659894e-05,
      "loss": 4.2426,
      "step": 850
    },
    {
      "epoch": 0.10461188988851361,
      "grad_norm": 3.5167605876922607,
      "learning_rate": 2.686551105797968e-05,
      "loss": 4.1722,
      "step": 875
    },
    {
      "epoch": 0.10760080102818544,
      "grad_norm": 3.3498499393463135,
      "learning_rate": 2.6775851763299463e-05,
      "loss": 4.1397,
      "step": 900
    },
    {
      "epoch": 0.11058971216785725,
      "grad_norm": 3.2989306449890137,
      "learning_rate": 2.6686192468619247e-05,
      "loss": 4.1014,
      "step": 925
    },
    {
      "epoch": 0.11357862330752906,
      "grad_norm": 3.3087029457092285,
      "learning_rate": 2.659653317393903e-05,
      "loss": 4.0581,
      "step": 950
    },
    {
      "epoch": 0.11656753444720089,
      "grad_norm": 3.6228277683258057,
      "learning_rate": 2.650687387925882e-05,
      "loss": 4.031,
      "step": 975
    },
    {
      "epoch": 0.1195564455868727,
      "grad_norm": 3.3014211654663086,
      "learning_rate": 2.6417214584578603e-05,
      "loss": 3.983,
      "step": 1000
    },
    {
      "eval_edit_distance": 0.6045104081667527,
      "eval_exact_match": 0.596,
      "eval_f1": 0.596,
      "step": 1000
    },
    {
      "epoch": 0.12254535672654451,
      "grad_norm": 3.6207056045532227,
      "learning_rate": 2.6327555289898387e-05,
      "loss": 3.9208,
      "step": 1025
    },
    {
      "epoch": 0.12553426786621633,
      "grad_norm": 3.8178722858428955,
      "learning_rate": 2.623789599521817e-05,
      "loss": 3.8883,
      "step": 1050
    },
    {
      "epoch": 0.12852317900588817,
      "grad_norm": 3.3429291248321533,
      "learning_rate": 2.6148236700537955e-05,
      "loss": 3.843,
      "step": 1075
    },
    {
      "epoch": 0.13151209014555998,
      "grad_norm": 3.0258212089538574,
      "learning_rate": 2.6058577405857743e-05,
      "loss": 3.805,
      "step": 1100
    },
    {
      "epoch": 0.1345010012852318,
      "grad_norm": 3.382310152053833,
      "learning_rate": 2.5968918111177527e-05,
      "loss": 3.7292,
      "step": 1125
    },
    {
      "epoch": 0.1374899124249036,
      "grad_norm": 3.266087770462036,
      "learning_rate": 2.587925881649731e-05,
      "loss": 3.7382,
      "step": 1150
    },
    {
      "epoch": 0.14047882356457542,
      "grad_norm": 3.6112985610961914,
      "learning_rate": 2.5789599521817095e-05,
      "loss": 3.7149,
      "step": 1175
    },
    {
      "epoch": 0.14346773470424723,
      "grad_norm": 3.2838971614837646,
      "learning_rate": 2.569994022713688e-05,
      "loss": 3.6771,
      "step": 1200
    },
    {
      "epoch": 0.14645664584391907,
      "grad_norm": 3.2663779258728027,
      "learning_rate": 2.5610280932456667e-05,
      "loss": 3.6044,
      "step": 1225
    },
    {
      "epoch": 0.14944555698359088,
      "grad_norm": 3.3739120960235596,
      "learning_rate": 2.5520621637776448e-05,
      "loss": 3.6066,
      "step": 1250
    },
    {
      "epoch": 0.1524344681232627,
      "grad_norm": 2.810539960861206,
      "learning_rate": 2.5430962343096235e-05,
      "loss": 3.569,
      "step": 1275
    },
    {
      "epoch": 0.1554233792629345,
      "grad_norm": 3.3575758934020996,
      "learning_rate": 2.534130304841602e-05,
      "loss": 3.4776,
      "step": 1300
    },
    {
      "epoch": 0.15841229040260632,
      "grad_norm": 3.3848214149475098,
      "learning_rate": 2.5251643753735807e-05,
      "loss": 3.4424,
      "step": 1325
    },
    {
      "epoch": 0.16140120154227816,
      "grad_norm": 3.130110025405884,
      "learning_rate": 2.5161984459055588e-05,
      "loss": 3.4446,
      "step": 1350
    },
    {
      "epoch": 0.16439011268194997,
      "grad_norm": 2.962725877761841,
      "learning_rate": 2.5072325164375372e-05,
      "loss": 3.3997,
      "step": 1375
    },
    {
      "epoch": 0.1673790238216218,
      "grad_norm": 3.1195788383483887,
      "learning_rate": 2.498266586969516e-05,
      "loss": 3.3859,
      "step": 1400
    },
    {
      "epoch": 0.1703679349612936,
      "grad_norm": 3.206864833831787,
      "learning_rate": 2.4893006575014944e-05,
      "loss": 3.3585,
      "step": 1425
    },
    {
      "epoch": 0.1733568461009654,
      "grad_norm": 2.903219223022461,
      "learning_rate": 2.480334728033473e-05,
      "loss": 3.318,
      "step": 1450
    },
    {
      "epoch": 0.17634575724063722,
      "grad_norm": 3.051422119140625,
      "learning_rate": 2.4713687985654512e-05,
      "loss": 3.3001,
      "step": 1475
    },
    {
      "epoch": 0.17933466838030906,
      "grad_norm": 3.008002758026123,
      "learning_rate": 2.46240286909743e-05,
      "loss": 3.2215,
      "step": 1500
    },
    {
      "loss": 3.2249,
      "grad_norm": 3.4110896587371826,
      "learning_rate": 2.4534369396294084e-05,
      "epoch": 0.18232357951998088,
      "step": 1525
    },
    {
      "loss": 3.214,
      "grad_norm": 3.1047885417938232,
      "learning_rate": 2.4444710101613868e-05,
      "epoch": 0.1853124906596527,
      "step": 1550
    },
    {
      "loss": 3.1911,
      "grad_norm": 3.0716137886047363,
      "learning_rate": 2.4355050806933652e-05,
      "epoch": 0.1883014017993245,
      "step": 1575
    },
    {
      "loss": 3.1229,
      "grad_norm": 2.8100433349609375,
      "learning_rate": 2.4265391512253436e-05,
      "epoch": 0.19129031293899632,
      "step": 1600
    },
    {
      "loss": 3.1385,
      "grad_norm": 2.610854387283325,
      "learning_rate": 2.4175732217573224e-05,
      "epoch": 0.19427922407866813,
      "step": 1625
    },
    {
      "loss": 3.0588,
      "grad_norm": 2.725205659866333,
      "learning_rate": 2.4086072922893008e-05,
      "epoch": 0.19726813521833997,
      "step": 1650
    },
    {
      "loss": 3.0343,
      "grad_norm": 2.7544503211975098,
      "learning_rate": 2.3996413628212792e-05,
      "epoch": 0.20025704635801178,
      "step": 1675
    },
    {
      "loss": 3.0334,
      "grad_norm": 2.6811840534210205,
      "learning_rate": 2.3906754333532576e-05,
      "epoch": 0.2032459574976836,
      "step": 1700
    },
    {
      "loss": 2.9919,
      "grad_norm": 2.8540024757385254,
      "learning_rate": 2.381709503885236e-05,
      "epoch": 0.2062348686373554,
      "step": 1725
    },
    {
      "loss": 2.9248,
      "grad_norm": 2.52355694770813,
      "learning_rate": 2.3727435744172148e-05,
      "epoch": 0.20922377977702722,
      "step": 1750
    },
    {
      "loss": 2.9092,
      "grad_norm": 2.7366244792938232,
      "learning_rate": 2.3637776449491932e-05,
      "epoch": 0.21221269091669906,
      "step": 1775
    },
    {
      "loss": 2.9741,
      "grad_norm": 2.7806646823883057,
      "learning_rate": 2.3548117154811716e-05,
      "epoch": 0.21520160205637087,
      "step": 1800
    },
    {
      "loss": 2.8433,
      "grad_norm": 2.7838656902313232,
      "learning_rate": 2.34584578601315e-05,
      "epoch": 0.21819051319604268,
      "step": 1825
    },
    {
      "loss": 2.8581,
      "grad_norm": 2.6938252449035645,
      "learning_rate": 2.3368798565451288e-05,
      "epoch": 0.2211794243357145,
      "step": 1850
    },
    {
      "loss": 2.8281,
      "grad_norm": 2.3198301792144775,
      "learning_rate": 2.3279139270771072e-05,
      "epoch": 0.2241683354753863,
      "step": 1875
    },
    {
      "loss": 2.8302,
      "grad_norm": 2.6109020709991455,
      "learning_rate": 2.3189479976090853e-05,
      "epoch": 0.22715724661505812,
      "step": 1900
    },
    {
      "loss": 2.7473,
      "grad_norm": 2.5459108352661133,
      "learning_rate": 2.309982068141064e-05,
      "epoch": 0.23014615775472996,
      "step": 1925
    },
    {
      "loss": 2.7523,
      "grad_norm": 2.3948891162872314,
      "learning_rate": 2.3010161386730424e-05,
      "epoch": 0.23313506889440178,
      "step": 1950
    },
    {
      "loss": 2.7208,
      "grad_norm": 2.789400339126587,
      "learning_rate": 2.2920502092050212e-05,
      "epoch": 0.2361239800340736,
      "step": 1975
    },
    {
      "loss": 2.6962,
      "grad_norm": 2.3287622928619385,
      "learning_rate": 2.2830842797369993e-05,
      "epoch": 0.2391128911737454,
      "step": 2000
    },
    {
      "step": 2000,
      "eval_exact_match": 0.632,
      "eval_f1": 0.632,
      "eval_edit_distance": 0.639022554633543
    },
    {
      "loss": 2.6524,
      "grad_norm": 2.587921619415283,
      "learning_rate": 2.274118350268978e-05,
      "epoch": 0.2421018023134172,
      "step": 2025
    },
    {
      "loss": 2.6793,
      "grad_norm": 2.7833259105682373,
      "learning_rate": 2.2651524208009564e-05,
      "epoch": 0.24509071345308903,
      "step": 2050
    },
    {
      "loss": 2.6424,
      "grad_norm": 2.2021634578704834,
      "learning_rate": 2.256186491332935e-05,
      "epoch": 0.24807962459276087,
      "step": 2075
    },
    {
      "loss": 2.6061,
      "grad_norm": 2.059055805206299,
      "learning_rate": 2.2472205618649133e-05,
      "epoch": 0.25106853573243265,
      "step": 2100
    },
    {
      "loss": 2.6256,
      "grad_norm": 2.365901470184326,
      "learning_rate": 2.2382546323968917e-05,
      "epoch": 0.2540574468721045,
      "step": 2125
    },
    {
      "loss": 2.6207,
      "grad_norm": 2.3235111236572266,
      "learning_rate": 2.2292887029288704e-05,
      "epoch": 0.25704635801177633,
      "step": 2150
    },
    {
      "loss": 2.5712,
      "grad_norm": 2.6602394580841064,
      "learning_rate": 2.220322773460849e-05,
      "epoch": 0.26003526915144815,
      "step": 2175
    },
    {
      "loss": 2.5579,
      "grad_norm": 2.4363436698913574,
      "learning_rate": 2.2113568439928276e-05,
      "epoch": 0.26302418029111996,
      "step": 2200
    },
    {
      "loss": 2.4786,
      "grad_norm": 2.145841598510742,
      "learning_rate": 2.2023909145248057e-05,
      "epoch": 0.26601309143079177,
      "step": 2225
    },
    {
      "loss": 2.532,
      "grad_norm": 2.5272772312164307,
      "learning_rate": 2.193424985056784e-05,
      "epoch": 0.2690020025704636,
      "step": 2250
    },
    {
      "loss": 2.4737,
      "grad_norm": 2.279456615447998,
      "learning_rate": 2.184459055588763e-05,
      "epoch": 0.2719909137101354,
      "step": 2275
    },
    {
      "loss": 2.4275,
      "grad_norm": 2.295675277709961,
      "learning_rate": 2.1754931261207413e-05,
      "epoch": 0.2749798248498072,
      "step": 2300
    },
    {
      "loss": 2.3603,
      "grad_norm": 2.4514412879943848,
      "learning_rate": 2.1665271966527197e-05,
      "epoch": 0.277968735989479,
      "step": 2325
    },
    {
      "loss": 2.378,
      "grad_norm": 2.191983938217163,
      "learning_rate": 2.157561267184698e-05,
      "epoch": 0.28095764712915083,
      "step": 2350
    },
    {
      "loss": 2.3396,
      "grad_norm": 2.217536687850952,
      "learning_rate": 2.148595337716677e-05,
      "epoch": 0.28394655826882265,
      "step": 2375
    },
    {
      "loss": 2.3583,
      "grad_norm": 2.259751796722412,
      "learning_rate": 2.1396294082486553e-05,
      "epoch": 0.28693546940849446,
      "step": 2400
    },
    {
      "loss": 2.4255,
      "grad_norm": 2.3697500228881836,
      "learning_rate": 2.1306634787806333e-05,
      "epoch": 0.2899243805481663,
      "step": 2425
    },
    {
      "loss": 2.3478,
      "grad_norm": 2.078655481338501,
      "learning_rate": 2.121697549312612e-05,
      "epoch": 0.29291329168783814,
      "step": 2450
    },
    {
      "loss": 2.3206,
      "grad_norm": 2.225888967514038,
      "learning_rate": 2.1127316198445905e-05,
      "epoch": 0.29590220282750995,
      "step": 2475
    },
    {
      "loss": 2.2882,
      "grad_norm": 2.4194154739379883,
      "learning_rate": 2.1037656903765693e-05,
      "epoch": 0.29889111396718177,
      "step": 2500
    },
    {
      "step": 2500,
      "eval_exact_match": 0.634,
      "eval_f1": 0.634,
      "eval_edit_distance": 0.641022554633543
    },
    {
      "loss": 2.2417,
      "grad_norm": 1.9963815212249756,
      "learning_rate": 2.0947997609085477e-05,
      "epoch": 0.3018800251068536,
      "step": 2525
    },
    {
      "loss": 2.2593,
      "grad_norm": 2.5868678092956543,
      "learning_rate": 2.085833831440526e-05,
      "epoch": 0.3048689362465254,
      "step": 2550
    },
    {
      "loss": 2.1762,
      "grad_norm": 2.0671398639678955,
      "learning_rate": 2.0768679019725045e-05,
      "epoch": 0.3078578473861972,
      "step": 2575
    },
    {
      "loss": 2.2124,
      "grad_norm": 2.0005199909210205,
      "learning_rate": 2.067901972504483e-05,
      "epoch": 0.310846758525869,
      "step": 2600
    },
    {
      "loss": 2.1814,
      "grad_norm": 1.8929002285003662,
      "learning_rate": 2.0589360430364617e-05,
      "epoch": 0.31383566966554083,
      "step": 2625
    },
    {
      "loss": 2.1606,
      "grad_norm": 2.0611305236816406,
      "learning_rate": 2.0499701135684398e-05,
      "epoch": 0.31682458080521264,
      "step": 2650
    },
    {
      "loss": 2.1661,
      "grad_norm": 2.0823311805725098,
      "learning_rate": 2.0410041841004185e-05,
      "epoch": 0.31981349194488445,
      "step": 2675
    },
    {
      "loss": 2.1147,
      "grad_norm": 2.067472457885742,
      "learning_rate": 2.032038254632397e-05,
      "epoch": 0.3228024030845563,
      "step": 2700
    },
    {
      "loss": 2.0369,
      "grad_norm": 2.274414539337158,
      "learning_rate": 2.0230723251643757e-05,
      "epoch": 0.32579131422422813,
      "step": 2725
    },
    {
      "loss": 2.1304,
      "grad_norm": 2.1410698890686035,
      "learning_rate": 2.0141063956963538e-05,
      "epoch": 0.32878022536389995,
      "step": 2750
    },
    {
      "loss": 2.0679,
      "grad_norm": 1.8997541666030884,
      "learning_rate": 2.005140466228332e-05,
      "epoch": 0.33176913650357176,
      "step": 2775
    },
    {
      "loss": 1.98,
      "grad_norm": 2.040457248687744,
      "learning_rate": 1.996174536760311e-05,
      "epoch": 0.3347580476432436,
      "step": 2800
    },
    {
      "loss": 1.998,
      "grad_norm": 2.177499771118164,
      "learning_rate": 1.9872086072922893e-05,
      "epoch": 0.3377469587829154,
      "step": 2825
    },
    {
      "loss": 2.0175,
      "grad_norm": 1.7341599464416504,
      "learning_rate": 1.978242677824268e-05,
      "epoch": 0.3407358699225872,
      "step": 2850
    },
    {
      "loss": 1.9539,
      "grad_norm": 1.8893922567367554,
      "learning_rate": 1.969276748356246e-05,
      "epoch": 0.343724781062259,
      "step": 2875
    },
    {
      "loss": 2.1318,
      "grad_norm": 2.0240542888641357,
      "learning_rate": 1.960310818888225e-05,
      "epoch": 0.3467136922019308,
      "step": 2900
    },
    {
      "loss": 2.0154,
      "grad_norm": 1.7595996856689453,
      "learning_rate": 1.9513448894202033e-05,
      "epoch": 0.34970260334160264,
      "step": 2925
    },
    {
      "loss": 2.0125,
      "grad_norm": 1.8667019605636597,
      "learning_rate": 1.9423789599521818e-05,
      "epoch": 0.35269151448127445,
      "step": 2950
    },
    {
      "loss": 1.9375,
      "grad_norm": 1.880919098854065,
      "learning_rate": 1.93341303048416e-05,
      "epoch": 0.3556804256209463,
      "step": 2975
    },
    {
      "loss": 1.9165,
      "grad_norm": 1.9088979959487915,
      "learning_rate": 1.9244471010161386e-05,
      "epoch": 0.35866933676061813,
      "step": 3000
    },
    {
      "step": 3000,
      "eval_exact_match": 0.638,
      "eval_f1": 0.638,
      "eval_edit_distance": 0.6449684455565423
    },
    {
      "loss": 1.9124,
      "grad_norm": 1.8758915662765503,
      "learning_rate": 1.9154811715481173e-05,
      "epoch": 0.36165824790028994,
      "step": 3025
    },
    {
      "loss": 1.9969,
      "grad_norm": 1.8107490539550781,
      "learning_rate": 1.9065152420800958e-05,
      "epoch": 0.36464715903996175,
      "step": 3050
    },
    {
      "loss": 1.9024,
      "grad_norm": 1.7781000137329102,
      "learning_rate": 1.897549312612074e-05,
      "epoch": 0.36763607017963357,
      "step": 3075
    },
    {
      "loss": 1.8544,
      "grad_norm": 1.9124153852462769,
      "learning_rate": 1.8885833831440526e-05,
      "epoch": 0.3706249813193054,
      "step": 3100
    },
    {
      "loss": 1.9208,
      "grad_norm": 1.7058638334274292,
      "learning_rate": 1.879617453676031e-05,
      "epoch": 0.3736138924589772,
      "step": 3125
    },
    {
      "loss": 1.8718,
      "grad_norm": 1.653246521949768,
      "learning_rate": 1.8706515242080098e-05,
      "epoch": 0.376602803598649,
      "step": 3150
    },
    {
      "loss": 1.8616,
      "grad_norm": 1.7214492559432983,
      "learning_rate": 1.861685594739988e-05,
      "epoch": 0.3795917147383208,
      "step": 3175
    },
    {
      "loss": 1.9541,
      "grad_norm": 1.8513215780258179,
      "learning_rate": 1.8527196652719666e-05,
      "epoch": 0.38258062587799263,
      "step": 3200
    },
    {
      "loss": 1.8514,
      "grad_norm": 1.6871063709259033,
      "learning_rate": 1.843753735803945e-05,
      "epoch": 0.38556953701766444,
      "step": 3225
    },
    {
      "loss": 1.8033,
      "grad_norm": 1.7201303243637085,
      "learning_rate": 1.8347878063359238e-05,
      "epoch": 0.38855844815733626,
      "step": 3250
    },
    {
      "loss": 1.7893,
      "grad_norm": 1.7184306383132935,
      "learning_rate": 1.825821876867902e-05,
      "epoch": 0.3915473592970081,
      "step": 3275
    },
    {
      "loss": 1.7984,
      "grad_norm": 1.6275200843811035,
      "learning_rate": 1.8168559473998802e-05,
      "epoch": 0.39453627043667994,
      "step": 3300
    },
    {
      "loss": 1.7997,
      "grad_norm": 1.7116130590438843,
      "learning_rate": 1.807890017931859e-05,
      "epoch": 0.39752518157635175,
      "step": 3325
    },
    {
      "loss": 1.7574,
      "grad_norm": 1.7328996658325195,
      "learning_rate": 1.7989240884638374e-05,
      "epoch": 0.40051409271602356,
      "step": 3350
    },
    {
      "loss": 1.7588,
      "grad_norm": 1.6392455101013184,
      "learning_rate": 1.789958158995816e-05,
      "epoch": 0.4035030038556954,
      "step": 3375
    },
    {
      "loss": 1.7606,
      "grad_norm": 1.5263535976409912,
      "learning_rate": 1.7809922295277942e-05,
      "epoch": 0.4064919149953672,
      "step": 3400
    },
    {
      "loss": 1.7604,
      "grad_norm": 1.5182112455368042,
      "learning_rate": 1.772026300059773e-05,
      "epoch": 0.409480826135039,
      "step": 3425
    },
    {
      "loss": 1.6708,
      "grad_norm": 1.5380651950836182,
      "learning_rate": 1.7630603705917514e-05,
      "epoch": 0.4124697372747108,
      "step": 3450
    },
    {
      "loss": 1.7468,
      "grad_norm": 1.640586256980896,
      "learning_rate": 1.7540944411237298e-05,
      "epoch": 0.4154586484143826,
      "step": 3475
    },
    {
      "loss": 1.7393,
      "grad_norm": 1.7219327688217163,
      "learning_rate": 1.7451285116557082e-05,
      "epoch": 0.41844755955405444,
      "step": 3500
    },
    {
      "step": 3500,
      "eval_exact_match": 0.638,
      "eval_f1": 0.6382051282051282,
      "eval_edit_distance": 0.6454266762722859
    },
    {
      "loss": 1.6261,
      "grad_norm": 1.6260991096496582,
      "learning_rate": 1.7361625821876867e-05,
      "epoch": 0.42143647069372625,
      "step": 3525
    },
    {
      "loss": 1.6486,
      "grad_norm": 1.7259726524353027,
      "learning_rate": 1.7271966527196654e-05,
      "epoch": 0.4244253818333981,
      "step": 3550
    },
    {
      "loss": 1.6625,
      "grad_norm": 1.5460923910140991,
      "learning_rate": 1.7182307232516438e-05,
      "epoch": 0.42741429297306993,
      "step": 3575
    },
    {
      "loss": 1.6409,
      "grad_norm": 1.442906379699707,
      "learning_rate": 1.7092647937836226e-05,
      "epoch": 0.43040320411274174,
      "step": 3600
    },
    {
      "loss": 1.6301,
      "grad_norm": 1.475453495979309,
      "learning_rate": 1.7002988643156007e-05,
      "epoch": 0.43339211525241356,
      "step": 3625
    },
    {
      "loss": 1.6256,
      "grad_norm": 1.5982885360717773,
      "learning_rate": 1.691332934847579e-05,
      "epoch": 0.43638102639208537,
      "step": 3650
    },
    {
      "loss": 1.5965,
      "grad_norm": 1.5877974033355713,
      "learning_rate": 1.6823670053795578e-05,
      "epoch": 0.4393699375317572,
      "step": 3675
    },
    {
      "loss": 1.5964,
      "grad_norm": 1.6221281290054321,
      "learning_rate": 1.6734010759115362e-05,
      "epoch": 0.442358848671429,
      "step": 3700
    },
    {
      "loss": 1.5669,
      "grad_norm": 1.4066736698150635,
      "learning_rate": 1.6644351464435147e-05,
      "epoch": 0.4453477598111008,
      "step": 3725
    },
    {
      "loss": 1.6665,
      "grad_norm": 1.5744314193725586,
      "learning_rate": 1.655469216975493e-05,
      "epoch": 0.4483366709507726,
      "step": 3750
    },
    {
      "loss": 1.5891,
      "grad_norm": 1.4982597827911377,
      "learning_rate": 1.6465032875074718e-05,
      "epoch": 0.45132558209044443,
      "step": 3775
    },
    {
      "loss": 1.6028,
      "grad_norm": 1.5065759420394897,
      "learning_rate": 1.6375373580394502e-05,
      "epoch": 0.45431449323011625,
      "step": 3800
    },
    {
      "loss": 1.5544,
      "grad_norm": 1.3042659759521484,
      "learning_rate": 1.6285714285714283e-05,
      "epoch": 0.4573034043697881,
      "step": 3825
    },
    {
      "loss": 1.6066,
      "grad_norm": 1.4807143211364746,
      "learning_rate": 1.619605499103407e-05,
      "epoch": 0.4602923155094599,
      "step": 3850
    },
    {
      "loss": 1.5568,
      "grad_norm": 1.2050237655639648,
      "learning_rate": 1.6106395696353855e-05,
      "epoch": 0.46328122664913174,
      "step": 3875
    },
    {
      "loss": 1.5621,
      "grad_norm": 1.6738258600234985,
      "learning_rate": 1.6016736401673642e-05,
      "epoch": 0.46627013778880355,
      "step": 3900
    },
    {
      "loss": 1.5423,
      "grad_norm": 1.4502309560775757,
      "learning_rate": 1.5927077106993427e-05,
      "epoch": 0.46925904892847536,
      "step": 3925
    },
    {
      "loss": 1.5867,
      "grad_norm": 1.4817126989364624,
      "learning_rate": 1.583741781231321e-05,
      "epoch": 0.4722479600681472,
      "step": 3950
    },
    {
      "loss": 1.5419,
      "grad_norm": 1.5377862453460693,
      "learning_rate": 1.5747758517632995e-05,
      "epoch": 0.475236871207819,
      "step": 3975
    },
    {
      "loss": 1.4506,
      "grad_norm": 1.4392633438110352,
      "learning_rate": 1.565809922295278e-05,
      "epoch": 0.4782257823474908,
      "step": 4000
    },
    {
      "step": 4000,
      "eval_exact_match": 0.642,
      "eval_f1": 0.642,
      "eval_edit_distance": 0.6488303210486408
    },
    {
      "loss": 1.424,
      "grad_norm": 1.4674757719039917,
      "learning_rate": 1.5568439928272567e-05,
      "epoch": 0.4812146934871626,
      "step": 4025
    },
    {
      "loss": 1.4687,
      "grad_norm": 1.5509477853775024,
      "learning_rate": 1.5478780633592347e-05,
      "epoch": 0.4842036046268344,
      "step": 4050
    },
    {
      "loss": 1.5043,
      "grad_norm": 1.2830204963684082,
      "learning_rate": 1.5389121338912135e-05,
      "epoch": 0.48719251576650624,
      "step": 4075
    },
    {
      "loss": 1.4446,
      "grad_norm": 1.3366175889968872,
      "learning_rate": 1.529946204423192e-05,
      "epoch": 0.49018142690617805,
      "step": 4100
    },
    {
      "loss": 1.4408,
      "grad_norm": 1.4765770435333252,
      "learning_rate": 1.5209802749551702e-05,
      "epoch": 0.4931703380458499,
      "step": 4125
    },
    {
      "loss": 1.5084,
      "grad_norm": 1.4896340370178223,
      "learning_rate": 1.5120143454871489e-05,
      "epoch": 0.49615924918552173,
      "step": 4150
    },
    {
      "loss": 1.5045,
      "grad_norm": 1.3887536525726318,
      "learning_rate": 1.5030484160191272e-05,
      "epoch": 0.49914816032519355,
      "step": 4175
    },
    {
      "loss": 1.5068,
      "grad_norm": 1.4078497886657715,
      "learning_rate": 1.4940824865511059e-05,
      "epoch": 0.5021370714648653,
      "step": 4200
    },
    {
      "loss": 1.5137,
      "grad_norm": 1.5021175146102905,
      "learning_rate": 1.4851165570830843e-05,
      "epoch": 0.5051259826045371,
      "step": 4225
    },
    {
      "loss": 1.4324,
      "grad_norm": 1.3682518005371094,
      "learning_rate": 1.4761506276150627e-05,
      "epoch": 0.508114893744209,
      "step": 4250
    },
    {
      "loss": 1.4455,
      "grad_norm": 1.436728596687317,
      "learning_rate": 1.4671846981470413e-05,
      "epoch": 0.5111038048838809,
      "step": 4275
    },
    {
      "loss": 1.3557,
      "grad_norm": 1.498822808265686,
      "learning_rate": 1.4582187686790197e-05,
      "epoch": 0.5140927160235527,
      "step": 4300
    },
    {
      "loss": 1.3104,
      "grad_norm": 1.361254334449768,
      "learning_rate": 1.4492528392109983e-05,
      "epoch": 0.5170816271632245,
      "step": 4325
    },
    {
      "loss": 1.4453,
      "grad_norm": 1.383448600769043,
      "learning_rate": 1.4402869097429767e-05,
      "epoch": 0.5200705383028963,
      "step": 4350
    },
    {
      "loss": 1.3458,
      "grad_norm": 1.470667839050293,
      "learning_rate": 1.4313209802749553e-05,
      "epoch": 0.5230594494425681,
      "step": 4375
    },
    {
      "loss": 1.3982,
      "grad_norm": 1.162700891494751,
      "learning_rate": 1.4223550508069336e-05,
      "epoch": 0.5260483605822399,
      "step": 4400
    },
    {
      "loss": 1.4194,
      "grad_norm": 1.278516411781311,
      "learning_rate": 1.4133891213389122e-05,
      "epoch": 0.5290372717219117,
      "step": 4425
    },
    {
      "loss": 1.3431,
      "grad_norm": 1.3115431070327759,
      "learning_rate": 1.4044231918708906e-05,
      "epoch": 0.5320261828615835,
      "step": 4450
    },
    {
      "loss": 1.3785,
      "grad_norm": 1.4113149642944336,
      "learning_rate": 1.3954572624028692e-05,
      "epoch": 0.5350150940012554,
      "step": 4475
    },
    {
      "loss": 1.3417,
      "grad_norm": 1.3530200719833374,
      "learning_rate": 1.3864913329348476e-05,
      "epoch": 0.5380040051409272,
      "step": 4500
    },
    {
      "step": 4500,
      "eval_exact_match": 0.642,
      "eval_f1": 0.642,
      "eval_edit_distance": 0.6488303210486408
    },
    {
      "loss": 1.3074,
      "grad_norm": 1.156948447227478,
      "learning_rate": 1.3775254034668262e-05,
      "epoch": 0.540992916280599,
      "step": 4525
    },
    {
      "loss": 1.3827,
      "grad_norm": 1.320425033569336,
      "learning_rate": 1.3685594739988047e-05,
      "epoch": 0.5439818274202708,
      "step": 4550
    },
    {
      "loss": 1.3678,
      "grad_norm": 1.198651671409607,
      "learning_rate": 1.359593544530783e-05,
      "epoch": 0.5469707385599426,
      "step": 4575
    },
    {
      "loss": 1.2848,
      "grad_norm": 1.2371768951416016,
      "learning_rate": 1.3506276150627616e-05,
      "epoch": 0.5499596496996144,
      "step": 4600
    },
    {
      "loss": 1.2727,
      "grad_norm": 1.390803337097168,
      "learning_rate": 1.34166168559474e-05,
      "epoch": 0.5529485608392862,
      "step": 4625
    },
    {
      "loss": 1.3961,
      "grad_norm": 1.099974513053894,
      "learning_rate": 1.3326957561267186e-05,
      "epoch": 0.555937471978958,
      "step": 4650
    },
    {
      "loss": 1.3827,
      "grad_norm": 1.3861122131347656,
      "learning_rate": 1.323729826658697e-05,
      "epoch": 0.5589263831186299,
      "step": 4675
    },
    {
      "loss": 1.3065,
      "grad_norm": 1.3929226398468018,
      "learning_rate": 1.3147638971906756e-05,
      "epoch": 0.5619152942583017,
      "step": 4700
    },
    {
      "loss": 1.2887,
      "grad_norm": 1.288530945777893,
      "learning_rate": 1.305797967722654e-05,
      "epoch": 0.5649042053979735,
      "step": 4725
    },
    {
      "loss": 1.2687,
      "grad_norm": 1.4069604873657227,
      "learning_rate": 1.2968320382546324e-05,
      "epoch": 0.5678931165376453,
      "step": 4750
    },
    {
      "loss": 1.3364,
      "grad_norm": 1.1729899644851685,
      "learning_rate": 1.2878661087866108e-05,
      "epoch": 0.5708820276773171,
      "step": 4775
    },
    {
      "loss": 1.2006,
      "grad_norm": 1.2334448099136353,
      "learning_rate": 1.2789001793185894e-05,
      "epoch": 0.5738709388169889,
      "step": 4800
    },
    {
      "loss": 1.1968,
      "grad_norm": 1.2147653102874756,
      "learning_rate": 1.2699342498505678e-05,
      "epoch": 0.5768598499566608,
      "step": 4825
    },
    {
      "loss": 1.3527,
      "grad_norm": 1.24263596534729,
      "learning_rate": 1.2609683203825464e-05,
      "epoch": 0.5798487610963327,
      "step": 4850
    },
    {
      "loss": 1.2957,
      "grad_norm": 1.1676173210144043,
      "learning_rate": 1.2520023909145248e-05,
      "epoch": 0.5828376722360045,
      "step": 4875
    },
    {
      "loss": 1.3467,
      "grad_norm": 1.309842586517334,
      "learning_rate": 1.2430364614465032e-05,
      "epoch": 0.5858265833756763,
      "step": 4900
    },
    {
      "loss": 1.2536,
      "grad_norm": 1.1256918907165527,
      "learning_rate": 1.2340705319784818e-05,
      "epoch": 0.5888154945153481,
      "step": 4925
    },
    {
      "loss": 1.2994,
      "grad_norm": 1.1414728164672852,
      "learning_rate": 1.2251046025104602e-05,
      "epoch": 0.5918044056550199,
      "step": 4950
    },
    {
      "loss": 1.2864,
      "grad_norm": 1.0529605150222778,
      "learning_rate": 1.2161386730424388e-05,
      "epoch": 0.5947933167946917,
      "step": 4975
    },
    {
      "loss": 1.3297,
      "grad_norm": 1.234291672706604,
      "learning_rate": 1.2071727435744172e-05,
      "epoch": 0.5977822279343635,
      "step": 5000
    },
    {
      "step": 5000,
      "eval_exact_match": 0.642,
      "eval_f1": 0.642,
      "eval_edit_distance": 0.6488303210486408
    },
    {
      "loss": 1.2562,
      "grad_norm": 1.1587883234024048,
      "learning_rate": 1.1982068141063958e-05,
      "epoch": 0.6007711390740353,
      "step": 5025
    },
    {
      "loss": 1.2219,
      "grad_norm": 1.334977149963379,
      "learning_rate": 1.1892408846383742e-05,
      "epoch": 0.6037600502137072,
      "step": 5050
    },
    {
      "loss": 1.2169,
      "grad_norm": 1.2973322868347168,
      "learning_rate": 1.1802749551703526e-05,
      "epoch": 0.606748961353379,
      "step": 5075
    },
    {
      "loss": 1.2866,
      "grad_norm": 1.1229310035705566,
      "learning_rate": 1.171309025702331e-05,
      "epoch": 0.6097378724930508,
      "step": 5100
    },
    {
      "loss": 1.2085,
      "grad_norm": 1.1247398853302002,
      "learning_rate": 1.1623430962343096e-05,
      "epoch": 0.6127267836327226,
      "step": 5125
    },
    {
      "loss": 1.289,
      "grad_norm": 1.2296860218048096,
      "learning_rate": 1.153377166766288e-05,
      "epoch": 0.6157156947723944,
      "step": 5150
    },
    {
      "loss": 1.2837,
      "grad_norm": 1.2186148166656494,
      "learning_rate": 1.1444112372982666e-05,
      "epoch": 0.6187046059120662,
      "step": 5175
    },
    {
      "loss": 1.1882,
      "grad_norm": 1.2596381902694702,
      "learning_rate": 1.135445307830245e-05,
      "epoch": 0.621693517051738,
      "step": 5200
    },
    {
      "loss": 1.1471,
      "grad_norm": 1.095268964767456,
      "learning_rate": 1.1264793783622236e-05,
      "epoch": 0.6246824281914098,
      "step": 5225
    },
    {
      "loss": 1.2827,
      "grad_norm": 1.2426941394805908,
      "learning_rate": 1.117513448894202e-05,
      "epoch": 0.6276713393310817,
      "step": 5250
    },
    {
      "loss": 1.1562,
      "grad_norm": 1.3329945802688599,
      "learning_rate": 1.1085475194261805e-05,
      "epoch": 0.6306602504707535,
      "step": 5275
    },
    {
      "loss": 1.1307,
      "grad_norm": 1.3975651264190674,
      "learning_rate": 1.099581589958159e-05,
      "epoch": 0.6336491616104253,
      "step": 5300
    },
    {
      "loss": 1.1241,
      "grad_norm": 1.1958051919937134,
      "learning_rate": 1.0906156604901375e-05,
      "epoch": 0.6366380727500971,
      "step": 5325
    },
    {
      "loss": 1.2293,
      "grad_norm": 1.1088508367538452,
      "learning_rate": 1.081649731022116e-05,
      "epoch": 0.6396269838897689,
      "step": 5350
    },
    {
      "loss": 1.1415,
      "grad_norm": 1.0378021001815796,
      "learning_rate": 1.0726838015540945e-05,
      "epoch": 0.6426158950294407,
      "step": 5375
    },
    {
      "loss": 1.1719,
      "grad_norm": 0.9923581480979919,
      "learning_rate": 1.063717872086073e-05,
      "epoch": 0.6456048061691126,
      "step": 5400
    },
    {
      "loss": 1.1897,
      "grad_norm": 1.0700891017913818,
      "learning_rate": 1.0547519426180513e-05,
      "epoch": 0.6485937173087845,
      "step": 5425
    },
    {
      "loss": 1.1671,
      "grad_norm": 0.9887668490409851,
      "learning_rate": 1.0457860131500299e-05,
      "epoch": 0.6515826284484563,
      "step": 5450
    },
    {
      "loss": 1.1439,
      "grad_norm": 0.968813419342041,
      "learning_rate": 1.0368200836820083e-05,
      "epoch": 0.6545715395881281,
      "step": 5475
    },
    {
      "loss": 1.107,
      "grad_norm": 1.1379203796386719,
      "learning_rate": 1.0278541542139869e-05,
      "epoch": 0.6575604507277999,
      "step": 5500
    },
    {
      "step": 5500,
      "eval_exact_match": 0.642,
      "eval_f1": 0.642,
      "eval_edit_distance": 0.6488303210486408
    },
    {
      "loss": 1.0664,
      "grad_norm": 0.9218945503234863,
      "learning_rate": 1.0188882247459653e-05,
      "epoch": 0.6605493618674717,
      "step": 5525
    },
    {
      "loss": 1.1093,
      "grad_norm": 1.087511658668518,
      "learning_rate": 1.0099222952779439e-05,
      "epoch": 0.6635382730071435,
      "step": 5550
    },
    {
      "loss": 1.0989,
      "grad_norm": 1.0572668313980103,
      "learning_rate": 1.0009563658099223e-05,
      "epoch": 0.6665271841468153,
      "step": 5575
    },
    {
      "loss": 1.154,
      "grad_norm": 1.159536361694336,
      "learning_rate": 9.919904363419007e-06,
      "epoch": 0.6695160952864871,
      "step": 5600
    },
    {
      "loss": 1.1731,
      "grad_norm": 1.1012808084487915,
      "learning_rate": 9.830245068738793e-06,
      "epoch": 0.672505006426159,
      "step": 5625
    },
    {
      "loss": 1.2257,
      "grad_norm": 1.069765329360962,
      "learning_rate": 9.740585774058577e-06,
      "epoch": 0.6754939175658308,
      "step": 5650
    },
    {
      "loss": 1.2648,
      "grad_norm": 1.1598985195159912,
      "learning_rate": 9.650926479378363e-06,
      "epoch": 0.6784828287055026,
      "step": 5675
    },
    {
      "loss": 1.0911,
      "grad_norm": 1.120226502418518,
      "learning_rate": 9.561267184698147e-06,
      "epoch": 0.6814717398451744,
      "step": 5700
    },
    {
      "loss": 1.096,
      "grad_norm": 1.1262834072113037,
      "learning_rate": 9.471607890017933e-06,
      "epoch": 0.6844606509848462,
      "step": 5725
    },
    {
      "loss": 1.1044,
      "grad_norm": 1.2056910991668701,
      "learning_rate": 9.381948595337717e-06,
      "epoch": 0.687449562124518,
      "step": 5750
    },
    {
      "loss": 1.1198,
      "grad_norm": 1.0471686124801636,
      "learning_rate": 9.292289300657501e-06,
      "epoch": 0.6904384732641898,
      "step": 5775
    },
    {
      "loss": 1.1055,
      "grad_norm": 1.0240474939346313,
      "learning_rate": 9.202630005977286e-06,
      "epoch": 0.6934273844038616,
      "step": 5800
    },
    {
      "loss": 1.0247,
      "grad_norm": 1.0811480283737183,
      "learning_rate": 9.112970711297071e-06,
      "epoch": 0.6964162955435335,
      "step": 5825
    },
    {
      "loss": 1.1048,
      "grad_norm": 0.9781812429428101,
      "learning_rate": 9.023311416616856e-06,
      "epoch": 0.6994052066832053,
      "step": 5850
    },
    {
      "loss": 1.1057,
      "grad_norm": 1.1096941232681274,
      "learning_rate": 8.933652121936641e-06,
      "epoch": 0.7023941178228771,
      "step": 5875
    },
    {
      "loss": 1.1547,
      "grad_norm": 1.048311471939087,
      "learning_rate": 8.843992827256426e-06,
      "epoch": 0.7053830289625489,
      "step": 5900
    },
    {
      "loss": 1.1905,
      "grad_norm": 0.998270571231842,
      "learning_rate": 8.754333532576211e-06,
      "epoch": 0.7083719401022207,
      "step": 5925
    },
    {
      "loss": 1.1716,
      "grad_norm": 1.0446946620941162,
      "learning_rate": 8.664674237895996e-06,
      "epoch": 0.7113608512418926,
      "step": 5950
    },
    {
      "loss": 1.0594,
      "grad_norm": 1.011132001876831,
      "learning_rate": 8.57501494321578e-06,
      "epoch": 0.7143497623815644,
      "step": 5975
    },
    {
      "loss": 1.0459,
      "grad_norm": 1.0436431169509888,
      "learning_rate": 8.485355648535566e-06,
      "epoch": 0.7173386735212363,
      "step": 6000
    },
    {
      "step": 6000,
      "eval_exact_match": 0.64,
      "eval_f1": 0.64,
      "eval_edit_distance": 0.6468503210486408
    },
    {
      "loss": 1.0407,
      "grad_norm": 1.0417046546936035,
      "learning_rate": 8.399282725642558e-06,
      "epoch": 0.7203275846609081,
      "step": 6025
    },
    {
      "loss": 1.1247,
      "grad_norm": 1.1534085273742676,
      "learning_rate": 8.309623430962344e-06,
      "epoch": 0.7233164958005799,
      "step": 6050
    },
    {
      "loss": 1.1677,
      "grad_norm": 0.9660203456878662,
      "learning_rate": 8.219964136282128e-06,
      "epoch": 0.7263054069402517,
      "step": 6075
    },
    {
      "loss": 1.1461,
      "grad_norm": 0.9787598848342896,
      "learning_rate": 8.130304841601913e-06,
      "epoch": 0.7292943180799235,
      "step": 6100
    },
    {
      "loss": 1.069,
      "grad_norm": 1.0337353944778442,
      "learning_rate": 8.040645546921697e-06,
      "epoch": 0.7322832292195953,
      "step": 6125
    },
    {
      "loss": 1.1167,
      "grad_norm": 0.9852858781814575,
      "learning_rate": 7.950986252241483e-06,
      "epoch": 0.7352721403592671,
      "step": 6150
    },
    {
      "loss": 1.1256,
      "grad_norm": 0.9556267261505127,
      "learning_rate": 7.861326957561267e-06,
      "epoch": 0.738261051498939,
      "step": 6175
    },
    {
      "loss": 1.0024,
      "grad_norm": 1.0182263851165771,
      "learning_rate": 7.771667662881053e-06,
      "epoch": 0.7412499626386108,
      "step": 6200
    },
    {
      "loss": 1.0391,
      "grad_norm": 1.1091406345367432,
      "learning_rate": 7.682008368200837e-06,
      "epoch": 0.7442388737782826,
      "step": 6225
    },
    {
      "loss": 1.157,
      "grad_norm": 1.0782504081726074,
      "learning_rate": 7.592349073520623e-06,
      "epoch": 0.7472277849179544,
      "step": 6250
    },
    {
      "loss": 1.0771,
      "grad_norm": 1.0760037899017334,
      "learning_rate": 7.502689778840406e-06,
      "epoch": 0.7502166960576262,
      "step": 6275
    },
    {
      "loss": 1.0044,
      "grad_norm": 1.1466796398162842,
      "learning_rate": 7.413030484160192e-06,
      "epoch": 0.753205607197298,
      "step": 6300
    },
    {
      "loss": 1.0375,
      "grad_norm": 0.9082123041152954,
      "learning_rate": 7.323371189479976e-06,
      "epoch": 0.7561945183369698,
      "step": 6325
    },
    {
      "loss": 1.0587,
      "grad_norm": 1.0100537538528442,
      "learning_rate": 7.233711894799761e-06,
      "epoch": 0.7591834294766416,
      "step": 6350
    },
    {
      "loss": 1.0486,
      "grad_norm": 0.9714524745941162,
      "learning_rate": 7.144052600119546e-06,
      "epoch": 0.7621723406163134,
      "step": 6375
    },
    {
      "loss": 1.0596,
      "grad_norm": 0.9493364095687866,
      "learning_rate": 7.05439330543933e-06,
      "epoch": 0.7651612517559853,
      "step": 6400
    },
    {
      "loss": 1.1138,
      "grad_norm": 0.9514263868331909,
      "learning_rate": 6.964734010759115e-06,
      "epoch": 0.7681501628956571,
      "step": 6425
    },
    {
      "loss": 1.0329,
      "grad_norm": 1.0007871389389038,
      "learning_rate": 6.8750747160789e-06,
      "epoch": 0.7711390740353289,
      "step": 6450
    },
    {
      "loss": 1.0532,
      "grad_norm": 1.1023263931274414,
      "learning_rate": 6.785415421398685e-06,
      "epoch": 0.7741279851750007,
      "step": 6475
    },
    {
      "loss": 1.0008,
      "grad_norm": 0.9366944432258606,
      "learning_rate": 6.69575612671847e-06,
      "epoch": 0.7771168963146725,
      "step": 6500
    },
    {
      "step": 6500,
      "eval_exact_match": 0.642,
      "eval_f1": 0.642,
      "eval_edit_distance": 0.6488303210486408
    },
    {
      "loss": 1.0269,
      "grad_norm": 0.9628545641899109,
      "learning_rate": 6.606096832038255e-06,
      "epoch": 0.7801058074543444,
      "step": 6525
    },
    {
      "loss": 1.0936,
      "grad_norm": 1.0128846168518066,
      "learning_rate": 6.51643753735804e-06,
      "epoch": 0.7830947185940162,
      "step": 6550
    },
    {
      "loss": 1.0783,
      "grad_norm": 1.0734103918075562,
      "learning_rate": 6.426778242677824e-06,
      "epoch": 0.7860836297336881,
      "step": 6575
    },
    {
      "loss": 1.0435,
      "grad_norm": 1.0738275051116943,
      "learning_rate": 6.337118947997609e-06,
      "epoch": 0.7890725408733599,
      "step": 6600
    },
    {
      "loss": 1.0236,
      "grad_norm": 0.9901419878005981,
      "learning_rate": 6.247459653317394e-06,
      "epoch": 0.7920614520130317,
      "step": 6625
    },
    {
      "loss": 1.0772,
      "grad_norm": 1.0516388416290283,
      "learning_rate": 6.157800358637179e-06,
      "epoch": 0.7950503631527035,
      "step": 6650
    },
    {
      "loss": 1.0149,
      "grad_norm": 1.0971369743347168,
      "learning_rate": 6.068141063956963e-06,
      "epoch": 0.7980392742923753,
      "step": 6675
    },
    {
      "loss": 1.0055,
      "grad_norm": 0.9980206489562988,
      "learning_rate": 5.978481769276748e-06,
      "epoch": 0.8010281854320471,
      "step": 6700
    },
    {
      "loss": 0.993,
      "grad_norm": 0.9601767659187317,
      "learning_rate": 5.888822474596533e-06,
      "epoch": 0.8040170965717189,
      "step": 6725
    },
    {
      "loss": 1.062,
      "grad_norm": 1.0515096187591553,
      "learning_rate": 5.7991631799163175e-06,
      "epoch": 0.8070060077113907,
      "step": 6750
    },
    {
      "loss": 1.0492,
      "grad_norm": 0.9984530210494995,
      "learning_rate": 5.7095038852361025e-06,
      "epoch": 0.8099949188510626,
      "step": 6775
    },
    {
      "loss": 0.9594,
      "grad_norm": 1.1010218858718872,
      "learning_rate": 5.6198445905558875e-06,
      "epoch": 0.8129838299907344,
      "step": 6800
    },
    {
      "loss": 0.9004,
      "grad_norm": 1.0409750938415527,
      "learning_rate": 5.5301852958756725e-06,
      "epoch": 0.8159727411304062,
      "step": 6825
    },
    {
      "loss": 1.0594,
      "grad_norm": 0.9659738540649414,
      "learning_rate": 5.4405260011954575e-06,
      "epoch": 0.818961652270078,
      "step": 6850
    },
    {
      "loss": 0.9576,
      "grad_norm": 0.9535633325576782,
      "learning_rate": 5.3508667065152425e-06,
      "epoch": 0.8219505634097498,
      "step": 6875
    },
    {
      "loss": 1.0442,
      "grad_norm": 0.9703330993652344,
      "learning_rate": 5.2612074118350275e-06,
      "epoch": 0.8249394745494216,
      "step": 6900
    },
    {
      "loss": 1.0245,
      "grad_norm": 0.9529238343238831,
      "learning_rate": 5.171548117154812e-06,
      "epoch": 0.8279283856890934,
      "step": 6925
    },
    {
      "loss": 1.0338,
      "grad_norm": 1.083257794380188,
      "learning_rate": 5.081888822474597e-06,
      "epoch": 0.8309172968287653,
      "step": 6950
    },
    {
      "loss": 1.0598,
      "grad_norm": 0.8858226537704468,
      "learning_rate": 4.992229527794382e-06,
      "epoch": 0.8339062079684371,
      "step": 6975
    },
    {
      "loss": 1.0548,
      "grad_norm": 1.042842984199524,
      "learning_rate": 4.902570233114167e-06,
      "epoch": 0.8368951191081089,
      "step": 7000
    },
    {
      "step": 7000,
      "eval_exact_match": 0.642,
      "eval_f1": 0.642,
      "eval_edit_distance": 0.6488303210486408
    }
  ],
  "logging_steps": 25,
  "max_steps": 8365,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.7676156870656e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}