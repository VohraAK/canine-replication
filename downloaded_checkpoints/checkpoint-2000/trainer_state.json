{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.2391128911737454,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0029889111396718174,
      "grad_norm": 4.664714336395264,
      "learning_rate": 2.9913927077106994e-05,
      "loss": 5.9394,
      "step": 25
    },
    {
      "epoch": 0.005977822279343635,
      "grad_norm": 4.6591949462890625,
      "learning_rate": 2.982426778242678e-05,
      "loss": 5.8818,
      "step": 50
    },
    {
      "epoch": 0.008966733419015452,
      "grad_norm": 4.387139797210693,
      "learning_rate": 2.9734608487746562e-05,
      "loss": 5.8175,
      "step": 75
    },
    {
      "epoch": 0.01195564455868727,
      "grad_norm": 4.054754734039307,
      "learning_rate": 2.964494919306635e-05,
      "loss": 5.7637,
      "step": 100
    },
    {
      "epoch": 0.014944555698359088,
      "grad_norm": 3.8591437339782715,
      "learning_rate": 2.9555289898386134e-05,
      "loss": 5.701,
      "step": 125
    },
    {
      "epoch": 0.017933466838030904,
      "grad_norm": 4.375348091125488,
      "learning_rate": 2.946563060370592e-05,
      "loss": 5.6423,
      "step": 150
    },
    {
      "epoch": 0.020922377977702723,
      "grad_norm": 4.744508266448975,
      "learning_rate": 2.9375971309025702e-05,
      "loss": 5.591,
      "step": 175
    },
    {
      "epoch": 0.02391128911737454,
      "grad_norm": 4.605898857116699,
      "learning_rate": 2.9286312014345486e-05,
      "loss": 5.529,
      "step": 200
    },
    {
      "epoch": 0.02690020025704636,
      "grad_norm": 4.188354969024658,
      "learning_rate": 2.9196652719665274e-05,
      "loss": 5.4671,
      "step": 225
    },
    {
      "epoch": 0.029889111396718175,
      "grad_norm": 4.483104228973389,
      "learning_rate": 2.9106993424985058e-05,
      "loss": 5.4146,
      "step": 250
    },
    {
      "epoch": 0.032878022536389995,
      "grad_norm": 3.746946334838867,
      "learning_rate": 2.9017334130304842e-05,
      "loss": 5.3471,
      "step": 275
    },
    {
      "epoch": 0.03586693367606181,
      "grad_norm": 4.39648962020874,
      "learning_rate": 2.8927674835624626e-05,
      "loss": 5.2967,
      "step": 300
    },
    {
      "epoch": 0.03885584481573363,
      "grad_norm": 4.34638786315918,
      "learning_rate": 2.8838015540944414e-05,
      "loss": 5.2435,
      "step": 325
    },
    {
      "epoch": 0.04184475595540545,
      "grad_norm": 4.189818859100342,
      "learning_rate": 2.8748356246264198e-05,
      "loss": 5.1977,
      "step": 350
    },
    {
      "epoch": 0.044833667095077266,
      "grad_norm": 4.193456172943115,
      "learning_rate": 2.865869695158398e-05,
      "loss": 5.1273,
      "step": 375
    },
    {
      "epoch": 0.04782257823474908,
      "grad_norm": 4.287274360656738,
      "learning_rate": 2.8569037656903766e-05,
      "loss": 5.0829,
      "step": 400
    },
    {
      "epoch": 0.0508114893744209,
      "grad_norm": 4.363275051116943,
      "learning_rate": 2.847937836222355e-05,
      "loss": 5.0267,
      "step": 425
    },
    {
      "epoch": 0.05380040051409272,
      "grad_norm": 4.160948276519775,
      "learning_rate": 2.8389719067543338e-05,
      "loss": 4.9804,
      "step": 450
    },
    {
      "epoch": 0.05678931165376453,
      "grad_norm": 4.112051963806152,
      "learning_rate": 2.8300059772863122e-05,
      "loss": 4.9438,
      "step": 475
    },
    {
      "epoch": 0.05977822279343635,
      "grad_norm": 3.8612821102142334,
      "learning_rate": 2.8210400478182906e-05,
      "loss": 4.8765,
      "step": 500
    },
    {
      "eval_edit_distance": 0.499224006996317,
      "eval_exact_match": 0.484,
      "eval_f1": 0.48614873390136554,
      "step": 500
    },
    {
      "epoch": 0.06276713393310816,
      "grad_norm": 4.288654804229736,
      "learning_rate": 2.812074118350269e-05,
      "loss": 4.8183,
      "step": 525
    },
    {
      "epoch": 0.06575604507277999,
      "grad_norm": 4.068612098693848,
      "learning_rate": 2.8031081888822474e-05,
      "loss": 4.787,
      "step": 550
    },
    {
      "epoch": 0.0687449562124518,
      "grad_norm": 4.133265018463135,
      "learning_rate": 2.7941422594142262e-05,
      "loss": 4.7346,
      "step": 575
    },
    {
      "epoch": 0.07173386735212361,
      "grad_norm": 3.6100070476531982,
      "learning_rate": 2.7851763299462043e-05,
      "loss": 4.6729,
      "step": 600
    },
    {
      "epoch": 0.07472277849179544,
      "grad_norm": 3.9019646644592285,
      "learning_rate": 2.776210400478183e-05,
      "loss": 4.6161,
      "step": 625
    },
    {
      "epoch": 0.07771168963146725,
      "grad_norm": 4.092576026916504,
      "learning_rate": 2.7672444710101614e-05,
      "loss": 4.5974,
      "step": 650
    },
    {
      "epoch": 0.08070060077113908,
      "grad_norm": 4.288166046142578,
      "learning_rate": 2.7582785415421402e-05,
      "loss": 4.5265,
      "step": 675
    },
    {
      "epoch": 0.0836895119108109,
      "grad_norm": 4.1215596199035645,
      "learning_rate": 2.7493126120741183e-05,
      "loss": 4.4717,
      "step": 700
    },
    {
      "epoch": 0.0866784230504827,
      "grad_norm": 3.5653364658355713,
      "learning_rate": 2.7403466826060967e-05,
      "loss": 4.4256,
      "step": 725
    },
    {
      "epoch": 0.08966733419015453,
      "grad_norm": 3.5655412673950195,
      "learning_rate": 2.7313807531380754e-05,
      "loss": 4.3724,
      "step": 750
    },
    {
      "epoch": 0.09265624532982634,
      "grad_norm": 3.333911180496216,
      "learning_rate": 2.722414823670054e-05,
      "loss": 4.3468,
      "step": 775
    },
    {
      "epoch": 0.09564515646949816,
      "grad_norm": 3.8427631855010986,
      "learning_rate": 2.7134488942020326e-05,
      "loss": 4.2868,
      "step": 800
    },
    {
      "epoch": 0.09863406760916998,
      "grad_norm": 3.825943946838379,
      "learning_rate": 2.7044829647340107e-05,
      "loss": 4.2752,
      "step": 825
    },
    {
      "epoch": 0.1016229787488418,
      "grad_norm": 3.7298505306243896,
      "learning_rate": 2.6955170352659894e-05,
      "loss": 4.2426,
      "step": 850
    },
    {
      "epoch": 0.10461188988851361,
      "grad_norm": 3.5167605876922607,
      "learning_rate": 2.686551105797968e-05,
      "loss": 4.1722,
      "step": 875
    },
    {
      "epoch": 0.10760080102818544,
      "grad_norm": 3.3498499393463135,
      "learning_rate": 2.6775851763299463e-05,
      "loss": 4.1397,
      "step": 900
    },
    {
      "epoch": 0.11058971216785725,
      "grad_norm": 3.2989306449890137,
      "learning_rate": 2.6686192468619247e-05,
      "loss": 4.1014,
      "step": 925
    },
    {
      "epoch": 0.11357862330752906,
      "grad_norm": 3.3087029457092285,
      "learning_rate": 2.659653317393903e-05,
      "loss": 4.0581,
      "step": 950
    },
    {
      "epoch": 0.11656753444720089,
      "grad_norm": 3.6228277683258057,
      "learning_rate": 2.650687387925882e-05,
      "loss": 4.031,
      "step": 975
    },
    {
      "epoch": 0.1195564455868727,
      "grad_norm": 3.3014211654663086,
      "learning_rate": 2.6417214584578603e-05,
      "loss": 3.983,
      "step": 1000
    },
    {
      "eval_edit_distance": 0.6045104081667527,
      "eval_exact_match": 0.596,
      "eval_f1": 0.596,
      "step": 1000
    },
    {
      "epoch": 0.12254535672654451,
      "grad_norm": 3.6207056045532227,
      "learning_rate": 2.6327555289898387e-05,
      "loss": 3.9208,
      "step": 1025
    },
    {
      "epoch": 0.12553426786621633,
      "grad_norm": 3.8178722858428955,
      "learning_rate": 2.623789599521817e-05,
      "loss": 3.8883,
      "step": 1050
    },
    {
      "epoch": 0.12852317900588817,
      "grad_norm": 3.3429291248321533,
      "learning_rate": 2.6148236700537955e-05,
      "loss": 3.843,
      "step": 1075
    },
    {
      "epoch": 0.13151209014555998,
      "grad_norm": 3.0258212089538574,
      "learning_rate": 2.6058577405857743e-05,
      "loss": 3.805,
      "step": 1100
    },
    {
      "epoch": 0.1345010012852318,
      "grad_norm": 3.382310152053833,
      "learning_rate": 2.5968918111177527e-05,
      "loss": 3.7292,
      "step": 1125
    },
    {
      "epoch": 0.1374899124249036,
      "grad_norm": 3.266087770462036,
      "learning_rate": 2.587925881649731e-05,
      "loss": 3.7382,
      "step": 1150
    },
    {
      "epoch": 0.14047882356457542,
      "grad_norm": 3.6112985610961914,
      "learning_rate": 2.5789599521817095e-05,
      "loss": 3.7149,
      "step": 1175
    },
    {
      "epoch": 0.14346773470424723,
      "grad_norm": 3.2838971614837646,
      "learning_rate": 2.569994022713688e-05,
      "loss": 3.6771,
      "step": 1200
    },
    {
      "epoch": 0.14645664584391907,
      "grad_norm": 3.2663779258728027,
      "learning_rate": 2.5610280932456667e-05,
      "loss": 3.6044,
      "step": 1225
    },
    {
      "epoch": 0.14944555698359088,
      "grad_norm": 3.3739120960235596,
      "learning_rate": 2.5520621637776448e-05,
      "loss": 3.6066,
      "step": 1250
    },
    {
      "epoch": 0.1524344681232627,
      "grad_norm": 2.810539960861206,
      "learning_rate": 2.5430962343096235e-05,
      "loss": 3.569,
      "step": 1275
    },
    {
      "epoch": 0.1554233792629345,
      "grad_norm": 3.3575758934020996,
      "learning_rate": 2.534130304841602e-05,
      "loss": 3.4776,
      "step": 1300
    },
    {
      "epoch": 0.15841229040260632,
      "grad_norm": 3.3848214149475098,
      "learning_rate": 2.5251643753735807e-05,
      "loss": 3.4424,
      "step": 1325
    },
    {
      "epoch": 0.16140120154227816,
      "grad_norm": 3.130110025405884,
      "learning_rate": 2.5161984459055588e-05,
      "loss": 3.4446,
      "step": 1350
    },
    {
      "epoch": 0.16439011268194997,
      "grad_norm": 2.962725877761841,
      "learning_rate": 2.5072325164375372e-05,
      "loss": 3.3997,
      "step": 1375
    },
    {
      "epoch": 0.1673790238216218,
      "grad_norm": 3.1195788383483887,
      "learning_rate": 2.498266586969516e-05,
      "loss": 3.3859,
      "step": 1400
    },
    {
      "epoch": 0.1703679349612936,
      "grad_norm": 3.206864833831787,
      "learning_rate": 2.4893006575014944e-05,
      "loss": 3.3585,
      "step": 1425
    },
    {
      "epoch": 0.1733568461009654,
      "grad_norm": 2.903219223022461,
      "learning_rate": 2.480334728033473e-05,
      "loss": 3.318,
      "step": 1450
    },
    {
      "epoch": 0.17634575724063722,
      "grad_norm": 3.051422119140625,
      "learning_rate": 2.4713687985654512e-05,
      "loss": 3.3001,
      "step": 1475
    },
    {
      "epoch": 0.17933466838030906,
      "grad_norm": 3.008002758026123,
      "learning_rate": 2.46240286909743e-05,
      "loss": 3.2215,
      "step": 1500
    },
    {
      "loss": 3.2249,
      "grad_norm": 3.4110896587371826,
      "learning_rate": 2.4534369396294084e-05,
      "epoch": 0.18232357951998088,
      "step": 1525
    },
    {
      "loss": 3.214,
      "grad_norm": 3.1047885417938232,
      "learning_rate": 2.4444710101613868e-05,
      "epoch": 0.1853124906596527,
      "step": 1550
    },
    {
      "loss": 3.1911,
      "grad_norm": 3.0716137886047363,
      "learning_rate": 2.4355050806933652e-05,
      "epoch": 0.1883014017993245,
      "step": 1575
    },
    {
      "loss": 3.1229,
      "grad_norm": 2.8100433349609375,
      "learning_rate": 2.4265391512253436e-05,
      "epoch": 0.19129031293899632,
      "step": 1600
    },
    {
      "loss": 3.1385,
      "grad_norm": 2.610854387283325,
      "learning_rate": 2.4175732217573224e-05,
      "epoch": 0.19427922407866813,
      "step": 1625
    },
    {
      "loss": 3.0588,
      "grad_norm": 2.725205659866333,
      "learning_rate": 2.4086072922893008e-05,
      "epoch": 0.19726813521833997,
      "step": 1650
    },
    {
      "loss": 3.0343,
      "grad_norm": 2.7544503211975098,
      "learning_rate": 2.3996413628212792e-05,
      "epoch": 0.20025704635801178,
      "step": 1675
    },
    {
      "loss": 3.0334,
      "grad_norm": 2.6811840534210205,
      "learning_rate": 2.3906754333532576e-05,
      "epoch": 0.2032459574976836,
      "step": 1700
    },
    {
      "loss": 2.9919,
      "grad_norm": 2.8540024757385254,
      "learning_rate": 2.381709503885236e-05,
      "epoch": 0.2062348686373554,
      "step": 1725
    },
    {
      "loss": 2.9248,
      "grad_norm": 2.52355694770813,
      "learning_rate": 2.3727435744172148e-05,
      "epoch": 0.20922377977702722,
      "step": 1750
    },
    {
      "loss": 2.9092,
      "grad_norm": 2.7366244792938232,
      "learning_rate": 2.3637776449491932e-05,
      "epoch": 0.21221269091669906,
      "step": 1775
    },
    {
      "loss": 2.9741,
      "grad_norm": 2.7806646823883057,
      "learning_rate": 2.3548117154811716e-05,
      "epoch": 0.21520160205637087,
      "step": 1800
    },
    {
      "loss": 2.8433,
      "grad_norm": 2.7838656902313232,
      "learning_rate": 2.34584578601315e-05,
      "epoch": 0.21819051319604268,
      "step": 1825
    },
    {
      "loss": 2.8581,
      "grad_norm": 2.6938252449035645,
      "learning_rate": 2.3368798565451288e-05,
      "epoch": 0.2211794243357145,
      "step": 1850
    },
    {
      "loss": 2.8281,
      "grad_norm": 2.3198301792144775,
      "learning_rate": 2.3279139270771072e-05,
      "epoch": 0.2241683354753863,
      "step": 1875
    },
    {
      "loss": 2.8302,
      "grad_norm": 2.6109020709991455,
      "learning_rate": 2.3189479976090853e-05,
      "epoch": 0.22715724661505812,
      "step": 1900
    },
    {
      "loss": 2.7473,
      "grad_norm": 2.5459108352661133,
      "learning_rate": 2.309982068141064e-05,
      "epoch": 0.23014615775472996,
      "step": 1925
    },
    {
      "loss": 2.7523,
      "grad_norm": 2.3948891162872314,
      "learning_rate": 2.3010161386730424e-05,
      "epoch": 0.23313506889440178,
      "step": 1950
    },
    {
      "loss": 2.7208,
      "grad_norm": 2.789400339126587,
      "learning_rate": 2.2920502092050212e-05,
      "epoch": 0.2361239800340736,
      "step": 1975
    },
    {
      "loss": 2.6962,
      "grad_norm": 2.3287622928619385,
      "learning_rate": 2.2830842797369993e-05,
      "epoch": 0.2391128911737454,
      "step": 2000
    },
    {
      "step": 2000,
      "eval_exact_match": 0.632,
      "eval_f1": 0.632,
      "eval_edit_distance": 0.639022554633543
    }
  ],
  "logging_steps": 25,
  "max_steps": 8365,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7907473391616000.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}