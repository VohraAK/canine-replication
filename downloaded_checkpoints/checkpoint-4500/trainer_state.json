{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5380040051409272,
  "eval_steps": 500,
  "global_step": 4500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0029889111396718174,
      "grad_norm": 4.664714336395264,
      "learning_rate": 2.9913927077106994e-05,
      "loss": 5.9394,
      "step": 25
    },
    {
      "epoch": 0.005977822279343635,
      "grad_norm": 4.6591949462890625,
      "learning_rate": 2.982426778242678e-05,
      "loss": 5.8818,
      "step": 50
    },
    {
      "epoch": 0.008966733419015452,
      "grad_norm": 4.387139797210693,
      "learning_rate": 2.9734608487746562e-05,
      "loss": 5.8175,
      "step": 75
    },
    {
      "epoch": 0.01195564455868727,
      "grad_norm": 4.054754734039307,
      "learning_rate": 2.964494919306635e-05,
      "loss": 5.7637,
      "step": 100
    },
    {
      "epoch": 0.014944555698359088,
      "grad_norm": 3.8591437339782715,
      "learning_rate": 2.9555289898386134e-05,
      "loss": 5.701,
      "step": 125
    },
    {
      "epoch": 0.017933466838030904,
      "grad_norm": 4.375348091125488,
      "learning_rate": 2.946563060370592e-05,
      "loss": 5.6423,
      "step": 150
    },
    {
      "epoch": 0.020922377977702723,
      "grad_norm": 4.744508266448975,
      "learning_rate": 2.9375971309025702e-05,
      "loss": 5.591,
      "step": 175
    },
    {
      "epoch": 0.02391128911737454,
      "grad_norm": 4.605898857116699,
      "learning_rate": 2.9286312014345486e-05,
      "loss": 5.529,
      "step": 200
    },
    {
      "epoch": 0.02690020025704636,
      "grad_norm": 4.188354969024658,
      "learning_rate": 2.9196652719665274e-05,
      "loss": 5.4671,
      "step": 225
    },
    {
      "epoch": 0.029889111396718175,
      "grad_norm": 4.483104228973389,
      "learning_rate": 2.9106993424985058e-05,
      "loss": 5.4146,
      "step": 250
    },
    {
      "epoch": 0.032878022536389995,
      "grad_norm": 3.746946334838867,
      "learning_rate": 2.9017334130304842e-05,
      "loss": 5.3471,
      "step": 275
    },
    {
      "epoch": 0.03586693367606181,
      "grad_norm": 4.39648962020874,
      "learning_rate": 2.8927674835624626e-05,
      "loss": 5.2967,
      "step": 300
    },
    {
      "epoch": 0.03885584481573363,
      "grad_norm": 4.34638786315918,
      "learning_rate": 2.8838015540944414e-05,
      "loss": 5.2435,
      "step": 325
    },
    {
      "epoch": 0.04184475595540545,
      "grad_norm": 4.189818859100342,
      "learning_rate": 2.8748356246264198e-05,
      "loss": 5.1977,
      "step": 350
    },
    {
      "epoch": 0.044833667095077266,
      "grad_norm": 4.193456172943115,
      "learning_rate": 2.865869695158398e-05,
      "loss": 5.1273,
      "step": 375
    },
    {
      "epoch": 0.04782257823474908,
      "grad_norm": 4.287274360656738,
      "learning_rate": 2.8569037656903766e-05,
      "loss": 5.0829,
      "step": 400
    },
    {
      "epoch": 0.0508114893744209,
      "grad_norm": 4.363275051116943,
      "learning_rate": 2.847937836222355e-05,
      "loss": 5.0267,
      "step": 425
    },
    {
      "epoch": 0.05380040051409272,
      "grad_norm": 4.160948276519775,
      "learning_rate": 2.8389719067543338e-05,
      "loss": 4.9804,
      "step": 450
    },
    {
      "epoch": 0.05678931165376453,
      "grad_norm": 4.112051963806152,
      "learning_rate": 2.8300059772863122e-05,
      "loss": 4.9438,
      "step": 475
    },
    {
      "epoch": 0.05977822279343635,
      "grad_norm": 3.8612821102142334,
      "learning_rate": 2.8210400478182906e-05,
      "loss": 4.8765,
      "step": 500
    },
    {
      "eval_edit_distance": 0.499224006996317,
      "eval_exact_match": 0.484,
      "eval_f1": 0.48614873390136554,
      "step": 500
    },
    {
      "epoch": 0.06276713393310816,
      "grad_norm": 4.288654804229736,
      "learning_rate": 2.812074118350269e-05,
      "loss": 4.8183,
      "step": 525
    },
    {
      "epoch": 0.06575604507277999,
      "grad_norm": 4.068612098693848,
      "learning_rate": 2.8031081888822474e-05,
      "loss": 4.787,
      "step": 550
    },
    {
      "epoch": 0.0687449562124518,
      "grad_norm": 4.133265018463135,
      "learning_rate": 2.7941422594142262e-05,
      "loss": 4.7346,
      "step": 575
    },
    {
      "epoch": 0.07173386735212361,
      "grad_norm": 3.6100070476531982,
      "learning_rate": 2.7851763299462043e-05,
      "loss": 4.6729,
      "step": 600
    },
    {
      "epoch": 0.07472277849179544,
      "grad_norm": 3.9019646644592285,
      "learning_rate": 2.776210400478183e-05,
      "loss": 4.6161,
      "step": 625
    },
    {
      "epoch": 0.07771168963146725,
      "grad_norm": 4.092576026916504,
      "learning_rate": 2.7672444710101614e-05,
      "loss": 4.5974,
      "step": 650
    },
    {
      "epoch": 0.08070060077113908,
      "grad_norm": 4.288166046142578,
      "learning_rate": 2.7582785415421402e-05,
      "loss": 4.5265,
      "step": 675
    },
    {
      "epoch": 0.0836895119108109,
      "grad_norm": 4.1215596199035645,
      "learning_rate": 2.7493126120741183e-05,
      "loss": 4.4717,
      "step": 700
    },
    {
      "epoch": 0.0866784230504827,
      "grad_norm": 3.5653364658355713,
      "learning_rate": 2.7403466826060967e-05,
      "loss": 4.4256,
      "step": 725
    },
    {
      "epoch": 0.08966733419015453,
      "grad_norm": 3.5655412673950195,
      "learning_rate": 2.7313807531380754e-05,
      "loss": 4.3724,
      "step": 750
    },
    {
      "epoch": 0.09265624532982634,
      "grad_norm": 3.333911180496216,
      "learning_rate": 2.722414823670054e-05,
      "loss": 4.3468,
      "step": 775
    },
    {
      "epoch": 0.09564515646949816,
      "grad_norm": 3.8427631855010986,
      "learning_rate": 2.7134488942020326e-05,
      "loss": 4.2868,
      "step": 800
    },
    {
      "epoch": 0.09863406760916998,
      "grad_norm": 3.825943946838379,
      "learning_rate": 2.7044829647340107e-05,
      "loss": 4.2752,
      "step": 825
    },
    {
      "epoch": 0.1016229787488418,
      "grad_norm": 3.7298505306243896,
      "learning_rate": 2.6955170352659894e-05,
      "loss": 4.2426,
      "step": 850
    },
    {
      "epoch": 0.10461188988851361,
      "grad_norm": 3.5167605876922607,
      "learning_rate": 2.686551105797968e-05,
      "loss": 4.1722,
      "step": 875
    },
    {
      "epoch": 0.10760080102818544,
      "grad_norm": 3.3498499393463135,
      "learning_rate": 2.6775851763299463e-05,
      "loss": 4.1397,
      "step": 900
    },
    {
      "epoch": 0.11058971216785725,
      "grad_norm": 3.2989306449890137,
      "learning_rate": 2.6686192468619247e-05,
      "loss": 4.1014,
      "step": 925
    },
    {
      "epoch": 0.11357862330752906,
      "grad_norm": 3.3087029457092285,
      "learning_rate": 2.659653317393903e-05,
      "loss": 4.0581,
      "step": 950
    },
    {
      "epoch": 0.11656753444720089,
      "grad_norm": 3.6228277683258057,
      "learning_rate": 2.650687387925882e-05,
      "loss": 4.031,
      "step": 975
    },
    {
      "epoch": 0.1195564455868727,
      "grad_norm": 3.3014211654663086,
      "learning_rate": 2.6417214584578603e-05,
      "loss": 3.983,
      "step": 1000
    },
    {
      "eval_edit_distance": 0.6045104081667527,
      "eval_exact_match": 0.596,
      "eval_f1": 0.596,
      "step": 1000
    },
    {
      "epoch": 0.12254535672654451,
      "grad_norm": 3.6207056045532227,
      "learning_rate": 2.6327555289898387e-05,
      "loss": 3.9208,
      "step": 1025
    },
    {
      "epoch": 0.12553426786621633,
      "grad_norm": 3.8178722858428955,
      "learning_rate": 2.623789599521817e-05,
      "loss": 3.8883,
      "step": 1050
    },
    {
      "epoch": 0.12852317900588817,
      "grad_norm": 3.3429291248321533,
      "learning_rate": 2.6148236700537955e-05,
      "loss": 3.843,
      "step": 1075
    },
    {
      "epoch": 0.13151209014555998,
      "grad_norm": 3.0258212089538574,
      "learning_rate": 2.6058577405857743e-05,
      "loss": 3.805,
      "step": 1100
    },
    {
      "epoch": 0.1345010012852318,
      "grad_norm": 3.382310152053833,
      "learning_rate": 2.5968918111177527e-05,
      "loss": 3.7292,
      "step": 1125
    },
    {
      "epoch": 0.1374899124249036,
      "grad_norm": 3.266087770462036,
      "learning_rate": 2.587925881649731e-05,
      "loss": 3.7382,
      "step": 1150
    },
    {
      "epoch": 0.14047882356457542,
      "grad_norm": 3.6112985610961914,
      "learning_rate": 2.5789599521817095e-05,
      "loss": 3.7149,
      "step": 1175
    },
    {
      "epoch": 0.14346773470424723,
      "grad_norm": 3.2838971614837646,
      "learning_rate": 2.569994022713688e-05,
      "loss": 3.6771,
      "step": 1200
    },
    {
      "epoch": 0.14645664584391907,
      "grad_norm": 3.2663779258728027,
      "learning_rate": 2.5610280932456667e-05,
      "loss": 3.6044,
      "step": 1225
    },
    {
      "epoch": 0.14944555698359088,
      "grad_norm": 3.3739120960235596,
      "learning_rate": 2.5520621637776448e-05,
      "loss": 3.6066,
      "step": 1250
    },
    {
      "epoch": 0.1524344681232627,
      "grad_norm": 2.810539960861206,
      "learning_rate": 2.5430962343096235e-05,
      "loss": 3.569,
      "step": 1275
    },
    {
      "epoch": 0.1554233792629345,
      "grad_norm": 3.3575758934020996,
      "learning_rate": 2.534130304841602e-05,
      "loss": 3.4776,
      "step": 1300
    },
    {
      "epoch": 0.15841229040260632,
      "grad_norm": 3.3848214149475098,
      "learning_rate": 2.5251643753735807e-05,
      "loss": 3.4424,
      "step": 1325
    },
    {
      "epoch": 0.16140120154227816,
      "grad_norm": 3.130110025405884,
      "learning_rate": 2.5161984459055588e-05,
      "loss": 3.4446,
      "step": 1350
    },
    {
      "epoch": 0.16439011268194997,
      "grad_norm": 2.962725877761841,
      "learning_rate": 2.5072325164375372e-05,
      "loss": 3.3997,
      "step": 1375
    },
    {
      "epoch": 0.1673790238216218,
      "grad_norm": 3.1195788383483887,
      "learning_rate": 2.498266586969516e-05,
      "loss": 3.3859,
      "step": 1400
    },
    {
      "epoch": 0.1703679349612936,
      "grad_norm": 3.206864833831787,
      "learning_rate": 2.4893006575014944e-05,
      "loss": 3.3585,
      "step": 1425
    },
    {
      "epoch": 0.1733568461009654,
      "grad_norm": 2.903219223022461,
      "learning_rate": 2.480334728033473e-05,
      "loss": 3.318,
      "step": 1450
    },
    {
      "epoch": 0.17634575724063722,
      "grad_norm": 3.051422119140625,
      "learning_rate": 2.4713687985654512e-05,
      "loss": 3.3001,
      "step": 1475
    },
    {
      "epoch": 0.17933466838030906,
      "grad_norm": 3.008002758026123,
      "learning_rate": 2.46240286909743e-05,
      "loss": 3.2215,
      "step": 1500
    },
    {
      "loss": 3.2249,
      "grad_norm": 3.4110896587371826,
      "learning_rate": 2.4534369396294084e-05,
      "epoch": 0.18232357951998088,
      "step": 1525
    },
    {
      "loss": 3.214,
      "grad_norm": 3.1047885417938232,
      "learning_rate": 2.4444710101613868e-05,
      "epoch": 0.1853124906596527,
      "step": 1550
    },
    {
      "loss": 3.1911,
      "grad_norm": 3.0716137886047363,
      "learning_rate": 2.4355050806933652e-05,
      "epoch": 0.1883014017993245,
      "step": 1575
    },
    {
      "loss": 3.1229,
      "grad_norm": 2.8100433349609375,
      "learning_rate": 2.4265391512253436e-05,
      "epoch": 0.19129031293899632,
      "step": 1600
    },
    {
      "loss": 3.1385,
      "grad_norm": 2.610854387283325,
      "learning_rate": 2.4175732217573224e-05,
      "epoch": 0.19427922407866813,
      "step": 1625
    },
    {
      "loss": 3.0588,
      "grad_norm": 2.725205659866333,
      "learning_rate": 2.4086072922893008e-05,
      "epoch": 0.19726813521833997,
      "step": 1650
    },
    {
      "loss": 3.0343,
      "grad_norm": 2.7544503211975098,
      "learning_rate": 2.3996413628212792e-05,
      "epoch": 0.20025704635801178,
      "step": 1675
    },
    {
      "loss": 3.0334,
      "grad_norm": 2.6811840534210205,
      "learning_rate": 2.3906754333532576e-05,
      "epoch": 0.2032459574976836,
      "step": 1700
    },
    {
      "loss": 2.9919,
      "grad_norm": 2.8540024757385254,
      "learning_rate": 2.381709503885236e-05,
      "epoch": 0.2062348686373554,
      "step": 1725
    },
    {
      "loss": 2.9248,
      "grad_norm": 2.52355694770813,
      "learning_rate": 2.3727435744172148e-05,
      "epoch": 0.20922377977702722,
      "step": 1750
    },
    {
      "loss": 2.9092,
      "grad_norm": 2.7366244792938232,
      "learning_rate": 2.3637776449491932e-05,
      "epoch": 0.21221269091669906,
      "step": 1775
    },
    {
      "loss": 2.9741,
      "grad_norm": 2.7806646823883057,
      "learning_rate": 2.3548117154811716e-05,
      "epoch": 0.21520160205637087,
      "step": 1800
    },
    {
      "loss": 2.8433,
      "grad_norm": 2.7838656902313232,
      "learning_rate": 2.34584578601315e-05,
      "epoch": 0.21819051319604268,
      "step": 1825
    },
    {
      "loss": 2.8581,
      "grad_norm": 2.6938252449035645,
      "learning_rate": 2.3368798565451288e-05,
      "epoch": 0.2211794243357145,
      "step": 1850
    },
    {
      "loss": 2.8281,
      "grad_norm": 2.3198301792144775,
      "learning_rate": 2.3279139270771072e-05,
      "epoch": 0.2241683354753863,
      "step": 1875
    },
    {
      "loss": 2.8302,
      "grad_norm": 2.6109020709991455,
      "learning_rate": 2.3189479976090853e-05,
      "epoch": 0.22715724661505812,
      "step": 1900
    },
    {
      "loss": 2.7473,
      "grad_norm": 2.5459108352661133,
      "learning_rate": 2.309982068141064e-05,
      "epoch": 0.23014615775472996,
      "step": 1925
    },
    {
      "loss": 2.7523,
      "grad_norm": 2.3948891162872314,
      "learning_rate": 2.3010161386730424e-05,
      "epoch": 0.23313506889440178,
      "step": 1950
    },
    {
      "loss": 2.7208,
      "grad_norm": 2.789400339126587,
      "learning_rate": 2.2920502092050212e-05,
      "epoch": 0.2361239800340736,
      "step": 1975
    },
    {
      "loss": 2.6962,
      "grad_norm": 2.3287622928619385,
      "learning_rate": 2.2830842797369993e-05,
      "epoch": 0.2391128911737454,
      "step": 2000
    },
    {
      "step": 2000,
      "eval_exact_match": 0.632,
      "eval_f1": 0.632,
      "eval_edit_distance": 0.639022554633543
    },
    {
      "loss": 2.6524,
      "grad_norm": 2.587921619415283,
      "learning_rate": 2.274118350268978e-05,
      "epoch": 0.2421018023134172,
      "step": 2025
    },
    {
      "loss": 2.6793,
      "grad_norm": 2.7833259105682373,
      "learning_rate": 2.2651524208009564e-05,
      "epoch": 0.24509071345308903,
      "step": 2050
    },
    {
      "loss": 2.6424,
      "grad_norm": 2.2021634578704834,
      "learning_rate": 2.256186491332935e-05,
      "epoch": 0.24807962459276087,
      "step": 2075
    },
    {
      "loss": 2.6061,
      "grad_norm": 2.059055805206299,
      "learning_rate": 2.2472205618649133e-05,
      "epoch": 0.25106853573243265,
      "step": 2100
    },
    {
      "loss": 2.6256,
      "grad_norm": 2.365901470184326,
      "learning_rate": 2.2382546323968917e-05,
      "epoch": 0.2540574468721045,
      "step": 2125
    },
    {
      "loss": 2.6207,
      "grad_norm": 2.3235111236572266,
      "learning_rate": 2.2292887029288704e-05,
      "epoch": 0.25704635801177633,
      "step": 2150
    },
    {
      "loss": 2.5712,
      "grad_norm": 2.6602394580841064,
      "learning_rate": 2.220322773460849e-05,
      "epoch": 0.26003526915144815,
      "step": 2175
    },
    {
      "loss": 2.5579,
      "grad_norm": 2.4363436698913574,
      "learning_rate": 2.2113568439928276e-05,
      "epoch": 0.26302418029111996,
      "step": 2200
    },
    {
      "loss": 2.4786,
      "grad_norm": 2.145841598510742,
      "learning_rate": 2.2023909145248057e-05,
      "epoch": 0.26601309143079177,
      "step": 2225
    },
    {
      "loss": 2.532,
      "grad_norm": 2.5272772312164307,
      "learning_rate": 2.193424985056784e-05,
      "epoch": 0.2690020025704636,
      "step": 2250
    },
    {
      "loss": 2.4737,
      "grad_norm": 2.279456615447998,
      "learning_rate": 2.184459055588763e-05,
      "epoch": 0.2719909137101354,
      "step": 2275
    },
    {
      "loss": 2.4275,
      "grad_norm": 2.295675277709961,
      "learning_rate": 2.1754931261207413e-05,
      "epoch": 0.2749798248498072,
      "step": 2300
    },
    {
      "loss": 2.3603,
      "grad_norm": 2.4514412879943848,
      "learning_rate": 2.1665271966527197e-05,
      "epoch": 0.277968735989479,
      "step": 2325
    },
    {
      "loss": 2.378,
      "grad_norm": 2.191983938217163,
      "learning_rate": 2.157561267184698e-05,
      "epoch": 0.28095764712915083,
      "step": 2350
    },
    {
      "loss": 2.3396,
      "grad_norm": 2.217536687850952,
      "learning_rate": 2.148595337716677e-05,
      "epoch": 0.28394655826882265,
      "step": 2375
    },
    {
      "loss": 2.3583,
      "grad_norm": 2.259751796722412,
      "learning_rate": 2.1396294082486553e-05,
      "epoch": 0.28693546940849446,
      "step": 2400
    },
    {
      "loss": 2.4255,
      "grad_norm": 2.3697500228881836,
      "learning_rate": 2.1306634787806333e-05,
      "epoch": 0.2899243805481663,
      "step": 2425
    },
    {
      "loss": 2.3478,
      "grad_norm": 2.078655481338501,
      "learning_rate": 2.121697549312612e-05,
      "epoch": 0.29291329168783814,
      "step": 2450
    },
    {
      "loss": 2.3206,
      "grad_norm": 2.225888967514038,
      "learning_rate": 2.1127316198445905e-05,
      "epoch": 0.29590220282750995,
      "step": 2475
    },
    {
      "loss": 2.2882,
      "grad_norm": 2.4194154739379883,
      "learning_rate": 2.1037656903765693e-05,
      "epoch": 0.29889111396718177,
      "step": 2500
    },
    {
      "step": 2500,
      "eval_exact_match": 0.634,
      "eval_f1": 0.634,
      "eval_edit_distance": 0.641022554633543
    },
    {
      "loss": 2.2417,
      "grad_norm": 1.9963815212249756,
      "learning_rate": 2.0947997609085477e-05,
      "epoch": 0.3018800251068536,
      "step": 2525
    },
    {
      "loss": 2.2593,
      "grad_norm": 2.5868678092956543,
      "learning_rate": 2.085833831440526e-05,
      "epoch": 0.3048689362465254,
      "step": 2550
    },
    {
      "loss": 2.1762,
      "grad_norm": 2.0671398639678955,
      "learning_rate": 2.0768679019725045e-05,
      "epoch": 0.3078578473861972,
      "step": 2575
    },
    {
      "loss": 2.2124,
      "grad_norm": 2.0005199909210205,
      "learning_rate": 2.067901972504483e-05,
      "epoch": 0.310846758525869,
      "step": 2600
    },
    {
      "loss": 2.1814,
      "grad_norm": 1.8929002285003662,
      "learning_rate": 2.0589360430364617e-05,
      "epoch": 0.31383566966554083,
      "step": 2625
    },
    {
      "loss": 2.1606,
      "grad_norm": 2.0611305236816406,
      "learning_rate": 2.0499701135684398e-05,
      "epoch": 0.31682458080521264,
      "step": 2650
    },
    {
      "loss": 2.1661,
      "grad_norm": 2.0823311805725098,
      "learning_rate": 2.0410041841004185e-05,
      "epoch": 0.31981349194488445,
      "step": 2675
    },
    {
      "loss": 2.1147,
      "grad_norm": 2.067472457885742,
      "learning_rate": 2.032038254632397e-05,
      "epoch": 0.3228024030845563,
      "step": 2700
    },
    {
      "loss": 2.0369,
      "grad_norm": 2.274414539337158,
      "learning_rate": 2.0230723251643757e-05,
      "epoch": 0.32579131422422813,
      "step": 2725
    },
    {
      "loss": 2.1304,
      "grad_norm": 2.1410698890686035,
      "learning_rate": 2.0141063956963538e-05,
      "epoch": 0.32878022536389995,
      "step": 2750
    },
    {
      "loss": 2.0679,
      "grad_norm": 1.8997541666030884,
      "learning_rate": 2.005140466228332e-05,
      "epoch": 0.33176913650357176,
      "step": 2775
    },
    {
      "loss": 1.98,
      "grad_norm": 2.040457248687744,
      "learning_rate": 1.996174536760311e-05,
      "epoch": 0.3347580476432436,
      "step": 2800
    },
    {
      "loss": 1.998,
      "grad_norm": 2.177499771118164,
      "learning_rate": 1.9872086072922893e-05,
      "epoch": 0.3377469587829154,
      "step": 2825
    },
    {
      "loss": 2.0175,
      "grad_norm": 1.7341599464416504,
      "learning_rate": 1.978242677824268e-05,
      "epoch": 0.3407358699225872,
      "step": 2850
    },
    {
      "loss": 1.9539,
      "grad_norm": 1.8893922567367554,
      "learning_rate": 1.969276748356246e-05,
      "epoch": 0.343724781062259,
      "step": 2875
    },
    {
      "loss": 2.1318,
      "grad_norm": 2.0240542888641357,
      "learning_rate": 1.960310818888225e-05,
      "epoch": 0.3467136922019308,
      "step": 2900
    },
    {
      "loss": 2.0154,
      "grad_norm": 1.7595996856689453,
      "learning_rate": 1.9513448894202033e-05,
      "epoch": 0.34970260334160264,
      "step": 2925
    },
    {
      "loss": 2.0125,
      "grad_norm": 1.8667019605636597,
      "learning_rate": 1.9423789599521818e-05,
      "epoch": 0.35269151448127445,
      "step": 2950
    },
    {
      "loss": 1.9375,
      "grad_norm": 1.880919098854065,
      "learning_rate": 1.93341303048416e-05,
      "epoch": 0.3556804256209463,
      "step": 2975
    },
    {
      "loss": 1.9165,
      "grad_norm": 1.9088979959487915,
      "learning_rate": 1.9244471010161386e-05,
      "epoch": 0.35866933676061813,
      "step": 3000
    },
    {
      "step": 3000,
      "eval_exact_match": 0.638,
      "eval_f1": 0.638,
      "eval_edit_distance": 0.6449684455565423
    },
    {
      "loss": 1.9124,
      "grad_norm": 1.8758915662765503,
      "learning_rate": 1.9154811715481173e-05,
      "epoch": 0.36165824790028994,
      "step": 3025
    },
    {
      "loss": 1.9969,
      "grad_norm": 1.8107490539550781,
      "learning_rate": 1.9065152420800958e-05,
      "epoch": 0.36464715903996175,
      "step": 3050
    },
    {
      "loss": 1.9024,
      "grad_norm": 1.7781000137329102,
      "learning_rate": 1.897549312612074e-05,
      "epoch": 0.36763607017963357,
      "step": 3075
    },
    {
      "loss": 1.8544,
      "grad_norm": 1.9124153852462769,
      "learning_rate": 1.8885833831440526e-05,
      "epoch": 0.3706249813193054,
      "step": 3100
    },
    {
      "loss": 1.9208,
      "grad_norm": 1.7058638334274292,
      "learning_rate": 1.879617453676031e-05,
      "epoch": 0.3736138924589772,
      "step": 3125
    },
    {
      "loss": 1.8718,
      "grad_norm": 1.653246521949768,
      "learning_rate": 1.8706515242080098e-05,
      "epoch": 0.376602803598649,
      "step": 3150
    },
    {
      "loss": 1.8616,
      "grad_norm": 1.7214492559432983,
      "learning_rate": 1.861685594739988e-05,
      "epoch": 0.3795917147383208,
      "step": 3175
    },
    {
      "loss": 1.9541,
      "grad_norm": 1.8513215780258179,
      "learning_rate": 1.8527196652719666e-05,
      "epoch": 0.38258062587799263,
      "step": 3200
    },
    {
      "loss": 1.8514,
      "grad_norm": 1.6871063709259033,
      "learning_rate": 1.843753735803945e-05,
      "epoch": 0.38556953701766444,
      "step": 3225
    },
    {
      "loss": 1.8033,
      "grad_norm": 1.7201303243637085,
      "learning_rate": 1.8347878063359238e-05,
      "epoch": 0.38855844815733626,
      "step": 3250
    },
    {
      "loss": 1.7893,
      "grad_norm": 1.7184306383132935,
      "learning_rate": 1.825821876867902e-05,
      "epoch": 0.3915473592970081,
      "step": 3275
    },
    {
      "loss": 1.7984,
      "grad_norm": 1.6275200843811035,
      "learning_rate": 1.8168559473998802e-05,
      "epoch": 0.39453627043667994,
      "step": 3300
    },
    {
      "loss": 1.7997,
      "grad_norm": 1.7116130590438843,
      "learning_rate": 1.807890017931859e-05,
      "epoch": 0.39752518157635175,
      "step": 3325
    },
    {
      "loss": 1.7574,
      "grad_norm": 1.7328996658325195,
      "learning_rate": 1.7989240884638374e-05,
      "epoch": 0.40051409271602356,
      "step": 3350
    },
    {
      "loss": 1.7588,
      "grad_norm": 1.6392455101013184,
      "learning_rate": 1.789958158995816e-05,
      "epoch": 0.4035030038556954,
      "step": 3375
    },
    {
      "loss": 1.7606,
      "grad_norm": 1.5263535976409912,
      "learning_rate": 1.7809922295277942e-05,
      "epoch": 0.4064919149953672,
      "step": 3400
    },
    {
      "loss": 1.7604,
      "grad_norm": 1.5182112455368042,
      "learning_rate": 1.772026300059773e-05,
      "epoch": 0.409480826135039,
      "step": 3425
    },
    {
      "loss": 1.6708,
      "grad_norm": 1.5380651950836182,
      "learning_rate": 1.7630603705917514e-05,
      "epoch": 0.4124697372747108,
      "step": 3450
    },
    {
      "loss": 1.7468,
      "grad_norm": 1.640586256980896,
      "learning_rate": 1.7540944411237298e-05,
      "epoch": 0.4154586484143826,
      "step": 3475
    },
    {
      "loss": 1.7393,
      "grad_norm": 1.7219327688217163,
      "learning_rate": 1.7451285116557082e-05,
      "epoch": 0.41844755955405444,
      "step": 3500
    },
    {
      "step": 3500,
      "eval_exact_match": 0.638,
      "eval_f1": 0.6382051282051282,
      "eval_edit_distance": 0.6454266762722859
    },
    {
      "loss": 1.6261,
      "grad_norm": 1.6260991096496582,
      "learning_rate": 1.7361625821876867e-05,
      "epoch": 0.42143647069372625,
      "step": 3525
    },
    {
      "loss": 1.6486,
      "grad_norm": 1.7259726524353027,
      "learning_rate": 1.7271966527196654e-05,
      "epoch": 0.4244253818333981,
      "step": 3550
    },
    {
      "loss": 1.6625,
      "grad_norm": 1.5460923910140991,
      "learning_rate": 1.7182307232516438e-05,
      "epoch": 0.42741429297306993,
      "step": 3575
    },
    {
      "loss": 1.6409,
      "grad_norm": 1.442906379699707,
      "learning_rate": 1.7092647937836226e-05,
      "epoch": 0.43040320411274174,
      "step": 3600
    },
    {
      "loss": 1.6301,
      "grad_norm": 1.475453495979309,
      "learning_rate": 1.7002988643156007e-05,
      "epoch": 0.43339211525241356,
      "step": 3625
    },
    {
      "loss": 1.6256,
      "grad_norm": 1.5982885360717773,
      "learning_rate": 1.691332934847579e-05,
      "epoch": 0.43638102639208537,
      "step": 3650
    },
    {
      "loss": 1.5965,
      "grad_norm": 1.5877974033355713,
      "learning_rate": 1.6823670053795578e-05,
      "epoch": 0.4393699375317572,
      "step": 3675
    },
    {
      "loss": 1.5964,
      "grad_norm": 1.6221281290054321,
      "learning_rate": 1.6734010759115362e-05,
      "epoch": 0.442358848671429,
      "step": 3700
    },
    {
      "loss": 1.5669,
      "grad_norm": 1.4066736698150635,
      "learning_rate": 1.6644351464435147e-05,
      "epoch": 0.4453477598111008,
      "step": 3725
    },
    {
      "loss": 1.6665,
      "grad_norm": 1.5744314193725586,
      "learning_rate": 1.655469216975493e-05,
      "epoch": 0.4483366709507726,
      "step": 3750
    },
    {
      "loss": 1.5891,
      "grad_norm": 1.4982597827911377,
      "learning_rate": 1.6465032875074718e-05,
      "epoch": 0.45132558209044443,
      "step": 3775
    },
    {
      "loss": 1.6028,
      "grad_norm": 1.5065759420394897,
      "learning_rate": 1.6375373580394502e-05,
      "epoch": 0.45431449323011625,
      "step": 3800
    },
    {
      "loss": 1.5544,
      "grad_norm": 1.3042659759521484,
      "learning_rate": 1.6285714285714283e-05,
      "epoch": 0.4573034043697881,
      "step": 3825
    },
    {
      "loss": 1.6066,
      "grad_norm": 1.4807143211364746,
      "learning_rate": 1.619605499103407e-05,
      "epoch": 0.4602923155094599,
      "step": 3850
    },
    {
      "loss": 1.5568,
      "grad_norm": 1.2050237655639648,
      "learning_rate": 1.6106395696353855e-05,
      "epoch": 0.46328122664913174,
      "step": 3875
    },
    {
      "loss": 1.5621,
      "grad_norm": 1.6738258600234985,
      "learning_rate": 1.6016736401673642e-05,
      "epoch": 0.46627013778880355,
      "step": 3900
    },
    {
      "loss": 1.5423,
      "grad_norm": 1.4502309560775757,
      "learning_rate": 1.5927077106993427e-05,
      "epoch": 0.46925904892847536,
      "step": 3925
    },
    {
      "loss": 1.5867,
      "grad_norm": 1.4817126989364624,
      "learning_rate": 1.583741781231321e-05,
      "epoch": 0.4722479600681472,
      "step": 3950
    },
    {
      "loss": 1.5419,
      "grad_norm": 1.5377862453460693,
      "learning_rate": 1.5747758517632995e-05,
      "epoch": 0.475236871207819,
      "step": 3975
    },
    {
      "loss": 1.4506,
      "grad_norm": 1.4392633438110352,
      "learning_rate": 1.565809922295278e-05,
      "epoch": 0.4782257823474908,
      "step": 4000
    },
    {
      "step": 4000,
      "eval_exact_match": 0.642,
      "eval_f1": 0.642,
      "eval_edit_distance": 0.6488303210486408
    },
    {
      "loss": 1.424,
      "grad_norm": 1.4674757719039917,
      "learning_rate": 1.5568439928272567e-05,
      "epoch": 0.4812146934871626,
      "step": 4025
    },
    {
      "loss": 1.4687,
      "grad_norm": 1.5509477853775024,
      "learning_rate": 1.5478780633592347e-05,
      "epoch": 0.4842036046268344,
      "step": 4050
    },
    {
      "loss": 1.5043,
      "grad_norm": 1.2830204963684082,
      "learning_rate": 1.5389121338912135e-05,
      "epoch": 0.48719251576650624,
      "step": 4075
    },
    {
      "loss": 1.4446,
      "grad_norm": 1.3366175889968872,
      "learning_rate": 1.529946204423192e-05,
      "epoch": 0.49018142690617805,
      "step": 4100
    },
    {
      "loss": 1.4408,
      "grad_norm": 1.4765770435333252,
      "learning_rate": 1.5209802749551702e-05,
      "epoch": 0.4931703380458499,
      "step": 4125
    },
    {
      "loss": 1.5084,
      "grad_norm": 1.4896340370178223,
      "learning_rate": 1.5120143454871489e-05,
      "epoch": 0.49615924918552173,
      "step": 4150
    },
    {
      "loss": 1.5045,
      "grad_norm": 1.3887536525726318,
      "learning_rate": 1.5030484160191272e-05,
      "epoch": 0.49914816032519355,
      "step": 4175
    },
    {
      "loss": 1.5068,
      "grad_norm": 1.4078497886657715,
      "learning_rate": 1.4940824865511059e-05,
      "epoch": 0.5021370714648653,
      "step": 4200
    },
    {
      "loss": 1.5137,
      "grad_norm": 1.5021175146102905,
      "learning_rate": 1.4851165570830843e-05,
      "epoch": 0.5051259826045371,
      "step": 4225
    },
    {
      "loss": 1.4324,
      "grad_norm": 1.3682518005371094,
      "learning_rate": 1.4761506276150627e-05,
      "epoch": 0.508114893744209,
      "step": 4250
    },
    {
      "loss": 1.4455,
      "grad_norm": 1.436728596687317,
      "learning_rate": 1.4671846981470413e-05,
      "epoch": 0.5111038048838809,
      "step": 4275
    },
    {
      "loss": 1.3557,
      "grad_norm": 1.498822808265686,
      "learning_rate": 1.4582187686790197e-05,
      "epoch": 0.5140927160235527,
      "step": 4300
    },
    {
      "loss": 1.3104,
      "grad_norm": 1.361254334449768,
      "learning_rate": 1.4492528392109983e-05,
      "epoch": 0.5170816271632245,
      "step": 4325
    },
    {
      "loss": 1.4453,
      "grad_norm": 1.383448600769043,
      "learning_rate": 1.4402869097429767e-05,
      "epoch": 0.5200705383028963,
      "step": 4350
    },
    {
      "loss": 1.3458,
      "grad_norm": 1.470667839050293,
      "learning_rate": 1.4313209802749553e-05,
      "epoch": 0.5230594494425681,
      "step": 4375
    },
    {
      "loss": 1.3982,
      "grad_norm": 1.162700891494751,
      "learning_rate": 1.4223550508069336e-05,
      "epoch": 0.5260483605822399,
      "step": 4400
    },
    {
      "loss": 1.4194,
      "grad_norm": 1.278516411781311,
      "learning_rate": 1.4133891213389122e-05,
      "epoch": 0.5290372717219117,
      "step": 4425
    },
    {
      "loss": 1.3431,
      "grad_norm": 1.3115431070327759,
      "learning_rate": 1.4044231918708906e-05,
      "epoch": 0.5320261828615835,
      "step": 4450
    },
    {
      "loss": 1.3785,
      "grad_norm": 1.4113149642944336,
      "learning_rate": 1.3954572624028692e-05,
      "epoch": 0.5350150940012554,
      "step": 4475
    },
    {
      "loss": 1.3417,
      "grad_norm": 1.3530200719833374,
      "learning_rate": 1.3864913329348476e-05,
      "epoch": 0.5380040051409272,
      "step": 4500
    },
    {
      "step": 4500,
      "eval_exact_match": 0.642,
      "eval_f1": 0.642,
      "eval_edit_distance": 0.6488303210486408
    }
  ],
  "logging_steps": 25,
  "max_steps": 8365,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.7791815131136e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}