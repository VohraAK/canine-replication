{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b1984a6d29864e2d940119370816a37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a307de6c263a4c20a6418344cbd98c0c",
              "IPY_MODEL_1db208af0dbc4f2facee78148266a207",
              "IPY_MODEL_d44d38a959ec44aa90e91c15a83abbd6"
            ],
            "layout": "IPY_MODEL_527baa5fc421480da4d2dc7041e19b1f"
          }
        },
        "a307de6c263a4c20a6418344cbd98c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d398c81b546d4527a41dd97bd87ad7d8",
            "placeholder": "​",
            "style": "IPY_MODEL_ab4047c7f0144667857fe835d452f6c7",
            "value": "Map: 100%"
          }
        },
        "1db208af0dbc4f2facee78148266a207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0120d513dd4d4fccac2d528eb7ff4696",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3e0981c2924416fbdf9ceab3e6b04ab",
            "value": 10000
          }
        },
        "d44d38a959ec44aa90e91c15a83abbd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc970c64373f4f69b6c6936087ed978a",
            "placeholder": "​",
            "style": "IPY_MODEL_4a74d22a2c334fbda54a95c5e29e712a",
            "value": " 10000/10000 [00:56&lt;00:00, 178.11 examples/s]"
          }
        },
        "527baa5fc421480da4d2dc7041e19b1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d398c81b546d4527a41dd97bd87ad7d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab4047c7f0144667857fe835d452f6c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0120d513dd4d4fccac2d528eb7ff4696": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e0981c2924416fbdf9ceab3e6b04ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc970c64373f4f69b6c6936087ed978a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a74d22a2c334fbda54a95c5e29e712a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05d936e2dc9d412b8637c174a3c0be64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e0b41aa16f241a4ba3bb8a2f3525984",
              "IPY_MODEL_2bebe7e1f3f341dfaabf29963d2c5995",
              "IPY_MODEL_41b300b02ed2413ba80865aaa99ece2a"
            ],
            "layout": "IPY_MODEL_b4740a7137e742d687e2075b60d2be8a"
          }
        },
        "7e0b41aa16f241a4ba3bb8a2f3525984": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80132c8e4fa743fca850936ecfebc7f7",
            "placeholder": "​",
            "style": "IPY_MODEL_303bb3d75f7d4e94aeb60c5491ea6e61",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "2bebe7e1f3f341dfaabf29963d2c5995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7463faafecf4e46a87dc6863a646cea",
            "max": 116995,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc199cddba714aeda650d97fef015a14",
            "value": 116995
          }
        },
        "41b300b02ed2413ba80865aaa99ece2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a508a6457bb460ba17d5adb0a9e9f85",
            "placeholder": "​",
            "style": "IPY_MODEL_3aac2656907a416291a622717ccaf929",
            "value": " 116995/116995 [00:00&lt;00:00, 259239.20 examples/s]"
          }
        },
        "b4740a7137e742d687e2075b60d2be8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80132c8e4fa743fca850936ecfebc7f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "303bb3d75f7d4e94aeb60c5491ea6e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7463faafecf4e46a87dc6863a646cea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc199cddba714aeda650d97fef015a14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a508a6457bb460ba17d5adb0a9e9f85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aac2656907a416291a622717ccaf929": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa1af70d9c95443c9f09666359ba3769": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddb717fd4dbc40c6bd8422a02f925060",
              "IPY_MODEL_6d1342eeaf4f4f0489fe0746ceaaeb09",
              "IPY_MODEL_a10683e5c1164f349cbdc75b1567994c"
            ],
            "layout": "IPY_MODEL_71cfe2c8df474badb255d7d28da04348"
          }
        },
        "ddb717fd4dbc40c6bd8422a02f925060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_077fbb403e5f4069841e558a3cc0c065",
            "placeholder": "​",
            "style": "IPY_MODEL_b068b9fac9f24eca9bd430bab30ea70c",
            "value": "Saving the dataset (1/1 shards): 100%"
          }
        },
        "6d1342eeaf4f4f0489fe0746ceaaeb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cbfc6f4ec434674ac59d3fbdbddcd3b",
            "max": 31446,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d675a6788b641c6a09604ef17514dec",
            "value": 31446
          }
        },
        "a10683e5c1164f349cbdc75b1567994c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd9b9f21be9744c49d99ac4bc76f11e1",
            "placeholder": "​",
            "style": "IPY_MODEL_89469ab4bd6f48d8b9aa369473c7230f",
            "value": " 31446/31446 [00:00&lt;00:00, 152136.58 examples/s]"
          }
        },
        "71cfe2c8df474badb255d7d28da04348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "077fbb403e5f4069841e558a3cc0c065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b068b9fac9f24eca9bd430bab30ea70c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cbfc6f4ec434674ac59d3fbdbddcd3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d675a6788b641c6a09604ef17514dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd9b9f21be9744c49d99ac4bc76f11e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89469ab4bd6f48d8b9aa369473c7230f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "c186240c",
      "cell_type": "code",
      "source": [
        "# %pip install peft evaluate transformers Levenshtein ipywidgets\n",
        "# %pip install protobuf==3.20.3\n",
        "# !rm -rf /kaggle/working/cache"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:41.749272Z",
          "iopub.execute_input": "2025-11-25T10:01:41.749873Z",
          "iopub.status.idle": "2025-11-25T10:01:41.753208Z",
          "shell.execute_reply.started": "2025-11-25T10:01:41.749845Z",
          "shell.execute_reply": "2025-11-25T10:01:41.752383Z"
        },
        "id": "c186240c",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "id": "cd8da8ab",
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TRANSFORMERS_DISABLE_CHAT_TEMPLATES\"] = \"1\"\n",
        "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
        "os.environ[\"TRANSFORMERS_NO_ADDITIONAL_CHAT_TEMPLATES\"] = \"1\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:41.754373Z",
          "iopub.execute_input": "2025-11-25T10:01:41.754744Z",
          "iopub.status.idle": "2025-11-25T10:01:41.766413Z",
          "shell.execute_reply.started": "2025-11-25T10:01:41.754723Z",
          "shell.execute_reply": "2025-11-25T10:01:41.765542Z"
        },
        "id": "cd8da8ab",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 26
    },
    {
      "id": "d87eba82",
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, load_from_disk\n",
        "# from UQA.canine_utils import preprocess_uqa, lora_config, print_trainable_parameters, normalize_answer, exact_match_score, f1_score, edit_distance_score, gold_answer, decode_prediction\n",
        "from transformers import CanineTokenizer\n",
        "from peft import LoraConfig, TaskType, get_peft_model\n",
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import Levenshtein\n",
        "\n",
        "from transformers import TrainingArguments, Trainer, TrainerCallback\n",
        "import json\n",
        "from huggingface_hub import HfApi, notebook_login, whoami"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:41.767717Z",
          "iopub.execute_input": "2025-11-25T10:01:41.768259Z",
          "iopub.status.idle": "2025-11-25T10:01:41.779869Z",
          "shell.execute_reply.started": "2025-11-25T10:01:41.768235Z",
          "shell.execute_reply": "2025-11-25T10:01:41.779102Z"
        },
        "id": "d87eba82",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 27
    },
    {
      "id": "0e98cebe-4c08-4850-b3c1-1529564fdb1b",
      "cell_type": "code",
      "source": [
        "\n",
        "# notebook_login()\n",
        "# whoami()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:41.780490Z",
          "iopub.execute_input": "2025-11-25T10:01:41.780714Z",
          "iopub.status.idle": "2025-11-25T10:01:41.791632Z",
          "shell.execute_reply.started": "2025-11-25T10:01:41.780696Z",
          "shell.execute_reply": "2025-11-25T10:01:41.790867Z"
        },
        "trusted": true,
        "id": "0e98cebe-4c08-4850-b3c1-1529564fdb1b"
      },
      "outputs": [],
      "execution_count": 28
    },
    {
      "id": "f2dd5a40",
      "cell_type": "code",
      "source": [
        "from transformers import CanineTokenizer, CanineForQuestionAnswering\n",
        "import torch\n",
        "model_name = 'google/canine-s'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
        "\n",
        "tokenizer = CanineTokenizer.from_pretrained(model_name, use_fast=False, trust_remote_code=False)\n",
        "model = CanineForQuestionAnswering.from_pretrained(model_name, trust_remote_code=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:41.793514Z",
          "iopub.execute_input": "2025-11-25T10:01:41.793835Z",
          "iopub.status.idle": "2025-11-25T10:01:43.874179Z",
          "shell.execute_reply.started": "2025-11-25T10:01:41.793809Z",
          "shell.execute_reply": "2025-11-25T10:01:43.873521Z"
        },
        "id": "f2dd5a40",
        "outputId": "140c30ea-575d-45cd-ea54-7818cdfe6bf5",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "execution_count": 29
    },
    {
      "id": "d474e2e8",
      "cell_type": "code",
      "source": [
        "uqa_dataset = load_dataset(\"uqa/UQA\")\n",
        "uqa_train = uqa_dataset[\"train\"].shuffle(seed=42).select(range(40000))\n",
        "uqa_val = uqa_dataset[\"validation\"].shuffle(seed=42).select(range(10000))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:43.875005Z",
          "iopub.execute_input": "2025-11-25T10:01:43.875226Z",
          "iopub.status.idle": "2025-11-25T10:01:45.718520Z",
          "shell.execute_reply.started": "2025-11-25T10:01:43.875206Z",
          "shell.execute_reply": "2025-11-25T10:01:45.717914Z"
        },
        "id": "d474e2e8",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 30
    },
    {
      "id": "89c472d5",
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "89c472d5"
      }
    },
    {
      "id": "6e80a8d3",
      "cell_type": "markdown",
      "source": [
        "## Updated preprocessors!\n",
        "\n",
        "Previously, we tried to apply the same approach we used in TYDIQA on UQA, the problem was the preprocessors were aligning the answer spans in units of **byte-level spans** instead of **character-level spans**. The calculations were adding byte-level offsets to the answer lengths, and since Urdu characters may be quantified in multiple bytes, the model was being fed the wrong spans -> GIGO!"
      ],
      "metadata": {
        "id": "6e80a8d3"
      }
    },
    {
      "id": "438d8765",
      "cell_type": "code",
      "source": [
        "MAX_SEQ_LENGTH = 384\n",
        "DOC_STRIDE = 64\n",
        "\n",
        "def preprocess_uqa(examples, tokenizer, max_length=MAX_SEQ_LENGTH, doc_stride=DOC_STRIDE, model_obj=None, indices=None):\n",
        "    # Handle tokenizer/model limits safely\n",
        "    tokenizer_max = getattr(tokenizer, \"model_max_length\", max_length)\n",
        "    model_max = getattr(model_obj.config, \"max_position_embeddings\", None) if model_obj is not None else None\n",
        "    max_allowed = max_length\n",
        "    if tokenizer_max is not None and tokenizer_max > 0:\n",
        "        max_allowed = min(max_allowed, tokenizer_max)\n",
        "    if model_max is not None and model_max > 0:\n",
        "        max_allowed = min(max_allowed, model_max)\n",
        "\n",
        "    questions = [q.strip() for q in examples[\"question\"]]\n",
        "    contexts = examples[\"context\"]\n",
        "    answers = examples[\"answer\"]\n",
        "    answer_starts = examples[\"answer_start\"]\n",
        "\n",
        "    encoded = {\n",
        "        \"input_ids\": [],\n",
        "        \"attention_mask\": [],\n",
        "        \"token_type_ids\": [],\n",
        "        \"start_positions\": [],\n",
        "        \"end_positions\": [],\n",
        "        \"overflow_to_sample_mapping\": []\n",
        "    }\n",
        "\n",
        "    for i, (question, context, answer, answer_start) in enumerate(zip(questions, contexts, answers, answer_starts)):\n",
        "        example_idx = indices[i] if indices is not None else i\n",
        "\n",
        "        # CANINE encodes to characters directly.\n",
        "        # add_special_tokens=False gives us raw character IDs.\n",
        "        question_ids = tokenizer.encode(question, add_special_tokens=False)\n",
        "        context_ids = tokenizer.encode(context, add_special_tokens=False)\n",
        "\n",
        "        # 1. Setup Targets (DIRECT MAPPING)\n",
        "        # UQA answer_start is a CHARACTER index. CANINE tokens are CHARACTERS.\n",
        "        # Therefore, answer_start maps 1:1 to the context_ids index.\n",
        "        if answer and answer_start != -1:\n",
        "            gold_char_start = answer_start\n",
        "            gold_char_end = answer_start + len(answer) # Points to char AFTER the answer\n",
        "        else:\n",
        "            gold_char_start = -1\n",
        "            gold_char_end = -1\n",
        "\n",
        "        # 2. Calculate Window Size\n",
        "        # [CLS] + Question + [SEP] + Context + [SEP]\n",
        "        special_tokens_count = tokenizer.num_special_tokens_to_add(pair=True)\n",
        "        max_context_length = max_allowed - len(question_ids) - special_tokens_count\n",
        "\n",
        "        if max_context_length <= 0:\n",
        "            # Edge case: Question is too long, skip or truncate question (skipping here for safety)\n",
        "            continue\n",
        "\n",
        "        # 3. Sliding Window Loop\n",
        "        stride_step = max_context_length - doc_stride\n",
        "        if stride_step <= 0: stride_step = max_context_length # Fallback if doc_stride is too big\n",
        "\n",
        "        for chunk_start_idx in range(0, len(context_ids), stride_step):\n",
        "            chunk_end_idx = min(chunk_start_idx + max_context_length, len(context_ids))\n",
        "            context_chunk = context_ids[chunk_start_idx:chunk_end_idx]\n",
        "\n",
        "            # Build inputs using tokenizer utility to handle special tokens correctly\n",
        "            input_ids = tokenizer.build_inputs_with_special_tokens(question_ids, context_chunk)\n",
        "            token_type_ids = tokenizer.create_token_type_ids_from_sequences(question_ids, context_chunk)\n",
        "            attention_mask = [1] * len(input_ids)\n",
        "\n",
        "            # Calculate Offset: Where does the context actually start in input_ids?\n",
        "            # Typically: [CLS] (1) + Q_Len + [SEP] (1) = Start of Context\n",
        "            # We calculate this dynamically to be safe:\n",
        "            sep_indices = [k for k, x in enumerate(input_ids) if x == tokenizer.sep_token_id]\n",
        "            if not sep_indices:\n",
        "                continue # Should not happen\n",
        "            context_offset_in_input = sep_indices[0] + 1\n",
        "\n",
        "            # 4. Label Assignment\n",
        "            # Check if the answer lies ENTIRELY within this specific chunk\n",
        "            is_answer_in_chunk = (\n",
        "                gold_char_start >= chunk_start_idx and\n",
        "                gold_char_end <= chunk_end_idx and\n",
        "                gold_char_start != -1\n",
        "            )\n",
        "\n",
        "            if is_answer_in_chunk:\n",
        "                # Map global context index to local window index\n",
        "                start_pos = context_offset_in_input + (gold_char_start - chunk_start_idx)\n",
        "                # -1 because end_positions is usually inclusive in HF Trainers\n",
        "                end_pos = context_offset_in_input + (gold_char_end - chunk_start_idx) - 1\n",
        "            else:\n",
        "                # Label as [CLS] (index 0) if answer is not here\n",
        "                start_pos = 0\n",
        "                end_pos = 0\n",
        "\n",
        "            # 5. Padding\n",
        "            pad_len = max_allowed - len(input_ids)\n",
        "            if pad_len > 0:\n",
        "                input_ids += [tokenizer.pad_token_id] * pad_len\n",
        "                attention_mask += [0] * pad_len\n",
        "                token_type_ids += [0] * pad_len\n",
        "\n",
        "            # 6. Final Safety Truncation (just in case)\n",
        "            if len(input_ids) > max_allowed:\n",
        "                input_ids = input_ids[:max_allowed]\n",
        "                attention_mask = attention_mask[:max_allowed]\n",
        "                token_type_ids = token_type_ids[:max_allowed]\n",
        "                # If labels were pushed out by truncation, reset to 0\n",
        "                if start_pos >= max_allowed or end_pos >= max_allowed:\n",
        "                    start_pos = 0\n",
        "                    end_pos = 0\n",
        "\n",
        "            encoded[\"input_ids\"].append(input_ids)\n",
        "            encoded[\"attention_mask\"].append(attention_mask)\n",
        "            encoded[\"token_type_ids\"].append(token_type_ids)\n",
        "            encoded[\"start_positions\"].append(start_pos)\n",
        "            encoded[\"end_positions\"].append(end_pos)\n",
        "            encoded[\"overflow_to_sample_mapping\"].append(example_idx)\n",
        "\n",
        "            # Break loop if this chunk reached the end of the context\n",
        "            if chunk_end_idx >= len(context_ids):\n",
        "                break\n",
        "\n",
        "    return encoded\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:45.719799Z",
          "iopub.execute_input": "2025-11-25T10:01:45.720068Z",
          "iopub.status.idle": "2025-11-25T10:01:45.732155Z",
          "shell.execute_reply.started": "2025-11-25T10:01:45.720042Z",
          "shell.execute_reply": "2025-11-25T10:01:45.731305Z"
        },
        "id": "438d8765",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 31
    },
    {
      "id": "a3e95eec",
      "cell_type": "code",
      "source": [
        "# LoRA config\n",
        "lora_config = LoraConfig(\n",
        "    task_type=TaskType.QUESTION_ANS,\n",
        "    r=32,   # changed from 8\n",
        "    lora_alpha=64,  # changed from 32\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"query\", \"value\", \"key\"],   # added key, output.dense\n",
        "    bias=\"none\",\n",
        "    modules_to_save=[\"qa_outputs\"],\n",
        ")\n",
        "\n",
        "def print_trainable_parameters(model):\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:45.732928Z",
          "iopub.execute_input": "2025-11-25T10:01:45.733140Z",
          "iopub.status.idle": "2025-11-25T10:01:45.751371Z",
          "shell.execute_reply.started": "2025-11-25T10:01:45.733123Z",
          "shell.execute_reply": "2025-11-25T10:01:45.750654Z"
        },
        "id": "a3e95eec",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 32
    },
    {
      "id": "d11807b9",
      "cell_type": "code",
      "source": [
        "# preprocess the train and val splits\n",
        "processed_train = uqa_train.map(lambda examples, indices: preprocess_uqa(examples, tokenizer, indices=indices), batched=True, remove_columns=uqa_train.column_names, with_indices=True)\n",
        "processed_val = uqa_val.map(lambda examples, indices: preprocess_uqa(examples, tokenizer, indices=indices), batched=True, remove_columns=uqa_val.column_names, with_indices=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:45.752239Z",
          "iopub.execute_input": "2025-11-25T10:01:45.752489Z",
          "iopub.status.idle": "2025-11-25T10:01:45.767280Z",
          "shell.execute_reply.started": "2025-11-25T10:01:45.752469Z",
          "shell.execute_reply": "2025-11-25T10:01:45.766540Z"
        },
        "id": "d11807b9",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "b1984a6d29864e2d940119370816a37e",
            "a307de6c263a4c20a6418344cbd98c0c",
            "1db208af0dbc4f2facee78148266a207",
            "d44d38a959ec44aa90e91c15a83abbd6",
            "527baa5fc421480da4d2dc7041e19b1f",
            "d398c81b546d4527a41dd97bd87ad7d8",
            "ab4047c7f0144667857fe835d452f6c7",
            "0120d513dd4d4fccac2d528eb7ff4696",
            "c3e0981c2924416fbdf9ceab3e6b04ab",
            "bc970c64373f4f69b6c6936087ed978a",
            "4a74d22a2c334fbda54a95c5e29e712a"
          ]
        },
        "outputId": "64fc2534-2871-4bd2-b3fa-4b37973486e2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1984a6d29864e2d940119370816a37e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (3198 > 2048). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "execution_count": 33
    },
    {
      "id": "D-emFQTIaZRL",
      "cell_type": "code",
      "source": [
        "# processed_train"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:45.768099Z",
          "iopub.execute_input": "2025-11-25T10:01:45.768419Z",
          "iopub.status.idle": "2025-11-25T10:01:45.780915Z",
          "shell.execute_reply.started": "2025-11-25T10:01:45.768399Z",
          "shell.execute_reply": "2025-11-25T10:01:45.780144Z"
        },
        "id": "D-emFQTIaZRL",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 34
    },
    {
      "id": "Yy3SiWwCabEi",
      "cell_type": "code",
      "source": [
        "# processed_val"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:45.781762Z",
          "iopub.execute_input": "2025-11-25T10:01:45.782363Z",
          "iopub.status.idle": "2025-11-25T10:01:45.795011Z",
          "shell.execute_reply.started": "2025-11-25T10:01:45.782335Z",
          "shell.execute_reply": "2025-11-25T10:01:45.794207Z"
        },
        "id": "Yy3SiWwCabEi",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 35
    },
    {
      "id": "77ecdd17",
      "cell_type": "code",
      "source": [
        "processed_train.save_to_disk(\"/kaggle/working/cache/processed_train_uqa\")\n",
        "processed_val.save_to_disk(\"/kaggle/working/cache/processed_val_uqa\")   # cached it\n",
        "\n",
        "\n",
        "processed_train = load_from_disk(\"/kaggle/working/cache/processed_train_uqa\")\n",
        "processed_val = load_from_disk(\"/kaggle/working/cache/processed_val_uqa\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:45.797209Z",
          "iopub.execute_input": "2025-11-25T10:01:45.797487Z",
          "iopub.status.idle": "2025-11-25T10:01:45.821164Z",
          "shell.execute_reply.started": "2025-11-25T10:01:45.797468Z",
          "shell.execute_reply": "2025-11-25T10:01:45.820573Z"
        },
        "id": "77ecdd17",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "05d936e2dc9d412b8637c174a3c0be64",
            "7e0b41aa16f241a4ba3bb8a2f3525984",
            "2bebe7e1f3f341dfaabf29963d2c5995",
            "41b300b02ed2413ba80865aaa99ece2a",
            "b4740a7137e742d687e2075b60d2be8a",
            "80132c8e4fa743fca850936ecfebc7f7",
            "303bb3d75f7d4e94aeb60c5491ea6e61",
            "d7463faafecf4e46a87dc6863a646cea",
            "bc199cddba714aeda650d97fef015a14",
            "1a508a6457bb460ba17d5adb0a9e9f85",
            "3aac2656907a416291a622717ccaf929",
            "fa1af70d9c95443c9f09666359ba3769",
            "ddb717fd4dbc40c6bd8422a02f925060",
            "6d1342eeaf4f4f0489fe0746ceaaeb09",
            "a10683e5c1164f349cbdc75b1567994c",
            "71cfe2c8df474badb255d7d28da04348",
            "077fbb403e5f4069841e558a3cc0c065",
            "b068b9fac9f24eca9bd430bab30ea70c",
            "8cbfc6f4ec434674ac59d3fbdbddcd3b",
            "4d675a6788b641c6a09604ef17514dec",
            "bd9b9f21be9744c49d99ac4bc76f11e1",
            "89469ab4bd6f48d8b9aa369473c7230f"
          ]
        },
        "outputId": "602e648b-4a75-424b-da09-d58f3295a65e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/116995 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05d936e2dc9d412b8637c174a3c0be64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/31446 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fa1af70d9c95443c9f09666359ba3769"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 36
    },
    {
      "id": "c0e06e6b",
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:45.821974Z",
          "iopub.execute_input": "2025-11-25T10:01:45.822256Z",
          "iopub.status.idle": "2025-11-25T10:01:45.826672Z",
          "shell.execute_reply.started": "2025-11-25T10:01:45.822231Z",
          "shell.execute_reply": "2025-11-25T10:01:45.825908Z"
        },
        "id": "c0e06e6b",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 37
    },
    {
      "id": "ba9eeeed",
      "cell_type": "code",
      "source": [
        "# build LoRA model\n",
        "\n",
        "peft_model = get_peft_model(model, lora_config)\n",
        "peft_model.gradient_checkpointing_enable()\n",
        "print_trainable_parameters(peft_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:45.827382Z",
          "iopub.execute_input": "2025-11-25T10:01:45.827582Z",
          "iopub.status.idle": "2025-11-25T10:01:45.914836Z",
          "shell.execute_reply.started": "2025-11-25T10:01:45.827567Z",
          "shell.execute_reply": "2025-11-25T10:01:45.914036Z"
        },
        "id": "ba9eeeed",
        "outputId": "27071b6e-b703-4b47-9288-9a1c6f3eba55",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2065922 || all params: 134150404 || trainable%: 1.5400043074040985\n"
          ]
        }
      ],
      "execution_count": 38
    },
    {
      "id": "61c5c7a7",
      "cell_type": "code",
      "source": [
        "# evals\n",
        "\n",
        "\n",
        "def normalize_answer(text):\n",
        "    text = (text or \"\").lower()\n",
        "    def remove_articles(s):\n",
        "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", s)\n",
        "    def remove_punctuation(s):\n",
        "        return \"\".join(ch for ch in s if ch not in string.punctuation)\n",
        "    def white_space_fix(s):\n",
        "        return \" \".join(s.split())\n",
        "    return white_space_fix(remove_articles(remove_punctuation(text)))\n",
        "\n",
        "def exact_match_score(prediction, ground_truth):\n",
        "    return float(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
        "\n",
        "def f1_score(prediction, ground_truth):\n",
        "    pred_tokens = normalize_answer(prediction).split()\n",
        "    gold_tokens = normalize_answer(ground_truth).split()\n",
        "    if not gold_tokens:\n",
        "        return 1.0 if not pred_tokens else 0.0\n",
        "    if not pred_tokens:\n",
        "        return 0.0\n",
        "    common = Counter(pred_tokens) & Counter(gold_tokens)\n",
        "    num_same = sum(common.values())\n",
        "    if num_same == 0:\n",
        "        return 0.0\n",
        "    precision = num_same / len(pred_tokens)\n",
        "    recall = num_same / len(gold_tokens)\n",
        "    return 2 * precision * recall / (precision + recall)\n",
        "\n",
        "def edit_distance_score(prediction, ground_truth):\n",
        "    pred_norm = normalize_answer(prediction)\n",
        "    gold_norm = normalize_answer(ground_truth)\n",
        "    if not gold_norm and not pred_norm:\n",
        "        return 1.0\n",
        "    if not gold_norm or not pred_norm:\n",
        "        return 0.0\n",
        "    distance = Levenshtein.distance(pred_norm, gold_norm)\n",
        "    max_len = max(len(pred_norm), len(gold_norm))\n",
        "    return 1.0 - (distance / max_len) if max_len > 0 else 1.0\n",
        "\n",
        "def gold_answer(example):\n",
        "    # Extracts the gold answer substring from the context using character offsets\n",
        "    answer = example.get(\"answer\")\n",
        "    context = example.get(\"context\")\n",
        "    answer_start = example.get(\"answer_start\", -1)\n",
        "    if answer and answer_start is not None and answer_start != -1:\n",
        "        return context[answer_start: answer_start + len(answer)]\n",
        "    return \"[CLS]\"\n",
        "\n",
        "\n",
        "def decode_prediction(input_ids, start_idx, end_idx, tokenizer=None):\n",
        "    if start_idx > end_idx:\n",
        "        start_idx, end_idx = end_idx, start_idx\n",
        "    if tokenizer is None:\n",
        "        raise ValueError(\"Tokenizer must be provided for decoding.\")\n",
        "    cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "    # If both point to CLS token, return [CLS] sentinel\n",
        "    if start_idx == cls_index and end_idx == cls_index:\n",
        "        return \"[CLS]\"\n",
        "    start_idx = max(start_idx, 0)\n",
        "    end_idx = min(end_idx, len(input_ids) - 1)\n",
        "    if start_idx > end_idx:\n",
        "        return \"[CLS]\"\n",
        "    text = tokenizer.decode(input_ids[start_idx:end_idx + 1], skip_special_tokens=True)\n",
        "    text = text.strip()\n",
        "    return text if text else \"[CLS]\"\n",
        "\n",
        "\n",
        "def evaluate_checkpoint(checkpoint_path=None, model_instance=None, eval_dataset=None):\n",
        "    \"\"\"Evaluate either a checkpoint path (loads model) or a provided model instance.\n",
        "\n",
        "    - checkpoint_path: path to checkpoint folder\n",
        "    - model_instance: an in-memory model (preferably a PeftModel or CanineForQuestionAnswering)\n",
        "    - eval_dataset: optional dataset to evaluate; if None the default processed_val will be used\n",
        "    \"\"\"\n",
        "    if eval_dataset is None:\n",
        "        eval_dataset = processed_val\n",
        "\n",
        "    # If a model_instance is given, use it directly (avoid re-loading a fresh base model)\n",
        "    if model_instance is not None:\n",
        "        eval_model = model_instance\n",
        "    else:\n",
        "        base_model = CanineForQuestionAnswering.from_pretrained(model_name, trust_remote_code=False)\n",
        "        eval_model = get_peft_model(base_model, lora_config)\n",
        "        # Try loading adapter weights; fall back to PeftModel.from_pretrained if needed\n",
        "        try:\n",
        "            eval_model.load_adapter(checkpoint_path)\n",
        "        except Exception:\n",
        "            from peft import PeftModel\n",
        "            eval_model = PeftModel.from_pretrained(base_model, checkpoint_path)\n",
        "\n",
        "    eval_model.to(device)\n",
        "\n",
        "    eval_args = TrainingArguments(\n",
        "        # Small evaluation config; uses cpu/mps if no gpu during eval\n",
        "        output_dir=\"outputs/canine-s-uqa\",\n",
        "        per_device_eval_batch_size=16,\n",
        "        dataloader_drop_last=False,\n",
        "        fp16=True,\n",
        "        bf16=False,\n",
        "        report_to=\"none\",\n",
        "    )\n",
        "\n",
        "    # Run evaluation via a lightweight Trainer so prediction loop is standard\n",
        "    eval_trainer = Trainer(\n",
        "        model=eval_model,\n",
        "        args=eval_args,\n",
        "        eval_dataset=eval_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "    )\n",
        "\n",
        "    predictions = eval_trainer.predict(eval_dataset)\n",
        "    start_logits, end_logits = predictions.predictions\n",
        "    best_predictions = {}\n",
        "    for feature_index, feature in enumerate(eval_dataset):\n",
        "        sample_idx = int(feature[\"overflow_to_sample_mapping\"])\n",
        "        input_ids = feature[\"input_ids\"]\n",
        "        start_idx = int(np.argmax(start_logits[feature_index]))\n",
        "        end_idx = int(np.argmax(end_logits[feature_index]))\n",
        "        score = float(start_logits[feature_index][start_idx] + end_logits[feature_index][end_idx])\n",
        "        prediction_text = decode_prediction(input_ids, start_idx, end_idx, tokenizer=tokenizer)\n",
        "        stored = best_predictions.get(sample_idx)\n",
        "        if stored is None or score > stored[0]:\n",
        "            best_predictions[sample_idx] = (score, prediction_text)\n",
        "\n",
        "    em_scores = []\n",
        "    f1_scores = []\n",
        "    edit_dist_scores = []\n",
        "    for sample_idx, (_, prediction_text) in best_predictions.items():\n",
        "        reference = gold_answer(uqa_val[int(sample_idx)])\n",
        "        em_scores.append(exact_match_score(prediction_text, reference))\n",
        "        f1_scores.append(f1_score(prediction_text, reference))\n",
        "        edit_dist_scores.append(edit_distance_score(prediction_text, reference))\n",
        "\n",
        "    em = float(np.mean(em_scores)) if em_scores else 0.0\n",
        "    f1 = float(np.mean(f1_scores)) if f1_scores else 0.0\n",
        "    edit_dist = float(np.mean(edit_dist_scores)) if edit_dist_scores else 0.0\n",
        "    print(f\"Examples evaluated: {len(em_scores)}\")\n",
        "    print(f\"Exact Match: {em * 100:.2f}\")\n",
        "    print(f\"F1: {f1 * 100:.2f}\")\n",
        "    print(f\"Edit Distance (normalized): {edit_dist * 100:.2f}\")\n",
        "    return {\"exact_match\": em, \"f1\": f1, \"edit_distance\": edit_dist}\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:45.915747Z",
          "iopub.execute_input": "2025-11-25T10:01:45.916115Z",
          "iopub.status.idle": "2025-11-25T10:01:45.932409Z",
          "shell.execute_reply.started": "2025-11-25T10:01:45.916091Z",
          "shell.execute_reply": "2025-11-25T10:01:45.931596Z"
        },
        "id": "61c5c7a7",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 39
    },
    {
      "id": "c4abaaab",
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"outputs/canine-s-uqa\",\n",
        "\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=16,\n",
        "\n",
        "    gradient_accumulation_steps=4,\n",
        "    gradient_checkpointing=True,\n",
        "\n",
        "    num_train_epochs=1,\n",
        "    learning_rate=3e-4,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"no\",\n",
        "    eval_steps=500,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    logging_steps=25,\n",
        "    fp16=True,\n",
        "    bf16=False,\n",
        "    report_to=\"none\",\n",
        "    push_to_hub=True,\n",
        "    hub_model_id=\"VohraAK/canine-s-uqa\",\n",
        "    hub_strategy=\"checkpoint\",\n",
        "    )\n",
        "\n",
        "class CustomEvalCallback(TrainerCallback):\n",
        "    def __init__(self, eval_func, eval_dataset, use_in_memory_model=True, verbose=True):\n",
        "        self.eval_func = eval_func\n",
        "        self.eval_dataset = eval_dataset\n",
        "        self.use_in_memory_model = use_in_memory_model\n",
        "        self.verbose = verbose\n",
        "        # trainer reference (set after trainer exists)\n",
        "        self.trainer = None\n",
        "\n",
        "    def on_save(self, args, state, control, model=None, **kwargs):\n",
        "        checkpoint_path = f\"{args.output_dir}/checkpoint-{state.global_step}\"\n",
        "        if self.verbose:\n",
        "            print(f\"\\n🔍 Running custom evaluation at step {state.global_step}...\")\n",
        "\n",
        "        # Prefer evaluating the in-memory trainer model (fast + avoids re-loading)\n",
        "        if self.use_in_memory_model and self.trainer is not None:\n",
        "            if self.verbose:\n",
        "                print(\"Using in-memory model for evaluation (no reloading).\")\n",
        "            try:\n",
        "                metrics = self.eval_func(checkpoint_path=None, model_instance=self.trainer.model, eval_dataset=self.eval_dataset)\n",
        "            except Exception as e:\n",
        "                print(\"⚠️ in-memory evaluation failed, falling back to checkpoint load:\", e)\n",
        "                metrics = self.eval_func(checkpoint_path)\n",
        "        else:\n",
        "            metrics = self.eval_func(checkpoint_path)\n",
        "\n",
        "        # record metrics in state.log_history\n",
        "        state.log_history.append({\n",
        "            \"step\": state.global_step,\n",
        "            \"eval_exact_match\": metrics.get(\"exact_match\"),\n",
        "            \"eval_f1\": metrics.get(\"f1\"),\n",
        "            \"eval_edit_distance\": metrics.get(\"edit_distance\"),\n",
        "        })\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"✅ Step {state.global_step}: EM={metrics.get('exact_match',0)*100:.2f}, F1={metrics.get('f1',0)*100:.2f}, EditDist={metrics.get('edit_distance',0)*100:.2f}\")\n",
        "\n",
        "        # Update trainer_state.json to include custom metrics\n",
        "        state_path = f\"{checkpoint_path}/trainer_state.json\"\n",
        "        try:\n",
        "            with open(state_path, 'r') as f:\n",
        "                state_dict = json.load(f)\n",
        "            state_dict['log_history'] = state.log_history\n",
        "            with open(state_path, 'w') as f:\n",
        "                json.dump(state_dict, f, indent=2)\n",
        "            if self.verbose:\n",
        "                print(f\"💾 Updated trainer_state.json with custom metrics\")\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"⚠️  Warning: Could not update trainer_state.json: {e}\")\n",
        "\n",
        "        try:\n",
        "            if self.verbose:\n",
        "                print(f\"☁️  Pushing checkpoint-{state.global_step} to Hub...\")\n",
        "            api = HfApi()\n",
        "            api.upload_folder(\n",
        "                folder_path=checkpoint_path,\n",
        "                repo_id=args.hub_model_id,\n",
        "                path_in_repo=f\"checkpoint-{state.global_step}\",\n",
        "                commit_message=f\"Add checkpoint {state.global_step} (EM={metrics.get('exact_match',0)*100:.1f}%, F1={metrics.get('f1',0)*100:.1f}%)\",\n",
        "                repo_type=\"model\"\n",
        "            )\n",
        "            if self.verbose:\n",
        "                print(f\"✅ Pushed checkpoint-{state.global_step} to Hub\")\n",
        "        except Exception as e:\n",
        "            if self.verbose:\n",
        "                print(f\"⚠️  Warning: Could not push to Hub: {e}\")\n",
        "\n",
        "        return control"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:45.933653Z",
          "iopub.execute_input": "2025-11-25T10:01:45.933927Z",
          "iopub.status.idle": "2025-11-25T10:01:45.978263Z",
          "shell.execute_reply.started": "2025-11-25T10:01:45.933904Z",
          "shell.execute_reply": "2025-11-25T10:01:45.977428Z"
        },
        "id": "c4abaaab",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 40
    },
    {
      "id": "055f5dda",
      "cell_type": "code",
      "source": [
        "trainer_cb = CustomEvalCallback(evaluate_checkpoint, processed_val, use_in_memory_model=True)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=processed_train,\n",
        "    eval_dataset=processed_val,\n",
        "    callbacks=[trainer_cb],\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:45.979158Z",
          "iopub.execute_input": "2025-11-25T10:01:45.979504Z",
          "iopub.status.idle": "2025-11-25T10:01:46.891831Z",
          "shell.execute_reply.started": "2025-11-25T10:01:45.979480Z",
          "shell.execute_reply": "2025-11-25T10:01:46.891061Z"
        },
        "id": "055f5dda",
        "trusted": true
      },
      "outputs": [],
      "execution_count": 41
    },
    {
      "id": "TOUimesUX5Re",
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "execution": {
          "iopub.status.busy": "2025-11-25T10:01:46.893217Z",
          "iopub.execute_input": "2025-11-25T10:01:46.893444Z",
          "iopub.status.idle": "2025-11-25T10:15:46.370866Z",
          "shell.execute_reply.started": "2025-11-25T10:01:46.893426Z",
          "shell.execute_reply": "2025-11-25T10:15:46.369672Z"
        },
        "id": "TOUimesUX5Re",
        "outputId": "cfa62dcd-8eb4-475a-910b-1c38a3894cc2",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7313' max='7313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7313/7313 1:04:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>5.840400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>5.625500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>5.390100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>5.216300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>5.061000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>4.950800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>4.811600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>4.576800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>4.570100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>4.440900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>4.388800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>4.265200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>4.184900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>4.056300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>375</td>\n",
              "      <td>3.935600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>3.947800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>425</td>\n",
              "      <td>3.886300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>3.780700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>475</td>\n",
              "      <td>3.729300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>3.854400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>525</td>\n",
              "      <td>3.616300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>3.622000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>575</td>\n",
              "      <td>3.541400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>3.568800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>625</td>\n",
              "      <td>3.690800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>3.574500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>675</td>\n",
              "      <td>3.555200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>3.421500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>725</td>\n",
              "      <td>3.286300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>3.516300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>775</td>\n",
              "      <td>3.197100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>3.243200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>825</td>\n",
              "      <td>3.250300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>3.186800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>875</td>\n",
              "      <td>3.260700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>3.061600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>925</td>\n",
              "      <td>3.117400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>3.254600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>975</td>\n",
              "      <td>3.141800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>3.134400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1025</td>\n",
              "      <td>3.144800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>3.089300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1075</td>\n",
              "      <td>2.971700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>3.058900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1125</td>\n",
              "      <td>3.057800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>2.917600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1175</td>\n",
              "      <td>3.061700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>2.923900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1225</td>\n",
              "      <td>2.865800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>3.074500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1275</td>\n",
              "      <td>2.890100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>2.959400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1325</td>\n",
              "      <td>2.848100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>2.817100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1375</td>\n",
              "      <td>2.804300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>2.945100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1425</td>\n",
              "      <td>2.858100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>3.007200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1475</td>\n",
              "      <td>2.777200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>2.940100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1525</td>\n",
              "      <td>2.920700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>2.947700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1575</td>\n",
              "      <td>2.702200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>2.768100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1625</td>\n",
              "      <td>2.635200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>2.974700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1675</td>\n",
              "      <td>2.862400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>2.923500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1725</td>\n",
              "      <td>2.696800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>2.827000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1775</td>\n",
              "      <td>2.536800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>2.652500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1825</td>\n",
              "      <td>2.837100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>2.749800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1875</td>\n",
              "      <td>2.735400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>2.653300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1925</td>\n",
              "      <td>2.587900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>2.523400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1975</td>\n",
              "      <td>2.313400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>2.724300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2025</td>\n",
              "      <td>2.477100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>2.646400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2075</td>\n",
              "      <td>2.536600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>2.530600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2125</td>\n",
              "      <td>2.540900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>2.505200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2175</td>\n",
              "      <td>2.498600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>2.492900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2225</td>\n",
              "      <td>2.436700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>2.552800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2275</td>\n",
              "      <td>2.645700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>2.741100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2325</td>\n",
              "      <td>2.776800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>2.481800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2375</td>\n",
              "      <td>2.276600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>2.436200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2425</td>\n",
              "      <td>2.519800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>2.537700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2475</td>\n",
              "      <td>2.398400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>2.455800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2525</td>\n",
              "      <td>2.635300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>2.398400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2575</td>\n",
              "      <td>2.606200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>2.532500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2625</td>\n",
              "      <td>2.666400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>2.415000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2675</td>\n",
              "      <td>2.484400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>2.799200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2725</td>\n",
              "      <td>2.489000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>2.356500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2775</td>\n",
              "      <td>2.607100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>2.551000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2825</td>\n",
              "      <td>2.536600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>2.774200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2875</td>\n",
              "      <td>2.569600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>2.358300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2925</td>\n",
              "      <td>2.337700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>2.486800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2975</td>\n",
              "      <td>2.446800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>2.320100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3025</td>\n",
              "      <td>2.434800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>2.544900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3075</td>\n",
              "      <td>2.412200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>2.428000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3125</td>\n",
              "      <td>2.362900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>2.278000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3175</td>\n",
              "      <td>2.640200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>2.234800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3225</td>\n",
              "      <td>2.478200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>2.581000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3275</td>\n",
              "      <td>2.320000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>2.534200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3325</td>\n",
              "      <td>2.567000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>2.402000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3375</td>\n",
              "      <td>2.476500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>2.207500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3425</td>\n",
              "      <td>2.477600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>2.402100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3475</td>\n",
              "      <td>2.837200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>2.361800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3525</td>\n",
              "      <td>2.412000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>2.305600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3575</td>\n",
              "      <td>2.470100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>2.692200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3625</td>\n",
              "      <td>2.423300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>2.481800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3675</td>\n",
              "      <td>2.363500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>2.490800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3725</td>\n",
              "      <td>2.473700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>2.328600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3775</td>\n",
              "      <td>2.509000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>2.134400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3825</td>\n",
              "      <td>2.519700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>2.360300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3875</td>\n",
              "      <td>2.554900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>2.575600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3925</td>\n",
              "      <td>2.516200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>2.291000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3975</td>\n",
              "      <td>2.389000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>2.612800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4025</td>\n",
              "      <td>2.590900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>2.667100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4075</td>\n",
              "      <td>2.279000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>2.333600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4125</td>\n",
              "      <td>2.254700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4150</td>\n",
              "      <td>2.159300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4175</td>\n",
              "      <td>2.457900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>2.639600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4225</td>\n",
              "      <td>2.542700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4250</td>\n",
              "      <td>2.483700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4275</td>\n",
              "      <td>2.494800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4300</td>\n",
              "      <td>2.486000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4325</td>\n",
              "      <td>2.418000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4350</td>\n",
              "      <td>2.188800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4375</td>\n",
              "      <td>2.252700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4400</td>\n",
              "      <td>2.450200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4425</td>\n",
              "      <td>2.588300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4450</td>\n",
              "      <td>2.290100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4475</td>\n",
              "      <td>2.478900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>2.554300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4525</td>\n",
              "      <td>2.171700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4550</td>\n",
              "      <td>2.321600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4575</td>\n",
              "      <td>2.421700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4600</td>\n",
              "      <td>2.537600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4625</td>\n",
              "      <td>2.411100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4650</td>\n",
              "      <td>2.458700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4675</td>\n",
              "      <td>2.578200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4700</td>\n",
              "      <td>2.550900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4725</td>\n",
              "      <td>2.561700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4750</td>\n",
              "      <td>2.428200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4775</td>\n",
              "      <td>2.242100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4800</td>\n",
              "      <td>2.684900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4825</td>\n",
              "      <td>2.316500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4850</td>\n",
              "      <td>2.277600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4875</td>\n",
              "      <td>2.590500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4900</td>\n",
              "      <td>2.363600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4925</td>\n",
              "      <td>2.405000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4950</td>\n",
              "      <td>2.375900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4975</td>\n",
              "      <td>2.498800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5000</td>\n",
              "      <td>2.421700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5025</td>\n",
              "      <td>2.608600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5050</td>\n",
              "      <td>2.496700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5075</td>\n",
              "      <td>2.508700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5100</td>\n",
              "      <td>2.284100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5125</td>\n",
              "      <td>2.492700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5150</td>\n",
              "      <td>2.231700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5175</td>\n",
              "      <td>2.166000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5200</td>\n",
              "      <td>2.386500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5225</td>\n",
              "      <td>2.099600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5250</td>\n",
              "      <td>2.107600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5275</td>\n",
              "      <td>2.441500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5300</td>\n",
              "      <td>2.437600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5325</td>\n",
              "      <td>2.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5350</td>\n",
              "      <td>2.288100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5375</td>\n",
              "      <td>2.437300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5400</td>\n",
              "      <td>2.451900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5425</td>\n",
              "      <td>2.198500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5450</td>\n",
              "      <td>2.542900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5475</td>\n",
              "      <td>2.356100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5500</td>\n",
              "      <td>2.500600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5525</td>\n",
              "      <td>2.548800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5550</td>\n",
              "      <td>2.398400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5575</td>\n",
              "      <td>2.267500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5600</td>\n",
              "      <td>2.408300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5625</td>\n",
              "      <td>2.221000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5650</td>\n",
              "      <td>2.228900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5675</td>\n",
              "      <td>2.472000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5700</td>\n",
              "      <td>2.397500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5725</td>\n",
              "      <td>2.304300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5750</td>\n",
              "      <td>2.352700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5775</td>\n",
              "      <td>2.408900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5800</td>\n",
              "      <td>2.290000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5825</td>\n",
              "      <td>2.554500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5850</td>\n",
              "      <td>2.324200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5875</td>\n",
              "      <td>2.493600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5900</td>\n",
              "      <td>2.376400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5925</td>\n",
              "      <td>2.422200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5950</td>\n",
              "      <td>2.363200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5975</td>\n",
              "      <td>2.369700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6000</td>\n",
              "      <td>2.618900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6025</td>\n",
              "      <td>2.588600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6050</td>\n",
              "      <td>2.543000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6075</td>\n",
              "      <td>2.406100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6100</td>\n",
              "      <td>2.273600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6125</td>\n",
              "      <td>2.590400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6150</td>\n",
              "      <td>2.230400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6175</td>\n",
              "      <td>2.314300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6200</td>\n",
              "      <td>2.422700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6225</td>\n",
              "      <td>2.361600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6250</td>\n",
              "      <td>2.318800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6275</td>\n",
              "      <td>2.299300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6300</td>\n",
              "      <td>2.459600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6325</td>\n",
              "      <td>2.374800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6350</td>\n",
              "      <td>2.295600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6375</td>\n",
              "      <td>2.443500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6400</td>\n",
              "      <td>2.013400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6425</td>\n",
              "      <td>2.329800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6450</td>\n",
              "      <td>2.473100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6475</td>\n",
              "      <td>2.108600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6500</td>\n",
              "      <td>2.359600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6525</td>\n",
              "      <td>2.299100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6550</td>\n",
              "      <td>2.127600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6575</td>\n",
              "      <td>2.422000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6600</td>\n",
              "      <td>2.501500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6625</td>\n",
              "      <td>2.398300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6650</td>\n",
              "      <td>2.325400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6675</td>\n",
              "      <td>2.587600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6700</td>\n",
              "      <td>2.433500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6725</td>\n",
              "      <td>2.316300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6750</td>\n",
              "      <td>2.428100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6775</td>\n",
              "      <td>2.474100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6800</td>\n",
              "      <td>2.452000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6825</td>\n",
              "      <td>2.403000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6850</td>\n",
              "      <td>2.387400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6875</td>\n",
              "      <td>2.209700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6900</td>\n",
              "      <td>2.444300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6925</td>\n",
              "      <td>2.284900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6950</td>\n",
              "      <td>2.383600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6975</td>\n",
              "      <td>2.273600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7000</td>\n",
              "      <td>2.510500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7025</td>\n",
              "      <td>2.416300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7050</td>\n",
              "      <td>2.080100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7075</td>\n",
              "      <td>2.283000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7100</td>\n",
              "      <td>2.217900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7125</td>\n",
              "      <td>2.249400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7150</td>\n",
              "      <td>2.404800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7175</td>\n",
              "      <td>2.502500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7200</td>\n",
              "      <td>2.497400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7225</td>\n",
              "      <td>2.663100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7250</td>\n",
              "      <td>2.437800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7275</td>\n",
              "      <td>2.305900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7300</td>\n",
              "      <td>2.324900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 30.15\n",
            "F1: 30.52\n",
            "Edit Distance (normalized): 30.96\n",
            "✅ Step 500: EM=30.15, F1=30.52, EditDist=30.96\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-500 to Hub...\n",
            "✅ Pushed checkpoint-500 to Hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 1000...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 31.22\n",
            "F1: 31.43\n",
            "Edit Distance (normalized): 31.73\n",
            "✅ Step 1000: EM=31.22, F1=31.43, EditDist=31.73\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-1000 to Hub...\n",
            "✅ Pushed checkpoint-1000 to Hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 1500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 31.79\n",
            "F1: 31.95\n",
            "Edit Distance (normalized): 32.22\n",
            "✅ Step 1500: EM=31.79, F1=31.95, EditDist=32.22\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-1500 to Hub...\n",
            "✅ Pushed checkpoint-1500 to Hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 2000...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 32.18\n",
            "F1: 32.32\n",
            "Edit Distance (normalized): 32.55\n",
            "✅ Step 2000: EM=32.18, F1=32.32, EditDist=32.55\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-2000 to Hub...\n",
            "✅ Pushed checkpoint-2000 to Hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 2500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 32.47\n",
            "F1: 32.57\n",
            "Edit Distance (normalized): 32.79\n",
            "✅ Step 2500: EM=32.47, F1=32.57, EditDist=32.79\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-2500 to Hub...\n",
            "✅ Pushed checkpoint-2500 to Hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 3000...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 32.65\n",
            "F1: 32.74\n",
            "Edit Distance (normalized): 32.95\n",
            "✅ Step 3000: EM=32.65, F1=32.74, EditDist=32.95\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-3000 to Hub...\n",
            "✅ Pushed checkpoint-3000 to Hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 3500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 32.76\n",
            "F1: 32.83\n",
            "Edit Distance (normalized): 33.04\n",
            "✅ Step 3500: EM=32.76, F1=32.83, EditDist=33.04\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-3500 to Hub...\n",
            "✅ Pushed checkpoint-3500 to Hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 4000...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 32.92\n",
            "F1: 33.00\n",
            "Edit Distance (normalized): 33.20\n",
            "✅ Step 4000: EM=32.92, F1=33.00, EditDist=33.20\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-4000 to Hub...\n",
            "✅ Pushed checkpoint-4000 to Hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 4500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 32.92\n",
            "F1: 32.98\n",
            "Edit Distance (normalized): 33.17\n",
            "✅ Step 4500: EM=32.92, F1=32.98, EditDist=33.17\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-4500 to Hub...\n",
            "✅ Pushed checkpoint-4500 to Hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 5000...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 32.93\n",
            "F1: 32.99\n",
            "Edit Distance (normalized): 33.18\n",
            "✅ Step 5000: EM=32.93, F1=32.99, EditDist=33.18\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-5000 to Hub...\n",
            "✅ Pushed checkpoint-5000 to Hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 5500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 32.95\n",
            "F1: 33.00\n",
            "Edit Distance (normalized): 33.20\n",
            "✅ Step 5500: EM=32.95, F1=33.00, EditDist=33.20\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-5500 to Hub...\n",
            "✅ Pushed checkpoint-5500 to Hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 6000...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 33.01\n",
            "F1: 33.07\n",
            "Edit Distance (normalized): 33.26\n",
            "✅ Step 6000: EM=33.01, F1=33.07, EditDist=33.26\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-6000 to Hub...\n",
            "✅ Pushed checkpoint-6000 to Hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 6500...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 33.01\n",
            "F1: 33.06\n",
            "Edit Distance (normalized): 33.26\n",
            "✅ Step 6500: EM=33.01, F1=33.06, EditDist=33.26\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-6500 to Hub...\n",
            "✅ Pushed checkpoint-6500 to Hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 7000...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 33.01\n",
            "F1: 33.06\n",
            "Edit Distance (normalized): 33.26\n",
            "✅ Step 7000: EM=33.01, F1=33.06, EditDist=33.26\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-7000 to Hub...\n",
            "✅ Pushed checkpoint-7000 to Hub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/checkpoint.py:85: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔍 Running custom evaluation at step 7313...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-733281207.py:107: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  eval_trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples evaluated: 10000\n",
            "Exact Match: 33.01\n",
            "F1: 33.06\n",
            "Edit Distance (normalized): 33.26\n",
            "✅ Step 7313: EM=33.01, F1=33.06, EditDist=33.26\n",
            "💾 Updated trainer_state.json with custom metrics\n",
            "☁️  Pushing checkpoint-7313 to Hub...\n",
            "✅ Pushed checkpoint-7313 to Hub\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=7313, training_loss=2.690779531701358, metrics={'train_runtime': 3842.2612, 'train_samples_per_second': 30.45, 'train_steps_per_second': 1.903, 'total_flos': 2.937418744905216e+16, 'train_loss': 2.690779531701358, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "execution_count": 42
    },
    {
      "id": "cc44692c-6652-4cda-9ba4-8a03acdab88d",
      "cell_type": "markdown",
      "source": [
        "### Diagnosing Preprocessing Functions!!!"
      ],
      "metadata": {
        "id": "cc44692c-6652-4cda-9ba4-8a03acdab88d"
      }
    },
    {
      "id": "49f3717d",
      "cell_type": "code",
      "source": [
        "# Diagnostic cell (fixed): Investigate preprocessing and truncation for many samples\n",
        "import random\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Set display options to see full Urdu text\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"google/canine-s\")\n",
        "except Exception:\n",
        "    tokenizer = None\n",
        "\n",
        "num_samples = 20000  # Number of samples to check\n",
        "results = []\n",
        "\n",
        "for split_name, orig_data, proc_data in [\n",
        "    (\"train\", uqa_train, processed_train),\n",
        "    (\"val\", uqa_val, processed_val)\n",
        "]:\n",
        "    # Sample random indices\n",
        "    if len(proc_data) < num_samples:\n",
        "        current_indices = range(len(proc_data))\n",
        "    else:\n",
        "        current_indices = random.sample(range(len(proc_data)), num_samples)\n",
        "\n",
        "    for idx in current_indices:\n",
        "        proc = proc_data[idx]\n",
        "        # Use overflow_to_sample_mapping to get the correct original index\n",
        "        orig_idx = proc[\"overflow_to_sample_mapping\"]\n",
        "        orig = orig_data[orig_idx]\n",
        "\n",
        "        input_ids = proc[\"input_ids\"]\n",
        "        start_pos = proc[\"start_positions\"]\n",
        "        end_pos = proc[\"end_positions\"]\n",
        "\n",
        "        gold_answer = orig.get(\"gold_answer\", orig.get(\"answer\", \"\"))\n",
        "        question = orig.get(\"question\", \"\")\n",
        "\n",
        "        # Decode input_ids to text (for debugging context)\n",
        "        if tokenizer:\n",
        "            decoded_text = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
        "        else:\n",
        "            decoded_text = str(input_ids)\n",
        "\n",
        "        # Extract predicted answer span\n",
        "        if 0 <= start_pos < len(input_ids) and 0 <= end_pos < len(input_ids):\n",
        "            if tokenizer:\n",
        "                pred_span = tokenizer.decode(input_ids[start_pos:end_pos+1], skip_special_tokens=True)\n",
        "            else:\n",
        "                pred_span = str(input_ids[start_pos:end_pos+1])\n",
        "        else:\n",
        "            pred_span = \"[CLS]\" # Represents no answer found in this chunk or invalid\n",
        "\n",
        "        # Check if pred_span matches gold answer\n",
        "        # We strip() to ignore minor whitespace differences\n",
        "        pred_matches_gold = pred_span.strip() == gold_answer.strip()\n",
        "\n",
        "        # Check if gold is even reachable in this chunk\n",
        "        gold_in_decoded = gold_answer in decoded_text\n",
        "\n",
        "        results.append({\n",
        "            \"Split\": split_name,\n",
        "            \"Question\": question,\n",
        "            \"Gold Answer\": gold_answer,\n",
        "            \"Extracted Answer\": pred_span,\n",
        "            \"Match\": pred_matches_gold,\n",
        "            \"Gold Reachable\": gold_in_decoded,\n",
        "            \"orig_idx\": orig_idx\n",
        "        })\n",
        "\n",
        "# Create DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# --- SIDE BY SIDE COMPARISON ---\n",
        "\n",
        "# 1. Filter for Solvable Mismatches (Gold was there, but we predicted wrong)\n",
        "problem_cases = results_df[\n",
        "    (results_df[\"Gold Reachable\"] == True) &\n",
        "    (results_df[\"Match\"] == False)\n",
        "][[\"Question\", \"Gold Answer\", \"Extracted Answer\", \"Split\"]]\n",
        "\n",
        "print(f\"🔍 Checked {len(results_df)} samples.\")\n",
        "print(f\"❌ Found {len(problem_cases)} cases where Gold was present but Extraction failed.\")\n",
        "\n",
        "print(\"\\n📊 Side-by-Side Comparison (Top 20 Failures):\")\n",
        "display(problem_cases.head(50))\n",
        "\n",
        "print(\"\\n✅ Side-by-Side Comparison (First 10 Rows - Mixed):\")\n",
        "display(results_df[[\"Question\", \"Gold Answer\", \"Extracted Answer\", \"Match\"]].head(50))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:15:46.371657Z",
          "iopub.status.idle": "2025-11-25T10:15:46.371963Z",
          "shell.execute_reply.started": "2025-11-25T10:15:46.371805Z",
          "shell.execute_reply": "2025-11-25T10:15:46.371817Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "49f3717d",
        "outputId": "38f435a4-1b55-4c2b-b6a5-86540fc23755"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Checked 40000 samples.\n",
            "❌ Found 1012 cases where Gold was present but Extraction failed.\n",
            "\n",
            "📊 Side-by-Side Comparison (Top 20 Failures):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                                                                                              Question  \\\n",
              "12                                                                              شکاری اور شکار کی بات چیت جس میں مہارت شامل ہوتی ہے اس کے نتیجے میں ایک توازن ہوتا ہے جسے کہا جاتا ہے؟   \n",
              "43                                                                           چینیوں کی طرف سے حملوں کی ایک مؤثر سیریز کے طور پر کیا شروع ہو سکتا ہے جس نے کس علاقے کو دوبارہ حاصل کیا؟   \n",
              "56                                                                                                          خانہ جنگی کے بعد ترقی کرنے والی پہلی بڑھتی ہوئی صنعتوں میں سے ایک کیا تھی؟   \n",
              "60                                                                                                                            بندوق کے نظام کو مکمل طور پر تبدیل کرنے کا امکان کیا ہے؟   \n",
              "92                                                                                                                  کس سال کے دوران چیواوا کو دشمن کے کنٹرول سے آزاد قرار دیا گیا تھا؟   \n",
              "111                                                                           کون سا جانور معجزاتی طور پر واپس آ گیا ہے اور اسے \"جنگل میں معدوم\" سے \"نقصان دہ\" میں اپ گریڈ کیا گیا ہے؟   \n",
              "120                                                                                               ایک عمل کیا ہے جو جسم کے ذریعے کیا جاتا ہے اور اس میں جان بوجھ کر کوشش شامل ہوتی ہے؟   \n",
              "222                                                                                                                              کون اپنی زیادہ تر موسیقی خود لکھتا اور تخلیق کرتا ہے؟   \n",
              "243                                                                                        کتنے امریکی سرمایہ کاری کے بینکوں نے 2004 سے 2007 تک اپنے مالی لیوریج میں نمایاں اضافہ کیا؟   \n",
              "246                                                                                                                  اس کی خصوصیات کو تبدیل کرنے کے لئے کس طرح کا علاج کیا جا سکتا ہے؟   \n",
              "320                                                                                                                                          مشرقی لو فرانکن کے لئے \"پنیر\" نام کیا ہے؟   \n",
              "340                                                                                                                                         سپیکٹرم کا مخفف اصل میں کیسے لکھا گیا تھا؟   \n",
              "379                                                                                                                  اعمال 24 میں، ایک اور لفظ کیا ہے جس سے عیسائیوں کو پکارا جاتا ہے؟   \n",
              "424                                                                                                                         208 عیسوی میں ریڈ کلفس کی لڑائی میں کس کو شکست دی گئی تھی؟   \n",
              "517                                                                                                                                               بیونسے کی پہلی خوشبو کا نام کیا تھا؟   \n",
              "620                                                                                                                                 الاسکا میں ڈیموکریٹس نے کتنے انتخابات جیت لئے ہیں؟   \n",
              "681                                                                                                                                  کتنے bloody noses اسپیلبرگ ہائی اسکول میں مل گیا؟   \n",
              "750                                                                                                                                                 روسیوں نے یقین کیا کہ روس کیا تھے؟   \n",
              "755                                                                                                              افریقی امریکیوں کو داخل کرنے سے انکار کرنے کی وجہ سے آج کیا موجود ہے؟   \n",
              "768                                                                                                                                       ایگزیکٹو کونسل کس کے لئے ایک متبادل نام تھا؟   \n",
              "788                                                                                                                                      اشکنازی کا نام کس بائبل کی شخصیت سے ماخوذ ہے؟   \n",
              "852                                                                                                                                                     مصیبت کس چیز کا مرکزی تصور ہے؟   \n",
              "888                                                                                                                                       امینز کے معاہدے پر کس سال دستخط کیے گئے تھے؟   \n",
              "911                                                                                                                       سولہویں صدی میں کتنی بار کمشنرز کی طرف سے منظوری دی گئی تھی؟   \n",
              "927                                                                                                                     اسٹالمین کیا سوچتا ہے کہ اختیاری اور تجرباتی ہونے کا مطلب تھا؟   \n",
              "933                                                                                                                                   آسٹریلیا کی \"زہریلی بیلٹ\" کا مرکز کون سا شہر ہے؟   \n",
              "957                                                                                                         غیر متناسب تعداد میں افریقی امریکی اور لاطینی کمیونٹیز پر کیا اثر پڑتا ہے؟   \n",
              "978                                                                                                                                     پہلی جنگ عظیم میں یونان میں کتنی حکومتیں تھیں؟   \n",
              "1001                                                                                                                                       وکٹورین دور میں ایک مقبول سماجی سرگرمی تھی؟   \n",
              "1046                                                                                                                                 آئزن ہاور کے والدین ہر روز کون سی کتاب پڑھتے تھے؟   \n",
              "1054                                                                            اعصابی نظام کی ایک غیر معمولی تعداد لوگوں کی ایک چھوٹی سی تعداد کو کس چیز کے لئے غیر حساس بنا سکتی ہے؟   \n",
              "1056                                                                                                                                         1967 کے بعد غزہ کی پٹی پر کس نے قبضہ کیا؟   \n",
              "1087                                                                                                                                             مادہ کس چیز میں تبدیل کیا جا سکتا ہے؟   \n",
              "1094                                                                                       کیا بجھنے والی لائٹس زیادہ، کم، یا ایک ہی مقدار میں روشنی خارج کرتی ہیں جیسا کہ وہ عمر ہیں؟   \n",
              "1095                                                                                                                     ییل کی کچھ خفیہ سوسائٹی عمارتوں کے لئے ایک اور اصطلاح کیا ہے؟   \n",
              "1114                                                                                                                                                 وارسا میں بغاوت کس سال شروع ہوئی؟   \n",
              "1145                                                                                                                   کون سوچتا تھا کہ عظیم میدانوں Quivira اور Cíbola کے مقامات تھے؟   \n",
              "1260                                                                                                                         کس شہر کو 2008 میں چین کا ہیبیٹٹ رول آف آنر سے نوازا گیا؟   \n",
              "1286                                                                                                       کیا بلبوں کی زندگی دیگر روشنی کے ذرائع کے مقابلے میں طویل یا مختصر ہوتی ہے؟   \n",
              "1297                                                                                                                           اے این ایس آئی میں کون سے سال میں بڑی تبدیلیاں کی گئیں؟   \n",
              "1393  کیا تحقیق اس مفروضے کی حمایت کرتی ہے یا مسترد کرتی ہے کہ نوجوان اور بالغ خطرے کے بارے میں ایک جیسے سوچتے ہیں لیکن مختلف اقدار رکھتے ہیں اور اس وجہ سے مختلف نتائج پر پہنچتے ہیں؟   \n",
              "1526                                                                                                                           نیو ہیون طرز کے پیزا کو عام اصطلاح میں کیا کہا جاتا ہے؟   \n",
              "1565                                                                                 ایک بہت پرانے درخت میں، کیا آپ کو دل کی لکڑی یا سیپ لکڑی میں بہت سے گرہیں ملنے کا زیادہ امکان ہے؟   \n",
              "1609                                                                                         کون سا شہر کسی دوسرے کے مقابلے میں زیادہ V-1 اور V-2 میزائلوں کی طرف سے حملہ کیا گیا تھا؟   \n",
              "1618                                                                                                                           پرانی انگریزی نے کچھ الفاظ کس زبان سے قرضے میں لیے تھے؟   \n",
              "1639                                                                                                              اس ریڈیو فارمیٹ کا نام کیا ہے جو شہری اور نرم بالغ معاصر کا مرکب ہے؟   \n",
              "1807                                                                                                                                                            یوگوسلاویہ کب ٹوٹ گیا؟   \n",
              "1941                                                                                                                                            انگریزوں نے تووالو پر کس طرح حکومت کی؟   \n",
              "1991                                                                                                                          کون سا سیمی کنڈکٹر سب سے زیادہ الیکٹران موبلٹی رکھتا ہے؟   \n",
              "2021                                                                                                                            پال Ehrenfest نام \"الٹرا وایلیٹ تباہی\" کے ساتھ آئے جب؟   \n",
              "\n",
              "              Gold Answer Extracted Answer  Split  \n",
              "12                  توازن                   train  \n",
              "43                   لائن                   train  \n",
              "56                 تمباکو                   train  \n",
              "60                 میزائل                   train  \n",
              "92                   1866                   train  \n",
              "111            عرب اوریکس                   train  \n",
              "120                  سیلا                   train  \n",
              "222                میڈونا                   train  \n",
              "243                  پانچ                   train  \n",
              "246          گرمی کے علاج                   train  \n",
              "320               لیمبرگش                   train  \n",
              "340                سپیکٹر                   train  \n",
              "379                 ناصری                   train  \n",
              "424                   کاؤ                   train  \n",
              "517                   ہیٹ                   train  \n",
              "620                   ایک                   train  \n",
              "681                    دو                   train  \n",
              "750                  سلاو                   train  \n",
              "755   پرنس ہال فری میسنری                   train  \n",
              "768                کابینہ                   train  \n",
              "788                اشکناز                   train  \n",
              "852                بدھ مت                   train  \n",
              "888                  1802                   train  \n",
              "911                  پانچ                   train  \n",
              "927             کاپی رائٹ                   train  \n",
              "933               میلبورن                   train  \n",
              "957     بڑے پیمانے پر قید                   train  \n",
              "978                    دو                   train  \n",
              "1001      لومڑیوں کا شکار                   train  \n",
              "1046                بائبل                   train  \n",
              "1054                  درد                   train  \n",
              "1056              اسرائیل                   train  \n",
              "1087              توانائی                   train  \n",
              "1094                   کم                   train  \n",
              "1095                  قبر                   train  \n",
              "1114                 1830                   train  \n",
              "1145              ہسپانوی                   train  \n",
              "1260               نانجنگ                   train  \n",
              "1286                مختصر                   train  \n",
              "1297                 1960                   train  \n",
              "1393                 پسند                   train  \n",
              "1526                اپیزا                   train  \n",
              "1565           دل کی لکڑی                   train  \n",
              "1609              اینٹورپ                   train  \n",
              "1618               لاطینی                   train  \n",
              "1639          خاموش طوفان                   train  \n",
              "1807                 1991                   train  \n",
              "1941  برطانوی پروٹیکٹوریٹ                   train  \n",
              "1991            گا اے ایس                   train  \n",
              "2021                 1911                   train  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b031967b-1b03-4094-8ff9-9102b0199736\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Gold Answer</th>\n",
              "      <th>Extracted Answer</th>\n",
              "      <th>Split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>شکاری اور شکار کی بات چیت جس میں مہارت شامل ہوتی ہے اس کے نتیجے میں ایک توازن ہوتا ہے جسے کہا جاتا ہے؟</td>\n",
              "      <td>توازن</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>چینیوں کی طرف سے حملوں کی ایک مؤثر سیریز کے طور پر کیا شروع ہو سکتا ہے جس نے کس علاقے کو دوبارہ حاصل کیا؟</td>\n",
              "      <td>لائن</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>خانہ جنگی کے بعد ترقی کرنے والی پہلی بڑھتی ہوئی صنعتوں میں سے ایک کیا تھی؟</td>\n",
              "      <td>تمباکو</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>بندوق کے نظام کو مکمل طور پر تبدیل کرنے کا امکان کیا ہے؟</td>\n",
              "      <td>میزائل</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>کس سال کے دوران چیواوا کو دشمن کے کنٹرول سے آزاد قرار دیا گیا تھا؟</td>\n",
              "      <td>1866</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>کون سا جانور معجزاتی طور پر واپس آ گیا ہے اور اسے \"جنگل میں معدوم\" سے \"نقصان دہ\" میں اپ گریڈ کیا گیا ہے؟</td>\n",
              "      <td>عرب اوریکس</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>ایک عمل کیا ہے جو جسم کے ذریعے کیا جاتا ہے اور اس میں جان بوجھ کر کوشش شامل ہوتی ہے؟</td>\n",
              "      <td>سیلا</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>کون اپنی زیادہ تر موسیقی خود لکھتا اور تخلیق کرتا ہے؟</td>\n",
              "      <td>میڈونا</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>کتنے امریکی سرمایہ کاری کے بینکوں نے 2004 سے 2007 تک اپنے مالی لیوریج میں نمایاں اضافہ کیا؟</td>\n",
              "      <td>پانچ</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>اس کی خصوصیات کو تبدیل کرنے کے لئے کس طرح کا علاج کیا جا سکتا ہے؟</td>\n",
              "      <td>گرمی کے علاج</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>مشرقی لو فرانکن کے لئے \"پنیر\" نام کیا ہے؟</td>\n",
              "      <td>لیمبرگش</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>سپیکٹرم کا مخفف اصل میں کیسے لکھا گیا تھا؟</td>\n",
              "      <td>سپیکٹر</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>اعمال 24 میں، ایک اور لفظ کیا ہے جس سے عیسائیوں کو پکارا جاتا ہے؟</td>\n",
              "      <td>ناصری</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>208 عیسوی میں ریڈ کلفس کی لڑائی میں کس کو شکست دی گئی تھی؟</td>\n",
              "      <td>کاؤ</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>بیونسے کی پہلی خوشبو کا نام کیا تھا؟</td>\n",
              "      <td>ہیٹ</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>620</th>\n",
              "      <td>الاسکا میں ڈیموکریٹس نے کتنے انتخابات جیت لئے ہیں؟</td>\n",
              "      <td>ایک</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>کتنے bloody noses اسپیلبرگ ہائی اسکول میں مل گیا؟</td>\n",
              "      <td>دو</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750</th>\n",
              "      <td>روسیوں نے یقین کیا کہ روس کیا تھے؟</td>\n",
              "      <td>سلاو</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>755</th>\n",
              "      <td>افریقی امریکیوں کو داخل کرنے سے انکار کرنے کی وجہ سے آج کیا موجود ہے؟</td>\n",
              "      <td>پرنس ہال فری میسنری</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>768</th>\n",
              "      <td>ایگزیکٹو کونسل کس کے لئے ایک متبادل نام تھا؟</td>\n",
              "      <td>کابینہ</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>788</th>\n",
              "      <td>اشکنازی کا نام کس بائبل کی شخصیت سے ماخوذ ہے؟</td>\n",
              "      <td>اشکناز</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>852</th>\n",
              "      <td>مصیبت کس چیز کا مرکزی تصور ہے؟</td>\n",
              "      <td>بدھ مت</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>امینز کے معاہدے پر کس سال دستخط کیے گئے تھے؟</td>\n",
              "      <td>1802</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>911</th>\n",
              "      <td>سولہویں صدی میں کتنی بار کمشنرز کی طرف سے منظوری دی گئی تھی؟</td>\n",
              "      <td>پانچ</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>اسٹالمین کیا سوچتا ہے کہ اختیاری اور تجرباتی ہونے کا مطلب تھا؟</td>\n",
              "      <td>کاپی رائٹ</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>933</th>\n",
              "      <td>آسٹریلیا کی \"زہریلی بیلٹ\" کا مرکز کون سا شہر ہے؟</td>\n",
              "      <td>میلبورن</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>957</th>\n",
              "      <td>غیر متناسب تعداد میں افریقی امریکی اور لاطینی کمیونٹیز پر کیا اثر پڑتا ہے؟</td>\n",
              "      <td>بڑے پیمانے پر قید</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>پہلی جنگ عظیم میں یونان میں کتنی حکومتیں تھیں؟</td>\n",
              "      <td>دو</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>وکٹورین دور میں ایک مقبول سماجی سرگرمی تھی؟</td>\n",
              "      <td>لومڑیوں کا شکار</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1046</th>\n",
              "      <td>آئزن ہاور کے والدین ہر روز کون سی کتاب پڑھتے تھے؟</td>\n",
              "      <td>بائبل</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1054</th>\n",
              "      <td>اعصابی نظام کی ایک غیر معمولی تعداد لوگوں کی ایک چھوٹی سی تعداد کو کس چیز کے لئے غیر حساس بنا سکتی ہے؟</td>\n",
              "      <td>درد</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056</th>\n",
              "      <td>1967 کے بعد غزہ کی پٹی پر کس نے قبضہ کیا؟</td>\n",
              "      <td>اسرائیل</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1087</th>\n",
              "      <td>مادہ کس چیز میں تبدیل کیا جا سکتا ہے؟</td>\n",
              "      <td>توانائی</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1094</th>\n",
              "      <td>کیا بجھنے والی لائٹس زیادہ، کم، یا ایک ہی مقدار میں روشنی خارج کرتی ہیں جیسا کہ وہ عمر ہیں؟</td>\n",
              "      <td>کم</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>ییل کی کچھ خفیہ سوسائٹی عمارتوں کے لئے ایک اور اصطلاح کیا ہے؟</td>\n",
              "      <td>قبر</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1114</th>\n",
              "      <td>وارسا میں بغاوت کس سال شروع ہوئی؟</td>\n",
              "      <td>1830</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1145</th>\n",
              "      <td>کون سوچتا تھا کہ عظیم میدانوں Quivira اور Cíbola کے مقامات تھے؟</td>\n",
              "      <td>ہسپانوی</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>کس شہر کو 2008 میں چین کا ہیبیٹٹ رول آف آنر سے نوازا گیا؟</td>\n",
              "      <td>نانجنگ</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1286</th>\n",
              "      <td>کیا بلبوں کی زندگی دیگر روشنی کے ذرائع کے مقابلے میں طویل یا مختصر ہوتی ہے؟</td>\n",
              "      <td>مختصر</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1297</th>\n",
              "      <td>اے این ایس آئی میں کون سے سال میں بڑی تبدیلیاں کی گئیں؟</td>\n",
              "      <td>1960</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1393</th>\n",
              "      <td>کیا تحقیق اس مفروضے کی حمایت کرتی ہے یا مسترد کرتی ہے کہ نوجوان اور بالغ خطرے کے بارے میں ایک جیسے سوچتے ہیں لیکن مختلف اقدار رکھتے ہیں اور اس وجہ سے مختلف نتائج پر پہنچتے ہیں؟</td>\n",
              "      <td>پسند</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1526</th>\n",
              "      <td>نیو ہیون طرز کے پیزا کو عام اصطلاح میں کیا کہا جاتا ہے؟</td>\n",
              "      <td>اپیزا</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1565</th>\n",
              "      <td>ایک بہت پرانے درخت میں، کیا آپ کو دل کی لکڑی یا سیپ لکڑی میں بہت سے گرہیں ملنے کا زیادہ امکان ہے؟</td>\n",
              "      <td>دل کی لکڑی</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1609</th>\n",
              "      <td>کون سا شہر کسی دوسرے کے مقابلے میں زیادہ V-1 اور V-2 میزائلوں کی طرف سے حملہ کیا گیا تھا؟</td>\n",
              "      <td>اینٹورپ</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1618</th>\n",
              "      <td>پرانی انگریزی نے کچھ الفاظ کس زبان سے قرضے میں لیے تھے؟</td>\n",
              "      <td>لاطینی</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1639</th>\n",
              "      <td>اس ریڈیو فارمیٹ کا نام کیا ہے جو شہری اور نرم بالغ معاصر کا مرکب ہے؟</td>\n",
              "      <td>خاموش طوفان</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1807</th>\n",
              "      <td>یوگوسلاویہ کب ٹوٹ گیا؟</td>\n",
              "      <td>1991</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1941</th>\n",
              "      <td>انگریزوں نے تووالو پر کس طرح حکومت کی؟</td>\n",
              "      <td>برطانوی پروٹیکٹوریٹ</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1991</th>\n",
              "      <td>کون سا سیمی کنڈکٹر سب سے زیادہ الیکٹران موبلٹی رکھتا ہے؟</td>\n",
              "      <td>گا اے ایس</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021</th>\n",
              "      <td>پال Ehrenfest نام \"الٹرا وایلیٹ تباہی\" کے ساتھ آئے جب؟</td>\n",
              "      <td>1911</td>\n",
              "      <td></td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b031967b-1b03-4094-8ff9-9102b0199736')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b031967b-1b03-4094-8ff9-9102b0199736 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b031967b-1b03-4094-8ff9-9102b0199736');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1d11c3d9-91e1-40ba-8a21-23acbff2928e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1d11c3d9-91e1-40ba-8a21-23acbff2928e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1d11c3d9-91e1-40ba-8a21-23acbff2928e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Side-by-Side Comparison (First 10 Rows - Mixed):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                                                                                    Question  \\\n",
              "0                رچرڈسن نے دعویٰ کیا کہ شوارزنیگر کے پبلسسٹ اور اسسٹنٹ نے اسے بدنام کرنے کے لئے کس اخبار کا استعمال کیا تھا؟   \n",
              "1          کیا قانون منظور کیا گیا تھا جو Plebeian کونسل patrician سینیٹرز کی منظوری کے بغیر ایک بل پر غور کرنے کی اجازت دی؟   \n",
              "2                                  بیکر کا خیال تھا کہ الیکٹرولائٹک کیپسیٹرز کا کون سا جزو پورس کاربن الیکٹروڈس سے مختلف ہے؟   \n",
              "3                                     کون سی انگریزی کالونی نے ایسے قوانین منظور کیے جنہوں نے بچوں کو باپ کی سماجی حیثیت دی؟   \n",
              "4                                                         ایک مشین کو اس کے صارف کی طرف سے رسائی حاصل کرنے کی اجازت دیتا ہے؟   \n",
              "5                                                                       تاجکستان کے اسکول کے نظام میں اسکول کے کتنے سال ہیں؟   \n",
              "6                                                                10 میگاواٹ سے کم ہائیڈرو پلانٹ سے بجلی کی اوسط لاگت کیا ہے؟   \n",
              "7                                                                          صنعاء کے مخطوطات کس سال سے پہلے تیار کیے گئے تھے؟   \n",
              "8                        پوپ فرانسس نے دنیا بھر میں سنتوں کے تہواروں کے جنرل رومن کیلنڈر میں اپنی اختیاری یادگار کب شامل کی؟   \n",
              "9                                                       13 ویں اور 14 ویں صدی کے دوران فرانس میں کون سا بڑا تنازعہ پیدا ہوا؟   \n",
              "10                                                                               ہندوستان کی تجارتی نوآبادیات کب شروع ہوئیں؟   \n",
              "11                                                    انیسویں صدی کے بعد یونانی آبادی کا کتنا حصہ چھوٹے ایشیا میں مقیم تھا ؟   \n",
              "12                    شکاری اور شکار کی بات چیت جس میں مہارت شامل ہوتی ہے اس کے نتیجے میں ایک توازن ہوتا ہے جسے کہا جاتا ہے؟   \n",
              "13                                                                         کس سال میں سینٹر جارج Pompidou تعمیر کیا گیا تھا؟   \n",
              "14                                                   جب یہ نیبراسکا میں ووٹنگ پر تھا تو ترمیم 36 کو کس طرح بیان کیا گیا تھا؟   \n",
              "15                                                                         \"امریکی نوآبادیاتی سوسائٹی\" کی بنیاد کب رکھی گئی؟   \n",
              "16                                                                                لومبارڈی نے کتنے آکٹیوز کا احاطہ نہیں کیا؟   \n",
              "17         تجربے، فنکشن اور جذبات کی اصل کے ساتھ ساتھ، جذبات کا کون سا پہلو موجودہ تحقیق کی وضاحت کرنے کی کوشش نہیں کرتا ہے؟   \n",
              "18                                              کون سا مدمقابل ایک بالغ ویب سائٹ کے لئے ماڈلنگ کے لئے شو سے ہٹا دیا گیا تھا؟   \n",
              "19                                                                                         کورک اوپیرا ہاؤس اصل سائٹ کیا ہے؟   \n",
              "20                                                                   کتنے Synergistic پروسیسنگ عناصر ایک PS3 کے CUP میں ہیں؟   \n",
              "21                                           1984 کے بعد کا جائزہ لینے والے کھانے کی اشیاء کا دوبارہ جائزہ کیوں لیا جاتا ہے؟   \n",
              "22                ان فلموں کی دو مثالیں کیا ہیں جو ان کی حقیقی آئی ایس او رفتار سے اوپر کی رفتار کے ساتھ مارکیٹ کی جاتی ہیں؟   \n",
              "23                                                                             کس امریکی محکمہ نے ان الزامات کی تحقیقات کیں؟   \n",
              "24                                                                          کچھ ڈھانچے کس چیز کی حفاظت کے لیے تیار ہوئے ہیں؟   \n",
              "25                       مقامی یونیورسٹیوں کو سرکاری اسکول اضلاع میں طلباء کے لئے مواقع کو کم کرنے کی حوصلہ افزائی کس نے کی؟   \n",
              "26                                                        کون سی نشانیاں بت پرستوں کے رسم و رواج کو خراج تحسین پیش کرتی ہیں؟   \n",
              "27                                                          اتنے لمبے عرصے تک فارم کا کام کرنے کے بعد بچے کام کرنے کہاں گئے؟   \n",
              "28                                                                                کس نے کہا کہ ہم مستقبل میں موجود نہیں ہیں؟   \n",
              "29                                               اسپیکٹر نے امریکہ اور کینیڈا میں اپنے پہلے ہفتے کے آخر میں کتنا پیسہ کمایا؟   \n",
              "30                                                      کون سا کپتان 1775 میں دنیا کے ارد گرد اپنے سفر پر جزیرے کا دورہ کیا؟   \n",
              "31                                                                                                     ہاکین کا کیا مطلب ہے؟   \n",
              "32                                                                                   نیو یارک میں سٹی ہاکس کے کتنے سیزن تھے؟   \n",
              "33                                                  ہومو فلوریسینسیس کتنی دیر پہلے زندہ تھا اس سے پہلے کہ وہ معدوم ہو جائیں؟   \n",
              "34  عدالتوں کی طرف سے اہم رہائش گاہ پر عائد حدود کو ختم کرنے کے بعد، اہم رہائش گاہوں کو بنیادی طور پر کہاں قائم کیا گیا تھا؟   \n",
              "35                                                                      اس کے نتیجے میں سالسبری اور Kilmuir کس سے مشورہ کیا؟   \n",
              "36                             جیسا کہ کارٹریجز نائنٹینڈو کو واپس نہیں کیا جا سکتا تھا، ڈویلپرز نے کیا کی مجموعی طور پر لیا؟   \n",
              "37                                                 1992 میں دیئے گئے مجموعی بیچلر کی ڈگریوں میں سے کتنے لاطینیوں کو گئے تھے؟   \n",
              "38                                                                                   پوپر نے 1982 میں کون سا ایوارڈ کھو دیا؟   \n",
              "39                                                                      ایل ای ڈی بریک لائٹس بلبوں سے کتنے گنا تیز ہوتی ہیں؟   \n",
              "40                                                                   دریائے تمار ڈیون اور کس دوسری کاؤنٹی کے درمیان سرحد ہے؟   \n",
              "41                                                                                                 کس وارڈ میں 10 ارکان ہیں؟   \n",
              "42                                      کیا سوال اٹھانے والے کا خیال تھا کہ مریم کے تصور کے تہوار کو منعقد کرنے کی اجازت ہے؟   \n",
              "43                 چینیوں کی طرف سے حملوں کی ایک مؤثر سیریز کے طور پر کیا شروع ہو سکتا ہے جس نے کس علاقے کو دوبارہ حاصل کیا؟   \n",
              "44                                                                                ڈیبرا برڈ امریکن آئیڈل پر کیا کام کرتی ہے؟   \n",
              "45                                                                                      ایسٹونیا خود کتنی بجلی پیدا کرتا ہے؟   \n",
              "46                                                                         \"پورگی\" پر مبنی \"لوک اوپیرا\" کا نام کیا نہیں تھا؟   \n",
              "47                                                        گنز این روزز کے طویل عرصے سے تاخیر سے 2008 کے البم کا نام کیا تھا؟   \n",
              "48                                                            بیسویں صدی میں اس خطے کے سب سے زیادہ بااثر فولڈ آرٹسٹ کون تھے؟   \n",
              "49                               اس فلم کا نام کیا ہے جس میں فین مین کی تووا سے فرار ہونے کی کوشش پر تبادلہ خیال کیا گیا ہے؟   \n",
              "\n",
              "                                                                                                                   Gold Answer  \\\n",
              "0                                                                                                             لاس اینجلس ٹائمز   \n",
              "1                                                                                                               لیکس ہورٹینسیا   \n",
              "2                                                                                                                                \n",
              "3                                                                                                                                \n",
              "4                                                                                                                                \n",
              "5                                                                                            11 سال کی پرائمری اور ثانوی تعلیم   \n",
              "6                                                                                                                                \n",
              "7                                                                                                                       671 AD   \n",
              "8                                                                                                                11 ستمبر 2014   \n",
              "9                                                                                                                  سو سالہ جنگ   \n",
              "10                                                                                                                        1757   \n",
              "11  20 ویں صدی کے اوائل تک ، مجموعی طور پر یونانی بولنے والی آبادی کا نصف سے زیادہ حصہ ایشیاء مائنر (اب ترکی) میں آباد ہوا تھا   \n",
              "12                                                                                                                       توازن   \n",
              "13                                                                                                                        1977   \n",
              "14                                                                                                                               \n",
              "15                                                                                                                        1816   \n",
              "16                                                                                                                               \n",
              "17                                                                                                                               \n",
              "18                                                                                                               فرانسیسی ڈیوس   \n",
              "19                                                                                                                               \n",
              "20                                                                                                                               \n",
              "21                                                                                                                               \n",
              "22                                                                                 ایلفورڈ ڈیلٹا 3200 اور کوڈک ٹی میکس پی 3200   \n",
              "23                                                                                                          ڈیپارٹمنٹ آف اسٹیٹ   \n",
              "24                                                                                                                  اسپوروفیلز   \n",
              "25                                                                                                                               \n",
              "26                                                                                                                               \n",
              "27                                                                                                               فیکٹری کے کام   \n",
              "28                                                                                                                               \n",
              "29                                                                                                              70.4 ملین ڈالر   \n",
              "30                                                                                                                     جیمز کک   \n",
              "31                                                                                                                 فوجیان صوبہ   \n",
              "32                                                                                                                          دو   \n",
              "33                                                                                                             12،000 سال پہلے   \n",
              "34                                                                                   ہوائی ، کیلیفورنیا اور دیگر مغربی ریاستوں   \n",
              "35                                                                                                              برطانوی کابینہ   \n",
              "36                                                                                                                        خطرہ   \n",
              "37                                                                                                                               \n",
              "38                                                                                                                               \n",
              "39                                                                                                                   0.5 سیکنڈ   \n",
              "40                                                                                                                    کارن وال   \n",
              "41                                                                                                                               \n",
              "42                                                                       پاکیزہ نشست کی اجازت کے بغیر اس طرح کا تہوار قائم کیا   \n",
              "43                                                                                                                        لائن   \n",
              "44                                                                                                                     گول کوچ   \n",
              "45                                                                                                                         75٪   \n",
              "46                                                                                                                               \n",
              "47                                                                                                                چینی جمہوریت   \n",
              "48                                                                                                                  دی اسپینرز   \n",
              "49                                                                                                                               \n",
              "\n",
              "      Extracted Answer  Match  \n",
              "0     لاس اینجلس ٹائمز   True  \n",
              "1                       False  \n",
              "2                        True  \n",
              "3                        True  \n",
              "4                        True  \n",
              "5                       False  \n",
              "6                        True  \n",
              "7               671 AD   True  \n",
              "8        11 ستمبر 2014   True  \n",
              "9                       False  \n",
              "10                      False  \n",
              "11                      False  \n",
              "12                      False  \n",
              "13                1977   True  \n",
              "14                       True  \n",
              "15                1816   True  \n",
              "16                       True  \n",
              "17                       True  \n",
              "18       فرانسیسی ڈیوس   True  \n",
              "19                       True  \n",
              "20                       True  \n",
              "21                       True  \n",
              "22                      False  \n",
              "23  ڈیپارٹمنٹ آف اسٹیٹ   True  \n",
              "24                      False  \n",
              "25                       True  \n",
              "26                       True  \n",
              "27                      False  \n",
              "28                       True  \n",
              "29      70.4 ملین ڈالر   True  \n",
              "30                      False  \n",
              "31         فوجیان صوبہ   True  \n",
              "32                      False  \n",
              "33                      False  \n",
              "34                      False  \n",
              "35      برطانوی کابینہ   True  \n",
              "36                      False  \n",
              "37                       True  \n",
              "38                       True  \n",
              "39                      False  \n",
              "40            کارن وال   True  \n",
              "41                       True  \n",
              "42                      False  \n",
              "43                      False  \n",
              "44                      False  \n",
              "45                 75٪   True  \n",
              "46                       True  \n",
              "47                      False  \n",
              "48          دی اسپینرز   True  \n",
              "49                       True  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e7f2fa9-87ea-4c19-9d80-e34604006303\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Gold Answer</th>\n",
              "      <th>Extracted Answer</th>\n",
              "      <th>Match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>رچرڈسن نے دعویٰ کیا کہ شوارزنیگر کے پبلسسٹ اور اسسٹنٹ نے اسے بدنام کرنے کے لئے کس اخبار کا استعمال کیا تھا؟</td>\n",
              "      <td>لاس اینجلس ٹائمز</td>\n",
              "      <td>لاس اینجلس ٹائمز</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>کیا قانون منظور کیا گیا تھا جو Plebeian کونسل patrician سینیٹرز کی منظوری کے بغیر ایک بل پر غور کرنے کی اجازت دی؟</td>\n",
              "      <td>لیکس ہورٹینسیا</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>بیکر کا خیال تھا کہ الیکٹرولائٹک کیپسیٹرز کا کون سا جزو پورس کاربن الیکٹروڈس سے مختلف ہے؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>کون سی انگریزی کالونی نے ایسے قوانین منظور کیے جنہوں نے بچوں کو باپ کی سماجی حیثیت دی؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ایک مشین کو اس کے صارف کی طرف سے رسائی حاصل کرنے کی اجازت دیتا ہے؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>تاجکستان کے اسکول کے نظام میں اسکول کے کتنے سال ہیں؟</td>\n",
              "      <td>11 سال کی پرائمری اور ثانوی تعلیم</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>10 میگاواٹ سے کم ہائیڈرو پلانٹ سے بجلی کی اوسط لاگت کیا ہے؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>صنعاء کے مخطوطات کس سال سے پہلے تیار کیے گئے تھے؟</td>\n",
              "      <td>671 AD</td>\n",
              "      <td>671 AD</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>پوپ فرانسس نے دنیا بھر میں سنتوں کے تہواروں کے جنرل رومن کیلنڈر میں اپنی اختیاری یادگار کب شامل کی؟</td>\n",
              "      <td>11 ستمبر 2014</td>\n",
              "      <td>11 ستمبر 2014</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>13 ویں اور 14 ویں صدی کے دوران فرانس میں کون سا بڑا تنازعہ پیدا ہوا؟</td>\n",
              "      <td>سو سالہ جنگ</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ہندوستان کی تجارتی نوآبادیات کب شروع ہوئیں؟</td>\n",
              "      <td>1757</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>انیسویں صدی کے بعد یونانی آبادی کا کتنا حصہ چھوٹے ایشیا میں مقیم تھا ؟</td>\n",
              "      <td>20 ویں صدی کے اوائل تک ، مجموعی طور پر یونانی بولنے والی آبادی کا نصف سے زیادہ حصہ ایشیاء مائنر (اب ترکی) میں آباد ہوا تھا</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>شکاری اور شکار کی بات چیت جس میں مہارت شامل ہوتی ہے اس کے نتیجے میں ایک توازن ہوتا ہے جسے کہا جاتا ہے؟</td>\n",
              "      <td>توازن</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>کس سال میں سینٹر جارج Pompidou تعمیر کیا گیا تھا؟</td>\n",
              "      <td>1977</td>\n",
              "      <td>1977</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>جب یہ نیبراسکا میں ووٹنگ پر تھا تو ترمیم 36 کو کس طرح بیان کیا گیا تھا؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>\"امریکی نوآبادیاتی سوسائٹی\" کی بنیاد کب رکھی گئی؟</td>\n",
              "      <td>1816</td>\n",
              "      <td>1816</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>لومبارڈی نے کتنے آکٹیوز کا احاطہ نہیں کیا؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>تجربے، فنکشن اور جذبات کی اصل کے ساتھ ساتھ، جذبات کا کون سا پہلو موجودہ تحقیق کی وضاحت کرنے کی کوشش نہیں کرتا ہے؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>کون سا مدمقابل ایک بالغ ویب سائٹ کے لئے ماڈلنگ کے لئے شو سے ہٹا دیا گیا تھا؟</td>\n",
              "      <td>فرانسیسی ڈیوس</td>\n",
              "      <td>فرانسیسی ڈیوس</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>کورک اوپیرا ہاؤس اصل سائٹ کیا ہے؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>کتنے Synergistic پروسیسنگ عناصر ایک PS3 کے CUP میں ہیں؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1984 کے بعد کا جائزہ لینے والے کھانے کی اشیاء کا دوبارہ جائزہ کیوں لیا جاتا ہے؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>ان فلموں کی دو مثالیں کیا ہیں جو ان کی حقیقی آئی ایس او رفتار سے اوپر کی رفتار کے ساتھ مارکیٹ کی جاتی ہیں؟</td>\n",
              "      <td>ایلفورڈ ڈیلٹا 3200 اور کوڈک ٹی میکس پی 3200</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>کس امریکی محکمہ نے ان الزامات کی تحقیقات کیں؟</td>\n",
              "      <td>ڈیپارٹمنٹ آف اسٹیٹ</td>\n",
              "      <td>ڈیپارٹمنٹ آف اسٹیٹ</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>کچھ ڈھانچے کس چیز کی حفاظت کے لیے تیار ہوئے ہیں؟</td>\n",
              "      <td>اسپوروفیلز</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>مقامی یونیورسٹیوں کو سرکاری اسکول اضلاع میں طلباء کے لئے مواقع کو کم کرنے کی حوصلہ افزائی کس نے کی؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>کون سی نشانیاں بت پرستوں کے رسم و رواج کو خراج تحسین پیش کرتی ہیں؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>اتنے لمبے عرصے تک فارم کا کام کرنے کے بعد بچے کام کرنے کہاں گئے؟</td>\n",
              "      <td>فیکٹری کے کام</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>کس نے کہا کہ ہم مستقبل میں موجود نہیں ہیں؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>اسپیکٹر نے امریکہ اور کینیڈا میں اپنے پہلے ہفتے کے آخر میں کتنا پیسہ کمایا؟</td>\n",
              "      <td>70.4 ملین ڈالر</td>\n",
              "      <td>70.4 ملین ڈالر</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>کون سا کپتان 1775 میں دنیا کے ارد گرد اپنے سفر پر جزیرے کا دورہ کیا؟</td>\n",
              "      <td>جیمز کک</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>ہاکین کا کیا مطلب ہے؟</td>\n",
              "      <td>فوجیان صوبہ</td>\n",
              "      <td>فوجیان صوبہ</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>نیو یارک میں سٹی ہاکس کے کتنے سیزن تھے؟</td>\n",
              "      <td>دو</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>ہومو فلوریسینسیس کتنی دیر پہلے زندہ تھا اس سے پہلے کہ وہ معدوم ہو جائیں؟</td>\n",
              "      <td>12،000 سال پہلے</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>عدالتوں کی طرف سے اہم رہائش گاہ پر عائد حدود کو ختم کرنے کے بعد، اہم رہائش گاہوں کو بنیادی طور پر کہاں قائم کیا گیا تھا؟</td>\n",
              "      <td>ہوائی ، کیلیفورنیا اور دیگر مغربی ریاستوں</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>اس کے نتیجے میں سالسبری اور Kilmuir کس سے مشورہ کیا؟</td>\n",
              "      <td>برطانوی کابینہ</td>\n",
              "      <td>برطانوی کابینہ</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>جیسا کہ کارٹریجز نائنٹینڈو کو واپس نہیں کیا جا سکتا تھا، ڈویلپرز نے کیا کی مجموعی طور پر لیا؟</td>\n",
              "      <td>خطرہ</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1992 میں دیئے گئے مجموعی بیچلر کی ڈگریوں میں سے کتنے لاطینیوں کو گئے تھے؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>پوپر نے 1982 میں کون سا ایوارڈ کھو دیا؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>ایل ای ڈی بریک لائٹس بلبوں سے کتنے گنا تیز ہوتی ہیں؟</td>\n",
              "      <td>0.5 سیکنڈ</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>دریائے تمار ڈیون اور کس دوسری کاؤنٹی کے درمیان سرحد ہے؟</td>\n",
              "      <td>کارن وال</td>\n",
              "      <td>کارن وال</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>کس وارڈ میں 10 ارکان ہیں؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>کیا سوال اٹھانے والے کا خیال تھا کہ مریم کے تصور کے تہوار کو منعقد کرنے کی اجازت ہے؟</td>\n",
              "      <td>پاکیزہ نشست کی اجازت کے بغیر اس طرح کا تہوار قائم کیا</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>چینیوں کی طرف سے حملوں کی ایک مؤثر سیریز کے طور پر کیا شروع ہو سکتا ہے جس نے کس علاقے کو دوبارہ حاصل کیا؟</td>\n",
              "      <td>لائن</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>ڈیبرا برڈ امریکن آئیڈل پر کیا کام کرتی ہے؟</td>\n",
              "      <td>گول کوچ</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>ایسٹونیا خود کتنی بجلی پیدا کرتا ہے؟</td>\n",
              "      <td>75٪</td>\n",
              "      <td>75٪</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>\"پورگی\" پر مبنی \"لوک اوپیرا\" کا نام کیا نہیں تھا؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>گنز این روزز کے طویل عرصے سے تاخیر سے 2008 کے البم کا نام کیا تھا؟</td>\n",
              "      <td>چینی جمہوریت</td>\n",
              "      <td></td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>بیسویں صدی میں اس خطے کے سب سے زیادہ بااثر فولڈ آرٹسٹ کون تھے؟</td>\n",
              "      <td>دی اسپینرز</td>\n",
              "      <td>دی اسپینرز</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>اس فلم کا نام کیا ہے جس میں فین مین کی تووا سے فرار ہونے کی کوشش پر تبادلہ خیال کیا گیا ہے؟</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e7f2fa9-87ea-4c19-9d80-e34604006303')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6e7f2fa9-87ea-4c19-9d80-e34604006303 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6e7f2fa9-87ea-4c19-9d80-e34604006303');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b4c332ea-cc88-44f1-957a-7ff798f7e1cb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b4c332ea-cc88-44f1-957a-7ff798f7e1cb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b4c332ea-cc88-44f1-957a-7ff798f7e1cb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(results_df[[\\\"Question\\\", \\\"Gold Answer\\\", \\\"Extracted Answer\\\", \\\"Match\\\"]]\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 50,\n        \"samples\": [\n          \"\\u06a9\\u0633 \\u0633\\u0627\\u0644 \\u0645\\u06cc\\u06ba \\u0633\\u06cc\\u0646\\u0679\\u0631 \\u062c\\u0627\\u0631\\u062c Pompidou \\u062a\\u0639\\u0645\\u06cc\\u0631 \\u06a9\\u06cc\\u0627 \\u06af\\u06cc\\u0627 \\u062a\\u06be\\u0627\\u061f\",\n          \"\\u0627\\u06cc\\u0644 \\u0627\\u06cc \\u0688\\u06cc \\u0628\\u0631\\u06cc\\u06a9 \\u0644\\u0627\\u0626\\u0679\\u0633 \\u0628\\u0644\\u0628\\u0648\\u06ba \\u0633\\u06d2 \\u06a9\\u062a\\u0646\\u06d2 \\u06af\\u0646\\u0627 \\u062a\\u06cc\\u0632 \\u06c1\\u0648\\u062a\\u06cc \\u06c1\\u06cc\\u06ba\\u061f\",\n          \"\\u06a9\\u0648\\u0646 \\u0633\\u0627 \\u06a9\\u067e\\u062a\\u0627\\u0646 1775 \\u0645\\u06cc\\u06ba \\u062f\\u0646\\u06cc\\u0627 \\u06a9\\u06d2 \\u0627\\u0631\\u062f \\u06af\\u0631\\u062f \\u0627\\u067e\\u0646\\u06d2 \\u0633\\u0641\\u0631 \\u067e\\u0631 \\u062c\\u0632\\u06cc\\u0631\\u06d2 \\u06a9\\u0627 \\u062f\\u0648\\u0631\\u06c1 \\u06a9\\u06cc\\u0627\\u061f\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gold Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 33,\n        \"samples\": [\n          \"\\u0686\\u06cc\\u0646\\u06cc \\u062c\\u0645\\u06c1\\u0648\\u0631\\u06cc\\u062a\",\n          \"\\u0627\\u0633\\u067e\\u0648\\u0631\\u0648\\u0641\\u06cc\\u0644\\u0632\",\n          \"\\u06a9\\u0627\\u0631\\u0646 \\u0648\\u0627\\u0644\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Extracted Answer\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"\\u0641\\u0648\\u062c\\u06cc\\u0627\\u0646 \\u0635\\u0648\\u0628\\u06c1\",\n          \"\\u06a9\\u0627\\u0631\\u0646 \\u0648\\u0627\\u0644\",\n          \"\\u0644\\u0627\\u0633 \\u0627\\u06cc\\u0646\\u062c\\u0644\\u0633 \\u0679\\u0627\\u0626\\u0645\\u0632\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Match\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          false,\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 43
    },
    {
      "id": "e67abc12",
      "cell_type": "code",
      "source": [
        "# Accuracy: fraction of rows where extracted answer matches gold answer\n",
        "accuracy = (results_df[\"Match\"]).mean()\n",
        "\n",
        "# Precision: among rows where extracted answer is non-empty, fraction that matches gold\n",
        "# We filter out cases where the model predicted nothing (empty string) or just whitespace\n",
        "non_empty_pred = results_df[\"Extracted Answer\"].str.strip() != \"\"\n",
        "\n",
        "# Avoid division by zero if no predictions were made\n",
        "if non_empty_pred.sum() > 0:\n",
        "    precision = (results_df[\"Match\"] & non_empty_pred).sum() / non_empty_pred.sum()\n",
        "else:\n",
        "    precision = 0.0\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.3f}\")\n",
        "print(f\"Precision: {precision:.3f}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2025-11-25T10:15:46.373305Z",
          "iopub.status.idle": "2025-11-25T10:15:46.373561Z",
          "shell.execute_reply.started": "2025-11-25T10:15:46.373453Z",
          "shell.execute_reply": "2025-11-25T10:15:46.373463Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e67abc12",
        "outputId": "c597ec41-a56e-4e5d-9eb6-e71bd0eafd38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.578\n",
            "Precision: 1.000\n"
          ]
        }
      ],
      "execution_count": 44
    }
  ]
}