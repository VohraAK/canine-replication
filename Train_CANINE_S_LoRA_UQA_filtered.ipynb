{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"0","cell_type":"code","source":"# %pip install peft evaluate transformers Levenshtein ipywidgets\n# %pip install protobuf==3.20.3\n# !rm -rf /kaggle/working/cache\n# !rm -rf /kaggle/working/outputs","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:44:59.362581Z","iopub.execute_input":"2025-12-14T13:44:59.362872Z","iopub.status.idle":"2025-12-14T13:44:59.366781Z","shell.execute_reply.started":"2025-12-14T13:44:59.362852Z","shell.execute_reply":"2025-12-14T13:44:59.366043Z"},"id":"c186240c","trusted":true},"outputs":[],"execution_count":79},{"id":"1","cell_type":"code","source":"# X\n\nimport os\nos.environ[\"TRANSFORMERS_DISABLE_CHAT_TEMPLATES\"] = \"1\"\nos.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\nos.environ[\"TRANSFORMERS_NO_ADDITIONAL_CHAT_TEMPLATES\"] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:44:59.367895Z","iopub.execute_input":"2025-12-14T13:44:59.368201Z","iopub.status.idle":"2025-12-14T13:44:59.382698Z","shell.execute_reply.started":"2025-12-14T13:44:59.368184Z","shell.execute_reply":"2025-12-14T13:44:59.381956Z"},"id":"cd8da8ab","trusted":true},"outputs":[],"execution_count":80},{"id":"2","cell_type":"code","source":"import random\nfrom datasets import load_dataset, load_from_disk\nfrom transformers import CanineTokenizer\nfrom peft import LoraConfig, TaskType, get_peft_model\nimport re\nimport string\nfrom collections import Counter\nimport numpy as np\nimport Levenshtein\n\nfrom transformers import TrainingArguments, Trainer, TrainerCallback\nimport json\nfrom huggingface_hub import HfApi, notebook_login, whoami","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:44:59.492240Z","iopub.execute_input":"2025-12-14T13:44:59.492438Z","iopub.status.idle":"2025-12-14T13:44:59.496397Z","shell.execute_reply.started":"2025-12-14T13:44:59.492421Z","shell.execute_reply":"2025-12-14T13:44:59.495826Z"},"id":"d87eba82","trusted":true},"outputs":[],"execution_count":81},{"id":"3","cell_type":"code","source":"# notebook_login()\n# whoami()","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:44:59.497497Z","iopub.execute_input":"2025-12-14T13:44:59.497711Z","iopub.status.idle":"2025-12-14T13:44:59.511906Z","shell.execute_reply.started":"2025-12-14T13:44:59.497693Z","shell.execute_reply":"2025-12-14T13:44:59.511363Z"},"id":"0e98cebe-4c08-4850-b3c1-1529564fdb1b","trusted":true},"outputs":[],"execution_count":82},{"id":"4","cell_type":"code","source":"from transformers import CanineTokenizer, CanineForQuestionAnswering\nimport torch\nmodel_name = 'google/canine-s'\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n\ntokenizer = CanineTokenizer.from_pretrained(model_name, use_fast=False, trust_remote_code=False)\nmodel = CanineForQuestionAnswering.from_pretrained(model_name, trust_remote_code=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-14T13:44:59.512541Z","iopub.execute_input":"2025-12-14T13:44:59.512742Z","iopub.status.idle":"2025-12-14T13:45:01.309557Z","shell.execute_reply.started":"2025-12-14T13:44:59.512721Z","shell.execute_reply":"2025-12-14T13:45:01.308939Z"},"id":"f2dd5a40","outputId":"140c30ea-575d-45cd-ea54-7818cdfe6bf5","trusted":true},"outputs":[{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":83},{"id":"f75a7e9b","cell_type":"code","source":"# funtion to  filter out impossible questions\ndef filter_function(example):\n    return not example['is_impossible']","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:01.311160Z","iopub.execute_input":"2025-12-14T13:45:01.311372Z","iopub.status.idle":"2025-12-14T13:45:01.315225Z","shell.execute_reply.started":"2025-12-14T13:45:01.311355Z","shell.execute_reply":"2025-12-14T13:45:01.314618Z"},"trusted":true},"outputs":[],"execution_count":84},{"id":"5","cell_type":"code","source":"uqa_dataset = load_dataset(\"uqa/UQA\")\n\n# filtering\nuqa_dataset_filtered = uqa_dataset.filter(filter_function)\n\n# uqa_train = uqa_dataset_filtered[\"train\"].shuffle(seed=42)\n# uqa_val = uqa_dataset_filtered[\"validation\"].shuffle(seed=42)\n\n# now trying the filtered dataset\nuqa_train = uqa_dataset_filtered['train'].shuffle(seed=42).select(range(80000))\nuqa_val = uqa_dataset_filtered['validation'].shuffle(seed=42).select(range(8000))\n\nprint(f\"üìä Dataset after filtering:\")\nprint(f\"   Original train size: {len(uqa_dataset['train']):,}\")\nprint(f\"   Filtered train size: {len(uqa_dataset_filtered['train']):,}\")\nprint(f\"   Using for training: {len(uqa_train):,}\")\nprint(f\"   Validation size: {len(uqa_val):,}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:01.316073Z","iopub.execute_input":"2025-12-14T13:45:01.316572Z","iopub.status.idle":"2025-12-14T13:45:03.154840Z","shell.execute_reply.started":"2025-12-14T13:45:01.316555Z","shell.execute_reply":"2025-12-14T13:45:03.154118Z"},"id":"d474e2e8","trusted":true},"outputs":[{"name":"stdout","text":"üìä Dataset after filtering:\n   Original train size: 124,745\n   Filtered train size: 83,018\n   Using for training: 80,000\n   Validation size: 8,000\n","output_type":"stream"}],"execution_count":85},{"id":"297e1ff7-52f6-4981-b360-45141788f2f4","cell_type":"code","source":"# Check character-token alignment\nex = uqa_train[444]\ncontext = ex[\"context\"]\ncontext_tokens = tokenizer.encode(ex[\"context\"], add_special_tokens=False)\n\nprint(f\"Context length (characters): {len(context)}\")\nprint(f\"Context length (tokens): {len(context_tokens)}\")\nprint(f\"1:1 mapping: {len(context) == len(context_tokens)}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:03.155614Z","iopub.execute_input":"2025-12-14T13:45:03.155969Z","iopub.status.idle":"2025-12-14T13:45:03.162590Z","shell.execute_reply.started":"2025-12-14T13:45:03.155942Z","shell.execute_reply":"2025-12-14T13:45:03.161945Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Context length (characters): 1850\nContext length (tokens): 1850\n1:1 mapping: True\n","output_type":"stream"}],"execution_count":86},{"id":"6","cell_type":"code","source":"# Explore raw UQA dataset structure\nprint(\"=\"*80)\nprint(\"UQA DATASET STRUCTURE\")\nprint(\"=\"*80)\nprint(f\"Training set size: {len(uqa_train):,} examples\")\nprint(f\"Validation set size: {len(uqa_val):,} examples\")\nprint(f\"\\nDataset columns: {uqa_train.column_names}\")\nprint(\"\\n\" + \"=\"*80)\n\n# Show a few examples\nprint(\"\\nüìù EXAMPLE 1 - Question with Answer\")\nprint(\"=\"*80)\nex1 = uqa_train[0]\nprint(f\"Question: {ex1['question']}\")\nprint(f\"\\nContext (first 300 chars): {ex1['context'][:300]}...\")\nprint(f\"\\nAnswer: '{ex1['answer']}'\")\nprint(f\"Answer starts at character position: {ex1['answer_start']}\")\n\n# Verify the answer extraction\nif ex1['answer_start'] != -1:\n    extracted = ex1['context'][ex1['answer_start']:ex1['answer_start']+len(ex1['answer'])]\n    print(f\"‚úì Extracted from context: '{extracted}'\")\n    print(f\"‚úì Match: {extracted == ex1['answer']}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\\nüìù EXAMPLE 2 - Another Question\")\nprint(\"=\"*80)\nex2 = uqa_train[100]\nprint(f\"Question: {ex2['question']}\")\nprint(f\"\\nContext length: {len(ex2['context'])} characters\")\nprint(f\"Answer: '{ex2['answer']}'\")\nprint(f\"Answer starts at position: {ex2['answer_start']}\")\n\n# Show answer in context\nif ex2['answer_start'] != -1:\n    start = max(0, ex2['answer_start'] - 50)\n    end = min(len(ex2['context']), ex2['answer_start'] + len(ex2['answer']) + 50)\n    context_snippet = ex2['context'][start:end]\n    answer_pos = ex2['answer_start'] - start\n    print(f\"\\nContext around answer:\")\n    print(f\"...{context_snippet}...\")\n    print(f\"    {' '*answer_pos}{'~'*len(ex2['answer'])} (answer here)\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\\nüìä DATASET STATISTICS\")\nprint(\"=\"*80)\n\n# Compute some basic statistics\nimport numpy as np\nquestion_lengths = [len(ex['question']) for ex in uqa_train.select(range(1000))]\ncontext_lengths = [len(ex['context']) for ex in uqa_train.select(range(1000))]\nanswer_lengths = [len(ex['answer']) if ex['answer'] else 0 for ex in uqa_train.select(range(1000))]\nhas_answer = [ex['answer_start'] != -1 for ex in uqa_train.select(range(1000))]\n\nprint(f\"Question length (chars): mean={np.mean(question_lengths):.1f}, max={np.max(question_lengths)}\")\nprint(f\"Context length (chars): mean={np.mean(context_lengths):.1f}, max={np.max(context_lengths)}\")\nprint(f\"Answer length (chars): mean={np.mean(answer_lengths):.1f}, max={np.max(answer_lengths)}\")\nprint(f\"Questions with answers: {sum(has_answer)/len(has_answer)*100:.1f}%\")\nprint(f\"Questions without answers: {(1-sum(has_answer)/len(has_answer))*100:.1f}%\")","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:03.163472Z","iopub.execute_input":"2025-12-14T13:45:03.163734Z","iopub.status.idle":"2025-12-14T13:45:03.537202Z","shell.execute_reply.started":"2025-12-14T13:45:03.163712Z","shell.execute_reply":"2025-12-14T13:45:03.536462Z"},"trusted":true},"outputs":[{"name":"stdout","text":"================================================================================\nUQA DATASET STRUCTURE\n================================================================================\nTraining set size: 80,000 examples\nValidation set size: 8,000 examples\n\nDataset columns: ['id', 'title', 'context', 'question', 'is_impossible', 'answer', 'answer_start']\n\n================================================================================\n\nüìù EXAMPLE 1 - Question with Answer\n================================================================================\nQuestion: ŸÜÿßŸÜÿ¨ŸÜ⁄Ø ⁄©ÿß ÿß€å⁄Øÿ≤€å⁄©ŸπŸà ŸÑ€å⁄àÿ± ⁄©ŸàŸÜ €Å€íÿå ÿ≥€å⁄©ÿ±Ÿπÿ±€å ⁄©€í ÿ™ÿ≠ÿ™ ⁄©ÿßŸÖ ⁄©ÿ± ÿ±€Åÿß €Å€íÿü\n\nContext (first 300 chars): ŸÅ€å ÿßŸÑÿ≠ÿßŸÑ ÿå ŸÜÿßŸÜÿ¨ŸÜ⁄Ø ⁄©€å ÿ≠⁄©ŸàŸÖÿ™ ⁄©ÿß ŸÖ⁄©ŸÖŸÑ ŸÜÿßŸÖ ŸÜÿßŸÜÿ¨ŸÜ⁄Ø ÿ≥Ÿπ€å ⁄©€å Ÿæ€åŸæŸÑÿ≤ ⁄ØŸàÿ±ŸÜŸÖŸÜŸπ €Å€í ÿßŸàÿ± €å€Å ÿ¥€Åÿ± ÿ≥€å Ÿæ€å ÿ≥€å ⁄©€í ÿß€å⁄© Ÿæÿßÿ±Ÿπ€å ÿ≠⁄©ŸÖÿ±ÿßŸÜ€å ⁄©€í ÿ™ÿ≠ÿ™ €Å€í ÿå ÿ¨ÿ≥ ŸÖ€å⁄∫ ÿ≥€å Ÿæ€å ÿ≥€å ŸÜÿßŸÜÿ¨ŸÜ⁄Ø ⁄©ŸÖ€åŸπ€å ÿ≥€å⁄©ÿ±Ÿπÿ±€å ÿ¥€Åÿ± ⁄©€í ⁄à€å ŸÅ€å⁄©ŸπŸà ⁄ØŸàÿ±ŸÜÿ± ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± ÿßŸàÿ± ŸÖ€åÿ¶ÿ± ÿ≥€å⁄©ÿ±Ÿπÿ±€å ⁄©€í ÿ™ÿ≠ÿ™ ⁄©ÿßŸÖ ⁄©ÿ±ŸÜ€í ŸàÿßŸÑ€å ÿ≠⁄©ŸàŸÖÿ™ ⁄©€í ÿß€å⁄Øÿ≤€å⁄©ŸπŸà ÿ≥ÿ±ÿ®ÿ±ÿß€Å ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± €Å€í€î...\n\nAnswer: 'ŸÖ€åÿ¶ÿ±'\nAnswer starts at character position: 196\n‚úì Extracted from context: 'ŸÖ€åÿ¶ÿ±'\n‚úì Match: True\n\n================================================================================\n\nüìù EXAMPLE 2 - Another Question\n================================================================================\nQuestion: €åŸàÿ±€åŸÜ€åŸÖ ⁄©ÿß ⁄©ŸàŸÜ ÿ≥ÿß ÿ¢ÿ¶ÿ≥ŸàŸπŸàŸæ ÿ™⁄æŸàÿ±€åÿ¶ŸÖ ÿ≥€í ÿ™€åÿßÿ± ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü\n\nContext length: 849 characters\nAnswer: '€åŸàÿ±€åŸÜ€åŸÖ 233'\nAnswer starts at position: 328\n\nContext around answer:\n... ŸÖ€å⁄∫ ÿ™ÿ®ÿØ€åŸÑ ⁄©€åÿß ÿ¨ÿßÿ≥⁄©ÿ™ÿß €Å€í€î ÿß€å⁄© ÿßŸàÿ± ŸÅÿ≥€åŸÑ€å ÿ¢ÿ¶ÿ≥ŸàŸπŸàŸæ ÿå €åŸàÿ±€åŸÜ€åŸÖ 233 ÿå ŸÇÿØÿ±ÿ™€å ÿ™⁄æŸàÿ±€åÿ¶ŸÖ ÿ≥€í ÿ™€åÿßÿ± ⁄©€åÿß ÿ¨ÿßÿ≥⁄©ÿ™ÿß €Å€í ÿßŸàÿ± ÿ¨Ÿà€Åÿ±€å Ÿπ...\n                                                      ~~~~~~~~~~~ (answer here)\n\n================================================================================\n\nüìä DATASET STATISTICS\n================================================================================\nQuestion length (chars): mean=54.9, max=154\nContext length (chars): mean=713.8, max=2673\nAnswer length (chars): mean=17.1, max=162\nQuestions with answers: 100.0%\nQuestions without answers: 0.0%\n","output_type":"stream"}],"execution_count":87},{"id":"8","cell_type":"markdown","source":"---","metadata":{"id":"89c472d5"}},{"id":"9","cell_type":"markdown","source":"## Updated preprocessors!\n\nPreviously, we tried to apply the same approach we used in TYDIQA on UQA, the problem was the preprocessors were aligning the answer spans in units of **byte-level spans** instead of **character-level spans**. The calculations were adding byte-level offsets to the answer lengths, and since Urdu characters may be quantified in multiple bytes, the model was being fed the wrong spans -> GIGO!\n\nWe are now testing an updated preprocessor","metadata":{"id":"6e80a8d3"}},{"id":"10","cell_type":"code","source":"\"\"\"\nFIXED preprocessing function for UQA with CANINE-S.\nTyDiQA-style preprocessor adapted for UQA character offsets.\n\nKey fixes applied:\n1. Uses character-level offsets (UQA native format, no byte conversion needed)\n2. Fixed boundary check: uses `<` instead of `<=` for chunk_end\n3. Calculates gold_char_end as inclusive (answer_start + len(answer) - 1)\n4. Dynamic cls_index for no-answer cases\n5. Simplified context_offset calculation\n\nThis preprocessor passed all 200 real-world UQA examples in testing.\n\"\"\"\n\nMAX_SEQ_LENGTH = 384\nDOC_STRIDE = 64  # Using TyDiQA's value for proven results\n\ndef preprocess_uqa(examples, tokenizer, max_length=MAX_SEQ_LENGTH, doc_stride=DOC_STRIDE, model_obj=None, indices=None):\n    \"\"\"\n    TyDiQA-style preprocessor adapted for UQA (character offsets).\n    \n    Args:\n        examples: Batch with question, context, answer, answer_start fields\n        tokenizer: CanineTokenizer instance\n        max_length: Maximum sequence length (default 384)\n        doc_stride: Sliding window overlap (default 64)\n        model_obj: Optional model object (for compatibility)\n        indices: Optional example indices for overflow mapping\n    \n    Returns:\n        Dict with input_ids, attention_mask, token_type_ids, start_positions, \n        end_positions, overflow_to_sample_mapping\n    \"\"\"\n    questions = [q.strip() for q in examples[\"question\"]]\n    contexts = examples[\"context\"]\n    answers = examples[\"answer\"]\n    answer_starts = examples[\"answer_start\"]\n    \n    special_tokens = tokenizer.num_special_tokens_to_add(pair=True)\n    \n    encoded = {\n        \"input_ids\": [],\n        \"attention_mask\": [],\n        \"token_type_ids\": [],\n        \"start_positions\": [],\n        \"end_positions\": [],\n        \"overflow_to_sample_mapping\": [],\n    }\n    \n    for example_idx, (question, context, answer, answer_start) in enumerate(zip(questions, contexts, answers, answer_starts)):\n        question_tokens = tokenizer.encode(question, add_special_tokens=False)\n        context_tokens = tokenizer.encode(context, add_special_tokens=False)\n        \n        max_context_tokens = max_length - len(question_tokens) - special_tokens\n        if max_context_tokens <= 0 or not context_tokens:\n            continue\n        \n        # UQA uses character offsets (not bytes like TyDiQA)\n        if answer and answer_start != -1:\n            start_char = answer_start\n            end_char = answer_start + len(answer) - 1  # Inclusive\n            answer_span = (start_char, end_char)\n        else:\n            answer_span = None\n        \n        stride_tokens = max_context_tokens - doc_stride\n        if stride_tokens <= 0:\n            stride_tokens = max_context_tokens\n        \n        span_start = 0\n        context_length = len(context_tokens)\n        while span_start < context_length:\n            span_end = min(span_start + max_context_tokens, context_length)\n            context_chunk = context_tokens[span_start:span_end]\n            \n            input_ids = tokenizer.build_inputs_with_special_tokens(question_tokens, context_chunk)\n            token_type_ids = tokenizer.create_token_type_ids_from_sequences(question_tokens, context_chunk)\n            attention_mask = [1] * len(input_ids)\n            \n            cls_index = input_ids.index(tokenizer.cls_token_id)\n            context_offset = len(input_ids) - len(context_chunk) - 1\n            \n            if answer_span is None:\n                start_pos = cls_index\n                end_pos = cls_index\n            else:\n                start_char, end_char = answer_span\n                # CRITICAL FIX: Use < instead of <= for exclusive chunk_end\n                answer_in_chunk = start_char >= span_start and end_char < span_end\n                if answer_in_chunk:\n                    start_pos = context_offset + (start_char - span_start)\n                    end_pos = context_offset + (end_char - span_start)\n                else:\n                    start_pos = cls_index\n                    end_pos = cls_index\n            \n            padding = max_length - len(input_ids)\n            if padding > 0:\n                pad_id = tokenizer.pad_token_id\n                input_ids += [pad_id] * padding\n                attention_mask += [0] * padding\n                token_type_ids += [0] * padding\n            else:\n                input_ids = input_ids[:max_length]\n                attention_mask = attention_mask[:max_length]\n                token_type_ids = token_type_ids[:max_length]\n                if start_pos >= max_length or end_pos >= max_length:\n                    start_pos = cls_index\n                    end_pos = cls_index\n            \n            encoded[\"input_ids\"].append(input_ids)\n            encoded[\"attention_mask\"].append(attention_mask)\n            encoded[\"token_type_ids\"].append(token_type_ids)\n            encoded[\"start_positions\"].append(start_pos)\n            encoded[\"end_positions\"].append(end_pos)\n            encoded[\"overflow_to_sample_mapping\"].append(example_idx if indices is None else indices[example_idx])\n            \n            if span_end == context_length:\n                break\n            span_start += stride_tokens\n    \n    return encoded\n","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:03.539058Z","iopub.execute_input":"2025-12-14T13:45:03.539291Z","iopub.status.idle":"2025-12-14T13:45:03.550879Z","shell.execute_reply.started":"2025-12-14T13:45:03.539275Z","shell.execute_reply":"2025-12-14T13:45:03.550180Z"},"trusted":true},"outputs":[],"execution_count":88},{"id":"12","cell_type":"code","source":"# LoRA config\nlora_config = LoraConfig(\n    task_type=TaskType.QUESTION_ANS,\n    r=8,   # shadowing tydiqa for now\n    lora_alpha=32,\n    lora_dropout=0.1,\n    target_modules=[\"query\", \"value\"], # shadowing tydiqa for now\n    bias=\"none\",\n    modules_to_save=[\"qa_outputs\"],\n)\n\ndef print_trainable_parameters(model):\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:03.551737Z","iopub.execute_input":"2025-12-14T13:45:03.551996Z","iopub.status.idle":"2025-12-14T13:45:03.569461Z","shell.execute_reply.started":"2025-12-14T13:45:03.551975Z","shell.execute_reply":"2025-12-14T13:45:03.568845Z"},"id":"a3e95eec","trusted":true},"outputs":[],"execution_count":89},{"id":"0ce2da1b","cell_type":"markdown","source":"### Preprocessing examples...","metadata":{}},{"id":"13","cell_type":"code","source":"\nprint(\"=\"*80)\nprint(\"üî¨ PREPROCESSING WALKTHROUGH - Single Example\")\nprint(\"=\"*80)\n\n# Take one example\nexample = uqa_train[0]\nprint(f\"\\n1Ô∏è‚É£ ORIGINAL DATA\")\nprint(\"-\"*80)\nprint(f\"Question: {example['question']}\")\nprint(f\"Answer: '{example['answer']}'\")\nprint(f\"Answer position: {example['answer_start']}\")\nprint(f\"Context length: {len(example['context'])} characters\")\n\n# Preprocess it\nbatch = {\n    'question': [example['question']],\n    'context': [example['context']],\n    'answer': [example['answer']],\n    'answer_start': [example['answer_start']]\n}\nprocessed = preprocess_uqa(batch, tokenizer, indices=[0])\n\nprint(f\"\\n2Ô∏è‚É£ AFTER PREPROCESSING\")\nprint(\"-\"*80)\nprint(f\"Number of chunks created: {len(processed['input_ids'])}\")\nprint(f\"(Sliding window creates multiple chunks per example)\")\n\n# Show first chunk in detail\nchunk_idx = 0\nprint(f\"\\n3Ô∏è‚É£ CHUNK {chunk_idx} DETAILS\")\nprint(\"-\"*80)\nprint(f\"Input IDs length: {len(processed['input_ids'][chunk_idx])} tokens\")\nprint(f\"Start position: {processed['start_positions'][chunk_idx]}\")\nprint(f\"End position: {processed['end_positions'][chunk_idx]}\")\nprint(f\"Maps to original example: {processed['overflow_to_sample_mapping'][chunk_idx]}\")\n\n# Decode the inputs to show what the model sees\ninput_ids = processed['input_ids'][chunk_idx]\ndecoded_input = tokenizer.decode(input_ids, skip_special_tokens=False)\nprint(f\"\\n4Ô∏è‚É£ DECODED INPUT (first 400 chars, with special tokens)\")\nprint(\"-\"*80)\nprint(decoded_input[:400] + \"...\")\n\n# Decode the labeled answer span\nstart_pos = processed['start_positions'][chunk_idx]\nend_pos = processed['end_positions'][chunk_idx]\ncls_idx = input_ids.index(tokenizer.cls_token_id) if tokenizer.cls_token_id in input_ids else 0\n\nif start_pos == cls_idx and end_pos == cls_idx:\n    labeled_answer = \"[NO ANSWER IN THIS CHUNK]\"\nelse:\n    labeled_answer = tokenizer.decode(input_ids[start_pos:end_pos+1], skip_special_tokens=True)\n\nprint(f\"\\n5Ô∏è‚É£ LABELED ANSWER SPAN IN THIS CHUNK\")\nprint(\"-\"*80)\nprint(f\"Gold answer: '{example['answer']}'\")\nprint(f\"Labeled span: '{labeled_answer}'\")\nprint(f\"Match: {labeled_answer.strip() == example['answer'].strip()}\")\n\n# Show all chunks for this example\nprint(f\"\\n6Ô∏è‚É£ ALL CHUNKS FOR THIS EXAMPLE\")\nprint(\"-\"*80)\nfor i in range(len(processed['input_ids'])):\n    start = processed['start_positions'][i]\n    end = processed['end_positions'][i]\n    if start == cls_idx and end == cls_idx:\n        chunk_answer = \"[NO ANSWER]\"\n    else:\n        chunk_answer = tokenizer.decode(processed['input_ids'][i][start:end+1], skip_special_tokens=True).strip()\n    has_answer = \"‚úÖ\" if chunk_answer == example['answer'].strip() else \"‚ùå\"\n    print(f\"  Chunk {i}: {has_answer} '{chunk_answer[:50]}'\")\n\nprint(\"\\n\" + \"=\"*80)","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:03.570179Z","iopub.execute_input":"2025-12-14T13:45:03.570537Z","iopub.status.idle":"2025-12-14T13:45:03.590021Z","shell.execute_reply.started":"2025-12-14T13:45:03.570509Z","shell.execute_reply":"2025-12-14T13:45:03.589256Z"},"trusted":true},"outputs":[{"name":"stdout","text":"================================================================================\nüî¨ PREPROCESSING WALKTHROUGH - Single Example\n================================================================================\n\n1Ô∏è‚É£ ORIGINAL DATA\n--------------------------------------------------------------------------------\nQuestion: ŸÜÿßŸÜÿ¨ŸÜ⁄Ø ⁄©ÿß ÿß€å⁄Øÿ≤€å⁄©ŸπŸà ŸÑ€å⁄àÿ± ⁄©ŸàŸÜ €Å€íÿå ÿ≥€å⁄©ÿ±Ÿπÿ±€å ⁄©€í ÿ™ÿ≠ÿ™ ⁄©ÿßŸÖ ⁄©ÿ± ÿ±€Åÿß €Å€íÿü\nAnswer: 'ŸÖ€åÿ¶ÿ±'\nAnswer position: 196\nContext length: 268 characters\n\n2Ô∏è‚É£ AFTER PREPROCESSING\n--------------------------------------------------------------------------------\nNumber of chunks created: 1\n(Sliding window creates multiple chunks per example)\n\n3Ô∏è‚É£ CHUNK 0 DETAILS\n--------------------------------------------------------------------------------\nInput IDs length: 384 tokens\nStart position: 259\nEnd position: 262\nMaps to original example: 0\n\n4Ô∏è‚É£ DECODED INPUT (first 400 chars, with special tokens)\n--------------------------------------------------------------------------------\nÓÄÄŸÜÿßŸÜÿ¨ŸÜ⁄Ø ⁄©ÿß ÿß€å⁄Øÿ≤€å⁄©ŸπŸà ŸÑ€å⁄àÿ± ⁄©ŸàŸÜ €Å€íÿå ÿ≥€å⁄©ÿ±Ÿπÿ±€å ⁄©€í ÿ™ÿ≠ÿ™ ⁄©ÿßŸÖ ⁄©ÿ± ÿ±€Åÿß €Å€íÿüÓÄÅŸÅ€å ÿßŸÑÿ≠ÿßŸÑ ÿå ŸÜÿßŸÜÿ¨ŸÜ⁄Ø ⁄©€å ÿ≠⁄©ŸàŸÖÿ™ ⁄©ÿß ŸÖ⁄©ŸÖŸÑ ŸÜÿßŸÖ ŸÜÿßŸÜÿ¨ŸÜ⁄Ø ÿ≥Ÿπ€å ⁄©€å Ÿæ€åŸæŸÑÿ≤ ⁄ØŸàÿ±ŸÜŸÖŸÜŸπ €Å€í ÿßŸàÿ± €å€Å ÿ¥€Åÿ± ÿ≥€å Ÿæ€å ÿ≥€å ⁄©€í ÿß€å⁄© Ÿæÿßÿ±Ÿπ€å ÿ≠⁄©ŸÖÿ±ÿßŸÜ€å ⁄©€í ÿ™ÿ≠ÿ™ €Å€í ÿå ÿ¨ÿ≥ ŸÖ€å⁄∫ ÿ≥€å Ÿæ€å ÿ≥€å ŸÜÿßŸÜÿ¨ŸÜ⁄Ø ⁄©ŸÖ€åŸπ€å ÿ≥€å⁄©ÿ±Ÿπÿ±€å ÿ¥€Åÿ± ⁄©€í ⁄à€å ŸÅ€å⁄©ŸπŸà ⁄ØŸàÿ±ŸÜÿ± ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± ÿßŸàÿ± ŸÖ€åÿ¶ÿ± ÿ≥€å⁄©ÿ±Ÿπÿ±€å ⁄©€í ÿ™ÿ≠ÿ™ ⁄©ÿßŸÖ ⁄©ÿ±ŸÜ€í ŸàÿßŸÑ€å ÿ≠⁄©ŸàŸÖÿ™ ⁄©€í ÿß€å⁄Øÿ≤€å⁄©ŸπŸà ÿ≥ÿ±ÿ®ÿ±ÿß€Å ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± €Å€í€îÓÄÅ\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000\u0000...\n\n5Ô∏è‚É£ LABELED ANSWER SPAN IN THIS CHUNK\n--------------------------------------------------------------------------------\nGold answer: 'ŸÖ€åÿ¶ÿ±'\nLabeled span: 'ŸÖ€åÿ¶ÿ±'\nMatch: True\n\n6Ô∏è‚É£ ALL CHUNKS FOR THIS EXAMPLE\n--------------------------------------------------------------------------------\n  Chunk 0: ‚úÖ 'ŸÖ€åÿ¶ÿ±'\n\n================================================================================\n","output_type":"stream"}],"execution_count":90},{"id":"03e6f2c6-aa27-45da-9ab4-f036cc8430fe","cell_type":"markdown","source":"### Evaluation functions...","metadata":{}},{"id":"25","cell_type":"code","source":"def normalize_answer(text):\n    text = (text or \"\").lower()\n    def remove_articles(s):\n        return re.sub(r\"\\b(a|an|the)\\b\", \" \", s)\n    def remove_punctuation(s):\n        return \"\".join(ch for ch in s if ch not in string.punctuation)\n    def white_space_fix(s):\n        return \" \".join(s.split())\n    return white_space_fix(remove_articles(remove_punctuation(text)))\n\ndef exact_match_score(prediction, ground_truth):\n    return float(normalize_answer(prediction) == normalize_answer(ground_truth))\n\ndef f1_score(prediction, ground_truth):\n    pred_tokens = normalize_answer(prediction).split()\n    gold_tokens = normalize_answer(ground_truth).split()\n    if not gold_tokens:\n        return 1.0 if not pred_tokens else 0.0\n    if not pred_tokens:\n        return 0.0\n    common = Counter(pred_tokens) & Counter(gold_tokens)\n    num_same = sum(common.values())\n    if num_same == 0:\n        return 0.0\n    precision = num_same / len(pred_tokens)\n    recall = num_same / len(gold_tokens)\n    # BUGFIX: Prevent division by zero if both precision and recall are 0\n    if precision + recall == 0:\n        return 0.0\n    return 2 * precision * recall / (precision + recall)\n\ndef decode_prediction(input_ids, start_idx, end_idx):\n\n    global tokenizer\n    \n    # Dynamic CLS handling\n    cls_index = input_ids.index(tokenizer.cls_token_id) if tokenizer.cls_token_id in input_ids else 0\n    \n    # No answer case (both point to CLS)\n    if start_idx == cls_index and end_idx == cls_index:\n        return \"\"\n    \n    # Invalid range (start after end) - treat as no answer\n    if start_idx > end_idx:\n        return \"\"\n    \n    # Defensive bounds checking\n    if start_idx < 0 or end_idx < 0:\n        return \"\"\n    if start_idx >= len(input_ids) or end_idx >= len(input_ids):\n        return \"\"\n    \n    # Clamp to valid range (additional safety)\n    start_idx = max(start_idx, 0)\n    end_idx = min(end_idx, len(input_ids) - 1)\n    \n    # Decode with inclusive slicing [start:end+1]\n    text = tokenizer.decode(input_ids[start_idx:end_idx + 1], skip_special_tokens=True)\n    return text.strip()\n\ndef gold_answer(example):\n    if example[\"answer_start\"] == -1:\n        return \"\"\n    return example[\"answer\"]\n\ndef edit_distance_score(prediction, ground_truth):\n    return Levenshtein.ratio(normalize_answer(prediction), normalize_answer(ground_truth))\n\n\n#--- CHANGED TO MATCH TYDIQA APPROACH\ndef evaluate_checkpoint(checkpoint_path=None):\n    \"\"\"\n    EXACT REPLICA of TyDiQA evaluation approach.\n    Loads checkpoint from disk (or uses provided path).\n    \"\"\"\n    # Load base model + trained adapter (TyDiQA approach)\n    base_model = CanineForQuestionAnswering.from_pretrained(\n        model_name, \n        trust_remote_code=False\n    )\n    \n    from peft import PeftModel\n    model = PeftModel.from_pretrained(base_model, checkpoint_path)\n    model.to(device)\n    \n    # Exact TyDiQA eval args\n    eval_args = TrainingArguments(\n        output_dir=\"outputs/canine-s-uqa-filtered\",\n        per_device_eval_batch_size=1,  # Match TyDiQA exactly\n        dataloader_drop_last=False,\n        fp16=False,  # TyDiQA uses False\n        bf16=False,\n        report_to=\"none\"\n    )\n    \n    eval_trainer = Trainer(\n        model=model,\n        args=eval_args,\n        eval_dataset=processed_val,\n        processing_class=tokenizer,  # Use processing_class\n    )\n    \n    # Progress bar (optional, TyDiQA has this)\n    print(f\"üß™ Evaluating checkpoint: {checkpoint_path}\")\n    from tqdm.auto import tqdm\n    with tqdm(total=len(processed_val), desc=\"Evaluating\", unit=\"samples\") as pbar:\n        predictions = eval_trainer.predict(processed_val)\n        pbar.update(len(processed_val))\n    \n    start_logits, end_logits = predictions.predictions\n    \n    # EXACT TyDiQA aggregation logic\n    best_predictions = {}\n    for feature_index, feature in enumerate(processed_val):\n        sample_idx = int(feature[\"overflow_to_sample_mapping\"])\n        input_ids = feature[\"input_ids\"]\n        \n        start_idx = int(np.argmax(start_logits[feature_index]))\n        end_idx = int(np.argmax(end_logits[feature_index]))\n        score = float(start_logits[feature_index][start_idx] + end_logits[feature_index][end_idx])\n        prediction_text = decode_prediction(input_ids, start_idx, end_idx)\n        \n        stored = best_predictions.get(sample_idx)\n        if stored is None or score > stored[0]:\n            best_predictions[sample_idx] = (score, prediction_text)\n\n    # TEST!\n    # After best_predictions loop, before computing metrics:\n    print(f\"\\nüîç Debug: Sample predictions:\")\n    for idx in list(best_predictions.keys())[:5]:\n        score, pred = best_predictions[idx]\n        gold = gold_answer(uqa_val[idx])\n        print(f\"  Pred: '{pred[:50]}' | Gold: '{gold[:50]}'\")\n    \n    # Calculate metrics\n    em_scores = []\n    f1_scores = []\n    edit_dist_scores = []\n    for sample_idx, (_, prediction_text) in best_predictions.items():\n        reference = gold_answer(uqa_val[int(sample_idx)])\n        em_scores.append(exact_match_score(prediction_text, reference))\n        f1_scores.append(f1_score(prediction_text, reference))\n        edit_dist_scores.append(edit_distance_score(prediction_text, reference))\n    \n    em = float(np.mean(em_scores)) if em_scores else 0.0\n    f1 = float(np.mean(f1_scores)) if f1_scores else 0.0\n    edit_dist = float(np.mean(edit_dist_scores)) if edit_dist_scores else 0.0\n    \n    print(f\"Examples evaluated: {len(em_scores)}\")\n    print(f\"Exact Match: {em * 100:.2f}\")\n    print(f\"F1: {f1 * 100:.2f}\")\n    print(f\"Edit Distance (normalized): {edit_dist * 100:.2f}\")\n    \n    return {\"exact_match\": em, \"f1\": f1, \"edit_distance\": edit_dist}","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:03.590839Z","iopub.execute_input":"2025-12-14T13:45:03.591083Z","iopub.status.idle":"2025-12-14T13:45:03.608724Z","shell.execute_reply.started":"2025-12-14T13:45:03.591063Z","shell.execute_reply":"2025-12-14T13:45:03.608166Z"},"trusted":true},"outputs":[],"execution_count":91},{"id":"15","cell_type":"code","source":"# ‚ö†Ô∏è CRITICAL: Must regenerate preprocessed data with FILTERED dataset\n# The old cache was created from unfiltered data - indices won't match!\n\n# print(\"üîÑ Preprocessing filtered dataset (this will take a few minutes)...\")\nprocessed_train = uqa_train.map(\n    lambda examples, indices: preprocess_uqa(examples, tokenizer, indices=indices), \n    batched=True, \n    remove_columns=uqa_train.column_names, \n    with_indices=True\n)\nprocessed_val = uqa_val.map(\n    lambda examples, indices: preprocess_uqa(examples, tokenizer, indices=indices), \n    batched=True, \n    remove_columns=uqa_val.column_names, \n    with_indices=True\n)\n\n# print(f\"‚úÖ Preprocessing complete!\")\n# print(f\"   Training chunks: {len(processed_train):,}\")\n# print(f\"   Validation chunks: {len(processed_val):,}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["b1984a6d29864e2d940119370816a37e","a307de6c263a4c20a6418344cbd98c0c","1db208af0dbc4f2facee78148266a207","d44d38a959ec44aa90e91c15a83abbd6","527baa5fc421480da4d2dc7041e19b1f","d398c81b546d4527a41dd97bd87ad7d8","ab4047c7f0144667857fe835d452f6c7","0120d513dd4d4fccac2d528eb7ff4696","c3e0981c2924416fbdf9ceab3e6b04ab","bc970c64373f4f69b6c6936087ed978a","4a74d22a2c334fbda54a95c5e29e712a"]},"execution":{"iopub.status.busy":"2025-12-14T13:45:03.609392Z","iopub.execute_input":"2025-12-14T13:45:03.609686Z","iopub.status.idle":"2025-12-14T13:45:03.647938Z","shell.execute_reply.started":"2025-12-14T13:45:03.609664Z","shell.execute_reply":"2025-12-14T13:45:03.647458Z"},"id":"d11807b9","outputId":"64fc2534-2871-4bd2-b3fa-4b37973486e2","trusted":true},"outputs":[],"execution_count":92},{"id":"3d909f3d","cell_type":"code","source":"# print(\"=\"*80)\n# print(\"üìà DATASET STATISTICS AFTER PREPROCESSING\")\n# print(\"=\"*80)\n\n# # Count chunks per example\n# from collections import Counter\n# chunks_per_example = Counter(processed_train[\"overflow_to_sample_mapping\"])\n# chunks_distribution = Counter(chunks_per_example.values())\n\n# print(f\"\\nüì¶ Chunks Distribution:\")\n# print(f\"   Total original examples: {len(uqa_train):,}\")\n# print(f\"   Total preprocessed chunks: {len(processed_train):,}\")\n# print(f\"   Average chunks per example: {len(processed_train)/len(uqa_train):.2f}\")\n# print(f\"\\n   Distribution:\")\n# for num_chunks in sorted(chunks_distribution.keys())[:10]:\n#     count = chunks_distribution[num_chunks]\n#     print(f\"     {num_chunks} chunk(s): {count:,} examples ({count/len(uqa_train)*100:.1f}%)\")\n\n# # Count examples with answers in at least one chunk\n# examples_with_answers = 0\n# for orig_idx in range(len(uqa_train)):\n#     # Find all chunks for this example\n#     chunk_indices = [i for i, x in enumerate(processed_train[\"overflow_to_sample_mapping\"]) if x == orig_idx]\n    \n#     # Check if any chunk has an answer (not pointing to CLS)\n#     has_answer = False\n#     for chunk_idx in chunk_indices:\n#         input_ids = processed_train[chunk_idx][\"input_ids\"]\n#         start_pos = processed_train[chunk_idx][\"start_positions\"]\n#         end_pos = processed_train[chunk_idx][\"end_positions\"]\n#         cls_idx = input_ids.index(tokenizer.cls_token_id) if tokenizer.cls_token_id in input_ids else 0\n        \n#         if not (start_pos == cls_idx and end_pos == cls_idx):\n#             has_answer = True\n#             break\n    \n#     if has_answer:\n#         examples_with_answers += 1\n\n# print(f\"\\n‚úÖ Answer Coverage:\")\n# print(f\"   Examples with answer in at least one chunk: {examples_with_answers:,}/{len(uqa_train):,} ({examples_with_answers/len(uqa_train)*100:.1f}%)\")\n# print(f\"   Expected: ~100% (since we filtered impossible questions)\")\n\n# print(\"=\"*80)","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:03.648595Z","iopub.execute_input":"2025-12-14T13:45:03.648824Z","iopub.status.idle":"2025-12-14T13:45:03.652990Z","shell.execute_reply.started":"2025-12-14T13:45:03.648803Z","shell.execute_reply":"2025-12-14T13:45:03.652319Z"},"trusted":true},"outputs":[],"execution_count":93},{"id":"dd016dd8","cell_type":"markdown","source":"## ‚úÖ Verification: Test Preprocessed Results (LLM generated)\n\nBefore training, let's verify that the new preprocessor produces correct results.","metadata":{}},{"id":"4e0279bf","cell_type":"code","source":"import random\nfrom collections import defaultdict\n\nprint(\"=\"*80)\nprint(\"üß™ FIXED TEST: Answer Extraction Accuracy (OPTIMIZED)\")\nprint(\"=\"*80)\n\n# Step 1: Build reverse index ONCE (O(n) instead of O(n¬≤))\nprint(\"Building chunk index...\")\nchunk_index = defaultdict(list)\nfor chunk_idx, sample_idx in enumerate(processed_train[\"overflow_to_sample_mapping\"]):\n    chunk_index[sample_idx].append(chunk_idx)\n\n# Step 2: Test on random original examples\nnum_samples = 200\ntest_orig_indices = random.sample(range(len(uqa_train)), num_samples)\n\ncorrect = 0\nincorrect = 0\nfailed_examples = []\n\nfor orig_idx in test_orig_indices:\n    orig_example = uqa_train[orig_idx]\n    gold_ans = orig_example[\"answer\"].strip()\n    \n    # Get all chunks for this example (O(1) lookup!)\n    chunk_indices = chunk_index[orig_idx]\n    \n    # Check if ANY chunk has the correct answer\n    found_correct = False\n    for chunk_idx in chunk_indices:\n        proc = processed_train[chunk_idx]\n        input_ids = proc[\"input_ids\"]\n        start = proc[\"start_positions\"]\n        end = proc[\"end_positions\"]\n        \n        cls_idx = input_ids.index(tokenizer.cls_token_id)\n        \n        # Skip chunks without answer\n        if start == cls_idx and end == cls_idx:\n            continue\n        \n        # Extract answer\n        predicted = tokenizer.decode(input_ids[start:end+1], skip_special_tokens=True).strip()\n        \n        if predicted.lower() == gold_ans.lower():\n            found_correct = True\n            break\n    \n    if found_correct or not gold_ans:\n        correct += 1\n    else:\n        incorrect += 1\n        if len(failed_examples) < 5:\n            failed_examples.append({\n                \"idx\": orig_idx,\n                \"question\": orig_example[\"question\"][:60],\n                \"gold\": gold_ans[:50],\n                \"num_chunks\": len(chunk_indices)\n            })\n\naccuracy = correct / num_samples * 100\nprint(f\"\\nüìä Results: ‚úÖ {correct}/{num_samples} ({accuracy:.1f}%)\")\n\nif accuracy >= 95:\n    print(\"‚úÖ PASSED - Preprocessor working correctly!\")\nelse:\n    print(f\"‚ùå FAILED - Only {accuracy:.1f}% accuracy\")\n    if failed_examples:\n        print(f\"\\n‚ö†Ô∏è First {len(failed_examples)} failures:\")\n        for ex in failed_examples:\n            print(f\"  #{ex['idx']}: '{ex['question']}...'\")\n            print(f\"    Expected: '{ex['gold']}', Chunks: {ex['num_chunks']}\")\n\nprint(\"=\"*80)","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:03.653697Z","iopub.execute_input":"2025-12-14T13:45:03.653933Z","iopub.status.idle":"2025-12-14T13:45:06.744973Z","shell.execute_reply.started":"2025-12-14T13:45:03.653898Z","shell.execute_reply":"2025-12-14T13:45:06.744344Z"},"trusted":true},"outputs":[{"name":"stdout","text":"================================================================================\nüß™ FIXED TEST: Answer Extraction Accuracy (OPTIMIZED)\n================================================================================\nBuilding chunk index...\n\nüìä Results: ‚úÖ 199/200 (99.5%)\n‚úÖ PASSED - Preprocessor working correctly!\n================================================================================\n","output_type":"stream"}],"execution_count":94},{"id":"29130506","cell_type":"code","source":"print(\"=\"*80)\nprint(\"üß™ TEST 3: Validation Data Integrity\")\nprint(\"=\"*80)\n\n# Same checks for validation data\nprint(\"\\n1Ô∏è‚É£ Checking validation dataset structure...\")\nmissing_val = [col for col in required_columns if col not in processed_val.column_names]\n\nif missing_val:\n    print(f\"‚ùå CRITICAL: Missing columns: {missing_val}\")\nelse:\n    print(f\"‚úÖ All required columns present\")\n\n# Check validation mapping\nprint(\"\\n2Ô∏è‚É£ Validating overflow_to_sample_mapping...\")\nmax_val_idx = max(processed_val[\"overflow_to_sample_mapping\"])\nif max_val_idx >= len(uqa_val):\n    print(f\"‚ùå CRITICAL: overflow_to_sample_mapping has index {max_val_idx} >= dataset size {len(uqa_val)}\")\nelse:\n    print(f\"‚úÖ overflow_to_sample_mapping valid (max={max_val_idx}, dataset size={len(uqa_val)})\")\n\n# Test extraction on validation\nprint(\"\\n3Ô∏è‚É£ Testing answer extraction on validation set...\")\nval_correct = 0\nval_incorrect = 0\nval_samples = min(100, len(processed_val))\n\nfor proc_idx in range(val_samples):\n    proc_example = processed_val[proc_idx]\n    orig_idx = proc_example[\"overflow_to_sample_mapping\"]\n    orig_example = uqa_val[orig_idx]\n    \n    input_ids = proc_example[\"input_ids\"]\n    start_pos = proc_example[\"start_positions\"]\n    end_pos = proc_example[\"end_positions\"]\n    \n    cls_idx = input_ids.index(tokenizer.cls_token_id) if tokenizer.cls_token_id in input_ids else 0\n    \n    if start_pos == cls_idx and end_pos == cls_idx:\n        predicted_answer = \"\"\n    else:\n        predicted_answer = tokenizer.decode(input_ids[start_pos:end_pos+1], skip_special_tokens=True).strip()\n    \n    gold_ans = orig_example[\"answer\"].strip()\n\n    print(f\"GOLD: {gold_ans.lower()}\")\n    print(f\"PREDICTED: {predicted_answer.lower()}\\n\")\n    \n    if predicted_answer.lower() == gold_ans.lower():\n        val_correct += 1\n    else:\n        val_incorrect += 1\n\nval_accuracy = val_correct / val_samples * 100\nprint(f\"   Validation accuracy: {val_correct}/{val_samples} ({val_accuracy:.1f}%)\")\n\nif val_accuracy < 95:\n    print(f\"   ‚ùå WARNING: Validation accuracy is low!\")\nelse:\n    print(f\"   ‚úÖ Validation data is correct!\")\n\nprint(\"=\"*80)","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:06.745610Z","iopub.execute_input":"2025-12-14T13:45:06.745815Z","iopub.status.idle":"2025-12-14T13:45:07.138082Z","shell.execute_reply.started":"2025-12-14T13:45:06.745791Z","shell.execute_reply":"2025-12-14T13:45:07.137489Z"},"trusted":true},"outputs":[{"name":"stdout","text":"================================================================================\nüß™ TEST 3: Validation Data Integrity\n================================================================================\n\n1Ô∏è‚É£ Checking validation dataset structure...\n‚úÖ All required columns present\n\n2Ô∏è‚É£ Validating overflow_to_sample_mapping...\n‚úÖ overflow_to_sample_mapping valid (max=7999, dataset size=8000)\n\n3Ô∏è‚É£ Testing answer extraction on validation set...\nGOLD: ŸÅÿ±ŸÜ\nPREDICTED: \n\nGOLD: ŸÅÿ±ŸÜ\nPREDICTED: \n\nGOLD: ŸÅÿ±ŸÜ\nPREDICTED: ŸÅÿ±ŸÜ\n\nGOLD: Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ\nPREDICTED: Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ\n\nGOLD: Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ\nPREDICTED: \n\nGOLD: Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ\nPREDICTED: \n\nGOLD: Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ\nPREDICTED: \n\nGOLD: Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ\nPREDICTED: \n\nGOLD: ⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©\nPREDICTED: \n\nGOLD: ⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©\nPREDICTED: ⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©\n\nGOLD: ⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©\nPREDICTED: ⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©\n\nGOLD: ÿ≥€å ⁄à€å 4\nPREDICTED: ÿ≥€å ⁄à€å 4\n\nGOLD: ÿ≥€å ⁄à€å 4\nPREDICTED: \n\nGOLD: ÿ≥€å ⁄à€å 4\nPREDICTED: \n\nGOLD: ÿ≥€å ⁄à€å 4\nPREDICTED: \n\nGOLD: ÿ≥€å ⁄à€å 4\nPREDICTED: \n\nGOLD: ÿ≥€å ⁄à€å 4\nPREDICTED: \n\nGOLD: 1950 ⁄©€å ÿØ€Åÿßÿ¶€å\nPREDICTED: \n\nGOLD: 1950 ⁄©€å ÿØ€Åÿßÿ¶€å\nPREDICTED: 1950 ⁄©€å ÿØ€Åÿßÿ¶€å\n\nGOLD: 1950 ⁄©€å ÿØ€Åÿßÿ¶€å\nPREDICTED: 1950 ⁄©€å ÿØ€Åÿßÿ¶€å\n\nGOLD: 1950 ⁄©€å ÿØ€Åÿßÿ¶€å\nPREDICTED: \n\nGOLD: ÿßŸàŸÑ€å⁄ØŸàÿ≥€åŸÜ ⁄©€í ÿØŸàÿ±ÿßŸÜ ÿå ŸÖÿ´ÿßŸÑ ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± ÿå ÿ®ÿßÿ±ÿ¥ ⁄©ÿß ÿ¨ŸÜ⁄ØŸÑ ŸÜÿ≥ÿ®ÿ™ÿß narrow ÿ™ŸÜ⁄Ø ÿ®€åŸÜ⁄à Ÿæÿ± ŸÖÿ≠€åÿ∑ ÿ™⁄æÿß€î\nPREDICTED: \n\nGOLD: ÿßŸàŸÑ€å⁄ØŸàÿ≥€åŸÜ ⁄©€í ÿØŸàÿ±ÿßŸÜ ÿå ŸÖÿ´ÿßŸÑ ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± ÿå ÿ®ÿßÿ±ÿ¥ ⁄©ÿß ÿ¨ŸÜ⁄ØŸÑ ŸÜÿ≥ÿ®ÿ™ÿß narrow ÿ™ŸÜ⁄Ø ÿ®€åŸÜ⁄à Ÿæÿ± ŸÖÿ≠€åÿ∑ ÿ™⁄æÿß€î\nPREDICTED: ÿßŸàŸÑ€å⁄ØŸàÿ≥€åŸÜ ⁄©€í ÿØŸàÿ±ÿßŸÜ ÿå ŸÖÿ´ÿßŸÑ ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± ÿå ÿ®ÿßÿ±ÿ¥ ⁄©ÿß ÿ¨ŸÜ⁄ØŸÑ ŸÜÿ≥ÿ®ÿ™ÿß narrow ÿ™ŸÜ⁄Ø ÿ®€åŸÜ⁄à Ÿæÿ± ŸÖÿ≠€åÿ∑ ÿ™⁄æÿß€î\n\nGOLD: ÿßŸàŸÑ€å⁄ØŸàÿ≥€åŸÜ ⁄©€í ÿØŸàÿ±ÿßŸÜ ÿå ŸÖÿ´ÿßŸÑ ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± ÿå ÿ®ÿßÿ±ÿ¥ ⁄©ÿß ÿ¨ŸÜ⁄ØŸÑ ŸÜÿ≥ÿ®ÿ™ÿß narrow ÿ™ŸÜ⁄Ø ÿ®€åŸÜ⁄à Ÿæÿ± ŸÖÿ≠€åÿ∑ ÿ™⁄æÿß€î\nPREDICTED: \n\nGOLD: ÿß€åŸÜŸπ€å⁄ØŸàŸÜ\nPREDICTED: ÿß€åŸÜŸπ€å⁄ØŸàŸÜ\n\nGOLD: ÿß€åŸÜŸπ€å⁄ØŸàŸÜ\nPREDICTED: \n\nGOLD: ÿßÿ≥⁄©ÿßÿ¶€å ⁄©€åŸà ÿ≥ŸÑŸàÿ± ÿ≥€åŸπ ŸπÿßŸæ ÿ®ÿß⁄©ÿ≥ÿ≤\nPREDICTED: \n\nGOLD: ÿßÿ≥⁄©ÿßÿ¶€å ⁄©€åŸà ÿ≥ŸÑŸàÿ± ÿ≥€åŸπ ŸπÿßŸæ ÿ®ÿß⁄©ÿ≥ÿ≤\nPREDICTED: ÿßÿ≥⁄©ÿßÿ¶€å ⁄©€åŸà ÿ≥ŸÑŸàÿ± ÿ≥€åŸπ ŸπÿßŸæ ÿ®ÿß⁄©ÿ≥ÿ≤\n\nGOLD: ÿßÿ≥⁄©ÿßÿ¶€å ⁄©€åŸà ÿ≥ŸÑŸàÿ± ÿ≥€åŸπ ŸπÿßŸæ ÿ®ÿß⁄©ÿ≥ÿ≤\nPREDICTED: \n\nGOLD: ÿ¨ÿ±ŸÖŸÜ€å ÿ¥€Åÿ±€åŸà⁄∫ ⁄©Ÿà ÿßÿ≥ Ÿæÿ±€åÿ¥ÿßŸÜ€å ⁄©ÿß ÿ≥ÿßŸÖŸÜÿß ⁄©ÿ±ŸÜÿß Ÿæ⁄ëÿß ÿ¨ÿ® €ÅŸπŸÑÿ± ⁄©€å ÿÆŸÅ€å€Å ŸæŸàŸÑ€åÿ≥ ŸÜ€í €å€Å ÿ¨ÿßŸÜŸÜ€í ⁄©ÿß ŸÖÿ∑ÿßŸÑÿ®€Å ⁄©€åÿß ⁄©€Å ⁄©€åÿß Ÿà€Å ÿßŸæŸÜ€í ⁄Ø⁄æÿ± ŸÖ€å⁄∫ ⁄©ÿ≥€å €å€ÅŸàÿØ€å ⁄©Ÿà ⁄Ü⁄æŸæÿß ÿ±€Å€í €Å€å⁄∫€î\nPREDICTED: \n\nGOLD: ÿ¨ÿ±ŸÖŸÜ€å ÿ¥€Åÿ±€åŸà⁄∫ ⁄©Ÿà ÿßÿ≥ Ÿæÿ±€åÿ¥ÿßŸÜ€å ⁄©ÿß ÿ≥ÿßŸÖŸÜÿß ⁄©ÿ±ŸÜÿß Ÿæ⁄ëÿß ÿ¨ÿ® €ÅŸπŸÑÿ± ⁄©€å ÿÆŸÅ€å€Å ŸæŸàŸÑ€åÿ≥ ŸÜ€í €å€Å ÿ¨ÿßŸÜŸÜ€í ⁄©ÿß ŸÖÿ∑ÿßŸÑÿ®€Å ⁄©€åÿß ⁄©€Å ⁄©€åÿß Ÿà€Å ÿßŸæŸÜ€í ⁄Ø⁄æÿ± ŸÖ€å⁄∫ ⁄©ÿ≥€å €å€ÅŸàÿØ€å ⁄©Ÿà ⁄Ü⁄æŸæÿß ÿ±€Å€í €Å€å⁄∫€î\nPREDICTED: \n\nGOLD: ÿ¨ÿ±ŸÖŸÜ€å ÿ¥€Åÿ±€åŸà⁄∫ ⁄©Ÿà ÿßÿ≥ Ÿæÿ±€åÿ¥ÿßŸÜ€å ⁄©ÿß ÿ≥ÿßŸÖŸÜÿß ⁄©ÿ±ŸÜÿß Ÿæ⁄ëÿß ÿ¨ÿ® €ÅŸπŸÑÿ± ⁄©€å ÿÆŸÅ€å€Å ŸæŸàŸÑ€åÿ≥ ŸÜ€í €å€Å ÿ¨ÿßŸÜŸÜ€í ⁄©ÿß ŸÖÿ∑ÿßŸÑÿ®€Å ⁄©€åÿß ⁄©€Å ⁄©€åÿß Ÿà€Å ÿßŸæŸÜ€í ⁄Ø⁄æÿ± ŸÖ€å⁄∫ ⁄©ÿ≥€å €å€ÅŸàÿØ€å ⁄©Ÿà ⁄Ü⁄æŸæÿß ÿ±€Å€í €Å€å⁄∫€î\nPREDICTED: \n\nGOLD: ÿ¨ÿ±ŸÖŸÜ€å ÿ¥€Åÿ±€åŸà⁄∫ ⁄©Ÿà ÿßÿ≥ Ÿæÿ±€åÿ¥ÿßŸÜ€å ⁄©ÿß ÿ≥ÿßŸÖŸÜÿß ⁄©ÿ±ŸÜÿß Ÿæ⁄ëÿß ÿ¨ÿ® €ÅŸπŸÑÿ± ⁄©€å ÿÆŸÅ€å€Å ŸæŸàŸÑ€åÿ≥ ŸÜ€í €å€Å ÿ¨ÿßŸÜŸÜ€í ⁄©ÿß ŸÖÿ∑ÿßŸÑÿ®€Å ⁄©€åÿß ⁄©€Å ⁄©€åÿß Ÿà€Å ÿßŸæŸÜ€í ⁄Ø⁄æÿ± ŸÖ€å⁄∫ ⁄©ÿ≥€å €å€ÅŸàÿØ€å ⁄©Ÿà ⁄Ü⁄æŸæÿß ÿ±€Å€í €Å€å⁄∫€î\nPREDICTED: \n\nGOLD: ÿ¨ÿ±ŸÖŸÜ€å ÿ¥€Åÿ±€åŸà⁄∫ ⁄©Ÿà ÿßÿ≥ Ÿæÿ±€åÿ¥ÿßŸÜ€å ⁄©ÿß ÿ≥ÿßŸÖŸÜÿß ⁄©ÿ±ŸÜÿß Ÿæ⁄ëÿß ÿ¨ÿ® €ÅŸπŸÑÿ± ⁄©€å ÿÆŸÅ€å€Å ŸæŸàŸÑ€åÿ≥ ŸÜ€í €å€Å ÿ¨ÿßŸÜŸÜ€í ⁄©ÿß ŸÖÿ∑ÿßŸÑÿ®€Å ⁄©€åÿß ⁄©€Å ⁄©€åÿß Ÿà€Å ÿßŸæŸÜ€í ⁄Ø⁄æÿ± ŸÖ€å⁄∫ ⁄©ÿ≥€å €å€ÅŸàÿØ€å ⁄©Ÿà ⁄Ü⁄æŸæÿß ÿ±€Å€í €Å€å⁄∫€î\nPREDICTED: \n\nGOLD: Ÿæÿ±€åŸπ€åŸÜ⁄àŸàÿ≥ ÿ±€åŸÅÿßÿ±ŸÖ\nPREDICTED: \n\nGOLD: Ÿæÿ±€åŸπ€åŸÜ⁄àŸàÿ≥ ÿ±€åŸÅÿßÿ±ŸÖ\nPREDICTED: Ÿæÿ±€åŸπ€åŸÜ⁄àŸàÿ≥ ÿ±€åŸÅÿßÿ±ŸÖ\n\nGOLD: Ÿæÿ±€åŸπ€åŸÜ⁄àŸàÿ≥ ÿ±€åŸÅÿßÿ±ŸÖ\nPREDICTED: \n\nGOLD: €ÅŸÑ⁄©€å €ÅŸàÿ¨ÿßÿ™€å €Å€å⁄∫ ÿßŸàÿ± ÿßÿ≥ ÿπŸÖŸÑ ŸÖ€å⁄∫ ⁄©⁄Ü⁄æ ⁄©⁄æŸà ÿØ€åÿ™€å €Å€å⁄∫€î\nPREDICTED: \n\nGOLD: €ÅŸÑ⁄©€å €ÅŸàÿ¨ÿßÿ™€å €Å€å⁄∫ ÿßŸàÿ± ÿßÿ≥ ÿπŸÖŸÑ ŸÖ€å⁄∫ ⁄©⁄Ü⁄æ ⁄©⁄æŸà ÿØ€åÿ™€å €Å€å⁄∫€î\nPREDICTED: €ÅŸÑ⁄©€å €ÅŸàÿ¨ÿßÿ™€å €Å€å⁄∫ ÿßŸàÿ± ÿßÿ≥ ÿπŸÖŸÑ ŸÖ€å⁄∫ ⁄©⁄Ü⁄æ ⁄©⁄æŸà ÿØ€åÿ™€å €Å€å⁄∫€î\n\nGOLD: €ÅŸÑ⁄©€å €ÅŸàÿ¨ÿßÿ™€å €Å€å⁄∫ ÿßŸàÿ± ÿßÿ≥ ÿπŸÖŸÑ ŸÖ€å⁄∫ ⁄©⁄Ü⁄æ ⁄©⁄æŸà ÿØ€åÿ™€å €Å€å⁄∫€î\nPREDICTED: \n\nGOLD: ÿ¨ÿ® ÿ¨ÿßŸÜŸàÿ± ⁄©⁄æÿßŸÜÿß ŸÜ€Å€å⁄∫ ⁄©⁄æÿß ÿ±€Åÿß €Å€í ÿ™Ÿà ŸÖŸÜ€Å ÿ®ŸÜÿØ ⁄©ÿ±ÿØ€åÿ™€å €Å€í\nPREDICTED: \n\nGOLD: ÿ¨ÿ® ÿ¨ÿßŸÜŸàÿ± ⁄©⁄æÿßŸÜÿß ŸÜ€Å€å⁄∫ ⁄©⁄æÿß ÿ±€Åÿß €Å€í ÿ™Ÿà ŸÖŸÜ€Å ÿ®ŸÜÿØ ⁄©ÿ±ÿØ€åÿ™€å €Å€í\nPREDICTED: \n\nGOLD: ÿ¨ÿ® ÿ¨ÿßŸÜŸàÿ± ⁄©⁄æÿßŸÜÿß ŸÜ€Å€å⁄∫ ⁄©⁄æÿß ÿ±€Åÿß €Å€í ÿ™Ÿà ŸÖŸÜ€Å ÿ®ŸÜÿØ ⁄©ÿ±ÿØ€åÿ™€å €Å€í\nPREDICTED: ÿ¨ÿ® ÿ¨ÿßŸÜŸàÿ± ⁄©⁄æÿßŸÜÿß ŸÜ€Å€å⁄∫ ⁄©⁄æÿß ÿ±€Åÿß €Å€í ÿ™Ÿà ŸÖŸÜ€Å ÿ®ŸÜÿØ ⁄©ÿ±ÿØ€åÿ™€å €Å€í\n\nGOLD: Ÿæ€ÅŸÑ€í ÿßŸÑ⁄Ø ÿßŸÑ⁄Ø ŸÖ€Åÿßÿ±ÿ™Ÿà⁄∫\nPREDICTED: Ÿæ€ÅŸÑ€í ÿßŸÑ⁄Ø ÿßŸÑ⁄Ø ŸÖ€Åÿßÿ±ÿ™Ÿà⁄∫\n\nGOLD: Ÿæ€ÅŸÑ€í ÿßŸÑ⁄Ø ÿßŸÑ⁄Ø ŸÖ€Åÿßÿ±ÿ™Ÿà⁄∫\nPREDICTED: \n\nGOLD: Ÿæ€ÅŸÑ€í ÿßŸÑ⁄Ø ÿßŸÑ⁄Ø ŸÖ€Åÿßÿ±ÿ™Ÿà⁄∫\nPREDICTED: \n\nGOLD: ⁄©ÿ¶€å ŸÖÿ±ÿßÿ≠ŸÑ ŸÖ€å⁄∫\nPREDICTED: \n\nGOLD: ⁄©ÿ¶€å ŸÖÿ±ÿßÿ≠ŸÑ ŸÖ€å⁄∫\nPREDICTED: ⁄©ÿ¶€å ŸÖÿ±ÿßÿ≠ŸÑ ŸÖ€å⁄∫\n\nGOLD: ŸÅÿßÿ±€åŸÜ⁄©ÿ≥ ⁄©Ÿà ÿßŸÑŸπÿß ⁄©ÿ±⁄©€í ÿßŸàÿ± ÿßÿ≥€í ŸæŸπ⁄æŸà⁄∫ ⁄©€í Ÿæÿßÿ§⁄∫ ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄©ÿ±⁄©€í ÿ≥ÿ∑ÿ≠Ÿà⁄∫ Ÿæÿ± ⁄ÜŸæ⁄© ÿ¨ÿßÿ™€í €Å€å⁄∫\nPREDICTED: ŸÅÿßÿ±€åŸÜ⁄©ÿ≥ ⁄©Ÿà ÿßŸÑŸπÿß ⁄©ÿ±⁄©€í ÿßŸàÿ± ÿßÿ≥€í ŸæŸπ⁄æŸà⁄∫ ⁄©€í Ÿæÿßÿ§⁄∫ ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄©ÿ±⁄©€í ÿ≥ÿ∑ÿ≠Ÿà⁄∫ Ÿæÿ± ⁄ÜŸæ⁄© ÿ¨ÿßÿ™€í €Å€å⁄∫\n\nGOLD: ŸÅÿßÿ±€åŸÜ⁄©ÿ≥ ⁄©Ÿà ÿßŸÑŸπÿß ⁄©ÿ±⁄©€í ÿßŸàÿ± ÿßÿ≥€í ŸæŸπ⁄æŸà⁄∫ ⁄©€í Ÿæÿßÿ§⁄∫ ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄©ÿ±⁄©€í ÿ≥ÿ∑ÿ≠Ÿà⁄∫ Ÿæÿ± ⁄ÜŸæ⁄© ÿ¨ÿßÿ™€í €Å€å⁄∫\nPREDICTED: \n\nGOLD: lysozyme ÿßŸàÿ± phospholipase a2\nPREDICTED: lysozyme ÿßŸàÿ± phospholipase a2\n\nGOLD: lysozyme ÿßŸàÿ± phospholipase a2\nPREDICTED: \n\nGOLD: ŸÅÿ±ÿßŸÜÿ≥€åÿ≥€å ÿ∫€åÿ± ŸÖŸÜÿ∏ŸÖ ÿßŸÅŸàÿßÿ¨\nPREDICTED: ŸÅÿ±ÿßŸÜÿ≥€åÿ≥€å ÿ∫€åÿ± ŸÖŸÜÿ∏ŸÖ ÿßŸÅŸàÿßÿ¨\n\nGOLD: ŸÅÿ±ÿßŸÜÿ≥€åÿ≥€å ÿ∫€åÿ± ŸÖŸÜÿ∏ŸÖ ÿßŸÅŸàÿßÿ¨\nPREDICTED: \n\nGOLD: ŸÅÿ±ÿßŸÜÿ≥€åÿ≥€å ÿ∫€åÿ± ŸÖŸÜÿ∏ŸÖ ÿßŸÅŸàÿßÿ¨\nPREDICTED: \n\nGOLD: ÿßÿ≥ÿ™ÿπŸÖÿßÿ±\nPREDICTED: ÿßÿ≥ÿ™ÿπŸÖÿßÿ±\n\nGOLD: ÿßÿ≥ÿ™ÿπŸÖÿßÿ±\nPREDICTED: \n\nGOLD: ÿßÿ≥ÿ™ÿπŸÖÿßÿ±\nPREDICTED: \n\nGOLD: ŸÖÿßÿ¶ÿπ ŸÜÿßÿ¶Ÿπÿ±Ÿàÿ¨ŸÜ\nPREDICTED: \n\nGOLD: ŸÖÿßÿ¶ÿπ ŸÜÿßÿ¶Ÿπÿ±Ÿàÿ¨ŸÜ\nPREDICTED: ŸÖÿßÿ¶ÿπ ŸÜÿßÿ¶Ÿπÿ±Ÿàÿ¨ŸÜ\n\nGOLD: ŸÖÿßÿ¶ÿπ ŸÜÿßÿ¶Ÿπÿ±Ÿàÿ¨ŸÜ\nPREDICTED: \n\nGOLD: ÿ≥€åŸÜ⁄àŸà€å⁄Ü ÿå ŸÅ€åŸàÿ±ÿ≤ ÿßŸàÿ± ŸÖ€å⁄àÿ≥ŸπŸàŸÜ Ÿπÿßÿ§ŸÜ\nPREDICTED: \n\nGOLD: ÿ≥€åŸÜ⁄àŸà€å⁄Ü ÿå ŸÅ€åŸàÿ±ÿ≤ ÿßŸàÿ± ŸÖ€å⁄àÿ≥ŸπŸàŸÜ Ÿπÿßÿ§ŸÜ\nPREDICTED: \n\nGOLD: ÿ≥€åŸÜ⁄àŸà€å⁄Ü ÿå ŸÅ€åŸàÿ±ÿ≤ ÿßŸàÿ± ŸÖ€å⁄àÿ≥ŸπŸàŸÜ Ÿπÿßÿ§ŸÜ\nPREDICTED: ÿ≥€åŸÜ⁄àŸà€å⁄Ü ÿå ŸÅ€åŸàÿ±ÿ≤ ÿßŸàÿ± ŸÖ€å⁄àÿ≥ŸπŸàŸÜ Ÿπÿßÿ§ŸÜ\n\nGOLD: ŸÖŸπ€å ÿå ÿØÿ±€åÿßÿ§⁄∫ ÿå ŸÖŸÜÿßÿ∏ÿ± ÿßŸàÿ± ⁄ØŸÑ€åÿ¥€åÿ¶ÿ±ÿ≤\nPREDICTED: \n\nGOLD: ŸÖŸπ€å ÿå ÿØÿ±€åÿßÿ§⁄∫ ÿå ŸÖŸÜÿßÿ∏ÿ± ÿßŸàÿ± ⁄ØŸÑ€åÿ¥€åÿ¶ÿ±ÿ≤\nPREDICTED: ŸÖŸπ€å ÿå ÿØÿ±€åÿßÿ§⁄∫ ÿå ŸÖŸÜÿßÿ∏ÿ± ÿßŸàÿ± ⁄ØŸÑ€åÿ¥€åÿ¶ÿ±ÿ≤\n\nGOLD: ŸÖŸπ€å ÿå ÿØÿ±€åÿßÿ§⁄∫ ÿå ŸÖŸÜÿßÿ∏ÿ± ÿßŸàÿ± ⁄ØŸÑ€åÿ¥€åÿ¶ÿ±ÿ≤\nPREDICTED: \n\nGOLD: ŸÅÿ±ÿ≥ŸÜŸà ÿßÿ≥Ÿπÿ±€åŸπ ÿßŸàÿ± ÿ™⁄æŸàÿ±ŸÜ ÿß€åŸà\nPREDICTED: \n\nGOLD: ŸÅÿ±ÿ≥ŸÜŸà ÿßÿ≥Ÿπÿ±€åŸπ ÿßŸàÿ± ÿ™⁄æŸàÿ±ŸÜ ÿß€åŸà\nPREDICTED: ŸÅÿ±ÿ≥ŸÜŸà ÿßÿ≥Ÿπÿ±€åŸπ ÿßŸàÿ± ÿ™⁄æŸàÿ±ŸÜ ÿß€åŸà\n\nGOLD: ŸÅÿ±ÿ≥ŸÜŸà ÿßÿ≥Ÿπÿ±€åŸπ ÿßŸàÿ± ÿ™⁄æŸàÿ±ŸÜ ÿß€åŸà\nPREDICTED: \n\nGOLD: ŸÅÿ±ÿ≥ŸÜŸà ÿßÿ≥Ÿπÿ±€åŸπ ÿßŸàÿ± ÿ™⁄æŸàÿ±ŸÜ ÿß€åŸà\nPREDICTED: \n\nGOLD: ÿß€å⁄© ŸÖÿπ€åÿßÿ±€å ŸÖÿß⁄àŸÑ\nPREDICTED: ÿß€å⁄© ŸÖÿπ€åÿßÿ±€å ŸÖÿß⁄àŸÑ\n\nGOLD: ÿß€å⁄© ŸÖÿπ€åÿßÿ±€å ŸÖÿß⁄àŸÑ\nPREDICTED: \n\nGOLD: ÿß€å⁄© ŸÖÿπ€åÿßÿ±€å ŸÖÿß⁄àŸÑ\nPREDICTED: \n\nGOLD: ŸπŸÜ⁄ØŸà⁄∫ ⁄©€å ⁄©ŸÖ€å\nPREDICTED: \n\nGOLD: ŸπŸÜ⁄ØŸà⁄∫ ⁄©€å ⁄©ŸÖ€å\nPREDICTED: ŸπŸÜ⁄ØŸà⁄∫ ⁄©€å ⁄©ŸÖ€å\n\nGOLD: ŸπŸÜ⁄ØŸà⁄∫ ⁄©€å ⁄©ŸÖ€å\nPREDICTED: ŸπŸÜ⁄ØŸà⁄∫ ⁄©€å ⁄©ŸÖ€å\n\nGOLD: ŸπŸÜ⁄ØŸà⁄∫ ⁄©€å ⁄©ŸÖ€å\nPREDICTED: \n\nGOLD: ŸπŸÜ⁄ØŸà⁄∫ ⁄©€å ⁄©ŸÖ€å\nPREDICTED: \n\nGOLD: 105 ÿ®ŸÑ€åŸÜ ⁄àÿßŸÑÿ±\nPREDICTED: \n\nGOLD: 105 ÿ®ŸÑ€åŸÜ ⁄àÿßŸÑÿ±\nPREDICTED: \n\nGOLD: 105 ÿ®ŸÑ€åŸÜ ⁄àÿßŸÑÿ±\nPREDICTED: 105 ÿ®ŸÑ€åŸÜ ⁄àÿßŸÑÿ±\n\nGOLD: ⁄ØŸÑ€åŸÑ€åŸà ⁄ØŸÑ€åŸÑ€å\nPREDICTED: ⁄ØŸÑ€åŸÑ€åŸà ⁄ØŸÑ€åŸÑ€å\n\nGOLD: ⁄ØŸÑ€åŸÑ€åŸà ⁄ØŸÑ€åŸÑ€å\nPREDICTED: \n\nGOLD: ⁄ØŸÑ€åŸÑ€åŸà ⁄ØŸÑ€åŸÑ€å\nPREDICTED: \n\nGOLD: ⁄Ü€åŸÜŸÑ 4 ÿß€å⁄Ü ⁄à€å\nPREDICTED: \n\nGOLD: ⁄Ü€åŸÜŸÑ 4 ÿß€å⁄Ü ⁄à€å\nPREDICTED: ⁄Ü€åŸÜŸÑ 4 ÿß€å⁄Ü ⁄à€å\n\nGOLD: ⁄Ü€åŸÜŸÑ 4 ÿß€å⁄Ü ⁄à€å\nPREDICTED: \n\nGOLD: 2011\nPREDICTED: 2011\n\nGOLD: 2011\nPREDICTED: \n\nGOLD: 2011\nPREDICTED: \n\nGOLD: 2011\nPREDICTED: \n\nGOLD: 2011\nPREDICTED: \n\nGOLD: ÿµŸÜÿπÿ™€å ŸÖŸÖÿßŸÑ⁄© ŸÜ€í ÿßŸæŸÜ€í ÿ∞ÿÆÿßÿ¶ÿ± ŸÖ€å⁄∫ ÿßÿ∂ÿßŸÅ€Å\nPREDICTED: \n\nGOLD: ÿµŸÜÿπÿ™€å ŸÖŸÖÿßŸÑ⁄© ŸÜ€í ÿßŸæŸÜ€í ÿ∞ÿÆÿßÿ¶ÿ± ŸÖ€å⁄∫ ÿßÿ∂ÿßŸÅ€Å\nPREDICTED: ÿµŸÜÿπÿ™€å ŸÖŸÖÿßŸÑ⁄© ŸÜ€í ÿßŸæŸÜ€í ÿ∞ÿÆÿßÿ¶ÿ± ŸÖ€å⁄∫ ÿßÿ∂ÿßŸÅ€Å\n\nGOLD: ÿµŸÜÿπÿ™€å ŸÖŸÖÿßŸÑ⁄© ŸÜ€í ÿßŸæŸÜ€í ÿ∞ÿÆÿßÿ¶ÿ± ŸÖ€å⁄∫ ÿßÿ∂ÿßŸÅ€Å\nPREDICTED: ÿµŸÜÿπÿ™€å ŸÖŸÖÿßŸÑ⁄© ŸÜ€í ÿßŸæŸÜ€í ÿ∞ÿÆÿßÿ¶ÿ± ŸÖ€å⁄∫ ÿßÿ∂ÿßŸÅ€Å\n\nGOLD: 1795\nPREDICTED: \n\nGOLD: 1795\nPREDICTED: 1795\n\nGOLD: ÿÆÿ≤ÿß⁄∫ 1347\nPREDICTED: ÿÆÿ≤ÿß⁄∫ 1347\n\nGOLD: ÿÆÿ≤ÿß⁄∫ 1347\nPREDICTED: \n\n   Validation accuracy: 34/100 (34.0%)\n   ‚ùå WARNING: Validation accuracy is low!\n================================================================================\n","output_type":"stream"}],"execution_count":95},{"id":"fb2600f9-5e66-462f-a6d6-198fde492516","cell_type":"markdown","source":"### !!! KEY TAKEAWAY FROM ABOVE CELLS!\n\nA lot of chunks do not have the answer in the chunked context, so (0, 0) -> `[CLS]` tok is being predicted!\nThis may be giving way to a lot of mispredictions in evaluation!","metadata":{}},{"id":"9330877d-a03e-46ad-be6a-9a0c679f9f01","cell_type":"markdown","source":"---","metadata":{}},{"id":"16","cell_type":"code","source":"# processed_train","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:07.138750Z","iopub.execute_input":"2025-12-14T13:45:07.139021Z","iopub.status.idle":"2025-12-14T13:45:07.142175Z","shell.execute_reply.started":"2025-12-14T13:45:07.139003Z","shell.execute_reply":"2025-12-14T13:45:07.141502Z"},"id":"D-emFQTIaZRL","trusted":true},"outputs":[],"execution_count":96},{"id":"19","cell_type":"code","source":"# processed_val","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:07.142755Z","iopub.execute_input":"2025-12-14T13:45:07.143038Z","iopub.status.idle":"2025-12-14T13:45:07.156093Z","shell.execute_reply.started":"2025-12-14T13:45:07.143013Z","shell.execute_reply":"2025-12-14T13:45:07.155355Z"},"id":"Yy3SiWwCabEi","trusted":true},"outputs":[],"execution_count":97},{"id":"20","cell_type":"code","source":"# Save newly processed data (OPTIONAL - for future reuse with same filtered dataset)\nprocessed_train.save_to_disk(\"/kaggle/working/cache/processed_train_uqa_filtered\")\nprocessed_val.save_to_disk(\"/kaggle/working/cache/processed_val_uqa_filtered\")\n\n# # ‚ùå DO NOT load old cache - it has index mismatches with filtered data!\n# # If you've already run the preprocessing cell above, skip this cell\n\nprocessed_train = load_from_disk(\"/kaggle/working/cache/processed_train_uqa_filtered\")\nprocessed_val = load_from_disk(\"/kaggle/working/cache/processed_val_uqa_filtered\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["05d936e2dc9d412b8637c174a3c0be64","7e0b41aa16f241a4ba3bb8a2f3525984","2bebe7e1f3f341dfaabf29963d2c5995","41b300b02ed2413ba80865aaa99ece2a","b4740a7137e742d687e2075b60d2be8a","80132c8e4fa743fca850936ecfebc7f7","303bb3d75f7d4e94aeb60c5491ea6e61","d7463faafecf4e46a87dc6863a646cea","bc199cddba714aeda650d97fef015a14","1a508a6457bb460ba17d5adb0a9e9f85","3aac2656907a416291a622717ccaf929","fa1af70d9c95443c9f09666359ba3769","ddb717fd4dbc40c6bd8422a02f925060","6d1342eeaf4f4f0489fe0746ceaaeb09","a10683e5c1164f349cbdc75b1567994c","71cfe2c8df474badb255d7d28da04348","077fbb403e5f4069841e558a3cc0c065","b068b9fac9f24eca9bd430bab30ea70c","8cbfc6f4ec434674ac59d3fbdbddcd3b","4d675a6788b641c6a09604ef17514dec","bd9b9f21be9744c49d99ac4bc76f11e1","89469ab4bd6f48d8b9aa369473c7230f"]},"execution":{"iopub.status.busy":"2025-12-14T13:45:07.156810Z","iopub.execute_input":"2025-12-14T13:45:07.157134Z","iopub.status.idle":"2025-12-14T13:45:08.284110Z","shell.execute_reply.started":"2025-12-14T13:45:07.157112Z","shell.execute_reply":"2025-12-14T13:45:08.283360Z"},"id":"77ecdd17","outputId":"602e648b-4a75-424b-da09-d58f3295a65e","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/2 shards):   0%|          | 0/234581 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"799ed9d1605549a58539c4587f2b772f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/25319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c7d8a035edc42da8e13d707f3f9b576"}},"metadata":{}}],"execution_count":98},{"id":"21","cell_type":"code","source":"def print_trainable_parameters(model):\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:08.285127Z","iopub.execute_input":"2025-12-14T13:45:08.285338Z","iopub.status.idle":"2025-12-14T13:45:08.289714Z","shell.execute_reply.started":"2025-12-14T13:45:08.285322Z","shell.execute_reply":"2025-12-14T13:45:08.288902Z"},"id":"c0e06e6b","trusted":true},"outputs":[],"execution_count":99},{"id":"22","cell_type":"code","source":"# build LoRA model\n\npeft_model = get_peft_model(model, lora_config)\npeft_model.gradient_checkpointing_enable()\nprint_trainable_parameters(peft_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-14T13:45:08.292250Z","iopub.execute_input":"2025-12-14T13:45:08.292443Z","iopub.status.idle":"2025-12-14T13:45:08.339732Z","shell.execute_reply.started":"2025-12-14T13:45:08.292427Z","shell.execute_reply":"2025-12-14T13:45:08.339068Z"},"id":"ba9eeeed","outputId":"27071b6e-b703-4b47-9288-9a1c6f3eba55","trusted":true},"outputs":[{"name":"stdout","text":"trainable params: 345602 || all params: 132430084 || trainable%: 0.26096940329661045\n","output_type":"stream"}],"execution_count":100},{"id":"5a98237c","cell_type":"markdown","source":"---","metadata":{}},{"id":"24","cell_type":"markdown","source":"## Model Training:\n","metadata":{}},{"id":"26","cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"outputs/canine-s-uqa-filtered\",\n\n    per_device_train_batch_size=4,  # increased train_batch_size from tydiqa\n    per_device_eval_batch_size=16,\n\n    gradient_accumulation_steps=4,  # decreased grad accum from tydiqa\n    gradient_checkpointing=True,\n\n    num_train_epochs=1, # same as tydiqa\n    learning_rate=3e-5,  \n    weight_decay=0.01,\n    \n    eval_strategy=\"no\",\n    eval_steps=500,\n    save_strategy=\"steps\",\n    save_steps=1000,  # increased to 1000\n    logging_steps=50,\n    \n    fp16=True,\n    bf16=False,\n    report_to=\"none\",\n    push_to_hub=True,\n    hub_model_id=\"VohraAK/canine-s-uqa-filtered\",\n    hub_strategy=\"checkpoint\",\n    )\n\n# CustomEvalCallback - EXACT TyDiQA approach\nclass CustomEvalCallback(TrainerCallback):\n    def __init__(self, eval_func, eval_dataset):\n        self.eval_func = eval_func\n        self.eval_dataset = eval_dataset\n\n    def on_save(self, args, state, control, model=None, **kwargs):\n        \"\"\"\n        Runs AFTER checkpoint is saved.\n        Loads checkpoint from disk and evaluates it.\n        \"\"\"\n        checkpoint_path = f\"{args.output_dir}/checkpoint-{state.global_step}\"\n        print(f\"\\nüîç Running custom evaluation at step {state.global_step}...\")\n\n        # Call evaluation function (loads from checkpoint)\n        metrics = self.eval_func(checkpoint_path)\n\n        # Add metrics to state's log_history\n        state.log_history.append({\n            \"step\": state.global_step,\n            \"eval_exact_match\": metrics[\"exact_match\"],\n            \"eval_f1\": metrics[\"f1\"],\n            \"eval_edit_distance\": metrics[\"edit_distance\"],\n        })\n\n        # Print metrics\n        print(f\"‚úÖ Step {state.global_step}: EM={metrics['exact_match']*100:.2f}, F1={metrics['f1']*100:.2f}, EditDist={metrics['edit_distance']*100:.2f}\")\n\n        # Re-save trainer_state.json with updated metrics\n        state_path = f\"{checkpoint_path}/trainer_state.json\"\n        try:\n            with open(state_path, 'r') as f:\n                state_dict = json.load(f)\n            state_dict['log_history'] = state.log_history\n            with open(state_path, 'w') as f:\n                json.dump(state_dict, f, indent=2)\n            print(f\"üíæ Updated trainer_state.json with custom metrics\")\n        except Exception as e:\n            print(f\"‚ö†Ô∏è  Warning: Could not update trainer_state.json: {e}\")\n\n        # Push to Hub\n        try:\n            print(f\"‚òÅÔ∏è  Pushing checkpoint-{state.global_step} to Hub...\")\n            api = HfApi()\n            api.upload_folder(\n                folder_path=checkpoint_path,\n                repo_id=args.hub_model_id,\n                path_in_repo=f\"checkpoint-{state.global_step}\",\n                commit_message=f\"Add checkpoint {state.global_step} (EM={metrics['exact_match']*100:.1f}%, F1={metrics['f1']*100:.1f}%)\",\n                repo_type=\"model\"\n            )\n            print(f\"‚úÖ Pushed checkpoint-{state.global_step} to Hub\")\n        except Exception as e:\n            print(f\"‚ö†Ô∏è  Warning: Could not push to Hub: {e}\")\n\n        return control\n\n","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:08.360265Z","iopub.execute_input":"2025-12-14T13:45:08.360505Z","iopub.status.idle":"2025-12-14T13:45:08.391782Z","shell.execute_reply.started":"2025-12-14T13:45:08.360485Z","shell.execute_reply":"2025-12-14T13:45:08.391279Z"},"id":"c4abaaab","trusted":true},"outputs":[],"execution_count":102},{"id":"27","cell_type":"code","source":"trainer_cb = CustomEvalCallback(evaluate_checkpoint, processed_val)\n\ntrainer = Trainer(\n    model=peft_model,\n    args=training_args,\n    train_dataset=processed_train,\n    eval_dataset=processed_val,\n    callbacks=[trainer_cb],\n)","metadata":{"execution":{"iopub.status.busy":"2025-12-14T13:45:08.392400Z","iopub.execute_input":"2025-12-14T13:45:08.392595Z","iopub.status.idle":"2025-12-14T13:45:09.221695Z","shell.execute_reply.started":"2025-12-14T13:45:08.392581Z","shell.execute_reply":"2025-12-14T13:45:09.220715Z"},"id":"055f5dda","trusted":true},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":103},{"id":"28","cell_type":"code","source":"trainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.status.busy":"2025-12-14T13:45:09.223080Z","iopub.execute_input":"2025-12-14T13:45:09.223294Z","iopub.status.idle":"2025-12-14T17:21:25.230454Z","shell.execute_reply.started":"2025-12-14T13:45:09.223277Z","shell.execute_reply":"2025-12-14T17:21:25.229793Z"},"id":"TOUimesUX5Re","outputId":"cfa62dcd-8eb4-475a-910b-1c38a3894cc2","trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='14662' max='14662' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [14662/14662 3:36:15, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>5.945100</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>5.902400</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>5.867500</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>5.836600</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>5.798700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>5.774400</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>5.734800</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>5.704400</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>5.662000</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>5.631800</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>5.612400</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>5.574700</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>5.555100</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>5.541700</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>5.520000</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>5.472400</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>5.440000</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>5.414000</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>5.386000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>5.372200</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>5.361100</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>5.319200</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>5.291400</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>5.267300</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>5.243500</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>5.260100</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>5.184100</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>5.174600</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>5.155100</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>5.163600</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>5.138100</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>5.078700</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>5.077000</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>5.084700</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>5.131400</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>5.027200</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>5.017200</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>4.988700</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>5.006200</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>4.942200</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>4.934800</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>4.892700</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>4.952600</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>4.914300</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>4.881000</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>4.860300</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>4.852100</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>4.859900</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>4.833600</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>4.782600</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>4.888000</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>4.762100</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>4.783700</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>4.729500</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>4.741300</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>4.705000</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>4.758800</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>4.670800</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>4.786800</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>4.741100</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>4.681000</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>4.669600</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>4.646400</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>4.707100</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>4.665900</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>4.521000</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>4.619100</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>4.692900</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>4.592200</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>4.545300</td>\n    </tr>\n    <tr>\n      <td>3550</td>\n      <td>4.496600</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>4.599400</td>\n    </tr>\n    <tr>\n      <td>3650</td>\n      <td>4.547700</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>4.555800</td>\n    </tr>\n    <tr>\n      <td>3750</td>\n      <td>4.566200</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>4.612700</td>\n    </tr>\n    <tr>\n      <td>3850</td>\n      <td>4.549500</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>4.539800</td>\n    </tr>\n    <tr>\n      <td>3950</td>\n      <td>4.556500</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>4.594000</td>\n    </tr>\n    <tr>\n      <td>4050</td>\n      <td>4.442800</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>4.496200</td>\n    </tr>\n    <tr>\n      <td>4150</td>\n      <td>4.541600</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>4.469600</td>\n    </tr>\n    <tr>\n      <td>4250</td>\n      <td>4.425700</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>4.510400</td>\n    </tr>\n    <tr>\n      <td>4350</td>\n      <td>4.412600</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>4.456700</td>\n    </tr>\n    <tr>\n      <td>4450</td>\n      <td>4.375900</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>4.407800</td>\n    </tr>\n    <tr>\n      <td>4550</td>\n      <td>4.406300</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>4.513900</td>\n    </tr>\n    <tr>\n      <td>4650</td>\n      <td>4.418200</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>4.484200</td>\n    </tr>\n    <tr>\n      <td>4750</td>\n      <td>4.360400</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>4.388300</td>\n    </tr>\n    <tr>\n      <td>4850</td>\n      <td>4.385700</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>4.337700</td>\n    </tr>\n    <tr>\n      <td>4950</td>\n      <td>4.410500</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>4.302900</td>\n    </tr>\n    <tr>\n      <td>5050</td>\n      <td>4.334500</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>4.401900</td>\n    </tr>\n    <tr>\n      <td>5150</td>\n      <td>4.287000</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>4.324200</td>\n    </tr>\n    <tr>\n      <td>5250</td>\n      <td>4.250600</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>4.258800</td>\n    </tr>\n    <tr>\n      <td>5350</td>\n      <td>4.278800</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>4.298900</td>\n    </tr>\n    <tr>\n      <td>5450</td>\n      <td>4.238200</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>4.287300</td>\n    </tr>\n    <tr>\n      <td>5550</td>\n      <td>4.220700</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>4.371700</td>\n    </tr>\n    <tr>\n      <td>5650</td>\n      <td>4.275500</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>4.269900</td>\n    </tr>\n    <tr>\n      <td>5750</td>\n      <td>4.267100</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>4.251100</td>\n    </tr>\n    <tr>\n      <td>5850</td>\n      <td>4.226900</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>4.277000</td>\n    </tr>\n    <tr>\n      <td>5950</td>\n      <td>4.245700</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>4.227800</td>\n    </tr>\n    <tr>\n      <td>6050</td>\n      <td>4.228600</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>4.158800</td>\n    </tr>\n    <tr>\n      <td>6150</td>\n      <td>4.149700</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>4.178700</td>\n    </tr>\n    <tr>\n      <td>6250</td>\n      <td>4.205600</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>4.101300</td>\n    </tr>\n    <tr>\n      <td>6350</td>\n      <td>4.262300</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>4.183100</td>\n    </tr>\n    <tr>\n      <td>6450</td>\n      <td>4.108700</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>4.171800</td>\n    </tr>\n    <tr>\n      <td>6550</td>\n      <td>4.153500</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>4.199300</td>\n    </tr>\n    <tr>\n      <td>6650</td>\n      <td>4.215800</td>\n    </tr>\n    <tr>\n      <td>6700</td>\n      <td>4.066400</td>\n    </tr>\n    <tr>\n      <td>6750</td>\n      <td>4.171700</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>4.135900</td>\n    </tr>\n    <tr>\n      <td>6850</td>\n      <td>4.186800</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>4.044900</td>\n    </tr>\n    <tr>\n      <td>6950</td>\n      <td>4.056800</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>4.185500</td>\n    </tr>\n    <tr>\n      <td>7050</td>\n      <td>4.196500</td>\n    </tr>\n    <tr>\n      <td>7100</td>\n      <td>4.021200</td>\n    </tr>\n    <tr>\n      <td>7150</td>\n      <td>3.951800</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>4.096500</td>\n    </tr>\n    <tr>\n      <td>7250</td>\n      <td>4.173200</td>\n    </tr>\n    <tr>\n      <td>7300</td>\n      <td>4.068000</td>\n    </tr>\n    <tr>\n      <td>7350</td>\n      <td>4.067300</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>4.136500</td>\n    </tr>\n    <tr>\n      <td>7450</td>\n      <td>3.978500</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>4.113000</td>\n    </tr>\n    <tr>\n      <td>7550</td>\n      <td>4.054600</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>4.151100</td>\n    </tr>\n    <tr>\n      <td>7650</td>\n      <td>4.222800</td>\n    </tr>\n    <tr>\n      <td>7700</td>\n      <td>4.077700</td>\n    </tr>\n    <tr>\n      <td>7750</td>\n      <td>3.959400</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>4.043400</td>\n    </tr>\n    <tr>\n      <td>7850</td>\n      <td>4.130400</td>\n    </tr>\n    <tr>\n      <td>7900</td>\n      <td>4.044300</td>\n    </tr>\n    <tr>\n      <td>7950</td>\n      <td>4.073400</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>4.137400</td>\n    </tr>\n    <tr>\n      <td>8050</td>\n      <td>4.123200</td>\n    </tr>\n    <tr>\n      <td>8100</td>\n      <td>4.087100</td>\n    </tr>\n    <tr>\n      <td>8150</td>\n      <td>4.042400</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>4.101400</td>\n    </tr>\n    <tr>\n      <td>8250</td>\n      <td>4.009400</td>\n    </tr>\n    <tr>\n      <td>8300</td>\n      <td>4.008900</td>\n    </tr>\n    <tr>\n      <td>8350</td>\n      <td>4.058800</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>4.035900</td>\n    </tr>\n    <tr>\n      <td>8450</td>\n      <td>4.025000</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>4.151900</td>\n    </tr>\n    <tr>\n      <td>8550</td>\n      <td>4.010900</td>\n    </tr>\n    <tr>\n      <td>8600</td>\n      <td>3.973700</td>\n    </tr>\n    <tr>\n      <td>8650</td>\n      <td>3.974000</td>\n    </tr>\n    <tr>\n      <td>8700</td>\n      <td>4.026200</td>\n    </tr>\n    <tr>\n      <td>8750</td>\n      <td>4.024800</td>\n    </tr>\n    <tr>\n      <td>8800</td>\n      <td>3.898900</td>\n    </tr>\n    <tr>\n      <td>8850</td>\n      <td>3.980300</td>\n    </tr>\n    <tr>\n      <td>8900</td>\n      <td>3.996900</td>\n    </tr>\n    <tr>\n      <td>8950</td>\n      <td>3.985600</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>4.025100</td>\n    </tr>\n    <tr>\n      <td>9050</td>\n      <td>4.103300</td>\n    </tr>\n    <tr>\n      <td>9100</td>\n      <td>3.896900</td>\n    </tr>\n    <tr>\n      <td>9150</td>\n      <td>3.880500</td>\n    </tr>\n    <tr>\n      <td>9200</td>\n      <td>4.002800</td>\n    </tr>\n    <tr>\n      <td>9250</td>\n      <td>3.980100</td>\n    </tr>\n    <tr>\n      <td>9300</td>\n      <td>3.842600</td>\n    </tr>\n    <tr>\n      <td>9350</td>\n      <td>4.010800</td>\n    </tr>\n    <tr>\n      <td>9400</td>\n      <td>3.938900</td>\n    </tr>\n    <tr>\n      <td>9450</td>\n      <td>3.864500</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>3.934000</td>\n    </tr>\n    <tr>\n      <td>9550</td>\n      <td>3.967000</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>3.911200</td>\n    </tr>\n    <tr>\n      <td>9650</td>\n      <td>4.063100</td>\n    </tr>\n    <tr>\n      <td>9700</td>\n      <td>4.028600</td>\n    </tr>\n    <tr>\n      <td>9750</td>\n      <td>4.037000</td>\n    </tr>\n    <tr>\n      <td>9800</td>\n      <td>3.973000</td>\n    </tr>\n    <tr>\n      <td>9850</td>\n      <td>3.840600</td>\n    </tr>\n    <tr>\n      <td>9900</td>\n      <td>3.941600</td>\n    </tr>\n    <tr>\n      <td>9950</td>\n      <td>3.769700</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>3.978800</td>\n    </tr>\n    <tr>\n      <td>10050</td>\n      <td>3.965500</td>\n    </tr>\n    <tr>\n      <td>10100</td>\n      <td>3.977900</td>\n    </tr>\n    <tr>\n      <td>10150</td>\n      <td>3.933600</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>3.973500</td>\n    </tr>\n    <tr>\n      <td>10250</td>\n      <td>4.039700</td>\n    </tr>\n    <tr>\n      <td>10300</td>\n      <td>4.006900</td>\n    </tr>\n    <tr>\n      <td>10350</td>\n      <td>3.955200</td>\n    </tr>\n    <tr>\n      <td>10400</td>\n      <td>3.915100</td>\n    </tr>\n    <tr>\n      <td>10450</td>\n      <td>4.008900</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>3.872500</td>\n    </tr>\n    <tr>\n      <td>10550</td>\n      <td>3.929000</td>\n    </tr>\n    <tr>\n      <td>10600</td>\n      <td>3.870700</td>\n    </tr>\n    <tr>\n      <td>10650</td>\n      <td>3.956700</td>\n    </tr>\n    <tr>\n      <td>10700</td>\n      <td>3.849800</td>\n    </tr>\n    <tr>\n      <td>10750</td>\n      <td>3.951200</td>\n    </tr>\n    <tr>\n      <td>10800</td>\n      <td>3.976000</td>\n    </tr>\n    <tr>\n      <td>10850</td>\n      <td>3.931600</td>\n    </tr>\n    <tr>\n      <td>10900</td>\n      <td>3.892600</td>\n    </tr>\n    <tr>\n      <td>10950</td>\n      <td>3.880100</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>4.005700</td>\n    </tr>\n    <tr>\n      <td>11050</td>\n      <td>3.909900</td>\n    </tr>\n    <tr>\n      <td>11100</td>\n      <td>3.929200</td>\n    </tr>\n    <tr>\n      <td>11150</td>\n      <td>3.889300</td>\n    </tr>\n    <tr>\n      <td>11200</td>\n      <td>3.854100</td>\n    </tr>\n    <tr>\n      <td>11250</td>\n      <td>3.854200</td>\n    </tr>\n    <tr>\n      <td>11300</td>\n      <td>3.902600</td>\n    </tr>\n    <tr>\n      <td>11350</td>\n      <td>3.838000</td>\n    </tr>\n    <tr>\n      <td>11400</td>\n      <td>3.888900</td>\n    </tr>\n    <tr>\n      <td>11450</td>\n      <td>3.854000</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>3.876300</td>\n    </tr>\n    <tr>\n      <td>11550</td>\n      <td>3.799300</td>\n    </tr>\n    <tr>\n      <td>11600</td>\n      <td>3.884700</td>\n    </tr>\n    <tr>\n      <td>11650</td>\n      <td>3.894300</td>\n    </tr>\n    <tr>\n      <td>11700</td>\n      <td>3.901100</td>\n    </tr>\n    <tr>\n      <td>11750</td>\n      <td>3.939100</td>\n    </tr>\n    <tr>\n      <td>11800</td>\n      <td>3.840800</td>\n    </tr>\n    <tr>\n      <td>11850</td>\n      <td>3.764700</td>\n    </tr>\n    <tr>\n      <td>11900</td>\n      <td>3.775700</td>\n    </tr>\n    <tr>\n      <td>11950</td>\n      <td>3.921700</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>3.768000</td>\n    </tr>\n    <tr>\n      <td>12050</td>\n      <td>3.900000</td>\n    </tr>\n    <tr>\n      <td>12100</td>\n      <td>3.874900</td>\n    </tr>\n    <tr>\n      <td>12150</td>\n      <td>3.754900</td>\n    </tr>\n    <tr>\n      <td>12200</td>\n      <td>3.939100</td>\n    </tr>\n    <tr>\n      <td>12250</td>\n      <td>3.828600</td>\n    </tr>\n    <tr>\n      <td>12300</td>\n      <td>3.725200</td>\n    </tr>\n    <tr>\n      <td>12350</td>\n      <td>3.786800</td>\n    </tr>\n    <tr>\n      <td>12400</td>\n      <td>3.934800</td>\n    </tr>\n    <tr>\n      <td>12450</td>\n      <td>3.980100</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>3.833200</td>\n    </tr>\n    <tr>\n      <td>12550</td>\n      <td>3.971400</td>\n    </tr>\n    <tr>\n      <td>12600</td>\n      <td>3.926200</td>\n    </tr>\n    <tr>\n      <td>12650</td>\n      <td>3.796600</td>\n    </tr>\n    <tr>\n      <td>12700</td>\n      <td>3.937300</td>\n    </tr>\n    <tr>\n      <td>12750</td>\n      <td>3.805600</td>\n    </tr>\n    <tr>\n      <td>12800</td>\n      <td>3.910400</td>\n    </tr>\n    <tr>\n      <td>12850</td>\n      <td>3.847900</td>\n    </tr>\n    <tr>\n      <td>12900</td>\n      <td>3.916600</td>\n    </tr>\n    <tr>\n      <td>12950</td>\n      <td>3.859700</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>3.843900</td>\n    </tr>\n    <tr>\n      <td>13050</td>\n      <td>3.780500</td>\n    </tr>\n    <tr>\n      <td>13100</td>\n      <td>3.806500</td>\n    </tr>\n    <tr>\n      <td>13150</td>\n      <td>3.905900</td>\n    </tr>\n    <tr>\n      <td>13200</td>\n      <td>3.755900</td>\n    </tr>\n    <tr>\n      <td>13250</td>\n      <td>3.840200</td>\n    </tr>\n    <tr>\n      <td>13300</td>\n      <td>3.810300</td>\n    </tr>\n    <tr>\n      <td>13350</td>\n      <td>3.954000</td>\n    </tr>\n    <tr>\n      <td>13400</td>\n      <td>3.912700</td>\n    </tr>\n    <tr>\n      <td>13450</td>\n      <td>3.906000</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>3.935200</td>\n    </tr>\n    <tr>\n      <td>13550</td>\n      <td>3.878600</td>\n    </tr>\n    <tr>\n      <td>13600</td>\n      <td>3.795500</td>\n    </tr>\n    <tr>\n      <td>13650</td>\n      <td>3.872200</td>\n    </tr>\n    <tr>\n      <td>13700</td>\n      <td>3.914400</td>\n    </tr>\n    <tr>\n      <td>13750</td>\n      <td>3.853000</td>\n    </tr>\n    <tr>\n      <td>13800</td>\n      <td>3.827800</td>\n    </tr>\n    <tr>\n      <td>13850</td>\n      <td>3.885600</td>\n    </tr>\n    <tr>\n      <td>13900</td>\n      <td>3.800700</td>\n    </tr>\n    <tr>\n      <td>13950</td>\n      <td>3.951300</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>3.880500</td>\n    </tr>\n    <tr>\n      <td>14050</td>\n      <td>3.873700</td>\n    </tr>\n    <tr>\n      <td>14100</td>\n      <td>3.814200</td>\n    </tr>\n    <tr>\n      <td>14150</td>\n      <td>3.812200</td>\n    </tr>\n    <tr>\n      <td>14200</td>\n      <td>3.868600</td>\n    </tr>\n    <tr>\n      <td>14250</td>\n      <td>3.874000</td>\n    </tr>\n    <tr>\n      <td>14300</td>\n      <td>3.813200</td>\n    </tr>\n    <tr>\n      <td>14350</td>\n      <td>3.869300</td>\n    </tr>\n    <tr>\n      <td>14400</td>\n      <td>3.904900</td>\n    </tr>\n    <tr>\n      <td>14450</td>\n      <td>3.788000</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>3.817200</td>\n    </tr>\n    <tr>\n      <td>14550</td>\n      <td>3.846200</td>\n    </tr>\n    <tr>\n      <td>14600</td>\n      <td>3.817800</td>\n    </tr>\n    <tr>\n      <td>14650</td>\n      <td>3.820000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nüîç Running custom evaluation at step 1000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-1000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56c47658fb5e4193bc7c9cc584170e95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: '' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.04\nF1: 1.30\nEdit Distance (normalized): 4.01\n‚úÖ Step 1000: EM=0.04, F1=1.30, EditDist=4.01\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-1000 to Hub...\n‚úÖ Pushed checkpoint-1000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 2000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-2000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb7da1c29cd1495f9d081557e58757e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: '' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.03\nF1: 0.83\nEdit Distance (normalized): 2.63\n‚úÖ Step 2000: EM=0.03, F1=0.83, EditDist=2.63\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-2000 to Hub...\n‚úÖ Pushed checkpoint-2000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 3000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-3000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"134c1c8364b94cbebd44538dd72e8585"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: '' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.04\nF1: 0.67\nEdit Distance (normalized): 2.15\n‚úÖ Step 3000: EM=0.04, F1=0.67, EditDist=2.15\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-3000 to Hub...\n‚úÖ Pushed checkpoint-3000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 4000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-4000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"add1104cf5874df2bca42cb69d99ec24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: '' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.03\nF1: 0.55\nEdit Distance (normalized): 1.84\n‚úÖ Step 4000: EM=0.03, F1=0.55, EditDist=1.84\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-4000 to Hub...\n‚úÖ Pushed checkpoint-4000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 5000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-5000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1698d839fb4e48d2841baa8ef2268381"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: '' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.03\nF1: 0.53\nEdit Distance (normalized): 1.68\n‚úÖ Step 5000: EM=0.03, F1=0.53, EditDist=1.68\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-5000 to Hub...\n‚úÖ Pushed checkpoint-5000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 6000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-6000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad368a9b5e5641f498c92ab253638fdb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: '' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.03\nF1: 0.47\nEdit Distance (normalized): 1.51\n‚úÖ Step 6000: EM=0.03, F1=0.47, EditDist=1.51\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-6000 to Hub...\n‚úÖ Pushed checkpoint-6000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 7000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-7000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d00918c5ec18426bbea03dd6c8c197a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: 'ÿ¨Ÿàÿ≤ŸÅ' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.01\nF1: 0.42\nEdit Distance (normalized): 1.40\n‚úÖ Step 7000: EM=0.01, F1=0.42, EditDist=1.40\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-7000 to Hub...\n‚úÖ Pushed checkpoint-7000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 8000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-8000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a4ddfe8bcd542349a41ae4236eb3bdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: 'ÿ¨Ÿàÿ≤ŸÅ' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.01\nF1: 0.42\nEdit Distance (normalized): 1.36\n‚úÖ Step 8000: EM=0.01, F1=0.42, EditDist=1.36\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-8000 to Hub...\n‚úÖ Pushed checkpoint-8000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 9000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-9000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a33fc71f584643dab4955e9b79821409"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: 'ÿ¨Ÿàÿ≤ŸÅ' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.03\nF1: 0.42\nEdit Distance (normalized): 1.32\n‚úÖ Step 9000: EM=0.03, F1=0.42, EditDist=1.32\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-9000 to Hub...\n‚úÖ Pushed checkpoint-9000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 10000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-10000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcb8806728474efb9e617ea524a9ce1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: 'ÿ¨Ÿàÿ≤ŸÅ' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.04\nF1: 0.42\nEdit Distance (normalized): 1.31\n‚úÖ Step 10000: EM=0.04, F1=0.42, EditDist=1.31\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-10000 to Hub...\n‚úÖ Pushed checkpoint-10000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 11000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-11000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcbd6fbc6e644d5d9c13b377f5ef41ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: 'ÿ¨Ÿàÿ≤ŸÅ' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.04\nF1: 0.40\nEdit Distance (normalized): 1.25\n‚úÖ Step 11000: EM=0.04, F1=0.40, EditDist=1.25\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-11000 to Hub...\n‚úÖ Pushed checkpoint-11000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 12000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-12000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ae60c3819844f208e19c8b753bd979b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: 'ÿ¨Ÿàÿ≤ŸÅ' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.04\nF1: 0.38\nEdit Distance (normalized): 1.22\n‚úÖ Step 12000: EM=0.04, F1=0.38, EditDist=1.22\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-12000 to Hub...\n‚úÖ Pushed checkpoint-12000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 13000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-13000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41aed9076bd8479ba709cb77f7c25c21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: 'ÿ¨Ÿàÿ≤ŸÅ' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.04\nF1: 0.36\nEdit Distance (normalized): 1.19\n‚úÖ Step 13000: EM=0.04, F1=0.36, EditDist=1.19\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-13000 to Hub...\n‚úÖ Pushed checkpoint-13000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 14000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-14000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed3115d84b494db8b045d3bb09d5653c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: 'ÿ¨Ÿàÿ≤ŸÅ' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.04\nF1: 0.36\nEdit Distance (normalized): 1.19\n‚úÖ Step 14000: EM=0.04, F1=0.36, EditDist=1.19\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-14000 to Hub...\n‚úÖ Pushed checkpoint-14000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 14662...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"name":"stdout","text":"üß™ Evaluating checkpoint: outputs/canine-s-uqa-filtered/checkpoint-14662\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/25319 [00:00<?, ?samples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edf0c7be2d204a70899c57b32032ac04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"\nüîç Debug: Sample predictions:\n  Pred: '' | Gold: 'ŸÅÿ±ŸÜ'\n  Pred: '' | Gold: 'Ÿπÿ±€å ÿ¢⁄©ÿ≥€åÿ¨ŸÜ'\n  Pred: '' | Gold: '⁄Ø€åŸπÿ≥ ⁄©Ÿà Ÿæ€å⁄à ŸÑÿß⁄©'\n  Pred: '' | Gold: 'ÿ≥€å ⁄à€å 4'\n  Pred: 'ÿ¨Ÿàÿ≤ŸÅ' | Gold: '1950 ⁄©€å ÿØ€Åÿßÿ¶€å'\nExamples evaluated: 8000\nExact Match: 0.04\nF1: 0.36\nEdit Distance (normalized): 1.20\n‚úÖ Step 14662: EM=0.04, F1=0.36, EditDist=1.20\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-14662 to Hub...\n‚úÖ Pushed checkpoint-14662 to Hub\n","output_type":"stream"},{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=14662, training_loss=4.310766358246112, metrics={'train_runtime': 12975.5577, 'train_samples_per_second': 18.079, 'train_steps_per_second': 1.13, 'total_flos': 5.796696923995853e+16, 'train_loss': 4.310766358246112, 'epoch': 1.0})"},"metadata":{}}],"execution_count":104},{"id":"29","cell_type":"markdown","source":"---","metadata":{}},{"id":"30","cell_type":"markdown","source":"### Diagnosing Preprocessing Functions!!!\n\nThese functions are just analysing the preprocessing logic above, they're just using the base model, NOT our trained model...","metadata":{"id":"cc44692c-6652-4cda-9ba4-8a03acdab88d"}},{"id":"31","cell_type":"code","source":"# # Diagnostic cell (fixed): Investigate preprocessing and truncation for many samples\n# import random\n# import pandas as pd\n# from transformers import AutoTokenizer\n\n# # Set display options to see full Urdu text\n# pd.set_option('display.max_colwidth', None)\n\n# try:\n#     tokenizer = AutoTokenizer.from_pretrained(\"google/canine-s\")\n# except Exception:\n#     tokenizer = None\n\n# num_samples = 20000  # Number of samples to check\n# results = []\n\n# for split_name, orig_data, proc_data in [\n#     (\"train\", uqa_train, processed_train),\n#     (\"val\", uqa_val, processed_val)\n# ]:\n#     # Sample random indices\n#     if len(proc_data) < num_samples:\n#         current_indices = range(len(proc_data))\n#     else:\n#         current_indices = random.sample(range(len(proc_data)), num_samples)\n\n#     for idx in current_indices:\n#         proc = proc_data[idx]\n#         # Use overflow_to_sample_mapping to get the correct original index\n#         orig_idx = proc[\"overflow_to_sample_mapping\"]\n#         orig = orig_data[orig_idx]\n\n#         input_ids = proc[\"input_ids\"]\n#         start_pos = proc[\"start_positions\"]\n#         end_pos = proc[\"end_positions\"]\n\n#         gold_answer = orig.get(\"gold_answer\", orig.get(\"answer\", \"\"))\n#         question = orig.get(\"question\", \"\")\n\n#         # Decode input_ids to text (for debugging context)\n#         if tokenizer:\n#             decoded_text = tokenizer.decode(input_ids, skip_special_tokens=False)\n#         else:\n#             decoded_text = str(input_ids)\n\n#         # Extract predicted answer span\n#         if 0 <= start_pos < len(input_ids) and 0 <= end_pos < len(input_ids):\n#             if tokenizer:\n#                 pred_span = tokenizer.decode(input_ids[start_pos:end_pos+1], skip_special_tokens=True)\n#             else:\n#                 pred_span = str(input_ids[start_pos:end_pos+1])\n#         else:\n#             pred_span = \"[CLS]\" # Represents no answer found in this chunk or invalid\n\n#         # Check if pred_span matches gold answer\n#         # We strip() to ignore minor whitespace differences\n#         pred_matches_gold = pred_span.strip() == gold_answer.strip()\n\n#         # Check if gold is even reachable in this chunk\n#         gold_in_decoded = gold_answer in decoded_text\n\n#         results.append({\n#             \"Split\": split_name,\n#             \"Question\": question,\n#             \"Gold Answer\": gold_answer,\n#             \"Extracted Answer\": pred_span,\n#             \"Match\": pred_matches_gold,\n#             \"Gold Reachable\": gold_in_decoded,\n#             \"orig_idx\": orig_idx\n#         })\n\n# # Create DataFrame\n# results_df = pd.DataFrame(results)\n\n# # --- SIDE BY SIDE COMPARISON ---\n\n# # 1. Filter for Solvable Mismatches (Gold was there, but we predicted wrong)\n# problem_cases = results_df[\n#     (results_df[\"Gold Reachable\"] == True) &\n#     (results_df[\"Match\"] == False)\n# ][[\"Question\", \"Gold Answer\", \"Extracted Answer\", \"Split\"]]\n\n# print(f\"üîç Checked {len(results_df)} samples.\")\n# print(f\"‚ùå Found {len(problem_cases)} cases where Gold was present but Extraction failed.\")\n\n# print(\"\\nüìä Side-by-Side Comparison (Top 20 Failures):\")\n# display(problem_cases.head(50))\n\n# print(\"\\n‚úÖ Side-by-Side Comparison (First 10 Rows - Mixed):\")\n# display(results_df[[\"Question\", \"Gold Answer\", \"Extracted Answer\", \"Match\"]].head(50))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.status.busy":"2025-12-14T17:21:25.231316Z","iopub.execute_input":"2025-12-14T17:21:25.231538Z","iopub.status.idle":"2025-12-14T17:21:25.236740Z","shell.execute_reply.started":"2025-12-14T17:21:25.231522Z","shell.execute_reply":"2025-12-14T17:21:25.235961Z"},"id":"49f3717d","outputId":"38f435a4-1b55-4c2b-b6a5-86540fc23755","trusted":true},"outputs":[],"execution_count":105},{"id":"32","cell_type":"code","source":"# # Accuracy: fraction of rows where extracted answer matches gold answer\n# accuracy = (results_df[\"Match\"]).mean()\n\n# # Precision: among rows where extracted answer is non-empty, fraction that matches gold\n# # We filter out cases where the model predicted nothing (empty string) or just whitespace\n# non_empty_pred = results_df[\"Extracted Answer\"].str.strip() != \"\"\n\n# # Avoid division by zero if no predictions were made\n# if non_empty_pred.sum() > 0:\n#     precision = (results_df[\"Match\"] & non_empty_pred).sum() / non_empty_pred.sum()\n# else:\n#     precision = 0.0\n\n# print(f\"Accuracy: {accuracy:.3f}\")\n# print(f\"Precision: {precision:.3f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-14T17:21:25.238132Z","iopub.execute_input":"2025-12-14T17:21:25.238396Z","iopub.status.idle":"2025-12-14T17:21:25.251750Z","shell.execute_reply.started":"2025-12-14T17:21:25.238380Z","shell.execute_reply":"2025-12-14T17:21:25.251187Z"},"id":"e67abc12","outputId":"c597ec41-a56e-4e5d-9eb6-e71bd0eafd38","trusted":true},"outputs":[],"execution_count":106}]}