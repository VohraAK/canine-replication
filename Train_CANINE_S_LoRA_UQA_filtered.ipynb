{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"0","cell_type":"code","source":"# %pip install peft evaluate transformers Levenshtein ipywidgets\n# %pip install protobuf==3.20.3\n# !rm -rf /kaggle/working/cache\n# !rm -rf /kaggle/working/outputs","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:01:58.003774Z","iopub.execute_input":"2025-12-10T17:01:58.004187Z","iopub.status.idle":"2025-12-10T17:01:58.007629Z","shell.execute_reply.started":"2025-12-10T17:01:58.004162Z","shell.execute_reply":"2025-12-10T17:01:58.006816Z"},"id":"c186240c","trusted":true},"outputs":[],"execution_count":90},{"id":"1","cell_type":"code","source":"# X\n\nimport os\nos.environ[\"TRANSFORMERS_DISABLE_CHAT_TEMPLATES\"] = \"1\"\nos.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\nos.environ[\"TRANSFORMERS_NO_ADDITIONAL_CHAT_TEMPLATES\"] = \"1\"","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:01:58.009257Z","iopub.execute_input":"2025-12-10T17:01:58.009696Z","iopub.status.idle":"2025-12-10T17:01:58.024080Z","shell.execute_reply.started":"2025-12-10T17:01:58.009677Z","shell.execute_reply":"2025-12-10T17:01:58.023335Z"},"id":"cd8da8ab","trusted":true},"outputs":[],"execution_count":91},{"id":"2","cell_type":"code","source":"from datasets import load_dataset, load_from_disk\n# from UQA.canine_utils import preprocess_uqa, lora_config, print_trainable_parameters, normalize_answer, exact_match_score, f1_score, edit_distance_score, gold_answer, decode_prediction\nfrom transformers import CanineTokenizer\nfrom peft import LoraConfig, TaskType, get_peft_model\nimport re\nimport string\nfrom collections import Counter\nimport numpy as np\nimport Levenshtein\n\nfrom transformers import TrainingArguments, Trainer, TrainerCallback\nimport json\nfrom huggingface_hub import HfApi, notebook_login, whoami","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:01:58.025315Z","iopub.execute_input":"2025-12-10T17:01:58.025559Z","iopub.status.idle":"2025-12-10T17:01:58.040722Z","shell.execute_reply.started":"2025-12-10T17:01:58.025537Z","shell.execute_reply":"2025-12-10T17:01:58.039994Z"},"id":"d87eba82","trusted":true},"outputs":[],"execution_count":92},{"id":"3","cell_type":"code","source":"# notebook_login()\n# whoami()","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:01:58.041399Z","iopub.execute_input":"2025-12-10T17:01:58.041599Z","iopub.status.idle":"2025-12-10T17:01:58.054152Z","shell.execute_reply.started":"2025-12-10T17:01:58.041585Z","shell.execute_reply":"2025-12-10T17:01:58.053422Z"},"id":"0e98cebe-4c08-4850-b3c1-1529564fdb1b","trusted":true},"outputs":[],"execution_count":93},{"id":"4","cell_type":"code","source":"from transformers import CanineTokenizer, CanineForQuestionAnswering\nimport torch\nmodel_name = 'google/canine-s'\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n\ntokenizer = CanineTokenizer.from_pretrained(model_name, use_fast=False, trust_remote_code=False)\nmodel = CanineForQuestionAnswering.from_pretrained(model_name, trust_remote_code=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-10T17:01:58.055512Z","iopub.execute_input":"2025-12-10T17:01:58.055715Z","iopub.status.idle":"2025-12-10T17:01:59.556095Z","shell.execute_reply.started":"2025-12-10T17:01:58.055701Z","shell.execute_reply":"2025-12-10T17:01:59.555333Z"},"id":"f2dd5a40","outputId":"140c30ea-575d-45cd-ea54-7818cdfe6bf5","trusted":true},"outputs":[{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":94},{"id":"f75a7e9b","cell_type":"code","source":"# filter out impossible questions\ndef filter_function(example):\n    return not example['is_impossible']","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:01:59.557008Z","iopub.execute_input":"2025-12-10T17:01:59.557310Z","iopub.status.idle":"2025-12-10T17:01:59.560840Z","shell.execute_reply.started":"2025-12-10T17:01:59.557281Z","shell.execute_reply":"2025-12-10T17:01:59.560235Z"},"trusted":true},"outputs":[],"execution_count":95},{"id":"5","cell_type":"code","source":"uqa_dataset = load_dataset(\"uqa/UQA\")\n\n# filtering\n# uqa_dataset_filtered = uqa_dataset.filter(filter_function)\n\n# increased to 60000 train samples\n# uqa_train = uqa_dataset_filtered[\"train\"].shuffle(seed=42).select(range(60000))\n# uqa_val = uqa_dataset_filtered[\"validation\"].shuffle(seed=42).select(range(2000))\n\nuqa_train = uqa_dataset[\"train\"].shuffle(seed=42).select(range(60000))\nuqa_val = uqa_dataset[\"validation\"].shuffle(seed=42).select(range(2000))\n\nprint(f\"üìä Dataset after filtering:\")\nprint(f\"   Original train size: {len(uqa_dataset['train']):,}\")\n# print(f\"   Filtered train size: {len(uqa_dataset_filtered['train']):,}\")\nprint(f\"   Using for training: {len(uqa_train):,}\")\nprint(f\"   Validation size: {len(uqa_val):,}\")","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:01:59.561717Z","iopub.execute_input":"2025-12-10T17:01:59.561994Z","iopub.status.idle":"2025-12-10T17:02:00.317758Z","shell.execute_reply.started":"2025-12-10T17:01:59.561959Z","shell.execute_reply":"2025-12-10T17:02:00.317158Z"},"id":"d474e2e8","trusted":true},"outputs":[{"name":"stdout","text":"üìä Dataset after filtering:\n   Original train size: 124,745\n   Using for training: 60,000\n   Validation size: 2,000\n","output_type":"stream"}],"execution_count":96},{"id":"145a43ff","cell_type":"markdown","source":"## üîß Hardware-Optimized Training Configuration\n\nBased on comparison with XLM-RoBERTa baseline, the following optimizations have been applied:\n\n### Critical Fixes:\n1. **‚úÖ Filter impossible questions** - Remove `answer_start == -1` examples (like XLM-RoBERTa does)\n2. **‚úÖ Increase dataset size** - 60k examples (up from 40k, +50% more training data)\n3. **‚úÖ Lower learning rate** - 5e-5 (down from 3e-4, prevents overshooting)\n4. **‚úÖ More training epochs** - 2 epochs (up from 1, allows convergence)\n5. **‚úÖ Better overlap** - DOC_STRIDE=96 (up from 64, more training signals)\n6. **‚úÖ Reduce checkpoint overhead** - save_steps=1000 (down from 500)\n\n### Expected Improvements:\n- **Filtering impossible questions**: +15-20% performance (removes label noise)\n- **Lower learning rate**: +10-15% performance (stable training)\n- **2 epochs**: +20-25% performance (sufficient learning time)\n- **Combined effect**: Should see **50-70% EM/F1** (vs current 33%)\n\n### Hardware Considerations:\n- Kept batch size at 4√ó4=16 (memory-friendly)\n- 60k examples instead of full dataset (manageable)\n- 2 epochs instead of 6 (time-efficient)\n- Learning rate 5e-5 instead of 2e-5 (faster convergence)","metadata":{}},{"id":"6","cell_type":"code","source":"# Explore raw UQA dataset structure\nprint(\"=\"*80)\nprint(\"UQA DATASET STRUCTURE\")\nprint(\"=\"*80)\nprint(f\"Training set size: {len(uqa_train):,} examples\")\nprint(f\"Validation set size: {len(uqa_val):,} examples\")\nprint(f\"\\nDataset columns: {uqa_train.column_names}\")\nprint(\"\\n\" + \"=\"*80)\n\n# Show a few examples\nprint(\"\\nüìù EXAMPLE 1 - Question with Answer\")\nprint(\"=\"*80)\nex1 = uqa_train[0]\nprint(f\"Question: {ex1['question']}\")\nprint(f\"\\nContext (first 300 chars): {ex1['context'][:300]}...\")\nprint(f\"\\nAnswer: '{ex1['answer']}'\")\nprint(f\"Answer starts at character position: {ex1['answer_start']}\")\n\n# Verify the answer extraction\nif ex1['answer_start'] != -1:\n    extracted = ex1['context'][ex1['answer_start']:ex1['answer_start']+len(ex1['answer'])]\n    print(f\"‚úì Extracted from context: '{extracted}'\")\n    print(f\"‚úì Match: {extracted == ex1['answer']}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\\nüìù EXAMPLE 2 - Another Question\")\nprint(\"=\"*80)\nex2 = uqa_train[100]\nprint(f\"Question: {ex2['question']}\")\nprint(f\"\\nContext length: {len(ex2['context'])} characters\")\nprint(f\"Answer: '{ex2['answer']}'\")\nprint(f\"Answer starts at position: {ex2['answer_start']}\")\n\n# Show answer in context\nif ex2['answer_start'] != -1:\n    start = max(0, ex2['answer_start'] - 50)\n    end = min(len(ex2['context']), ex2['answer_start'] + len(ex2['answer']) + 50)\n    context_snippet = ex2['context'][start:end]\n    answer_pos = ex2['answer_start'] - start\n    print(f\"\\nContext around answer:\")\n    print(f\"...{context_snippet}...\")\n    print(f\"    {' '*answer_pos}{'~'*len(ex2['answer'])} (answer here)\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\\nüìä DATASET STATISTICS\")\nprint(\"=\"*80)\n\n# Compute some basic statistics\nimport numpy as np\nquestion_lengths = [len(ex['question']) for ex in uqa_train.select(range(1000))]\ncontext_lengths = [len(ex['context']) for ex in uqa_train.select(range(1000))]\nanswer_lengths = [len(ex['answer']) if ex['answer'] else 0 for ex in uqa_train.select(range(1000))]\nhas_answer = [ex['answer_start'] != -1 for ex in uqa_train.select(range(1000))]\n\nprint(f\"Question length (chars): mean={np.mean(question_lengths):.1f}, max={np.max(question_lengths)}\")\nprint(f\"Context length (chars): mean={np.mean(context_lengths):.1f}, max={np.max(context_lengths)}\")\nprint(f\"Answer length (chars): mean={np.mean(answer_lengths):.1f}, max={np.max(answer_lengths)}\")\nprint(f\"Questions with answers: {sum(has_answer)/len(has_answer)*100:.1f}%\")\nprint(f\"Questions without answers: {(1-sum(has_answer)/len(has_answer))*100:.1f}%\")","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:02:00.319297Z","iopub.execute_input":"2025-12-10T17:02:00.319547Z","iopub.status.idle":"2025-12-10T17:02:00.692103Z","shell.execute_reply.started":"2025-12-10T17:02:00.319530Z","shell.execute_reply":"2025-12-10T17:02:00.691344Z"},"trusted":true},"outputs":[{"name":"stdout","text":"================================================================================\nUQA DATASET STRUCTURE\n================================================================================\nTraining set size: 60,000 examples\nValidation set size: 2,000 examples\n\nDataset columns: ['id', 'title', 'context', 'question', 'is_impossible', 'answer', 'answer_start']\n\n================================================================================\n\nüìù EXAMPLE 1 - Question with Answer\n================================================================================\nQuestion: ÿ¨ÿØ€åÿØ €ÅŸàÿßÿ¶€å ÿ¨€Åÿßÿ≤Ÿà⁄∫ ⁄©€å ÿ™ÿπŸÖ€åÿ± ŸÖ€å⁄∫ ⁄©€åÿß ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄©€åÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿü\n\nContext (first 300 chars): 1906 ŸÖ€å⁄∫ ÿå ÿßŸÑŸÅÿ±€å⁄à ŸàŸêŸÑŸÖ ŸÜ€í ÿ®ÿßÿ±ÿ¥ ÿ≥€í ÿ≥ÿÆÿ™ €ÅŸàŸÜ€í ŸàÿßŸÑ€í ŸÖÿ±⁄©ÿ® ÿØÿ±€åÿßŸÅÿ™ ⁄©€å€í€î ÿ®ÿßÿ±ÿ¥ ÿ≥€í ÿ≥ÿÆÿ™ €ÅŸàŸÜ€í ŸàÿßŸÑ€í ŸÖÿ±⁄©ÿ® ÿå ÿ¨€åÿ≥€í ÿß€åŸÑŸàŸÖ€åŸÜ€åŸÖ ÿå Ÿπÿßÿ¶Ÿπ€åŸÜ€åŸÖ ÿßŸàÿ± ÿ™ÿßŸÜÿ®€í ⁄©€í ⁄©⁄Ü⁄æ ŸÖÿ±⁄©ÿ® ÿå ⁄Øÿ±ŸÖ€å ÿ≥€í ÿπŸÑÿßÿ¨ ⁄©ÿ±ŸÜ€í ŸàÿßŸÑ€í ŸÖÿ±⁄©ÿ® €Å€å⁄∫ ÿ¨Ÿà Ÿπ⁄æŸÜ⁄àÿß €ÅŸàŸÜ€í Ÿæÿ± ŸÜÿ±ŸÖ €ÅŸàÿ¨ÿßÿ™€í €Å€å⁄∫ (ÿ¨ŸÑÿØ€å ÿ≥€í Ÿπ⁄æŸÜ⁄àÿß €ÅŸàÿ¨ÿßÿ™€í €Å€å⁄∫) ÿå ÿßŸàÿ± Ÿæ⁄æÿ± ŸàŸÇÿ™ ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ≥ÿÆÿ™ €ÅŸàÿ¨ÿßÿ™€í €Å€å⁄∫€î ÿß€åŸÑŸàŸÖ€åŸÜ€åŸÖ ÿå ÿ™ÿßŸÜÿ®€í ÿßŸàÿ± ŸÖ€å⁄ØŸÜ€å...\n\nAnswer: '⁄àŸàÿ±ÿßŸÑŸàŸÖ€åŸÜ'\nAnswer starts at character position: 503\n‚úì Extracted from context: '⁄àŸàÿ±ÿßŸÑŸàŸÖ€åŸÜ'\n‚úì Match: True\n\n================================================================================\n\nüìù EXAMPLE 2 - Another Question\n================================================================================\nQuestion: ⁄©ŸàŸÜ ÿ≥ÿß ŸÖŸÜ⁄Ø ÿ¥€Åÿ≤ÿßÿØ€Å ŸÜÿßŸÜÿ¨ŸÜ⁄Ø ŸÖ€å⁄∫ ÿ™ÿÆÿ™ ŸÜÿ¥€åŸÜ €ÅŸàÿß ÿ™⁄æÿßÿü\n\nContext length: 447 characters\nAnswer: 'ÿ¨Ÿà €åŸà ÿ≥ŸàŸÜ⁄Ø'\nAnswer starts at position: 262\n\nContext around answer:\n...ÿßŸÑ€å ⁄ÜŸÜ⁄Ø ÿÆÿßŸÜÿØÿßŸÜ ⁄©€í €Åÿßÿ™⁄æŸà⁄∫ ⁄Øÿ±ŸÜ€í ⁄©€í ÿ®ÿπÿØ ÿå ŸÖŸÜ⁄Ø ÿ¥€Åÿ≤ÿßÿØ€Å ÿ¨Ÿà €åŸà ÿ≥ŸàŸÜ⁄Ø ⁄©Ÿà ÿ¨ŸàŸÜ 1644 ŸÖ€å⁄∫ €ÅÿßŸÜ⁄Ø ⁄ØŸàÿßŸÜ⁄Ø ÿ¥€ÅŸÜÿ¥ÿß€Å ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± ŸÜÿßŸÜÿ¨ŸÜ...\n                                                      ~~~~~~~~~~ (answer here)\n\n================================================================================\n\nüìä DATASET STATISTICS\n================================================================================\nQuestion length (chars): mean=54.1, max=155\nContext length (chars): mean=685.5, max=3179\nAnswer length (chars): mean=11.5, max=142\nQuestions with answers: 64.9%\nQuestions without answers: 35.1%\n","output_type":"stream"}],"execution_count":97},{"id":"7","cell_type":"markdown","source":"## üîç Data Exploration: Understanding the UQA Dataset\n\nLet's explore what the raw dataset looks like before preprocessing.","metadata":{}},{"id":"8","cell_type":"markdown","source":"---","metadata":{"id":"89c472d5"}},{"id":"9","cell_type":"markdown","source":"## Updated preprocessors!\n\nPreviously, we tried to apply the same approach we used in TYDIQA on UQA, the problem was the preprocessors were aligning the answer spans in units of **byte-level spans** instead of **character-level spans**. The calculations were adding byte-level offsets to the answer lengths, and since Urdu characters may be quantified in multiple bytes, the model was being fed the wrong spans -> GIGO!","metadata":{"id":"6e80a8d3"}},{"id":"10","cell_type":"code","source":"\"\"\"\nFIXED preprocessing function for UQA with CANINE-S.\nCopy this into Train_CANINE_S_LoRA_UQA.ipynb cell 8 to replace the existing preprocess_uqa function.\n\nKey fixes:\n1. Added byte-to-char conversion helpers (from TyDiQA)\n2. Support both byte-based and character-based offsets via use_byte_offsets parameter\n3. Changed gold_char_end calculation to be inclusive (removed +1, added -1 after len(answer))\n4. Use dynamic cls_index for no-answer cases instead of hardcoded 0\n5. Fixed answer chunk boundary check (< instead of <=)\n6. Removed incorrect -1 subtraction from end_pos calculation\n\"\"\"\n\nfrom bisect import bisect_right\n\nMAX_SEQ_LENGTH = 384\nDOC_STRIDE = 96  # Increased from 64 to 96 for better overlap (compromise between 64 and 128)\n\ndef _build_byte_to_char_index(text: str) -> list:\n    \"\"\"Build cumulative UTF-8 byte offsets for each character boundary.\"\"\"\n    cumulative = [0]\n    for char in text:\n        cumulative.append(cumulative[-1] + len(char.encode(\"utf-8\")))\n    return cumulative\n\ndef _byte_to_char(cumulative_bytes: list, byte_index: int) -> int:\n    \"\"\"Map a byte offset to the nearest character index (floor).\"\"\"\n    position = bisect_right(cumulative_bytes, byte_index) - 1\n    return max(position, 0)\n\ndef preprocess_uqa(examples, tokenizer, max_length=MAX_SEQ_LENGTH, doc_stride=DOC_STRIDE, model_obj=None, indices=None, use_byte_offsets=False):\n    \"\"\"\n    Robust preprocessing for UQA (Urdu Question Answering) with CANINE-S.\n    \n    Args:\n        examples: Batch of examples with question, context, answer, answer_start fields\n        tokenizer: CanineTokenizer instance\n        max_length: Maximum sequence length\n        doc_stride: Sliding window stride\n        model_obj: Optional model object (unused, for compatibility)\n        indices: Optional example indices for overflow mapping\n        use_byte_offsets: If True, treats answer_start as byte offset (like TyDiQA)\n                         If False, treats as character offset (default UQA behavior)\n    \n    Returns:\n        Dict with input_ids, attention_mask, token_type_ids, start_positions, \n        end_positions, overflow_to_sample_mapping\n    \"\"\"\n    # Handle tokenizer/model limits safely\n    tokenizer_max = getattr(tokenizer, \"model_max_length\", max_length)\n    model_max = getattr(model_obj.config, \"max_position_embeddings\", None) if model_obj is not None else None\n    max_allowed = max_length\n    if tokenizer_max is not None and tokenizer_max > 0:\n        max_allowed = min(max_allowed, tokenizer_max)\n    if model_max is not None and model_max > 0:\n        max_allowed = min(max_allowed, model_max)\n\n    questions = [q.strip() for q in examples[\"question\"]]\n    contexts = examples[\"context\"]\n    answers = examples[\"answer\"]\n    answer_starts = examples[\"answer_start\"]\n\n    encoded = {\n        \"input_ids\": [],\n        \"attention_mask\": [],\n        \"token_type_ids\": [],\n        \"start_positions\": [],\n        \"end_positions\": [],\n        \"overflow_to_sample_mapping\": []\n    }\n\n    for i, (question, context, answer, answer_start) in enumerate(zip(questions, contexts, answers, answer_starts)):\n        example_idx = indices[i] if indices is not None else i\n\n        # CANINE encodes to characters directly (1 char = 1 token)\n        question_ids = tokenizer.encode(question, add_special_tokens=False)\n        context_ids = tokenizer.encode(context, add_special_tokens=False)\n\n        # 1. Setup Targets - Convert offsets to character indices\n        if answer and answer_start != -1:\n            if use_byte_offsets:\n                # UQA might use byte offsets for multi-byte Urdu characters\n                byte_map = _build_byte_to_char_index(context)\n                gold_char_start = _byte_to_char(byte_map, answer_start)\n                answer_end_byte = answer_start + len(answer.encode('utf-8'))\n                gold_char_end = _byte_to_char(byte_map, answer_end_byte - 1)\n            else:\n                # Standard character-based offsets\n                gold_char_start = answer_start\n                # CRITICAL FIX: gold_char_end is INCLUSIVE (points to last char, not past it)\n                gold_char_end = answer_start + len(answer) - 1\n        else:\n            gold_char_start = -1\n            gold_char_end = -1\n\n        # 2. Calculate Window Size\n        special_tokens_count = tokenizer.num_special_tokens_to_add(pair=True)\n        max_context_length = max_allowed - len(question_ids) - special_tokens_count\n\n        if max_context_length <= 0:\n            continue\n\n        # 3. Sliding Window Loop\n        stride_step = max_context_length - doc_stride\n        if stride_step <= 0:\n            stride_step = max_context_length\n\n        for chunk_start_idx in range(0, len(context_ids), stride_step):\n            chunk_end_idx = min(chunk_start_idx + max_context_length, len(context_ids))\n            context_chunk = context_ids[chunk_start_idx:chunk_end_idx]\n\n            # Build inputs with special tokens: [CLS] question [SEP] context [SEP]\n            input_ids = tokenizer.build_inputs_with_special_tokens(question_ids, context_chunk)\n            token_type_ids = tokenizer.create_token_type_ids_from_sequences(question_ids, context_chunk)\n            attention_mask = [1] * len(input_ids)\n\n            # Find where context starts in input_ids\n            sep_indices = [k for k, x in enumerate(input_ids) if x == tokenizer.sep_token_id]\n            if not sep_indices:\n                continue\n            context_offset_in_input = sep_indices[0] + 1\n            \n            # Find CLS position dynamically (should be 0 for CANINE, but be safe)\n            cls_index = input_ids.index(tokenizer.cls_token_id) if tokenizer.cls_token_id in input_ids else 0\n\n            # 4. Label Assignment\n            # Check if answer is ENTIRELY within this chunk (both start and end)\n            is_answer_in_chunk = (\n                gold_char_start >= chunk_start_idx and\n                gold_char_end <= chunk_end_idx and  # Inclusive: answer must fit within chunk\n                gold_char_start != -1\n            )\n\n            if is_answer_in_chunk:\n                # Map global context indices to local input_ids indices\n                start_pos = context_offset_in_input + (gold_char_start - chunk_start_idx)\n                end_pos = context_offset_in_input + (gold_char_end - chunk_start_idx)\n                # NO -1 here because gold_char_end is already INCLUSIVE\n            else:\n                # No answer in this chunk - point to [CLS] token\n                start_pos = cls_index\n                end_pos = cls_index\n\n            # 5. Padding\n            pad_len = max_allowed - len(input_ids)\n            if pad_len > 0:\n                input_ids += [tokenizer.pad_token_id] * pad_len\n                attention_mask += [0] * pad_len\n                token_type_ids += [0] * pad_len\n\n            # 6. Final Safety Truncation\n            if len(input_ids) > max_allowed:\n                input_ids = input_ids[:max_allowed]\n                attention_mask = attention_mask[:max_allowed]\n                token_type_ids = token_type_ids[:max_allowed]\n                if start_pos >= max_allowed or end_pos >= max_allowed:\n                    start_pos = cls_index\n                    end_pos = cls_index\n\n            encoded[\"input_ids\"].append(input_ids)\n            encoded[\"attention_mask\"].append(attention_mask)\n            encoded[\"token_type_ids\"].append(token_type_ids)\n            encoded[\"start_positions\"].append(start_pos)\n            encoded[\"end_positions\"].append(end_pos)\n            encoded[\"overflow_to_sample_mapping\"].append(example_idx)\n\n            # Break if we've covered the entire context\n            if chunk_end_idx >= len(context_ids):\n                break\n\n    return encoded\n\n\n# USAGE EXAMPLE:\n# First, test which offset type UQA uses:\n# Run: python diagnose_uqa_offsets.py\n#\n# If character-based (expected):\n# processed_train = uqa_train.map(\n#     lambda examples, indices: preprocess_uqa(examples, tokenizer, indices=indices, use_byte_offsets=False),\n#     batched=True, remove_columns=uqa_train.column_names, with_indices=True\n# )\n#\n# If byte-based (like TyDiQA):\n# processed_train = uqa_train.map(\n#     lambda examples, indices: preprocess_uqa(examples, tokenizer, indices=indices, use_byte_offsets=True),\n#     batched=True, remove_columns=uqa_train.column_names, with_indices=True\n# )\n","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:02:00.692981Z","iopub.execute_input":"2025-12-10T17:02:00.693340Z","iopub.status.idle":"2025-12-10T17:02:00.708798Z","shell.execute_reply.started":"2025-12-10T17:02:00.693314Z","shell.execute_reply":"2025-12-10T17:02:00.708106Z"},"trusted":true},"outputs":[],"execution_count":98},{"id":"11","cell_type":"code","source":"# ‚úÖ FIXED preprocess_uqa function is defined in cell 16 below (with evaluation helpers)\n# The updated function includes:\n# - Character-level offset handling (UQA uses character offsets, not bytes)\n# - Dynamic cls_index for no-answer cases (not hardcoded 0)\n# - Inclusive end position calculation (gold_char_end points to last char)\n# - Correct chunk boundary check (<=)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:02:00.709583Z","iopub.execute_input":"2025-12-10T17:02:00.709812Z","iopub.status.idle":"2025-12-10T17:02:00.726279Z","shell.execute_reply.started":"2025-12-10T17:02:00.709789Z","shell.execute_reply":"2025-12-10T17:02:00.725520Z"},"id":"438d8765","trusted":true},"outputs":[],"execution_count":99},{"id":"12","cell_type":"code","source":"# LoRA config\nlora_config = LoraConfig(\n    task_type=TaskType.QUESTION_ANS,\n    r=16,   # changed from 8\n    lora_alpha=32,\n    lora_dropout=0.1,\n    target_modules=[\"query\", \"value\", \"key\"],\n    bias=\"none\",\n    modules_to_save=[\"qa_outputs\"],\n)\n\ndef print_trainable_parameters(model):\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:02:00.727019Z","iopub.execute_input":"2025-12-10T17:02:00.727213Z","iopub.status.idle":"2025-12-10T17:02:00.740552Z","shell.execute_reply.started":"2025-12-10T17:02:00.727195Z","shell.execute_reply":"2025-12-10T17:02:00.739983Z"},"id":"a3e95eec","trusted":true},"outputs":[],"execution_count":100},{"id":"0ce2da1b","cell_type":"markdown","source":"### Preprocessing examples...","metadata":{}},{"id":"13","cell_type":"code","source":"\nprint(\"=\"*80)\nprint(\"üî¨ PREPROCESSING WALKTHROUGH - Single Example\")\nprint(\"=\"*80)\n\n# Take one example\nexample = uqa_train[0]\nprint(f\"\\n1Ô∏è‚É£ ORIGINAL DATA\")\nprint(\"-\"*80)\nprint(f\"Question: {example['question']}\")\nprint(f\"Answer: '{example['answer']}'\")\nprint(f\"Answer position: {example['answer_start']}\")\nprint(f\"Context length: {len(example['context'])} characters\")\n\n# Preprocess it\nbatch = {\n    'question': [example['question']],\n    'context': [example['context']],\n    'answer': [example['answer']],\n    'answer_start': [example['answer_start']]\n}\nprocessed = preprocess_uqa(batch, tokenizer, indices=[0])\n\nprint(f\"\\n2Ô∏è‚É£ AFTER PREPROCESSING\")\nprint(\"-\"*80)\nprint(f\"Number of chunks created: {len(processed['input_ids'])}\")\nprint(f\"(Sliding window creates multiple chunks per example)\")\n\n# Show first chunk in detail\nchunk_idx = 0\nprint(f\"\\n3Ô∏è‚É£ CHUNK {chunk_idx} DETAILS\")\nprint(\"-\"*80)\nprint(f\"Input IDs length: {len(processed['input_ids'][chunk_idx])} tokens\")\nprint(f\"Start position: {processed['start_positions'][chunk_idx]}\")\nprint(f\"End position: {processed['end_positions'][chunk_idx]}\")\nprint(f\"Maps to original example: {processed['overflow_to_sample_mapping'][chunk_idx]}\")\n\n# Decode the inputs to show what the model sees\ninput_ids = processed['input_ids'][chunk_idx]\ndecoded_input = tokenizer.decode(input_ids, skip_special_tokens=False)\nprint(f\"\\n4Ô∏è‚É£ DECODED INPUT (first 400 chars, with special tokens)\")\nprint(\"-\"*80)\nprint(decoded_input[:400] + \"...\")\n\n# Decode the labeled answer span\nstart_pos = processed['start_positions'][chunk_idx]\nend_pos = processed['end_positions'][chunk_idx]\ncls_idx = input_ids.index(tokenizer.cls_token_id) if tokenizer.cls_token_id in input_ids else 0\n\nif start_pos == cls_idx and end_pos == cls_idx:\n    labeled_answer = \"[NO ANSWER IN THIS CHUNK]\"\nelse:\n    labeled_answer = tokenizer.decode(input_ids[start_pos:end_pos+1], skip_special_tokens=True)\n\nprint(f\"\\n5Ô∏è‚É£ LABELED ANSWER SPAN IN THIS CHUNK\")\nprint(\"-\"*80)\nprint(f\"Gold answer: '{example['answer']}'\")\nprint(f\"Labeled span: '{labeled_answer}'\")\nprint(f\"Match: {labeled_answer.strip() == example['answer'].strip()}\")\n\n# Show all chunks for this example\nprint(f\"\\n6Ô∏è‚É£ ALL CHUNKS FOR THIS EXAMPLE\")\nprint(\"-\"*80)\nfor i in range(len(processed['input_ids'])):\n    start = processed['start_positions'][i]\n    end = processed['end_positions'][i]\n    if start == cls_idx and end == cls_idx:\n        chunk_answer = \"[NO ANSWER]\"\n    else:\n        chunk_answer = tokenizer.decode(processed['input_ids'][i][start:end+1], skip_special_tokens=True).strip()\n    has_answer = \"‚úÖ\" if chunk_answer == example['answer'].strip() else \"‚ùå\"\n    print(f\"  Chunk {i}: {has_answer} '{chunk_answer[:50]}'\")\n\nprint(\"\\n\" + \"=\"*80)","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:02:00.741492Z","iopub.execute_input":"2025-12-10T17:02:00.741695Z","iopub.status.idle":"2025-12-10T17:02:00.766491Z","shell.execute_reply.started":"2025-12-10T17:02:00.741670Z","shell.execute_reply":"2025-12-10T17:02:00.765908Z"},"trusted":true},"outputs":[{"name":"stdout","text":"================================================================================\nüî¨ PREPROCESSING WALKTHROUGH - Single Example\n================================================================================\n\n1Ô∏è‚É£ ORIGINAL DATA\n--------------------------------------------------------------------------------\nQuestion: ÿ¨ÿØ€åÿØ €ÅŸàÿßÿ¶€å ÿ¨€Åÿßÿ≤Ÿà⁄∫ ⁄©€å ÿ™ÿπŸÖ€åÿ± ŸÖ€å⁄∫ ⁄©€åÿß ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄©€åÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿü\nAnswer: '⁄àŸàÿ±ÿßŸÑŸàŸÖ€åŸÜ'\nAnswer position: 503\nContext length: 767 characters\n\n2Ô∏è‚É£ AFTER PREPROCESSING\n--------------------------------------------------------------------------------\nNumber of chunks created: 3\n(Sliding window creates multiple chunks per example)\n\n3Ô∏è‚É£ CHUNK 0 DETAILS\n--------------------------------------------------------------------------------\nInput IDs length: 384 tokens\nStart position: 0\nEnd position: 0\nMaps to original example: 0\n\n4Ô∏è‚É£ DECODED INPUT (first 400 chars, with special tokens)\n--------------------------------------------------------------------------------\nÓÄÄÿ¨ÿØ€åÿØ €ÅŸàÿßÿ¶€å ÿ¨€Åÿßÿ≤Ÿà⁄∫ ⁄©€å ÿ™ÿπŸÖ€åÿ± ŸÖ€å⁄∫ ⁄©€åÿß ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄©€åÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿüÓÄÅ1906 ŸÖ€å⁄∫ ÿå ÿßŸÑŸÅÿ±€å⁄à ŸàŸêŸÑŸÖ ŸÜ€í ÿ®ÿßÿ±ÿ¥ ÿ≥€í ÿ≥ÿÆÿ™ €ÅŸàŸÜ€í ŸàÿßŸÑ€í ŸÖÿ±⁄©ÿ® ÿØÿ±€åÿßŸÅÿ™ ⁄©€å€í€î ÿ®ÿßÿ±ÿ¥ ÿ≥€í ÿ≥ÿÆÿ™ €ÅŸàŸÜ€í ŸàÿßŸÑ€í ŸÖÿ±⁄©ÿ® ÿå ÿ¨€åÿ≥€í ÿß€åŸÑŸàŸÖ€åŸÜ€åŸÖ ÿå Ÿπÿßÿ¶Ÿπ€åŸÜ€åŸÖ ÿßŸàÿ± ÿ™ÿßŸÜÿ®€í ⁄©€í ⁄©⁄Ü⁄æ ŸÖÿ±⁄©ÿ® ÿå ⁄Øÿ±ŸÖ€å ÿ≥€í ÿπŸÑÿßÿ¨ ⁄©ÿ±ŸÜ€í ŸàÿßŸÑ€í ŸÖÿ±⁄©ÿ® €Å€å⁄∫ ÿ¨Ÿà Ÿπ⁄æŸÜ⁄àÿß €ÅŸàŸÜ€í Ÿæÿ± ŸÜÿ±ŸÖ €ÅŸàÿ¨ÿßÿ™€í €Å€å⁄∫ (ÿ¨ŸÑÿØ€å ÿ≥€í Ÿπ⁄æŸÜ⁄àÿß €ÅŸàÿ¨ÿßÿ™€í €Å€å⁄∫) ÿå ÿßŸàÿ± Ÿæ⁄æÿ± ŸàŸÇÿ™ ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ≥ÿÆÿ™ €ÅŸàÿ¨ÿßÿ™€í €Å€å⁄∫€î ÿß€åŸÑŸàŸÖ€åŸÜ€åŸÖ ÿå ÿ™ÿßŸÜÿ®€í ÿßŸàÿ± ŸÖ€å⁄ØŸÜ€åÿ¥€åŸÖ ⁄©€í Ÿπÿ±ŸÜÿ±€å ŸÖÿ±⁄©ÿ® ⁄©Ÿà Ÿπ⁄æŸÜ⁄àÓÄÅ...\n\n5Ô∏è‚É£ LABELED ANSWER SPAN IN THIS CHUNK\n--------------------------------------------------------------------------------\nGold answer: '⁄àŸàÿ±ÿßŸÑŸàŸÖ€åŸÜ'\nLabeled span: '[NO ANSWER IN THIS CHUNK]'\nMatch: False\n\n6Ô∏è‚É£ ALL CHUNKS FOR THIS EXAMPLE\n--------------------------------------------------------------------------------\n  Chunk 0: ‚ùå '[NO ANSWER]'\n  Chunk 1: ‚úÖ '⁄àŸàÿ±ÿßŸÑŸàŸÖ€åŸÜ'\n  Chunk 2: ‚úÖ '⁄àŸàÿ±ÿßŸÑŸàŸÖ€åŸÜ'\n\n================================================================================\n","output_type":"stream"}],"execution_count":101},{"id":"14","cell_type":"markdown","source":"## üîß Preprocessing Exploration: Raw Data ‚Üí Model Input\n\nNow let's see what happens during preprocessing - how we convert text to token IDs and create training labels.","metadata":{}},{"id":"15","cell_type":"code","source":"# ‚ö†Ô∏è CRITICAL: Must regenerate preprocessed data with FILTERED dataset\n# The old cache was created from unfiltered data - indices won't match!\n\n# print(\"üîÑ Preprocessing filtered dataset (this will take a few minutes)...\")\nprocessed_train = uqa_train.map(\n    lambda examples, indices: preprocess_uqa(examples, tokenizer, indices=indices), \n    batched=True, \n    remove_columns=uqa_train.column_names, \n    with_indices=True\n)\nprocessed_val = uqa_val.map(\n    lambda examples, indices: preprocess_uqa(examples, tokenizer, indices=indices), \n    batched=True, \n    remove_columns=uqa_val.column_names, \n    with_indices=True\n)\n\n# print(f\"‚úÖ Preprocessing complete!\")\n# print(f\"   Training chunks: {len(processed_train):,}\")\n# print(f\"   Validation chunks: {len(processed_val):,}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["b1984a6d29864e2d940119370816a37e","a307de6c263a4c20a6418344cbd98c0c","1db208af0dbc4f2facee78148266a207","d44d38a959ec44aa90e91c15a83abbd6","527baa5fc421480da4d2dc7041e19b1f","d398c81b546d4527a41dd97bd87ad7d8","ab4047c7f0144667857fe835d452f6c7","0120d513dd4d4fccac2d528eb7ff4696","c3e0981c2924416fbdf9ceab3e6b04ab","bc970c64373f4f69b6c6936087ed978a","4a74d22a2c334fbda54a95c5e29e712a"]},"execution":{"iopub.status.busy":"2025-12-10T17:02:00.767131Z","iopub.execute_input":"2025-12-10T17:02:00.767333Z","iopub.status.idle":"2025-12-10T17:07:51.444133Z","shell.execute_reply.started":"2025-12-10T17:02:00.767317Z","shell.execute_reply":"2025-12-10T17:07:51.443325Z"},"id":"d11807b9","outputId":"64fc2534-2871-4bd2-b3fa-4b37973486e2","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/60000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba1bb10d6b9d49f7a82b9ef1ba4b9dc0"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (3179 > 2048). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32bca560725247be8790ecfb5ae93170"}},"metadata":{}}],"execution_count":102},{"id":"16","cell_type":"code","source":"# processed_train","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:07:51.445520Z","iopub.execute_input":"2025-12-10T17:07:51.445830Z","iopub.status.idle":"2025-12-10T17:07:51.448934Z","shell.execute_reply.started":"2025-12-10T17:07:51.445811Z","shell.execute_reply":"2025-12-10T17:07:51.448309Z"},"id":"D-emFQTIaZRL","trusted":true},"outputs":[],"execution_count":103},{"id":"19","cell_type":"code","source":"# processed_val","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:07:51.449622Z","iopub.execute_input":"2025-12-10T17:07:51.449785Z","iopub.status.idle":"2025-12-10T17:07:51.483303Z","shell.execute_reply.started":"2025-12-10T17:07:51.449772Z","shell.execute_reply":"2025-12-10T17:07:51.482752Z"},"id":"Yy3SiWwCabEi","trusted":true},"outputs":[],"execution_count":104},{"id":"20","cell_type":"code","source":"# Save newly processed data (OPTIONAL - for future reuse with same filtered dataset)\n# processed_train.save_to_disk(\"/kaggle/working/cache/processed_train_uqa_filtered\")\n# processed_val.save_to_disk(\"/kaggle/working/cache/processed_val_uqa_filtered\")\n\n# ‚ùå DO NOT load old cache - it has index mismatches with filtered data!\n# If you've already run the preprocessing cell above, skip this cell\n\n# processed_train = load_from_disk(\"/kaggle/working/cache/processed_train_uqa_filtered\")\n# processed_val = load_from_disk(\"/kaggle/working/cache/processed_val_uqa_filtered\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["05d936e2dc9d412b8637c174a3c0be64","7e0b41aa16f241a4ba3bb8a2f3525984","2bebe7e1f3f341dfaabf29963d2c5995","41b300b02ed2413ba80865aaa99ece2a","b4740a7137e742d687e2075b60d2be8a","80132c8e4fa743fca850936ecfebc7f7","303bb3d75f7d4e94aeb60c5491ea6e61","d7463faafecf4e46a87dc6863a646cea","bc199cddba714aeda650d97fef015a14","1a508a6457bb460ba17d5adb0a9e9f85","3aac2656907a416291a622717ccaf929","fa1af70d9c95443c9f09666359ba3769","ddb717fd4dbc40c6bd8422a02f925060","6d1342eeaf4f4f0489fe0746ceaaeb09","a10683e5c1164f349cbdc75b1567994c","71cfe2c8df474badb255d7d28da04348","077fbb403e5f4069841e558a3cc0c065","b068b9fac9f24eca9bd430bab30ea70c","8cbfc6f4ec434674ac59d3fbdbddcd3b","4d675a6788b641c6a09604ef17514dec","bd9b9f21be9744c49d99ac4bc76f11e1","89469ab4bd6f48d8b9aa369473c7230f"]},"execution":{"iopub.status.busy":"2025-12-10T17:07:51.485482Z","iopub.execute_input":"2025-12-10T17:07:51.485686Z","iopub.status.idle":"2025-12-10T17:07:51.498457Z","shell.execute_reply.started":"2025-12-10T17:07:51.485670Z","shell.execute_reply":"2025-12-10T17:07:51.497918Z"},"id":"77ecdd17","outputId":"602e648b-4a75-424b-da09-d58f3295a65e","trusted":true},"outputs":[],"execution_count":105},{"id":"21","cell_type":"code","source":"def print_trainable_parameters(model):\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n\n","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:07:51.499058Z","iopub.execute_input":"2025-12-10T17:07:51.499216Z","iopub.status.idle":"2025-12-10T17:07:51.514122Z","shell.execute_reply.started":"2025-12-10T17:07:51.499203Z","shell.execute_reply":"2025-12-10T17:07:51.513524Z"},"id":"c0e06e6b","trusted":true},"outputs":[],"execution_count":106},{"id":"22","cell_type":"code","source":"# build LoRA model\n\npeft_model = get_peft_model(model, lora_config)\npeft_model.gradient_checkpointing_enable()\nprint_trainable_parameters(peft_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-10T17:07:51.514782Z","iopub.execute_input":"2025-12-10T17:07:51.515021Z","iopub.status.idle":"2025-12-10T17:07:51.585485Z","shell.execute_reply.started":"2025-12-10T17:07:51.514996Z","shell.execute_reply":"2025-12-10T17:07:51.584954Z"},"id":"ba9eeeed","outputId":"27071b6e-b703-4b47-9288-9a1c6f3eba55","trusted":true},"outputs":[{"name":"stdout","text":"trainable params: 1033730 || all params: 133118212 || trainable%: 0.7765503941714602\n","output_type":"stream"}],"execution_count":107},{"id":"23","cell_type":"code","source":"# Show what the model sees during training\nprint(\"=\"*80)\nprint(\"üéì MODEL TRAINING DATA FLOW\")\nprint(\"=\"*80)\n\n# Take one batch from preprocessed data\nbatch_size = 4\nsample_batch = processed_train.select(range(batch_size))\n\nprint(f\"\\n1Ô∏è‚É£ BATCH STRUCTURE\")\nprint(\"-\"*80)\nprint(f\"Batch size: {batch_size} chunks\")\nprint(f\"Each chunk in the batch contains:\")\n\n# Show batch structure\nfor key in sample_batch.column_names:\n    sample_value = sample_batch[0][key]\n    if isinstance(sample_value, list):\n        print(f\"  - {key}: shape ({batch_size}, {len(sample_value)})\")\n    else:\n        print(f\"  - {key}: shape ({batch_size},)\")\n\nprint(f\"\\n2Ô∏è‚É£ WHAT THE MODEL RECEIVES (for 1 chunk in batch)\")\nprint(\"-\"*80)\nexample_idx = 0\nprint(f\"Input IDs: {len(sample_batch[example_idx]['input_ids'])} tokens\")\nprint(f\"  First 10 token IDs: {sample_batch[example_idx]['input_ids'][:10]}\")\nprint(f\"\\nAttention mask: {sample_batch[example_idx]['attention_mask'][:20]}...\")\nprint(f\"  (1=attend to token, 0=ignore padding)\")\nprint(f\"\\nToken type IDs: {sample_batch[example_idx]['token_type_ids'][:20]}...\")\nprint(f\"  (0=question tokens, 1=context tokens)\")\n\nprint(f\"\\n3Ô∏è‚É£ TRAINING TARGETS (what model learns to predict)\")\nprint(\"-\"*80)\nprint(f\"Target start position: {sample_batch[example_idx]['start_positions']}\")\nprint(f\"Target end position: {sample_batch[example_idx]['end_positions']}\")\nprint(f\"\\nüí° The model learns to output these exact positions!\")\n\nprint(\"\\n\" + \"=\"*80)","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:07:51.586173Z","iopub.execute_input":"2025-12-10T17:07:51.586769Z","iopub.status.idle":"2025-12-10T17:07:51.604628Z","shell.execute_reply.started":"2025-12-10T17:07:51.586743Z","shell.execute_reply":"2025-12-10T17:07:51.604056Z"},"trusted":true},"outputs":[{"name":"stdout","text":"================================================================================\nüéì MODEL TRAINING DATA FLOW\n================================================================================\n\n1Ô∏è‚É£ BATCH STRUCTURE\n--------------------------------------------------------------------------------\nBatch size: 4 chunks\nEach chunk in the batch contains:\n  - input_ids: shape (4, 384)\n  - attention_mask: shape (4, 384)\n  - token_type_ids: shape (4, 384)\n  - start_positions: shape (4,)\n  - end_positions: shape (4,)\n  - overflow_to_sample_mapping: shape (4,)\n\n2Ô∏è‚É£ WHAT THE MODEL RECEIVES (for 1 chunk in batch)\n--------------------------------------------------------------------------------\nInput IDs: 384 tokens\n  First 10 token IDs: [57344, 1580, 1583, 1740, 1583, 32, 1729, 1608, 1575, 1574]\n\nAttention mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]...\n  (1=attend to token, 0=ignore padding)\n\nToken type IDs: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]...\n  (0=question tokens, 1=context tokens)\n\n3Ô∏è‚É£ TRAINING TARGETS (what model learns to predict)\n--------------------------------------------------------------------------------\nTarget start position: 0\nTarget end position: 0\n\nüí° The model learns to output these exact positions!\n\n================================================================================\n","output_type":"stream"}],"execution_count":108},{"id":"5a98237c","cell_type":"markdown","source":"---","metadata":{}},{"id":"24","cell_type":"markdown","source":"## Model Training:\n","metadata":{}},{"id":"25","cell_type":"code","source":"def normalize_answer(text):\n    text = (text or \"\").lower()\n    def remove_articles(s):\n        return re.sub(r\"\\b(a|an|the)\\b\", \" \", s)\n    def remove_punctuation(s):\n        return \"\".join(ch for ch in s if ch not in string.punctuation)\n    def white_space_fix(s):\n        return \" \".join(s.split())\n    return white_space_fix(remove_articles(remove_punctuation(text)))\n\ndef exact_match_score(prediction, ground_truth):\n    return float(normalize_answer(prediction) == normalize_answer(ground_truth))\n\ndef f1_score(prediction, ground_truth):\n    pred_tokens = normalize_answer(prediction).split()\n    gold_tokens = normalize_answer(ground_truth).split()\n    if not gold_tokens:\n        return 1.0 if not pred_tokens else 0.0\n    if not pred_tokens:\n        return 0.0\n    common = Counter(pred_tokens) & Counter(gold_tokens)\n    num_same = sum(common.values())\n    if num_same == 0:\n        return 0.0\n    precision = num_same / len(pred_tokens)\n    recall = num_same / len(gold_tokens)\n    # BUGFIX: Prevent division by zero if both precision and recall are 0\n    if precision + recall == 0:\n        return 0.0\n    return 2 * precision * recall / (precision + recall)\n\ndef decode_prediction(input_ids, start_idx, end_idx, tokenizer):\n    # Dynamic CLS handling\n    cls_index = input_ids.index(tokenizer.cls_token_id) if tokenizer.cls_token_id in input_ids else 0\n    \n    # No answer case (both point to CLS)\n    if start_idx == cls_index and end_idx == cls_index:\n        return \"\"\n    \n    # Invalid range (start after end) - treat as no answer\n    if start_idx > end_idx:\n        return \"\"\n    \n    # Defensive bounds checking\n    if start_idx < 0 or end_idx < 0:\n        return \"\"\n    if start_idx >= len(input_ids) or end_idx >= len(input_ids):\n        return \"\"\n    \n    # Clamp to valid range (additional safety)\n    start_idx = max(start_idx, 0)\n    end_idx = min(end_idx, len(input_ids) - 1)\n    \n    # Decode with inclusive slicing [start:end+1]\n    text = tokenizer.decode(input_ids[start_idx:end_idx + 1], skip_special_tokens=True)\n    return text.strip()\n\ndef gold_answer(example):\n    if example[\"answer_start\"] == -1:\n        return \"\"\n    return example[\"answer\"]\n\ndef edit_distance_score(prediction, ground_truth):\n    return Levenshtein.ratio(normalize_answer(prediction), normalize_answer(ground_truth))\n\n\ndef evaluate_checkpoint(checkpoint_path=None, model_instance=None, eval_dataset=None):\n    \"\"\"Evaluate either a checkpoint path (loads model) or a provided model instance.\n\n    - checkpoint_path: path to checkpoint folder\n    - model_instance: an in-memory model (preferably a PeftModel or CanineForQuestionAnswering)\n    - eval_dataset: optional dataset to evaluate; if None the default processed_val will be used\n    \"\"\"\n    if eval_dataset is None:\n        eval_dataset = processed_val\n\n    # If a model_instance is given, use it directly (avoid re-loading a fresh base model)\n    if model_instance is not None:\n        eval_model = model_instance\n    else:\n        base_model = CanineForQuestionAnswering.from_pretrained(model_name, trust_remote_code=False)\n        eval_model = get_peft_model(base_model, lora_config)\n        # Try loading adapter weights; fall back to PeftModel.from_pretrained if needed\n        try:\n            eval_model.load_adapter(checkpoint_path)\n        except Exception:\n            from peft import PeftModel\n            eval_model = PeftModel.from_pretrained(base_model, checkpoint_path)\n\n    eval_model.to(device)\n\n    eval_args = TrainingArguments(\n        # Small evaluation config; uses cpu/mps if no gpu during eval\n        output_dir=\"outputs/canine-s-uqa-filtered\",\n        per_device_eval_batch_size=16,\n        dataloader_drop_last=False,\n        fp16=True,\n        bf16=False,\n        report_to=\"none\",\n    )\n\n    # Run evaluation via a lightweight Trainer so prediction loop is standard\n    eval_trainer = Trainer(\n        model=eval_model,\n        args=eval_args,\n        eval_dataset=eval_dataset,\n        tokenizer=tokenizer,\n    )\n\n    predictions = eval_trainer.predict(eval_dataset)\n    start_logits, end_logits = predictions.predictions\n    \n    # BUGFIX: Validate logits shape before processing\n    if len(start_logits) == 0 or len(end_logits) == 0:\n        print(\"‚ö†Ô∏è Warning: Empty logits received from model!\")\n        return {\"exact_match\": 0.0, \"f1\": 0.0, \"edit_distance\": 0.0}\n    \n    if start_logits.shape[0] != end_logits.shape[0]:\n        print(f\"‚ö†Ô∏è Warning: Mismatched logits shapes: {start_logits.shape} vs {end_logits.shape}\")\n        return {\"exact_match\": 0.0, \"f1\": 0.0, \"edit_distance\": 0.0}\n    \n    best_predictions = {}\n    for feature_index, feature in enumerate(eval_dataset):\n        # Defensive check: ensure feature_index is within logits bounds\n        if feature_index >= len(start_logits) or feature_index >= len(end_logits):\n            print(f\"‚ö†Ô∏è Warning: Feature index {feature_index} out of bounds (logits length: {len(start_logits)})\")\n            continue\n            \n        sample_idx = int(feature[\"overflow_to_sample_mapping\"])\n        input_ids = feature[\"input_ids\"]\n        \n        # BUGFIX: Validate logits arrays are non-empty before argmax\n        if len(start_logits[feature_index]) == 0 or len(end_logits[feature_index]) == 0:\n            print(f\"‚ö†Ô∏è Warning: Empty logits at feature {feature_index}, skipping\")\n            continue\n        \n        start_idx = int(np.argmax(start_logits[feature_index]))\n        end_idx = int(np.argmax(end_logits[feature_index]))\n        score = float(start_logits[feature_index][start_idx] + end_logits[feature_index][end_idx])\n        prediction_text = decode_prediction(input_ids, start_idx, end_idx, tokenizer=tokenizer)\n        stored = best_predictions.get(sample_idx)\n        if stored is None or score > stored[0]:\n            best_predictions[sample_idx] = (score, prediction_text)\n\n    em_scores = []\n    f1_scores = []\n    edit_dist_scores = []\n    for sample_idx, (_, prediction_text) in best_predictions.items():\n        # BUGFIX: Validate sample_idx is within dataset bounds\n        if sample_idx >= len(uqa_val):\n            print(f\"‚ö†Ô∏è Warning: sample_idx {sample_idx} out of bounds (dataset size: {len(uqa_val)})\")\n            continue\n            \n        reference = gold_answer(uqa_val[int(sample_idx)])\n        em_scores.append(exact_match_score(prediction_text, reference))\n        f1_scores.append(f1_score(prediction_text, reference))\n        edit_dist_scores.append(edit_distance_score(prediction_text, reference))\n\n    em = float(np.mean(em_scores)) if em_scores else 0.0\n    f1 = float(np.mean(f1_scores)) if f1_scores else 0.0\n    edit_dist = float(np.mean(edit_dist_scores)) if edit_dist_scores else 0.0\n    print(f\"Examples evaluated: {len(em_scores)}\")\n    print(f\"Exact Match: {em * 100:.2f}\")\n    print(f\"F1: {f1 * 100:.2f}\")\n    print(f\"Edit Distance (normalized): {edit_dist * 100:.2f}\")\n    return {\"exact_match\": em, \"f1\": f1, \"edit_distance\": edit_dist}\n","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:07:51.605319Z","iopub.execute_input":"2025-12-10T17:07:51.605480Z","iopub.status.idle":"2025-12-10T17:07:51.622902Z","shell.execute_reply.started":"2025-12-10T17:07:51.605466Z","shell.execute_reply":"2025-12-10T17:07:51.622223Z"},"trusted":true},"outputs":[],"execution_count":109},{"id":"26","cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"outputs/canine-s-uqa-filtered\",\n\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=16,\n\n    gradient_accumulation_steps=4,\n    gradient_checkpointing=True,\n\n    num_train_epochs=2,  # increased to 2\n    learning_rate=3e-4,  # increased to 3e-4\n    weight_decay=0.01,\n    \n    eval_strategy=\"no\",\n    eval_steps=500,\n    save_strategy=\"steps\",\n    save_steps=1000,  # increased to 1000\n    logging_steps=50,\n    \n    fp16=True,\n    bf16=False,\n    report_to=\"none\",\n    push_to_hub=True,\n    hub_model_id=\"VohraAK/canine-s-uqa-filtered\",\n    hub_strategy=\"checkpoint\",\n    )\n\nclass CustomEvalCallback(TrainerCallback):\n    def __init__(self, eval_func, eval_dataset, use_in_memory_model=True, verbose=True):\n        self.eval_func = eval_func\n        self.eval_dataset = eval_dataset\n        self.use_in_memory_model = use_in_memory_model\n        self.verbose = verbose\n        # trainer reference (set after trainer exists)\n        self.trainer = None\n\n    def on_save(self, args, state, control, model=None, **kwargs):\n        checkpoint_path = f\"{args.output_dir}/checkpoint-{state.global_step}\"\n        if self.verbose:\n            print(f\"\\nüîç Running custom evaluation at step {state.global_step}...\")\n\n        # Prefer evaluating the in-memory trainer model (fast + avoids re-loading)\n        if self.use_in_memory_model and self.trainer is not None:\n            if self.verbose:\n                print(\"Using in-memory model for evaluation (no reloading).\")\n            try:\n                metrics = self.eval_func(checkpoint_path=None, model_instance=self.trainer.model, eval_dataset=self.eval_dataset)\n            except Exception as e:\n                print(\"‚ö†Ô∏è in-memory evaluation failed, falling back to checkpoint load:\", e)\n                metrics = self.eval_func(checkpoint_path)\n        else:\n            metrics = self.eval_func(checkpoint_path)\n\n        # record metrics in state.log_history\n        state.log_history.append({\n            \"step\": state.global_step,\n            \"eval_exact_match\": metrics.get(\"exact_match\"),\n            \"eval_f1\": metrics.get(\"f1\"),\n            \"eval_edit_distance\": metrics.get(\"edit_distance\"),\n        })\n\n        if self.verbose:\n            print(f\"‚úÖ Step {state.global_step}: EM={metrics.get('exact_match',0)*100:.2f}, F1={metrics.get('f1',0)*100:.2f}, EditDist={metrics.get('edit_distance',0)*100:.2f}\")\n\n        # Update trainer_state.json to include custom metrics\n        state_path = f\"{checkpoint_path}/trainer_state.json\"\n        try:\n            with open(state_path, 'r') as f:\n                state_dict = json.load(f)\n            state_dict['log_history'] = state.log_history\n            with open(state_path, 'w') as f:\n                json.dump(state_dict, f, indent=2)\n            if self.verbose:\n                print(f\"üíæ Updated trainer_state.json with custom metrics\")\n        except Exception as e:\n            if self.verbose:\n                print(f\"‚ö†Ô∏è  Warning: Could not update trainer_state.json: {e}\")\n\n        try:\n            if self.verbose:\n                print(f\"‚òÅÔ∏è  Pushing checkpoint-{state.global_step} to Hub...\")\n            api = HfApi()\n            api.upload_folder(\n                folder_path=checkpoint_path,\n                repo_id=args.hub_model_id,\n                path_in_repo=f\"checkpoint-{state.global_step}\",\n                commit_message=f\"Add checkpoint {state.global_step} (EM={metrics.get('exact_match',0)*100:.1f}%, F1={metrics.get('f1',0)*100:.1f}%)\",\n                repo_type=\"model\"\n            )\n            if self.verbose:\n                print(f\"‚úÖ Pushed checkpoint-{state.global_step} to Hub\")\n        except Exception as e:\n            if self.verbose:\n                print(f\"‚ö†Ô∏è  Warning: Could not push to Hub: {e}\")\n\n        return control","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:07:51.623692Z","iopub.execute_input":"2025-12-10T17:07:51.623933Z","iopub.status.idle":"2025-12-10T17:07:51.668699Z","shell.execute_reply.started":"2025-12-10T17:07:51.623912Z","shell.execute_reply":"2025-12-10T17:07:51.668177Z"},"id":"c4abaaab","trusted":true},"outputs":[],"execution_count":110},{"id":"27","cell_type":"code","source":"trainer_cb = CustomEvalCallback(evaluate_checkpoint, processed_val, use_in_memory_model=True)\n\ntrainer = Trainer(\n    model=peft_model,\n    args=training_args,\n    train_dataset=processed_train,\n    eval_dataset=processed_val,\n    callbacks=[trainer_cb],\n)\n","metadata":{"execution":{"iopub.status.busy":"2025-12-10T17:07:51.669362Z","iopub.execute_input":"2025-12-10T17:07:51.669557Z","iopub.status.idle":"2025-12-10T17:07:52.090870Z","shell.execute_reply.started":"2025-12-10T17:07:51.669542Z","shell.execute_reply":"2025-12-10T17:07:52.090158Z"},"id":"055f5dda","trusted":true},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":111},{"id":"28","cell_type":"code","source":"trainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.status.busy":"2025-12-10T17:07:52.091712Z","iopub.execute_input":"2025-12-10T17:07:52.091994Z","iopub.status.idle":"2025-12-10T18:44:16.433412Z","shell.execute_reply.started":"2025-12-10T17:07:52.091967Z","shell.execute_reply":"2025-12-10T18:44:16.432750Z"},"id":"TOUimesUX5Re","outputId":"cfa62dcd-8eb4-475a-910b-1c38a3894cc2","trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='23480' max='23480' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [23480/23480 1:36:23, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>5.737000</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>5.330800</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>5.014200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>4.782200</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>4.496800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>4.316500</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>4.149200</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>4.001600</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>3.846600</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>3.694100</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>3.727700</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>3.534400</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>3.432600</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>3.318500</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>3.326300</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>3.278400</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>3.292200</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>3.229400</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>3.175000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>3.135900</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>3.015000</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>2.979400</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>2.898100</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>2.916100</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>2.817100</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>2.951200</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>2.716400</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>2.780000</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>2.726100</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>2.772900</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>2.883000</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>2.833900</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>2.731200</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>2.704900</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>2.624600</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>2.491400</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>2.540500</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>2.768100</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>2.655400</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>2.534200</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>2.739000</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>2.688200</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>2.492200</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>2.640000</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>2.385300</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>2.549500</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>2.427500</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>2.645700</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>2.570900</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>2.360900</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>2.556800</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>2.536200</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>2.374100</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>2.644300</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>2.409600</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>2.712600</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>2.454000</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>2.526000</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>2.391400</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>2.385800</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>2.654800</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>2.439900</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>2.210700</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>2.597200</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>2.520700</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>2.208100</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>2.483800</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>2.439500</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>2.328700</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>2.507100</td>\n    </tr>\n    <tr>\n      <td>3550</td>\n      <td>2.498100</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>2.547500</td>\n    </tr>\n    <tr>\n      <td>3650</td>\n      <td>2.320900</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>2.509000</td>\n    </tr>\n    <tr>\n      <td>3750</td>\n      <td>2.282100</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>2.444700</td>\n    </tr>\n    <tr>\n      <td>3850</td>\n      <td>2.511900</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>2.359300</td>\n    </tr>\n    <tr>\n      <td>3950</td>\n      <td>2.557300</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>2.337800</td>\n    </tr>\n    <tr>\n      <td>4050</td>\n      <td>2.404700</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>2.306300</td>\n    </tr>\n    <tr>\n      <td>4150</td>\n      <td>2.267100</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>2.367300</td>\n    </tr>\n    <tr>\n      <td>4250</td>\n      <td>2.163100</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>2.344800</td>\n    </tr>\n    <tr>\n      <td>4350</td>\n      <td>2.471200</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>2.257700</td>\n    </tr>\n    <tr>\n      <td>4450</td>\n      <td>2.402600</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>2.227200</td>\n    </tr>\n    <tr>\n      <td>4550</td>\n      <td>2.363500</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>2.394200</td>\n    </tr>\n    <tr>\n      <td>4650</td>\n      <td>2.427200</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>2.386700</td>\n    </tr>\n    <tr>\n      <td>4750</td>\n      <td>2.350900</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>2.484400</td>\n    </tr>\n    <tr>\n      <td>4850</td>\n      <td>2.277900</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>2.494500</td>\n    </tr>\n    <tr>\n      <td>4950</td>\n      <td>2.190200</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>2.379900</td>\n    </tr>\n    <tr>\n      <td>5050</td>\n      <td>2.409500</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>2.432500</td>\n    </tr>\n    <tr>\n      <td>5150</td>\n      <td>2.375100</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>2.378100</td>\n    </tr>\n    <tr>\n      <td>5250</td>\n      <td>2.415400</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>2.246900</td>\n    </tr>\n    <tr>\n      <td>5350</td>\n      <td>2.251900</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>2.272400</td>\n    </tr>\n    <tr>\n      <td>5450</td>\n      <td>2.333600</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>2.362000</td>\n    </tr>\n    <tr>\n      <td>5550</td>\n      <td>2.423800</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>2.448100</td>\n    </tr>\n    <tr>\n      <td>5650</td>\n      <td>2.281500</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>2.482500</td>\n    </tr>\n    <tr>\n      <td>5750</td>\n      <td>2.275500</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>2.423500</td>\n    </tr>\n    <tr>\n      <td>5850</td>\n      <td>2.139300</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>2.178800</td>\n    </tr>\n    <tr>\n      <td>5950</td>\n      <td>2.233100</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>2.361500</td>\n    </tr>\n    <tr>\n      <td>6050</td>\n      <td>2.175100</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>2.323400</td>\n    </tr>\n    <tr>\n      <td>6150</td>\n      <td>2.300600</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>2.084000</td>\n    </tr>\n    <tr>\n      <td>6250</td>\n      <td>2.176000</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>2.280800</td>\n    </tr>\n    <tr>\n      <td>6350</td>\n      <td>2.235000</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>2.295300</td>\n    </tr>\n    <tr>\n      <td>6450</td>\n      <td>2.341100</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>2.306300</td>\n    </tr>\n    <tr>\n      <td>6550</td>\n      <td>2.135700</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>2.106800</td>\n    </tr>\n    <tr>\n      <td>6650</td>\n      <td>2.099600</td>\n    </tr>\n    <tr>\n      <td>6700</td>\n      <td>2.198100</td>\n    </tr>\n    <tr>\n      <td>6750</td>\n      <td>2.414100</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>2.093100</td>\n    </tr>\n    <tr>\n      <td>6850</td>\n      <td>2.306600</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>2.150800</td>\n    </tr>\n    <tr>\n      <td>6950</td>\n      <td>2.191100</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>2.245900</td>\n    </tr>\n    <tr>\n      <td>7050</td>\n      <td>2.202100</td>\n    </tr>\n    <tr>\n      <td>7100</td>\n      <td>2.394300</td>\n    </tr>\n    <tr>\n      <td>7150</td>\n      <td>2.362500</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>2.414300</td>\n    </tr>\n    <tr>\n      <td>7250</td>\n      <td>2.159200</td>\n    </tr>\n    <tr>\n      <td>7300</td>\n      <td>2.149200</td>\n    </tr>\n    <tr>\n      <td>7350</td>\n      <td>2.185000</td>\n    </tr>\n    <tr>\n      <td>7400</td>\n      <td>2.285200</td>\n    </tr>\n    <tr>\n      <td>7450</td>\n      <td>2.393100</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>2.236200</td>\n    </tr>\n    <tr>\n      <td>7550</td>\n      <td>2.221200</td>\n    </tr>\n    <tr>\n      <td>7600</td>\n      <td>2.062200</td>\n    </tr>\n    <tr>\n      <td>7650</td>\n      <td>2.317100</td>\n    </tr>\n    <tr>\n      <td>7700</td>\n      <td>2.233300</td>\n    </tr>\n    <tr>\n      <td>7750</td>\n      <td>2.300700</td>\n    </tr>\n    <tr>\n      <td>7800</td>\n      <td>2.169300</td>\n    </tr>\n    <tr>\n      <td>7850</td>\n      <td>2.242200</td>\n    </tr>\n    <tr>\n      <td>7900</td>\n      <td>2.245500</td>\n    </tr>\n    <tr>\n      <td>7950</td>\n      <td>2.213600</td>\n    </tr>\n    <tr>\n      <td>8000</td>\n      <td>2.164400</td>\n    </tr>\n    <tr>\n      <td>8050</td>\n      <td>2.260000</td>\n    </tr>\n    <tr>\n      <td>8100</td>\n      <td>1.962500</td>\n    </tr>\n    <tr>\n      <td>8150</td>\n      <td>2.365000</td>\n    </tr>\n    <tr>\n      <td>8200</td>\n      <td>2.152000</td>\n    </tr>\n    <tr>\n      <td>8250</td>\n      <td>2.456800</td>\n    </tr>\n    <tr>\n      <td>8300</td>\n      <td>2.333100</td>\n    </tr>\n    <tr>\n      <td>8350</td>\n      <td>2.246800</td>\n    </tr>\n    <tr>\n      <td>8400</td>\n      <td>2.475700</td>\n    </tr>\n    <tr>\n      <td>8450</td>\n      <td>2.396900</td>\n    </tr>\n    <tr>\n      <td>8500</td>\n      <td>1.905200</td>\n    </tr>\n    <tr>\n      <td>8550</td>\n      <td>2.370000</td>\n    </tr>\n    <tr>\n      <td>8600</td>\n      <td>2.318200</td>\n    </tr>\n    <tr>\n      <td>8650</td>\n      <td>2.385900</td>\n    </tr>\n    <tr>\n      <td>8700</td>\n      <td>2.142500</td>\n    </tr>\n    <tr>\n      <td>8750</td>\n      <td>2.214000</td>\n    </tr>\n    <tr>\n      <td>8800</td>\n      <td>2.292800</td>\n    </tr>\n    <tr>\n      <td>8850</td>\n      <td>2.216100</td>\n    </tr>\n    <tr>\n      <td>8900</td>\n      <td>2.202700</td>\n    </tr>\n    <tr>\n      <td>8950</td>\n      <td>2.218300</td>\n    </tr>\n    <tr>\n      <td>9000</td>\n      <td>2.164100</td>\n    </tr>\n    <tr>\n      <td>9050</td>\n      <td>2.233600</td>\n    </tr>\n    <tr>\n      <td>9100</td>\n      <td>2.274300</td>\n    </tr>\n    <tr>\n      <td>9150</td>\n      <td>2.262900</td>\n    </tr>\n    <tr>\n      <td>9200</td>\n      <td>2.335000</td>\n    </tr>\n    <tr>\n      <td>9250</td>\n      <td>2.253400</td>\n    </tr>\n    <tr>\n      <td>9300</td>\n      <td>2.363900</td>\n    </tr>\n    <tr>\n      <td>9350</td>\n      <td>2.188000</td>\n    </tr>\n    <tr>\n      <td>9400</td>\n      <td>2.147600</td>\n    </tr>\n    <tr>\n      <td>9450</td>\n      <td>2.460400</td>\n    </tr>\n    <tr>\n      <td>9500</td>\n      <td>2.271200</td>\n    </tr>\n    <tr>\n      <td>9550</td>\n      <td>2.324900</td>\n    </tr>\n    <tr>\n      <td>9600</td>\n      <td>2.081100</td>\n    </tr>\n    <tr>\n      <td>9650</td>\n      <td>2.228700</td>\n    </tr>\n    <tr>\n      <td>9700</td>\n      <td>2.252100</td>\n    </tr>\n    <tr>\n      <td>9750</td>\n      <td>2.260100</td>\n    </tr>\n    <tr>\n      <td>9800</td>\n      <td>2.267100</td>\n    </tr>\n    <tr>\n      <td>9850</td>\n      <td>2.484800</td>\n    </tr>\n    <tr>\n      <td>9900</td>\n      <td>2.146200</td>\n    </tr>\n    <tr>\n      <td>9950</td>\n      <td>2.163500</td>\n    </tr>\n    <tr>\n      <td>10000</td>\n      <td>2.264300</td>\n    </tr>\n    <tr>\n      <td>10050</td>\n      <td>2.259300</td>\n    </tr>\n    <tr>\n      <td>10100</td>\n      <td>2.274900</td>\n    </tr>\n    <tr>\n      <td>10150</td>\n      <td>2.221500</td>\n    </tr>\n    <tr>\n      <td>10200</td>\n      <td>2.358700</td>\n    </tr>\n    <tr>\n      <td>10250</td>\n      <td>2.469600</td>\n    </tr>\n    <tr>\n      <td>10300</td>\n      <td>2.338200</td>\n    </tr>\n    <tr>\n      <td>10350</td>\n      <td>2.132200</td>\n    </tr>\n    <tr>\n      <td>10400</td>\n      <td>2.225200</td>\n    </tr>\n    <tr>\n      <td>10450</td>\n      <td>2.185700</td>\n    </tr>\n    <tr>\n      <td>10500</td>\n      <td>2.280000</td>\n    </tr>\n    <tr>\n      <td>10550</td>\n      <td>2.257700</td>\n    </tr>\n    <tr>\n      <td>10600</td>\n      <td>2.206300</td>\n    </tr>\n    <tr>\n      <td>10650</td>\n      <td>2.179000</td>\n    </tr>\n    <tr>\n      <td>10700</td>\n      <td>1.990400</td>\n    </tr>\n    <tr>\n      <td>10750</td>\n      <td>2.348500</td>\n    </tr>\n    <tr>\n      <td>10800</td>\n      <td>2.351300</td>\n    </tr>\n    <tr>\n      <td>10850</td>\n      <td>2.157400</td>\n    </tr>\n    <tr>\n      <td>10900</td>\n      <td>2.241100</td>\n    </tr>\n    <tr>\n      <td>10950</td>\n      <td>2.206400</td>\n    </tr>\n    <tr>\n      <td>11000</td>\n      <td>2.229800</td>\n    </tr>\n    <tr>\n      <td>11050</td>\n      <td>2.244600</td>\n    </tr>\n    <tr>\n      <td>11100</td>\n      <td>2.404400</td>\n    </tr>\n    <tr>\n      <td>11150</td>\n      <td>2.181800</td>\n    </tr>\n    <tr>\n      <td>11200</td>\n      <td>2.146600</td>\n    </tr>\n    <tr>\n      <td>11250</td>\n      <td>2.120900</td>\n    </tr>\n    <tr>\n      <td>11300</td>\n      <td>2.171200</td>\n    </tr>\n    <tr>\n      <td>11350</td>\n      <td>2.366900</td>\n    </tr>\n    <tr>\n      <td>11400</td>\n      <td>2.288800</td>\n    </tr>\n    <tr>\n      <td>11450</td>\n      <td>2.181700</td>\n    </tr>\n    <tr>\n      <td>11500</td>\n      <td>2.294700</td>\n    </tr>\n    <tr>\n      <td>11550</td>\n      <td>2.140300</td>\n    </tr>\n    <tr>\n      <td>11600</td>\n      <td>2.102100</td>\n    </tr>\n    <tr>\n      <td>11650</td>\n      <td>2.064100</td>\n    </tr>\n    <tr>\n      <td>11700</td>\n      <td>2.284000</td>\n    </tr>\n    <tr>\n      <td>11750</td>\n      <td>1.993100</td>\n    </tr>\n    <tr>\n      <td>11800</td>\n      <td>2.260600</td>\n    </tr>\n    <tr>\n      <td>11850</td>\n      <td>1.986500</td>\n    </tr>\n    <tr>\n      <td>11900</td>\n      <td>1.946900</td>\n    </tr>\n    <tr>\n      <td>11950</td>\n      <td>2.223700</td>\n    </tr>\n    <tr>\n      <td>12000</td>\n      <td>2.314200</td>\n    </tr>\n    <tr>\n      <td>12050</td>\n      <td>2.134400</td>\n    </tr>\n    <tr>\n      <td>12100</td>\n      <td>2.149100</td>\n    </tr>\n    <tr>\n      <td>12150</td>\n      <td>2.080500</td>\n    </tr>\n    <tr>\n      <td>12200</td>\n      <td>2.218300</td>\n    </tr>\n    <tr>\n      <td>12250</td>\n      <td>2.245600</td>\n    </tr>\n    <tr>\n      <td>12300</td>\n      <td>2.176400</td>\n    </tr>\n    <tr>\n      <td>12350</td>\n      <td>2.079400</td>\n    </tr>\n    <tr>\n      <td>12400</td>\n      <td>2.149200</td>\n    </tr>\n    <tr>\n      <td>12450</td>\n      <td>2.034200</td>\n    </tr>\n    <tr>\n      <td>12500</td>\n      <td>2.241000</td>\n    </tr>\n    <tr>\n      <td>12550</td>\n      <td>2.286900</td>\n    </tr>\n    <tr>\n      <td>12600</td>\n      <td>2.266100</td>\n    </tr>\n    <tr>\n      <td>12650</td>\n      <td>2.281800</td>\n    </tr>\n    <tr>\n      <td>12700</td>\n      <td>1.908900</td>\n    </tr>\n    <tr>\n      <td>12750</td>\n      <td>2.141500</td>\n    </tr>\n    <tr>\n      <td>12800</td>\n      <td>2.294600</td>\n    </tr>\n    <tr>\n      <td>12850</td>\n      <td>2.308900</td>\n    </tr>\n    <tr>\n      <td>12900</td>\n      <td>2.168200</td>\n    </tr>\n    <tr>\n      <td>12950</td>\n      <td>2.067400</td>\n    </tr>\n    <tr>\n      <td>13000</td>\n      <td>2.159100</td>\n    </tr>\n    <tr>\n      <td>13050</td>\n      <td>2.003100</td>\n    </tr>\n    <tr>\n      <td>13100</td>\n      <td>2.154600</td>\n    </tr>\n    <tr>\n      <td>13150</td>\n      <td>2.179000</td>\n    </tr>\n    <tr>\n      <td>13200</td>\n      <td>2.129000</td>\n    </tr>\n    <tr>\n      <td>13250</td>\n      <td>2.203500</td>\n    </tr>\n    <tr>\n      <td>13300</td>\n      <td>2.154300</td>\n    </tr>\n    <tr>\n      <td>13350</td>\n      <td>2.061700</td>\n    </tr>\n    <tr>\n      <td>13400</td>\n      <td>2.126500</td>\n    </tr>\n    <tr>\n      <td>13450</td>\n      <td>2.148900</td>\n    </tr>\n    <tr>\n      <td>13500</td>\n      <td>2.322500</td>\n    </tr>\n    <tr>\n      <td>13550</td>\n      <td>2.258800</td>\n    </tr>\n    <tr>\n      <td>13600</td>\n      <td>2.224700</td>\n    </tr>\n    <tr>\n      <td>13650</td>\n      <td>2.293100</td>\n    </tr>\n    <tr>\n      <td>13700</td>\n      <td>2.156300</td>\n    </tr>\n    <tr>\n      <td>13750</td>\n      <td>2.244300</td>\n    </tr>\n    <tr>\n      <td>13800</td>\n      <td>2.077200</td>\n    </tr>\n    <tr>\n      <td>13850</td>\n      <td>2.272000</td>\n    </tr>\n    <tr>\n      <td>13900</td>\n      <td>2.122300</td>\n    </tr>\n    <tr>\n      <td>13950</td>\n      <td>2.260700</td>\n    </tr>\n    <tr>\n      <td>14000</td>\n      <td>2.243300</td>\n    </tr>\n    <tr>\n      <td>14050</td>\n      <td>2.141000</td>\n    </tr>\n    <tr>\n      <td>14100</td>\n      <td>2.191800</td>\n    </tr>\n    <tr>\n      <td>14150</td>\n      <td>2.038300</td>\n    </tr>\n    <tr>\n      <td>14200</td>\n      <td>2.181700</td>\n    </tr>\n    <tr>\n      <td>14250</td>\n      <td>2.365600</td>\n    </tr>\n    <tr>\n      <td>14300</td>\n      <td>2.228100</td>\n    </tr>\n    <tr>\n      <td>14350</td>\n      <td>2.145000</td>\n    </tr>\n    <tr>\n      <td>14400</td>\n      <td>2.254500</td>\n    </tr>\n    <tr>\n      <td>14450</td>\n      <td>2.160000</td>\n    </tr>\n    <tr>\n      <td>14500</td>\n      <td>2.110100</td>\n    </tr>\n    <tr>\n      <td>14550</td>\n      <td>2.248300</td>\n    </tr>\n    <tr>\n      <td>14600</td>\n      <td>2.157100</td>\n    </tr>\n    <tr>\n      <td>14650</td>\n      <td>2.049400</td>\n    </tr>\n    <tr>\n      <td>14700</td>\n      <td>2.246500</td>\n    </tr>\n    <tr>\n      <td>14750</td>\n      <td>2.200900</td>\n    </tr>\n    <tr>\n      <td>14800</td>\n      <td>2.446000</td>\n    </tr>\n    <tr>\n      <td>14850</td>\n      <td>2.167800</td>\n    </tr>\n    <tr>\n      <td>14900</td>\n      <td>2.304000</td>\n    </tr>\n    <tr>\n      <td>14950</td>\n      <td>2.225500</td>\n    </tr>\n    <tr>\n      <td>15000</td>\n      <td>2.103500</td>\n    </tr>\n    <tr>\n      <td>15050</td>\n      <td>2.099800</td>\n    </tr>\n    <tr>\n      <td>15100</td>\n      <td>2.171900</td>\n    </tr>\n    <tr>\n      <td>15150</td>\n      <td>2.171900</td>\n    </tr>\n    <tr>\n      <td>15200</td>\n      <td>2.246700</td>\n    </tr>\n    <tr>\n      <td>15250</td>\n      <td>2.028600</td>\n    </tr>\n    <tr>\n      <td>15300</td>\n      <td>2.098100</td>\n    </tr>\n    <tr>\n      <td>15350</td>\n      <td>2.262900</td>\n    </tr>\n    <tr>\n      <td>15400</td>\n      <td>2.219700</td>\n    </tr>\n    <tr>\n      <td>15450</td>\n      <td>2.127300</td>\n    </tr>\n    <tr>\n      <td>15500</td>\n      <td>2.127100</td>\n    </tr>\n    <tr>\n      <td>15550</td>\n      <td>2.165600</td>\n    </tr>\n    <tr>\n      <td>15600</td>\n      <td>2.336600</td>\n    </tr>\n    <tr>\n      <td>15650</td>\n      <td>2.108000</td>\n    </tr>\n    <tr>\n      <td>15700</td>\n      <td>2.153700</td>\n    </tr>\n    <tr>\n      <td>15750</td>\n      <td>2.149900</td>\n    </tr>\n    <tr>\n      <td>15800</td>\n      <td>2.103900</td>\n    </tr>\n    <tr>\n      <td>15850</td>\n      <td>2.121300</td>\n    </tr>\n    <tr>\n      <td>15900</td>\n      <td>2.292000</td>\n    </tr>\n    <tr>\n      <td>15950</td>\n      <td>2.165600</td>\n    </tr>\n    <tr>\n      <td>16000</td>\n      <td>2.154500</td>\n    </tr>\n    <tr>\n      <td>16050</td>\n      <td>2.319800</td>\n    </tr>\n    <tr>\n      <td>16100</td>\n      <td>2.266200</td>\n    </tr>\n    <tr>\n      <td>16150</td>\n      <td>2.281700</td>\n    </tr>\n    <tr>\n      <td>16200</td>\n      <td>2.368800</td>\n    </tr>\n    <tr>\n      <td>16250</td>\n      <td>2.309800</td>\n    </tr>\n    <tr>\n      <td>16300</td>\n      <td>2.166400</td>\n    </tr>\n    <tr>\n      <td>16350</td>\n      <td>2.341900</td>\n    </tr>\n    <tr>\n      <td>16400</td>\n      <td>2.129700</td>\n    </tr>\n    <tr>\n      <td>16450</td>\n      <td>2.320300</td>\n    </tr>\n    <tr>\n      <td>16500</td>\n      <td>2.169200</td>\n    </tr>\n    <tr>\n      <td>16550</td>\n      <td>2.144700</td>\n    </tr>\n    <tr>\n      <td>16600</td>\n      <td>2.024700</td>\n    </tr>\n    <tr>\n      <td>16650</td>\n      <td>2.183400</td>\n    </tr>\n    <tr>\n      <td>16700</td>\n      <td>2.307000</td>\n    </tr>\n    <tr>\n      <td>16750</td>\n      <td>2.235800</td>\n    </tr>\n    <tr>\n      <td>16800</td>\n      <td>2.152800</td>\n    </tr>\n    <tr>\n      <td>16850</td>\n      <td>2.277800</td>\n    </tr>\n    <tr>\n      <td>16900</td>\n      <td>2.216900</td>\n    </tr>\n    <tr>\n      <td>16950</td>\n      <td>2.173100</td>\n    </tr>\n    <tr>\n      <td>17000</td>\n      <td>2.266800</td>\n    </tr>\n    <tr>\n      <td>17050</td>\n      <td>2.294100</td>\n    </tr>\n    <tr>\n      <td>17100</td>\n      <td>2.127900</td>\n    </tr>\n    <tr>\n      <td>17150</td>\n      <td>2.207800</td>\n    </tr>\n    <tr>\n      <td>17200</td>\n      <td>2.139900</td>\n    </tr>\n    <tr>\n      <td>17250</td>\n      <td>2.276500</td>\n    </tr>\n    <tr>\n      <td>17300</td>\n      <td>2.291200</td>\n    </tr>\n    <tr>\n      <td>17350</td>\n      <td>2.014700</td>\n    </tr>\n    <tr>\n      <td>17400</td>\n      <td>2.134000</td>\n    </tr>\n    <tr>\n      <td>17450</td>\n      <td>2.356300</td>\n    </tr>\n    <tr>\n      <td>17500</td>\n      <td>2.106600</td>\n    </tr>\n    <tr>\n      <td>17550</td>\n      <td>2.165300</td>\n    </tr>\n    <tr>\n      <td>17600</td>\n      <td>2.243700</td>\n    </tr>\n    <tr>\n      <td>17650</td>\n      <td>2.144700</td>\n    </tr>\n    <tr>\n      <td>17700</td>\n      <td>2.229600</td>\n    </tr>\n    <tr>\n      <td>17750</td>\n      <td>2.302800</td>\n    </tr>\n    <tr>\n      <td>17800</td>\n      <td>2.235700</td>\n    </tr>\n    <tr>\n      <td>17850</td>\n      <td>2.216800</td>\n    </tr>\n    <tr>\n      <td>17900</td>\n      <td>2.221700</td>\n    </tr>\n    <tr>\n      <td>17950</td>\n      <td>2.115000</td>\n    </tr>\n    <tr>\n      <td>18000</td>\n      <td>2.172700</td>\n    </tr>\n    <tr>\n      <td>18050</td>\n      <td>2.008000</td>\n    </tr>\n    <tr>\n      <td>18100</td>\n      <td>2.239900</td>\n    </tr>\n    <tr>\n      <td>18150</td>\n      <td>2.248900</td>\n    </tr>\n    <tr>\n      <td>18200</td>\n      <td>2.268300</td>\n    </tr>\n    <tr>\n      <td>18250</td>\n      <td>1.950500</td>\n    </tr>\n    <tr>\n      <td>18300</td>\n      <td>2.161600</td>\n    </tr>\n    <tr>\n      <td>18350</td>\n      <td>2.265200</td>\n    </tr>\n    <tr>\n      <td>18400</td>\n      <td>2.257600</td>\n    </tr>\n    <tr>\n      <td>18450</td>\n      <td>2.355000</td>\n    </tr>\n    <tr>\n      <td>18500</td>\n      <td>2.153400</td>\n    </tr>\n    <tr>\n      <td>18550</td>\n      <td>1.992700</td>\n    </tr>\n    <tr>\n      <td>18600</td>\n      <td>2.035500</td>\n    </tr>\n    <tr>\n      <td>18650</td>\n      <td>2.167000</td>\n    </tr>\n    <tr>\n      <td>18700</td>\n      <td>2.169400</td>\n    </tr>\n    <tr>\n      <td>18750</td>\n      <td>2.280900</td>\n    </tr>\n    <tr>\n      <td>18800</td>\n      <td>2.294400</td>\n    </tr>\n    <tr>\n      <td>18850</td>\n      <td>2.092700</td>\n    </tr>\n    <tr>\n      <td>18900</td>\n      <td>2.229600</td>\n    </tr>\n    <tr>\n      <td>18950</td>\n      <td>2.140800</td>\n    </tr>\n    <tr>\n      <td>19000</td>\n      <td>2.117200</td>\n    </tr>\n    <tr>\n      <td>19050</td>\n      <td>2.227700</td>\n    </tr>\n    <tr>\n      <td>19100</td>\n      <td>2.119300</td>\n    </tr>\n    <tr>\n      <td>19150</td>\n      <td>2.100100</td>\n    </tr>\n    <tr>\n      <td>19200</td>\n      <td>2.211100</td>\n    </tr>\n    <tr>\n      <td>19250</td>\n      <td>2.138200</td>\n    </tr>\n    <tr>\n      <td>19300</td>\n      <td>2.037200</td>\n    </tr>\n    <tr>\n      <td>19350</td>\n      <td>2.257600</td>\n    </tr>\n    <tr>\n      <td>19400</td>\n      <td>2.254800</td>\n    </tr>\n    <tr>\n      <td>19450</td>\n      <td>2.194300</td>\n    </tr>\n    <tr>\n      <td>19500</td>\n      <td>2.102400</td>\n    </tr>\n    <tr>\n      <td>19550</td>\n      <td>2.192800</td>\n    </tr>\n    <tr>\n      <td>19600</td>\n      <td>2.204100</td>\n    </tr>\n    <tr>\n      <td>19650</td>\n      <td>2.144700</td>\n    </tr>\n    <tr>\n      <td>19700</td>\n      <td>2.362500</td>\n    </tr>\n    <tr>\n      <td>19750</td>\n      <td>2.172400</td>\n    </tr>\n    <tr>\n      <td>19800</td>\n      <td>2.354200</td>\n    </tr>\n    <tr>\n      <td>19850</td>\n      <td>2.243600</td>\n    </tr>\n    <tr>\n      <td>19900</td>\n      <td>2.177400</td>\n    </tr>\n    <tr>\n      <td>19950</td>\n      <td>2.030400</td>\n    </tr>\n    <tr>\n      <td>20000</td>\n      <td>2.336200</td>\n    </tr>\n    <tr>\n      <td>20050</td>\n      <td>2.316600</td>\n    </tr>\n    <tr>\n      <td>20100</td>\n      <td>2.160800</td>\n    </tr>\n    <tr>\n      <td>20150</td>\n      <td>2.074000</td>\n    </tr>\n    <tr>\n      <td>20200</td>\n      <td>2.409600</td>\n    </tr>\n    <tr>\n      <td>20250</td>\n      <td>2.084500</td>\n    </tr>\n    <tr>\n      <td>20300</td>\n      <td>2.219400</td>\n    </tr>\n    <tr>\n      <td>20350</td>\n      <td>2.384400</td>\n    </tr>\n    <tr>\n      <td>20400</td>\n      <td>2.281200</td>\n    </tr>\n    <tr>\n      <td>20450</td>\n      <td>2.140600</td>\n    </tr>\n    <tr>\n      <td>20500</td>\n      <td>2.198300</td>\n    </tr>\n    <tr>\n      <td>20550</td>\n      <td>2.375000</td>\n    </tr>\n    <tr>\n      <td>20600</td>\n      <td>2.426500</td>\n    </tr>\n    <tr>\n      <td>20650</td>\n      <td>2.317500</td>\n    </tr>\n    <tr>\n      <td>20700</td>\n      <td>2.088300</td>\n    </tr>\n    <tr>\n      <td>20750</td>\n      <td>2.294500</td>\n    </tr>\n    <tr>\n      <td>20800</td>\n      <td>2.257600</td>\n    </tr>\n    <tr>\n      <td>20850</td>\n      <td>2.268600</td>\n    </tr>\n    <tr>\n      <td>20900</td>\n      <td>2.180500</td>\n    </tr>\n    <tr>\n      <td>20950</td>\n      <td>2.093500</td>\n    </tr>\n    <tr>\n      <td>21000</td>\n      <td>2.279200</td>\n    </tr>\n    <tr>\n      <td>21050</td>\n      <td>2.206000</td>\n    </tr>\n    <tr>\n      <td>21100</td>\n      <td>2.129100</td>\n    </tr>\n    <tr>\n      <td>21150</td>\n      <td>2.286600</td>\n    </tr>\n    <tr>\n      <td>21200</td>\n      <td>2.248600</td>\n    </tr>\n    <tr>\n      <td>21250</td>\n      <td>2.263400</td>\n    </tr>\n    <tr>\n      <td>21300</td>\n      <td>2.225200</td>\n    </tr>\n    <tr>\n      <td>21350</td>\n      <td>2.396600</td>\n    </tr>\n    <tr>\n      <td>21400</td>\n      <td>1.928300</td>\n    </tr>\n    <tr>\n      <td>21450</td>\n      <td>2.029900</td>\n    </tr>\n    <tr>\n      <td>21500</td>\n      <td>2.291900</td>\n    </tr>\n    <tr>\n      <td>21550</td>\n      <td>2.195100</td>\n    </tr>\n    <tr>\n      <td>21600</td>\n      <td>2.135100</td>\n    </tr>\n    <tr>\n      <td>21650</td>\n      <td>2.212600</td>\n    </tr>\n    <tr>\n      <td>21700</td>\n      <td>2.018900</td>\n    </tr>\n    <tr>\n      <td>21750</td>\n      <td>2.033700</td>\n    </tr>\n    <tr>\n      <td>21800</td>\n      <td>2.160700</td>\n    </tr>\n    <tr>\n      <td>21850</td>\n      <td>2.117100</td>\n    </tr>\n    <tr>\n      <td>21900</td>\n      <td>2.216600</td>\n    </tr>\n    <tr>\n      <td>21950</td>\n      <td>2.120600</td>\n    </tr>\n    <tr>\n      <td>22000</td>\n      <td>2.143200</td>\n    </tr>\n    <tr>\n      <td>22050</td>\n      <td>2.169400</td>\n    </tr>\n    <tr>\n      <td>22100</td>\n      <td>2.275700</td>\n    </tr>\n    <tr>\n      <td>22150</td>\n      <td>2.055500</td>\n    </tr>\n    <tr>\n      <td>22200</td>\n      <td>2.239900</td>\n    </tr>\n    <tr>\n      <td>22250</td>\n      <td>2.121900</td>\n    </tr>\n    <tr>\n      <td>22300</td>\n      <td>2.250300</td>\n    </tr>\n    <tr>\n      <td>22350</td>\n      <td>2.192600</td>\n    </tr>\n    <tr>\n      <td>22400</td>\n      <td>2.093000</td>\n    </tr>\n    <tr>\n      <td>22450</td>\n      <td>2.030300</td>\n    </tr>\n    <tr>\n      <td>22500</td>\n      <td>1.978500</td>\n    </tr>\n    <tr>\n      <td>22550</td>\n      <td>2.294400</td>\n    </tr>\n    <tr>\n      <td>22600</td>\n      <td>2.341800</td>\n    </tr>\n    <tr>\n      <td>22650</td>\n      <td>2.182800</td>\n    </tr>\n    <tr>\n      <td>22700</td>\n      <td>2.045100</td>\n    </tr>\n    <tr>\n      <td>22750</td>\n      <td>2.258700</td>\n    </tr>\n    <tr>\n      <td>22800</td>\n      <td>2.128000</td>\n    </tr>\n    <tr>\n      <td>22850</td>\n      <td>2.241100</td>\n    </tr>\n    <tr>\n      <td>22900</td>\n      <td>2.368400</td>\n    </tr>\n    <tr>\n      <td>22950</td>\n      <td>2.223700</td>\n    </tr>\n    <tr>\n      <td>23000</td>\n      <td>2.118300</td>\n    </tr>\n    <tr>\n      <td>23050</td>\n      <td>2.135100</td>\n    </tr>\n    <tr>\n      <td>23100</td>\n      <td>2.134900</td>\n    </tr>\n    <tr>\n      <td>23150</td>\n      <td>2.347400</td>\n    </tr>\n    <tr>\n      <td>23200</td>\n      <td>2.084700</td>\n    </tr>\n    <tr>\n      <td>23250</td>\n      <td>2.225800</td>\n    </tr>\n    <tr>\n      <td>23300</td>\n      <td>2.074900</td>\n    </tr>\n    <tr>\n      <td>23350</td>\n      <td>2.213300</td>\n    </tr>\n    <tr>\n      <td>23400</td>\n      <td>2.255300</td>\n    </tr>\n    <tr>\n      <td>23450</td>\n      <td>2.290300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nüîç Running custom evaluation at step 1000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.00\nF1: 33.05\nEdit Distance (normalized): 33.21\n‚úÖ Step 1000: EM=33.00, F1=33.05, EditDist=33.21\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-1000 to Hub...\n‚úÖ Pushed checkpoint-1000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 2000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.05\nF1: 33.06\nEdit Distance (normalized): 33.09\n‚úÖ Step 2000: EM=33.05, F1=33.06, EditDist=33.09\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-2000 to Hub...\n‚úÖ Pushed checkpoint-2000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 3000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.45\nF1: 33.45\nEdit Distance (normalized): 33.49\n‚úÖ Step 3000: EM=33.45, F1=33.45, EditDist=33.49\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-3000 to Hub...\n‚úÖ Pushed checkpoint-3000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 4000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.55\nF1: 33.56\nEdit Distance (normalized): 33.59\n‚úÖ Step 4000: EM=33.55, F1=33.56, EditDist=33.59\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-4000 to Hub...\n‚úÖ Pushed checkpoint-4000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 5000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.55\nF1: 33.55\nEdit Distance (normalized): 33.57\n‚úÖ Step 5000: EM=33.55, F1=33.55, EditDist=33.57\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-5000 to Hub...\n‚úÖ Pushed checkpoint-5000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 6000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.55\nF1: 33.55\nEdit Distance (normalized): 33.57\n‚úÖ Step 6000: EM=33.55, F1=33.55, EditDist=33.57\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-6000 to Hub...\n‚úÖ Pushed checkpoint-6000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 7000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.55\nF1: 33.55\nEdit Distance (normalized): 33.57\n‚úÖ Step 7000: EM=33.55, F1=33.55, EditDist=33.57\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-7000 to Hub...\n‚úÖ Pushed checkpoint-7000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 8000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.60\nF1: 33.60\nEdit Distance (normalized): 33.62\n‚úÖ Step 8000: EM=33.60, F1=33.60, EditDist=33.62\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-8000 to Hub...\n‚úÖ Pushed checkpoint-8000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 9000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.60\nF1: 33.60\nEdit Distance (normalized): 33.62\n‚úÖ Step 9000: EM=33.60, F1=33.60, EditDist=33.62\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-9000 to Hub...\n‚úÖ Pushed checkpoint-9000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 10000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.55\nF1: 33.55\nEdit Distance (normalized): 33.55\n‚úÖ Step 10000: EM=33.55, F1=33.55, EditDist=33.55\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-10000 to Hub...\n‚úÖ Pushed checkpoint-10000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 11000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.50\nF1: 33.52\nEdit Distance (normalized): 33.54\n‚úÖ Step 11000: EM=33.50, F1=33.52, EditDist=33.54\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-11000 to Hub...\n‚úÖ Pushed checkpoint-11000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 12000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.55\nF1: 33.57\nEdit Distance (normalized): 33.59\n‚úÖ Step 12000: EM=33.55, F1=33.57, EditDist=33.59\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-12000 to Hub...\n‚úÖ Pushed checkpoint-12000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 13000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.55\nF1: 33.57\nEdit Distance (normalized): 33.59\n‚úÖ Step 13000: EM=33.55, F1=33.57, EditDist=33.59\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-13000 to Hub...\n‚úÖ Pushed checkpoint-13000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 14000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.55\nF1: 33.57\nEdit Distance (normalized): 33.59\n‚úÖ Step 14000: EM=33.55, F1=33.57, EditDist=33.59\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-14000 to Hub...\n‚úÖ Pushed checkpoint-14000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 15000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.50\nF1: 33.52\nEdit Distance (normalized): 33.53\n‚úÖ Step 15000: EM=33.50, F1=33.52, EditDist=33.53\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-15000 to Hub...\n‚úÖ Pushed checkpoint-15000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 16000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.55\nF1: 33.57\nEdit Distance (normalized): 33.59\n‚úÖ Step 16000: EM=33.55, F1=33.57, EditDist=33.59\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-16000 to Hub...\n‚úÖ Pushed checkpoint-16000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 17000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.50\nF1: 33.52\nEdit Distance (normalized): 33.53\n‚úÖ Step 17000: EM=33.50, F1=33.52, EditDist=33.53\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-17000 to Hub...\n‚úÖ Pushed checkpoint-17000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 18000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.50\nF1: 33.52\nEdit Distance (normalized): 33.54\n‚úÖ Step 18000: EM=33.50, F1=33.52, EditDist=33.54\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-18000 to Hub...\n‚úÖ Pushed checkpoint-18000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 19000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.50\nF1: 33.52\nEdit Distance (normalized): 33.54\n‚úÖ Step 19000: EM=33.50, F1=33.52, EditDist=33.54\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-19000 to Hub...\n‚úÖ Pushed checkpoint-19000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 20000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.55\nF1: 33.57\nEdit Distance (normalized): 33.59\n‚úÖ Step 20000: EM=33.55, F1=33.57, EditDist=33.59\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-20000 to Hub...\n‚úÖ Pushed checkpoint-20000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 21000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.50\nF1: 33.52\nEdit Distance (normalized): 33.54\n‚úÖ Step 21000: EM=33.50, F1=33.52, EditDist=33.54\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-21000 to Hub...\n‚úÖ Pushed checkpoint-21000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 22000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.55\nF1: 33.57\nEdit Distance (normalized): 33.59\n‚úÖ Step 22000: EM=33.55, F1=33.57, EditDist=33.59\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-22000 to Hub...\n‚úÖ Pushed checkpoint-22000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 23000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.50\nF1: 33.52\nEdit Distance (normalized): 33.54\n‚úÖ Step 23000: EM=33.50, F1=33.52, EditDist=33.54\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-23000 to Hub...\n‚úÖ Pushed checkpoint-23000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 23480...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_116/892429289.py:103: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 33.50\nF1: 33.52\nEdit Distance (normalized): 33.54\n‚úÖ Step 23480: EM=33.50, F1=33.52, EditDist=33.54\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-23480 to Hub...\n‚úÖ Pushed checkpoint-23480 to Hub\n","output_type":"stream"},{"execution_count":112,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=23480, training_loss=2.339275272538349, metrics={'train_runtime': 5783.8888, 'train_samples_per_second': 64.949, 'train_steps_per_second': 4.06, 'total_flos': 9.34233896577024e+16, 'train_loss': 2.339275272538349, 'epoch': 2.0})"},"metadata":{}}],"execution_count":112},{"id":"29","cell_type":"markdown","source":"---","metadata":{}},{"id":"30","cell_type":"markdown","source":"### Diagnosing Preprocessing Functions!!!\n\nThese functions are just analysing the preprocessing logic above, they're just using the base model, NOT our trained model...","metadata":{"id":"cc44692c-6652-4cda-9ba4-8a03acdab88d"}},{"id":"31","cell_type":"code","source":"# # Diagnostic cell (fixed): Investigate preprocessing and truncation for many samples\n# import random\n# import pandas as pd\n# from transformers import AutoTokenizer\n\n# # Set display options to see full Urdu text\n# pd.set_option('display.max_colwidth', None)\n\n# try:\n#     tokenizer = AutoTokenizer.from_pretrained(\"google/canine-s\")\n# except Exception:\n#     tokenizer = None\n\n# num_samples = 20000  # Number of samples to check\n# results = []\n\n# for split_name, orig_data, proc_data in [\n#     (\"train\", uqa_train, processed_train),\n#     (\"val\", uqa_val, processed_val)\n# ]:\n#     # Sample random indices\n#     if len(proc_data) < num_samples:\n#         current_indices = range(len(proc_data))\n#     else:\n#         current_indices = random.sample(range(len(proc_data)), num_samples)\n\n#     for idx in current_indices:\n#         proc = proc_data[idx]\n#         # Use overflow_to_sample_mapping to get the correct original index\n#         orig_idx = proc[\"overflow_to_sample_mapping\"]\n#         orig = orig_data[orig_idx]\n\n#         input_ids = proc[\"input_ids\"]\n#         start_pos = proc[\"start_positions\"]\n#         end_pos = proc[\"end_positions\"]\n\n#         gold_answer = orig.get(\"gold_answer\", orig.get(\"answer\", \"\"))\n#         question = orig.get(\"question\", \"\")\n\n#         # Decode input_ids to text (for debugging context)\n#         if tokenizer:\n#             decoded_text = tokenizer.decode(input_ids, skip_special_tokens=False)\n#         else:\n#             decoded_text = str(input_ids)\n\n#         # Extract predicted answer span\n#         if 0 <= start_pos < len(input_ids) and 0 <= end_pos < len(input_ids):\n#             if tokenizer:\n#                 pred_span = tokenizer.decode(input_ids[start_pos:end_pos+1], skip_special_tokens=True)\n#             else:\n#                 pred_span = str(input_ids[start_pos:end_pos+1])\n#         else:\n#             pred_span = \"[CLS]\" # Represents no answer found in this chunk or invalid\n\n#         # Check if pred_span matches gold answer\n#         # We strip() to ignore minor whitespace differences\n#         pred_matches_gold = pred_span.strip() == gold_answer.strip()\n\n#         # Check if gold is even reachable in this chunk\n#         gold_in_decoded = gold_answer in decoded_text\n\n#         results.append({\n#             \"Split\": split_name,\n#             \"Question\": question,\n#             \"Gold Answer\": gold_answer,\n#             \"Extracted Answer\": pred_span,\n#             \"Match\": pred_matches_gold,\n#             \"Gold Reachable\": gold_in_decoded,\n#             \"orig_idx\": orig_idx\n#         })\n\n# # Create DataFrame\n# results_df = pd.DataFrame(results)\n\n# # --- SIDE BY SIDE COMPARISON ---\n\n# # 1. Filter for Solvable Mismatches (Gold was there, but we predicted wrong)\n# problem_cases = results_df[\n#     (results_df[\"Gold Reachable\"] == True) &\n#     (results_df[\"Match\"] == False)\n# ][[\"Question\", \"Gold Answer\", \"Extracted Answer\", \"Split\"]]\n\n# print(f\"üîç Checked {len(results_df)} samples.\")\n# print(f\"‚ùå Found {len(problem_cases)} cases where Gold was present but Extraction failed.\")\n\n# print(\"\\nüìä Side-by-Side Comparison (Top 20 Failures):\")\n# display(problem_cases.head(50))\n\n# print(\"\\n‚úÖ Side-by-Side Comparison (First 10 Rows - Mixed):\")\n# display(results_df[[\"Question\", \"Gold Answer\", \"Extracted Answer\", \"Match\"]].head(50))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"execution":{"iopub.status.busy":"2025-12-10T18:44:16.434217Z","iopub.execute_input":"2025-12-10T18:44:16.434496Z","iopub.status.idle":"2025-12-10T18:44:16.439629Z","shell.execute_reply.started":"2025-12-10T18:44:16.434468Z","shell.execute_reply":"2025-12-10T18:44:16.438822Z"},"id":"49f3717d","outputId":"38f435a4-1b55-4c2b-b6a5-86540fc23755","trusted":true},"outputs":[],"execution_count":113},{"id":"32","cell_type":"code","source":"# # Accuracy: fraction of rows where extracted answer matches gold answer\n# accuracy = (results_df[\"Match\"]).mean()\n\n# # Precision: among rows where extracted answer is non-empty, fraction that matches gold\n# # We filter out cases where the model predicted nothing (empty string) or just whitespace\n# non_empty_pred = results_df[\"Extracted Answer\"].str.strip() != \"\"\n\n# # Avoid division by zero if no predictions were made\n# if non_empty_pred.sum() > 0:\n#     precision = (results_df[\"Match\"] & non_empty_pred).sum() / non_empty_pred.sum()\n# else:\n#     precision = 0.0\n\n# print(f\"Accuracy: {accuracy:.3f}\")\n# print(f\"Precision: {precision:.3f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2025-12-10T18:44:16.440350Z","iopub.execute_input":"2025-12-10T18:44:16.440698Z","iopub.status.idle":"2025-12-10T18:44:16.458082Z","shell.execute_reply.started":"2025-12-10T18:44:16.440674Z","shell.execute_reply":"2025-12-10T18:44:16.457379Z"},"id":"e67abc12","outputId":"c597ec41-a56e-4e5d-9eb6-e71bd0eafd38","trusted":true},"outputs":[],"execution_count":114}]}