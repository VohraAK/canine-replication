{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cb0fcb5",
   "metadata": {},
   "source": [
    "# CANINE-S Hybrid - UQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:11:48.243073Z",
     "iopub.status.busy": "2025-11-28T11:11:48.242413Z",
     "iopub.status.idle": "2025-11-28T11:11:48.246594Z",
     "shell.execute_reply": "2025-11-28T11:11:48.245793Z",
     "shell.execute_reply.started": "2025-11-28T11:11:48.243045Z"
    },
    "id": "c186240c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %pip install peft evaluate transformers Levenshtein ipywidgets\n",
    "# %pip install protobuf==3.20.3\n",
    "# !rm -rf /kaggle/working/cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:11:48.247828Z",
     "iopub.status.busy": "2025-11-28T11:11:48.247517Z",
     "iopub.status.idle": "2025-11-28T11:11:48.263852Z",
     "shell.execute_reply": "2025-11-28T11:11:48.263227Z",
     "shell.execute_reply.started": "2025-11-28T11:11:48.247808Z"
    },
    "id": "cd8da8ab",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# X\n",
    "\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_DISABLE_CHAT_TEMPLATES\"] = \"1\"\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_ADDITIONAL_CHAT_TEMPLATES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:11:48.265048Z",
     "iopub.status.busy": "2025-11-28T11:11:48.264845Z",
     "iopub.status.idle": "2025-11-28T11:11:48.280590Z",
     "shell.execute_reply": "2025-11-28T11:11:48.279966Z",
     "shell.execute_reply.started": "2025-11-28T11:11:48.265031Z"
    },
    "id": "d87eba82",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "# from UQA.canine_utils import preprocess_uqa, lora_config, print_trainable_parameters, normalize_answer, exact_match_score, f1_score, edit_distance_score, gold_answer, decode_prediction\n",
    "from transformers import CanineTokenizer\n",
    "from peft import LoraConfig, TaskType, get_peft_model\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import Levenshtein\n",
    "\n",
    "from transformers import TrainingArguments, Trainer, TrainerCallback\n",
    "import json\n",
    "from huggingface_hub import HfApi, notebook_login, whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:11:48.281454Z",
     "iopub.status.busy": "2025-11-28T11:11:48.281234Z",
     "iopub.status.idle": "2025-11-28T11:11:48.293889Z",
     "shell.execute_reply": "2025-11-28T11:11:48.293246Z",
     "shell.execute_reply.started": "2025-11-28T11:11:48.281436Z"
    },
    "id": "0e98cebe-4c08-4850-b3c1-1529564fdb1b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# notebook_login()\n",
    "# whoami()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-28T11:11:48.295278Z",
     "iopub.status.busy": "2025-11-28T11:11:48.294982Z",
     "iopub.status.idle": "2025-11-28T11:11:54.546342Z",
     "shell.execute_reply": "2025-11-28T11:11:54.545465Z",
     "shell.execute_reply.started": "2025-11-28T11:11:48.295257Z"
    },
    "id": "f2dd5a40",
    "outputId": "140c30ea-575d-45cd-ea54-7818cdfe6bf5",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef83badc19d342b29d393ed515680f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/854 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa501ee0d4134901a8b3ad1feaa9e6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/657 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a7c5c531e944d49da401bac6d2e79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/670 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6662eec4af418f94ca2659464619c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import CanineTokenizer, CanineForQuestionAnswering\n",
    "import torch\n",
    "model_name = 'google/canine-s'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "\n",
    "tokenizer = CanineTokenizer.from_pretrained(model_name, use_fast=False, trust_remote_code=False)\n",
    "model = CanineForQuestionAnswering.from_pretrained(model_name, trust_remote_code=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:11:54.547715Z",
     "iopub.status.busy": "2025-11-28T11:11:54.547289Z",
     "iopub.status.idle": "2025-11-28T11:11:58.228385Z",
     "shell.execute_reply": "2025-11-28T11:11:58.227799Z",
     "shell.execute_reply.started": "2025-11-28T11:11:54.547689Z"
    },
    "id": "d474e2e8",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4bf08b13dc9404b88eceac9291d80cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/898 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1fa97bea2c4e548544cd15fbc0f5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001-bac007e8ca7192(‚Ä¶):   0%|          | 0.00/30.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454e6291b615412aa3369d0b7f21eaad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/validation-00000-of-00001-cf8a6960d(‚Ä¶):   0%|          | 0.00/2.92M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9ceba9de34443797aa8ce5370150a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/124745 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c280fa0cc371413bb18072c97b50a75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/16824 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "uqa_dataset = load_dataset(\"uqa/UQA\")\n",
    "uqa_train = uqa_dataset[\"train\"].shuffle(seed=42).select(range(40000))\n",
    "uqa_val = uqa_dataset[\"validation\"].shuffle(seed=42).select(range(2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561ffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore raw UQA dataset structure\n",
    "print(\"=\"*80)\n",
    "print(\"UQA DATASET STRUCTURE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Training set size: {len(uqa_train):,} examples\")\n",
    "print(f\"Validation set size: {len(uqa_val):,} examples\")\n",
    "print(f\"\\nDataset columns: {uqa_train.column_names}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Show a few examples\n",
    "print(\"\\nüìù EXAMPLE 1 - Question with Answer\")\n",
    "print(\"=\"*80)\n",
    "ex1 = uqa_train[0]\n",
    "print(f\"Question: {ex1['question']}\")\n",
    "print(f\"\\nContext (first 300 chars): {ex1['context'][:300]}...\")\n",
    "print(f\"\\nAnswer: '{ex1['answer']}'\")\n",
    "print(f\"Answer starts at character position: {ex1['answer_start']}\")\n",
    "\n",
    "# Verify the answer extraction\n",
    "if ex1['answer_start'] != -1:\n",
    "    extracted = ex1['context'][ex1['answer_start']:ex1['answer_start']+len(ex1['answer'])]\n",
    "    print(f\"‚úì Extracted from context: '{extracted}'\")\n",
    "    print(f\"‚úì Match: {extracted == ex1['answer']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nüìù EXAMPLE 2 - Another Question\")\n",
    "print(\"=\"*80)\n",
    "ex2 = uqa_train[100]\n",
    "print(f\"Question: {ex2['question']}\")\n",
    "print(f\"\\nContext length: {len(ex2['context'])} characters\")\n",
    "print(f\"Answer: '{ex2['answer']}'\")\n",
    "print(f\"Answer starts at position: {ex2['answer_start']}\")\n",
    "\n",
    "# Show answer in context\n",
    "if ex2['answer_start'] != -1:\n",
    "    start = max(0, ex2['answer_start'] - 50)\n",
    "    end = min(len(ex2['context']), ex2['answer_start'] + len(ex2['answer']) + 50)\n",
    "    context_snippet = ex2['context'][start:end]\n",
    "    answer_pos = ex2['answer_start'] - start\n",
    "    print(f\"\\nContext around answer:\")\n",
    "    print(f\"...{context_snippet}...\")\n",
    "    print(f\"    {' '*answer_pos}{'~'*len(ex2['answer'])} (answer here)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nüìä DATASET STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Compute some basic statistics\n",
    "import numpy as np\n",
    "question_lengths = [len(ex['question']) for ex in uqa_train.select(range(1000))]\n",
    "context_lengths = [len(ex['context']) for ex in uqa_train.select(range(1000))]\n",
    "answer_lengths = [len(ex['answer']) if ex['answer'] else 0 for ex in uqa_train.select(range(1000))]\n",
    "has_answer = [ex['answer_start'] != -1 for ex in uqa_train.select(range(1000))]\n",
    "\n",
    "print(f\"Question length (chars): mean={np.mean(question_lengths):.1f}, max={np.max(question_lengths)}\")\n",
    "print(f\"Context length (chars): mean={np.mean(context_lengths):.1f}, max={np.max(context_lengths)}\")\n",
    "print(f\"Answer length (chars): mean={np.mean(answer_lengths):.1f}, max={np.max(answer_lengths)}\")\n",
    "print(f\"Questions with answers: {sum(has_answer)/len(has_answer)*100:.1f}%\")\n",
    "print(f\"Questions without answers: {(1-sum(has_answer)/len(has_answer))*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676e2829",
   "metadata": {},
   "source": [
    "## üîç Data Exploration: Understanding the UQA Dataset\n",
    "\n",
    "Let's explore what the raw dataset looks like before preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "id": "89c472d5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "6e80a8d3"
   },
   "source": [
    "## Updated preprocessors!\n",
    "\n",
    "Previously, we tried to apply the same approach we used in TYDIQA on UQA, the problem was the preprocessors were aligning the answer spans in units of **byte-level spans** instead of **character-level spans**. The calculations were adding byte-level offsets to the answer lengths, and since Urdu characters may be quantified in multiple bytes, the model was being fed the wrong spans -> GIGO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a1ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FIXED preprocessing function for UQA with CANINE-S.\n",
    "Copy this into Train_CANINE_S_LoRA_UQA.ipynb cell 8 to replace the existing preprocess_uqa function.\n",
    "\n",
    "Key fixes:\n",
    "1. Added byte-to-char conversion helpers (from TyDiQA)\n",
    "2. Support both byte-based and character-based offsets via use_byte_offsets parameter\n",
    "3. Changed gold_char_end calculation to be inclusive (removed +1, added -1 after len(answer))\n",
    "4. Use dynamic cls_index for no-answer cases instead of hardcoded 0\n",
    "5. Fixed answer chunk boundary check (< instead of <=)\n",
    "6. Removed incorrect -1 subtraction from end_pos calculation\n",
    "\"\"\"\n",
    "\n",
    "from bisect import bisect_right\n",
    "\n",
    "MAX_SEQ_LENGTH = 384\n",
    "DOC_STRIDE = 64\n",
    "\n",
    "def _build_byte_to_char_index(text: str) -> list:\n",
    "    \"\"\"Build cumulative UTF-8 byte offsets for each character boundary.\"\"\"\n",
    "    cumulative = [0]\n",
    "    for char in text:\n",
    "        cumulative.append(cumulative[-1] + len(char.encode(\"utf-8\")))\n",
    "    return cumulative\n",
    "\n",
    "def _byte_to_char(cumulative_bytes: list, byte_index: int) -> int:\n",
    "    \"\"\"Map a byte offset to the nearest character index (floor).\"\"\"\n",
    "    position = bisect_right(cumulative_bytes, byte_index) - 1\n",
    "    return max(position, 0)\n",
    "\n",
    "def preprocess_uqa(examples, tokenizer, max_length=MAX_SEQ_LENGTH, doc_stride=DOC_STRIDE, model_obj=None, indices=None, use_byte_offsets=False):\n",
    "    \"\"\"\n",
    "    Robust preprocessing for UQA (Urdu Question Answering) with CANINE-S.\n",
    "    \n",
    "    Args:\n",
    "        examples: Batch of examples with question, context, answer, answer_start fields\n",
    "        tokenizer: CanineTokenizer instance\n",
    "        max_length: Maximum sequence length\n",
    "        doc_stride: Sliding window stride\n",
    "        model_obj: Optional model object (unused, for compatibility)\n",
    "        indices: Optional example indices for overflow mapping\n",
    "        use_byte_offsets: If True, treats answer_start as byte offset (like TyDiQA)\n",
    "                         If False, treats as character offset (default UQA behavior)\n",
    "    \n",
    "    Returns:\n",
    "        Dict with input_ids, attention_mask, token_type_ids, start_positions, \n",
    "        end_positions, overflow_to_sample_mapping\n",
    "    \"\"\"\n",
    "    # Handle tokenizer/model limits safely\n",
    "    tokenizer_max = getattr(tokenizer, \"model_max_length\", max_length)\n",
    "    model_max = getattr(model_obj.config, \"max_position_embeddings\", None) if model_obj is not None else None\n",
    "    max_allowed = max_length\n",
    "    if tokenizer_max is not None and tokenizer_max > 0:\n",
    "        max_allowed = min(max_allowed, tokenizer_max)\n",
    "    if model_max is not None and model_max > 0:\n",
    "        max_allowed = min(max_allowed, model_max)\n",
    "\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    contexts = examples[\"context\"]\n",
    "    answers = examples[\"answer\"]\n",
    "    answer_starts = examples[\"answer_start\"]\n",
    "\n",
    "    encoded = {\n",
    "        \"input_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"token_type_ids\": [],\n",
    "        \"start_positions\": [],\n",
    "        \"end_positions\": [],\n",
    "        \"overflow_to_sample_mapping\": []\n",
    "    }\n",
    "\n",
    "    for i, (question, context, answer, answer_start) in enumerate(zip(questions, contexts, answers, answer_starts)):\n",
    "        example_idx = indices[i] if indices is not None else i\n",
    "\n",
    "        # CANINE encodes to characters directly (1 char = 1 token)\n",
    "        question_ids = tokenizer.encode(question, add_special_tokens=False)\n",
    "        context_ids = tokenizer.encode(context, add_special_tokens=False)\n",
    "\n",
    "        # 1. Setup Targets - Convert offsets to character indices\n",
    "        if answer and answer_start != -1:\n",
    "            if use_byte_offsets:\n",
    "                # UQA might use byte offsets for multi-byte Urdu characters\n",
    "                byte_map = _build_byte_to_char_index(context)\n",
    "                gold_char_start = _byte_to_char(byte_map, answer_start)\n",
    "                answer_end_byte = answer_start + len(answer.encode('utf-8'))\n",
    "                gold_char_end = _byte_to_char(byte_map, answer_end_byte - 1)\n",
    "            else:\n",
    "                # Standard character-based offsets\n",
    "                gold_char_start = answer_start\n",
    "                # CRITICAL FIX: gold_char_end is INCLUSIVE (points to last char, not past it)\n",
    "                gold_char_end = answer_start + len(answer) - 1\n",
    "        else:\n",
    "            gold_char_start = -1\n",
    "            gold_char_end = -1\n",
    "\n",
    "        # 2. Calculate Window Size\n",
    "        special_tokens_count = tokenizer.num_special_tokens_to_add(pair=True)\n",
    "        max_context_length = max_allowed - len(question_ids) - special_tokens_count\n",
    "\n",
    "        if max_context_length <= 0:\n",
    "            continue\n",
    "\n",
    "        # 3. Sliding Window Loop\n",
    "        stride_step = max_context_length - doc_stride\n",
    "        if stride_step <= 0:\n",
    "            stride_step = max_context_length\n",
    "\n",
    "        for chunk_start_idx in range(0, len(context_ids), stride_step):\n",
    "            chunk_end_idx = min(chunk_start_idx + max_context_length, len(context_ids))\n",
    "            context_chunk = context_ids[chunk_start_idx:chunk_end_idx]\n",
    "\n",
    "            # Build inputs with special tokens: [CLS] question [SEP] context [SEP]\n",
    "            input_ids = tokenizer.build_inputs_with_special_tokens(question_ids, context_chunk)\n",
    "            token_type_ids = tokenizer.create_token_type_ids_from_sequences(question_ids, context_chunk)\n",
    "            attention_mask = [1] * len(input_ids)\n",
    "\n",
    "            # Find where context starts in input_ids\n",
    "            sep_indices = [k for k, x in enumerate(input_ids) if x == tokenizer.sep_token_id]\n",
    "            if not sep_indices:\n",
    "                continue\n",
    "            context_offset_in_input = sep_indices[0] + 1\n",
    "            \n",
    "            # Find CLS position dynamically (should be 0 for CANINE, but be safe)\n",
    "            cls_index = input_ids.index(tokenizer.cls_token_id) if tokenizer.cls_token_id in input_ids else 0\n",
    "\n",
    "            # 4. Label Assignment\n",
    "            # Check if answer is ENTIRELY within this chunk (both start and end)\n",
    "            is_answer_in_chunk = (\n",
    "                gold_char_start >= chunk_start_idx and\n",
    "                gold_char_end <= chunk_end_idx and  # Inclusive: answer must fit within chunk\n",
    "                gold_char_start != -1\n",
    "            )\n",
    "\n",
    "            if is_answer_in_chunk:\n",
    "                # Map global context indices to local input_ids indices\n",
    "                start_pos = context_offset_in_input + (gold_char_start - chunk_start_idx)\n",
    "                end_pos = context_offset_in_input + (gold_char_end - chunk_start_idx)\n",
    "                # NO -1 here because gold_char_end is already INCLUSIVE\n",
    "            else:\n",
    "                # No answer in this chunk - point to [CLS] token\n",
    "                start_pos = cls_index\n",
    "                end_pos = cls_index\n",
    "\n",
    "            # 5. Padding\n",
    "            pad_len = max_allowed - len(input_ids)\n",
    "            if pad_len > 0:\n",
    "                input_ids += [tokenizer.pad_token_id] * pad_len\n",
    "                attention_mask += [0] * pad_len\n",
    "                token_type_ids += [0] * pad_len\n",
    "\n",
    "            # 6. Final Safety Truncation\n",
    "            if len(input_ids) > max_allowed:\n",
    "                input_ids = input_ids[:max_allowed]\n",
    "                attention_mask = attention_mask[:max_allowed]\n",
    "                token_type_ids = token_type_ids[:max_allowed]\n",
    "                if start_pos >= max_allowed or end_pos >= max_allowed:\n",
    "                    start_pos = cls_index\n",
    "                    end_pos = cls_index\n",
    "\n",
    "            encoded[\"input_ids\"].append(input_ids)\n",
    "            encoded[\"attention_mask\"].append(attention_mask)\n",
    "            encoded[\"token_type_ids\"].append(token_type_ids)\n",
    "            encoded[\"start_positions\"].append(start_pos)\n",
    "            encoded[\"end_positions\"].append(end_pos)\n",
    "            encoded[\"overflow_to_sample_mapping\"].append(example_idx)\n",
    "\n",
    "            # Break if we've covered the entire context\n",
    "            if chunk_end_idx >= len(context_ids):\n",
    "                break\n",
    "\n",
    "    return encoded\n",
    "\n",
    "\n",
    "# USAGE EXAMPLE:\n",
    "# First, test which offset type UQA uses:\n",
    "# Run: python diagnose_uqa_offsets.py\n",
    "#\n",
    "# If character-based (expected):\n",
    "# processed_train = uqa_train.map(\n",
    "#     lambda examples, indices: preprocess_uqa(examples, tokenizer, indices=indices, use_byte_offsets=False),\n",
    "#     batched=True, remove_columns=uqa_train.column_names, with_indices=True\n",
    "# )\n",
    "#\n",
    "# If byte-based (like TyDiQA):\n",
    "# processed_train = uqa_train.map(\n",
    "#     lambda examples, indices: preprocess_uqa(examples, tokenizer, indices=indices, use_byte_offsets=True),\n",
    "#     batched=True, remove_columns=uqa_train.column_names, with_indices=True\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b746f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Inspect CANINE-S Architecture to determine layer count\n",
    "print(\"=\"*80)\n",
    "print(\"üîç INSPECTING CANINE-S ARCHITECTURE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Count encoder layers\n",
    "num_encoder_layers = 0\n",
    "for name, _ in model.named_parameters():\n",
    "    if \"encoder.layer.\" in name:\n",
    "        layer_num = int(name.split(\"encoder.layer.\")[1].split(\".\")[0])\n",
    "        num_encoder_layers = max(num_encoder_layers, layer_num + 1)\n",
    "\n",
    "print(f\"\\nüìä Model Architecture:\")\n",
    "print(f\"  Total encoder layers: {num_encoder_layers}\")\n",
    "print(f\"  Will apply LoRA to: All {num_encoder_layers} layers (Q, K, V)\")\n",
    "print(f\"  Will fully unfreeze: Layer {num_encoder_layers - 1} (last layer only)\")\n",
    "print(f\"  Will keep frozen: Layers 0-{num_encoder_layers - 2}\")\n",
    "\n",
    "print(f\"\\nüéØ Hybrid Strategy:\")\n",
    "print(f\"  - LoRA adapters provide parameter-efficient adaptation\")\n",
    "print(f\"  - Last layer unfrozen for maximum task-specific expressiveness\")\n",
    "print(f\"  - Expected trainable params: ~6-8M (~5% of 133M total)\")\n",
    "print(f\"  - Training time increase: ~25% (acceptable trade-off)\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de01063e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.QUESTION_ANS,\n",
    "    r=16,   # changed from 8\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"query\", \"value\", \"key\"],\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"qa_outputs\"],\n",
    ")\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:11:58.243268Z",
     "iopub.status.busy": "2025-11-28T11:11:58.242997Z",
     "iopub.status.idle": "2025-11-28T11:11:58.268086Z",
     "shell.execute_reply": "2025-11-28T11:11:58.267273Z",
     "shell.execute_reply.started": "2025-11-28T11:11:58.243244Z"
    },
    "id": "a3e95eec",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.QUESTION_ANS,\n",
    "    r=16,   # changed from 8\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"query\", \"value\", \"key\"],\n",
    "    bias=\"none\",\n",
    "    modules_to_save=[\"qa_outputs\"],\n",
    ")\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82d3cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's manually preprocess ONE example to see what happens step by step\n",
    "print(\"=\"*80)\n",
    "print(\"üî¨ PREPROCESSING WALKTHROUGH - Single Example\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Take one example\n",
    "example = uqa_train[0]\n",
    "print(f\"\\n1Ô∏è‚É£ ORIGINAL DATA\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Question: {example['question']}\")\n",
    "print(f\"Answer: '{example['answer']}'\")\n",
    "print(f\"Answer position: {example['answer_start']}\")\n",
    "print(f\"Context length: {len(example['context'])} characters\")\n",
    "\n",
    "# Preprocess it\n",
    "batch = {\n",
    "    'question': [example['question']],\n",
    "    'context': [example['context']],\n",
    "    'answer': [example['answer']],\n",
    "    'answer_start': [example['answer_start']]\n",
    "}\n",
    "processed = preprocess_uqa(batch, tokenizer, indices=[0])\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£ AFTER PREPROCESSING\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Number of chunks created: {len(processed['input_ids'])}\")\n",
    "print(f\"(Sliding window creates multiple chunks per example)\")\n",
    "\n",
    "# Show first chunk in detail\n",
    "chunk_idx = 0\n",
    "print(f\"\\n3Ô∏è‚É£ CHUNK {chunk_idx} DETAILS\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Input IDs length: {len(processed['input_ids'][chunk_idx])} tokens\")\n",
    "print(f\"Start position: {processed['start_positions'][chunk_idx]}\")\n",
    "print(f\"End position: {processed['end_positions'][chunk_idx]}\")\n",
    "print(f\"Maps to original example: {processed['overflow_to_sample_mapping'][chunk_idx]}\")\n",
    "\n",
    "# Decode the inputs to show what the model sees\n",
    "input_ids = processed['input_ids'][chunk_idx]\n",
    "decoded_input = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "print(f\"\\n4Ô∏è‚É£ DECODED INPUT (first 400 chars, with special tokens)\")\n",
    "print(\"-\"*80)\n",
    "print(decoded_input[:400] + \"...\")\n",
    "\n",
    "# Decode the labeled answer span\n",
    "start_pos = processed['start_positions'][chunk_idx]\n",
    "end_pos = processed['end_positions'][chunk_idx]\n",
    "cls_idx = input_ids.index(tokenizer.cls_token_id) if tokenizer.cls_token_id in input_ids else 0\n",
    "\n",
    "if start_pos == cls_idx and end_pos == cls_idx:\n",
    "    labeled_answer = \"[NO ANSWER IN THIS CHUNK]\"\n",
    "else:\n",
    "    labeled_answer = tokenizer.decode(input_ids[start_pos:end_pos+1], skip_special_tokens=True)\n",
    "\n",
    "print(f\"\\n5Ô∏è‚É£ LABELED ANSWER SPAN IN THIS CHUNK\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Gold answer: '{example['answer']}'\")\n",
    "print(f\"Labeled span: '{labeled_answer}'\")\n",
    "print(f\"Match: {labeled_answer.strip() == example['answer'].strip()}\")\n",
    "\n",
    "# Show all chunks for this example\n",
    "print(f\"\\n6Ô∏è‚É£ ALL CHUNKS FOR THIS EXAMPLE\")\n",
    "print(\"-\"*80)\n",
    "for i in range(len(processed['input_ids'])):\n",
    "    start = processed['start_positions'][i]\n",
    "    end = processed['end_positions'][i]\n",
    "    if start == cls_idx and end == cls_idx:\n",
    "        chunk_answer = \"[NO ANSWER]\"\n",
    "    else:\n",
    "        chunk_answer = tokenizer.decode(processed['input_ids'][i][start:end+1], skip_special_tokens=True).strip()\n",
    "    has_answer = \"‚úÖ\" if chunk_answer == example['answer'].strip() else \"‚ùå\"\n",
    "    print(f\"  Chunk {i}: {has_answer} '{chunk_answer[:50]}'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674bd103",
   "metadata": {},
   "source": [
    "## üîß Preprocessing Exploration: Raw Data ‚Üí Model Input\n",
    "\n",
    "Now let's see what happens during preprocessing - how we convert text to token IDs and create training labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86,
     "referenced_widgets": [
      "b1984a6d29864e2d940119370816a37e",
      "a307de6c263a4c20a6418344cbd98c0c",
      "1db208af0dbc4f2facee78148266a207",
      "d44d38a959ec44aa90e91c15a83abbd6",
      "527baa5fc421480da4d2dc7041e19b1f",
      "d398c81b546d4527a41dd97bd87ad7d8",
      "ab4047c7f0144667857fe835d452f6c7",
      "0120d513dd4d4fccac2d528eb7ff4696",
      "c3e0981c2924416fbdf9ceab3e6b04ab",
      "bc970c64373f4f69b6c6936087ed978a",
      "4a74d22a2c334fbda54a95c5e29e712a"
     ]
    },
    "execution": {
     "iopub.execute_input": "2025-11-28T11:11:58.269233Z",
     "iopub.status.busy": "2025-11-28T11:11:58.268995Z",
     "iopub.status.idle": "2025-11-28T11:15:38.690199Z",
     "shell.execute_reply": "2025-11-28T11:15:38.689310Z",
     "shell.execute_reply.started": "2025-11-28T11:11:58.269210Z"
    },
    "id": "d11807b9",
    "outputId": "64fc2534-2871-4bd2-b3fa-4b37973486e2",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b0de37122a498f8a276ebcc1b2cc6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (3179 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325528da1bc44de381a5065221eb8e8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# preprocess the train and val splits\n",
    "processed_train = uqa_train.map(lambda examples, indices: preprocess_uqa(examples, tokenizer, indices=indices), batched=True, remove_columns=uqa_train.column_names, with_indices=True)\n",
    "processed_val = uqa_val.map(lambda examples, indices: preprocess_uqa(examples, tokenizer, indices=indices), batched=True, remove_columns=uqa_val.column_names, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:15:38.691596Z",
     "iopub.status.busy": "2025-11-28T11:15:38.691302Z",
     "iopub.status.idle": "2025-11-28T11:15:38.695246Z",
     "shell.execute_reply": "2025-11-28T11:15:38.694441Z",
     "shell.execute_reply.started": "2025-11-28T11:15:38.691576Z"
    },
    "id": "D-emFQTIaZRL",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# processed_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a804f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore preprocessed dataset structure\n",
    "print(\"=\"*80)\n",
    "print(\"üì¶ PREPROCESSED DATASET STRUCTURE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Original training examples: {len(uqa_train):,}\")\n",
    "print(f\"Preprocessed training chunks: {len(processed_train):,}\")\n",
    "print(f\"Expansion ratio: {len(processed_train)/len(uqa_train):.2f}x\")\n",
    "print(f\"(Each example creates ~{len(processed_train)//len(uqa_train):.1f} chunks due to sliding window)\")\n",
    "\n",
    "print(f\"\\nFeatures in preprocessed data: {processed_train.column_names}\")\n",
    "print(f\"\\nFeature shapes (for one chunk):\")\n",
    "for col in processed_train.column_names:\n",
    "    sample = processed_train[0][col]\n",
    "    if isinstance(sample, list):\n",
    "        print(f\"  - {col}: list of {len(sample)} elements\")\n",
    "    else:\n",
    "        print(f\"  - {col}: scalar value = {sample}\")\n",
    "\n",
    "# Analyze label distribution\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä LABEL DISTRIBUTION IN PREPROCESSED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sample_size = min(5000, len(processed_train))\n",
    "cls_idx = 0  # CLS is at position 0 for CANINE\n",
    "\n",
    "no_answer_chunks = 0\n",
    "answer_chunks = 0\n",
    "\n",
    "for i in range(sample_size):\n",
    "    start = processed_train[i]['start_positions']\n",
    "    end = processed_train[i]['end_positions']\n",
    "    if start == cls_idx and end == cls_idx:\n",
    "        no_answer_chunks += 1\n",
    "    else:\n",
    "        answer_chunks += 1\n",
    "\n",
    "print(f\"Chunks with answer: {answer_chunks:,} ({answer_chunks/sample_size*100:.1f}%)\")\n",
    "print(f\"Chunks without answer: {no_answer_chunks:,} ({no_answer_chunks/sample_size*100:.1f}%)\")\n",
    "print(f\"\\nüí° This is expected! Most chunks don't contain the answer due to sliding window.\")\n",
    "print(f\"   Each question gets ~3-5 chunks, but only 1 contains the answer.\")\n",
    "\n",
    "# Show a few preprocessed examples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üîç SAMPLE PREPROCESSED CHUNKS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for i in [0, 10, 20]:\n",
    "    chunk = processed_train[i]\n",
    "    orig_idx = chunk['overflow_to_sample_mapping']\n",
    "    original = uqa_train[orig_idx]\n",
    "    \n",
    "    input_ids = chunk['input_ids']\n",
    "    start_pos = chunk['start_positions']\n",
    "    end_pos = chunk['end_positions']\n",
    "    \n",
    "    # Decode\n",
    "    if start_pos == 0 and end_pos == 0:\n",
    "        labeled = \"[NO ANSWER]\"\n",
    "    else:\n",
    "        labeled = tokenizer.decode(input_ids[start_pos:end_pos+1], skip_special_tokens=True).strip()\n",
    "    \n",
    "    print(f\"\\nChunk {i} (from example {orig_idx}):\")\n",
    "    print(f\"  Question: {original['question'][:60]}...\")\n",
    "    print(f\"  Gold answer: '{original['answer']}'\")\n",
    "    print(f\"  This chunk's label: '{labeled}'\")\n",
    "    print(f\"  Positions: [{start_pos}, {end_pos}]\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5094a1d1",
   "metadata": {},
   "source": [
    "## üì¶ Understanding the Preprocessed Dataset\n",
    "\n",
    "Let's explore the full preprocessed dataset structure that gets fed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:15:38.696219Z",
     "iopub.status.busy": "2025-11-28T11:15:38.695967Z",
     "iopub.status.idle": "2025-11-28T11:15:38.723658Z",
     "shell.execute_reply": "2025-11-28T11:15:38.722762Z",
     "shell.execute_reply.started": "2025-11-28T11:15:38.696195Z"
    },
    "id": "Yy3SiWwCabEi",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# processed_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea46d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Hybrid Model: LoRA + Unfrozen Last Layer\n",
    "print(\"=\"*80)\n",
    "print(\"üî® BUILDING HYBRID MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Step 1: Apply LoRA to all layers\n",
    "print(\"\\n1Ô∏è‚É£ Applying LoRA adapters to all encoder layers...\")\n",
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model.gradient_checkpointing_enable()\n",
    "\n",
    "print(\"\\nüìä After LoRA (before unfreezing):\")\n",
    "print_trainable_parameters(peft_model)\n",
    "\n",
    "# Step 2: Unfreeze ONLY the last encoder layer\n",
    "last_layer_idx = num_encoder_layers - 1\n",
    "print(f\"\\n2Ô∏è‚É£ Unfreezing last encoder layer (layer {last_layer_idx})...\")\n",
    "\n",
    "unfrozen_param_count = 0\n",
    "for name, param in peft_model.named_parameters():\n",
    "    if f\"encoder.layer.{last_layer_idx}.\" in name:\n",
    "        param.requires_grad = True\n",
    "        unfrozen_param_count += param.numel()\n",
    "\n",
    "print(f\"   Unfrozen {unfrozen_param_count:,} additional parameters from layer {last_layer_idx}\")\n",
    "\n",
    "print(\"\\nüìä Final Hybrid Model (LoRA + Unfrozen Last Layer):\")\n",
    "print_trainable_parameters(peft_model)\n",
    "\n",
    "print(\"\\n‚úÖ Hybrid model ready for training!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3455192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show what the model sees during training\n",
    "print(\"=\"*80)\n",
    "print(\"üéì MODEL TRAINING DATA FLOW\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Take one batch from preprocessed data\n",
    "batch_size = 4\n",
    "sample_batch = processed_train.select(range(batch_size))\n",
    "\n",
    "print(f\"\\n1Ô∏è‚É£ BATCH STRUCTURE\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Batch size: {batch_size} chunks\")\n",
    "print(f\"Each chunk in the batch contains:\")\n",
    "\n",
    "# Show batch structure\n",
    "for key in sample_batch.column_names:\n",
    "    sample_value = sample_batch[0][key]\n",
    "    if isinstance(sample_value, list):\n",
    "        print(f\"  - {key}: shape ({batch_size}, {len(sample_value)})\")\n",
    "    else:\n",
    "        print(f\"  - {key}: shape ({batch_size},)\")\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£ WHAT THE MODEL RECEIVES (for 1 chunk in batch)\")\n",
    "print(\"-\"*80)\n",
    "example_idx = 0\n",
    "print(f\"Input IDs: {len(sample_batch[example_idx]['input_ids'])} tokens\")\n",
    "print(f\"  First 10 token IDs: {sample_batch[example_idx]['input_ids'][:10]}\")\n",
    "print(f\"\\nAttention mask: {sample_batch[example_idx]['attention_mask'][:20]}...\")\n",
    "print(f\"  (1=attend to token, 0=ignore padding)\")\n",
    "print(f\"\\nToken type IDs: {sample_batch[example_idx]['token_type_ids'][:20]}...\")\n",
    "print(f\"  (0=question tokens, 1=context tokens)\")\n",
    "\n",
    "print(f\"\\n3Ô∏è‚É£ TRAINING TARGETS (what model learns to predict)\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Target start position: {sample_batch[example_idx]['start_positions']}\")\n",
    "print(f\"Target end position: {sample_batch[example_idx]['end_positions']}\")\n",
    "print(f\"\\nüí° The model learns to output these exact positions!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178f9a44",
   "metadata": {},
   "source": [
    "## üß† Model Training: How Data Flows Through CANINE\n",
    "\n",
    "Let's understand what happens during training - how the preprocessed chunks get fed into the model and what it learns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08785366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_answer(text):\n",
    "    text = (text or \"\").lower()\n",
    "    def remove_articles(s):\n",
    "        return re.sub(r\"\\b(a|an|the)\\b\", \" \", s)\n",
    "    def remove_punctuation(s):\n",
    "        return \"\".join(ch for ch in s if ch not in string.punctuation)\n",
    "    def white_space_fix(s):\n",
    "        return \" \".join(s.split())\n",
    "    return white_space_fix(remove_articles(remove_punctuation(text)))\n",
    "\n",
    "def exact_match_score(prediction, ground_truth):\n",
    "    return float(normalize_answer(prediction) == normalize_answer(ground_truth))\n",
    "\n",
    "def f1_score(prediction, ground_truth):\n",
    "    pred_tokens = normalize_answer(prediction).split()\n",
    "    gold_tokens = normalize_answer(ground_truth).split()\n",
    "    if not gold_tokens:\n",
    "        return 1.0 if not pred_tokens else 0.0\n",
    "    if not pred_tokens:\n",
    "        return 0.0\n",
    "    common = Counter(pred_tokens) & Counter(gold_tokens)\n",
    "    num_same = sum(common.values())\n",
    "    if num_same == 0:\n",
    "        return 0.0\n",
    "    precision = num_same / len(pred_tokens)\n",
    "    recall = num_same / len(gold_tokens)\n",
    "    # BUGFIX: Prevent division by zero if both precision and recall are 0\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * precision * recall / (precision + recall)\n",
    "\n",
    "def decode_prediction(input_ids, start_idx, end_idx, tokenizer):\n",
    "    # Dynamic CLS handling\n",
    "    cls_index = input_ids.index(tokenizer.cls_token_id) if tokenizer.cls_token_id in input_ids else 0\n",
    "    \n",
    "    # No answer case (both point to CLS)\n",
    "    if start_idx == cls_index and end_idx == cls_index:\n",
    "        return \"\"\n",
    "    \n",
    "    # Invalid range (start after end) - treat as no answer\n",
    "    if start_idx > end_idx:\n",
    "        return \"\"\n",
    "    \n",
    "    # Defensive bounds checking\n",
    "    if start_idx < 0 or end_idx < 0:\n",
    "        return \"\"\n",
    "    if start_idx >= len(input_ids) or end_idx >= len(input_ids):\n",
    "        return \"\"\n",
    "    \n",
    "    # Clamp to valid range (additional safety)\n",
    "    start_idx = max(start_idx, 0)\n",
    "    end_idx = min(end_idx, len(input_ids) - 1)\n",
    "    \n",
    "    # Decode with inclusive slicing [start:end+1]\n",
    "    text = tokenizer.decode(input_ids[start_idx:end_idx + 1], skip_special_tokens=True)\n",
    "    return text.strip()\n",
    "\n",
    "def gold_answer(example):\n",
    "    if example[\"answer_start\"] == -1:\n",
    "        return \"\"\n",
    "    return example[\"answer\"]\n",
    "\n",
    "def edit_distance_score(prediction, ground_truth):\n",
    "    return Levenshtein.ratio(normalize_answer(prediction), normalize_answer(ground_truth))\n",
    "\n",
    "\n",
    "def evaluate_checkpoint(checkpoint_path=None, model_instance=None, eval_dataset=None):\n",
    "    \"\"\"Evaluate either a checkpoint path (loads model) or a provided model instance.\n",
    "\n",
    "    - checkpoint_path: path to checkpoint folder\n",
    "    - model_instance: an in-memory model (preferably a PeftModel or CanineForQuestionAnswering)\n",
    "    - eval_dataset: optional dataset to evaluate; if None the default processed_val will be used\n",
    "    \"\"\"\n",
    "    if eval_dataset is None:\n",
    "        eval_dataset = processed_val\n",
    "\n",
    "    # If a model_instance is given, use it directly (avoid re-loading a fresh base model)\n",
    "    if model_instance is not None:\n",
    "        eval_model = model_instance\n",
    "    else:\n",
    "        base_model = CanineForQuestionAnswering.from_pretrained(model_name, trust_remote_code=False)\n",
    "        eval_model = get_peft_model(base_model, lora_config)\n",
    "        # Try loading adapter weights; fall back to PeftModel.from_pretrained if needed\n",
    "        try:\n",
    "            eval_model.load_adapter(checkpoint_path)\n",
    "        except Exception:\n",
    "            from peft import PeftModel\n",
    "            eval_model = PeftModel.from_pretrained(base_model, checkpoint_path)\n",
    "        \n",
    "        # HYBRID: Unfreeze last layer to match training configuration\n",
    "        # Discover layer count\n",
    "        num_layers = 0\n",
    "        for name, _ in eval_model.named_parameters():\n",
    "            if \"encoder.layer.\" in name:\n",
    "                layer_num = int(name.split(\"encoder.layer.\")[1].split(\".\")[0])\n",
    "                num_layers = max(num_layers, layer_num + 1)\n",
    "        \n",
    "        # Unfreeze last layer\n",
    "        if num_layers > 0:\n",
    "            last_layer_idx = num_layers - 1\n",
    "            for name, param in eval_model.named_parameters():\n",
    "                if f\"encoder.layer.{last_layer_idx}.\" in name:\n",
    "                    param.requires_grad = True\n",
    "\n",
    "    eval_model.to(device)\n",
    "\n",
    "    eval_args = TrainingArguments(\n",
    "        # Small evaluation config; uses cpu/mps if no gpu during eval\n",
    "        output_dir=\"outputs/canine-s-uqa-hybrid\",\n",
    "        per_device_eval_batch_size=16,\n",
    "        dataloader_drop_last=False,\n",
    "        fp16=True,\n",
    "        bf16=False,\n",
    "        report_to=\"none\",\n",
    "    )\n",
    "\n",
    "    # Run evaluation via a lightweight Trainer so prediction loop is standard\n",
    "    eval_trainer = Trainer(\n",
    "        model=eval_model,\n",
    "        args=eval_args,\n",
    "        eval_dataset=eval_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    predictions = eval_trainer.predict(eval_dataset)\n",
    "    start_logits, end_logits = predictions.predictions\n",
    "    \n",
    "    # BUGFIX: Validate logits shape before processing\n",
    "    if len(start_logits) == 0 or len(end_logits) == 0:\n",
    "        print(\"‚ö†Ô∏è Warning: Empty logits received from model!\")\n",
    "        return {\"exact_match\": 0.0, \"f1\": 0.0, \"edit_distance\": 0.0}\n",
    "    \n",
    "    if start_logits.shape[0] != end_logits.shape[0]:\n",
    "        print(f\"‚ö†Ô∏è Warning: Mismatched logits shapes: {start_logits.shape} vs {end_logits.shape}\")\n",
    "        return {\"exact_match\": 0.0, \"f1\": 0.0, \"edit_distance\": 0.0}\n",
    "    \n",
    "    best_predictions = {}\n",
    "    for feature_index, feature in enumerate(eval_dataset):\n",
    "        # Defensive check: ensure feature_index is within logits bounds\n",
    "        if feature_index >= len(start_logits) or feature_index >= len(end_logits):\n",
    "            print(f\"‚ö†Ô∏è Warning: Feature index {feature_index} out of bounds (logits length: {len(start_logits)})\")\n",
    "            continue\n",
    "            \n",
    "        sample_idx = int(feature[\"overflow_to_sample_mapping\"])\n",
    "        input_ids = feature[\"input_ids\"]\n",
    "        \n",
    "        # BUGFIX: Validate logits arrays are non-empty before argmax\n",
    "        if len(start_logits[feature_index]) == 0 or len(end_logits[feature_index]) == 0:\n",
    "            print(f\"‚ö†Ô∏è Warning: Empty logits at feature {feature_index}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        start_idx = int(np.argmax(start_logits[feature_index]))\n",
    "        end_idx = int(np.argmax(end_logits[feature_index]))\n",
    "        score = float(start_logits[feature_index][start_idx] + end_logits[feature_index][end_idx])\n",
    "        prediction_text = decode_prediction(input_ids, start_idx, end_idx, tokenizer=tokenizer)\n",
    "        stored = best_predictions.get(sample_idx)\n",
    "        if stored is None or score > stored[0]:\n",
    "            best_predictions[sample_idx] = (score, prediction_text)\n",
    "\n",
    "    em_scores = []\n",
    "    f1_scores = []\n",
    "    edit_dist_scores = []\n",
    "    for sample_idx, (_, prediction_text) in best_predictions.items():\n",
    "        # BUGFIX: Validate sample_idx is within dataset bounds\n",
    "        if sample_idx >= len(uqa_val):\n",
    "            print(f\"‚ö†Ô∏è Warning: sample_idx {sample_idx} out of bounds (dataset size: {len(uqa_val)})\")\n",
    "            continue\n",
    "\n",
    "            \n",
    "\n",
    "        reference = gold_answer(uqa_val[int(sample_idx)])    return {\"exact_match\": em, \"f1\": f1, \"edit_distance\": edit_dist}\n",
    "\n",
    "        em_scores.append(exact_match_score(prediction_text, reference))    print(f\"Edit Distance (normalized): {edit_dist * 100:.2f}\")\n",
    "\n",
    "        f1_scores.append(f1_score(prediction_text, reference))    print(f\"F1: {f1 * 100:.2f}\")\n",
    "\n",
    "        edit_dist_scores.append(edit_distance_score(prediction_text, reference))    print(f\"Exact Match: {em * 100:.2f}\")\n",
    "\n",
    "    print(f\"Examples evaluated: {len(em_scores)}\")\n",
    "\n",
    "    em = float(np.mean(em_scores)) if em_scores else 0.0    edit_dist = float(np.mean(edit_dist_scores)) if edit_dist_scores else 0.0\n",
    "    f1 = float(np.mean(f1_scores)) if f1_scores else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:15:39.185061Z",
     "iopub.status.busy": "2025-11-28T11:15:39.184799Z",
     "iopub.status.idle": "2025-11-28T11:15:39.233564Z",
     "shell.execute_reply": "2025-11-28T11:15:39.232990Z",
     "shell.execute_reply.started": "2025-11-28T11:15:39.185044Z"
    },
    "id": "c4abaaab",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"outputs/canine-s-uqa-hybrid\",  # Changed for hybrid\n",
    "\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "\n",
    "    gradient_accumulation_steps=4,\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=4e-5,     # Reduced from 5e-5 for hybrid (more trainable params)\n",
    "    warmup_ratio=0.06,      # Added warmup for stability (~420 steps)\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"no\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    logging_steps=50,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    report_to=\"none\",\n",
    "    push_to_hub=True,\n",
    "    hub_model_id=\"VohraAK/canine-s-uqa-hybrid\",  # Changed for hybrid\n",
    "    hub_strategy=\"checkpoint\",\n",
    "    )\n",
    "\n",
    "class CustomEvalCallback(TrainerCallback):\n",
    "    def __init__(self, eval_func, eval_dataset, use_in_memory_model=True, verbose=True):\n",
    "        self.eval_func = eval_func\n",
    "        self.eval_dataset = eval_dataset\n",
    "        self.use_in_memory_model = use_in_memory_model\n",
    "        self.verbose = verbose\n",
    "        # trainer reference (set after trainer exists)\n",
    "        self.trainer = None\n",
    "\n",
    "    def on_save(self, args, state, control, model=None, **kwargs):\n",
    "        checkpoint_path = f\"{args.output_dir}/checkpoint-{state.global_step}\"\n",
    "        if self.verbose:\n",
    "            print(f\"\\nüîç Running custom evaluation at step {state.global_step}...\")\n",
    "\n",
    "        # Prefer evaluating the in-memory trainer model (fast + avoids re-loading)\n",
    "        if self.use_in_memory_model and self.trainer is not None:\n",
    "            if self.verbose:\n",
    "                print(\"Using in-memory model for evaluation (no reloading).\")\n",
    "            try:\n",
    "                metrics = self.eval_func(checkpoint_path=None, model_instance=self.trainer.model, eval_dataset=self.eval_dataset)\n",
    "            except Exception as e:\n",
    "                print(\"‚ö†Ô∏è in-memory evaluation failed, falling back to checkpoint load:\", e)\n",
    "                metrics = self.eval_func(checkpoint_path)\n",
    "        else:\n",
    "            metrics = self.eval_func(checkpoint_path)\n",
    "\n",
    "        # record metrics in state.log_history\n",
    "        state.log_history.append({\n",
    "            \"step\": state.global_step,\n",
    "            \"eval_exact_match\": metrics.get(\"exact_match\"),\n",
    "            \"eval_f1\": metrics.get(\"f1\"),\n",
    "            \"eval_edit_distance\": metrics.get(\"edit_distance\"),\n",
    "        })\n",
    "\n",
    "        if self.verbose:\n",
    "            print(f\"‚úÖ Step {state.global_step}: EM={metrics.get('exact_match',0)*100:.2f}, F1={metrics.get('f1',0)*100:.2f}, EditDist={metrics.get('edit_distance',0)*100:.2f}\")\n",
    "\n",
    "        # Update trainer_state.json to include custom metrics\n",
    "        state_path = f\"{checkpoint_path}/trainer_state.json\"\n",
    "        try:\n",
    "            with open(state_path, 'r') as f:\n",
    "                state_dict = json.load(f)\n",
    "            state_dict['log_history'] = state.log_history\n",
    "            with open(state_path, 'w') as f:\n",
    "                json.dump(state_dict, f, indent=2)\n",
    "            if self.verbose:\n",
    "                print(f\"üíæ Updated trainer_state.json with custom metrics\")\n",
    "        except Exception as e:\n",
    "            if self.verbose:\n",
    "                print(f\"‚ö†Ô∏è  Warning: Could not update trainer_state.json: {e}\")\n",
    "\n",
    "        try:\n",
    "            if self.verbose:\n",
    "                print(f\"‚òÅÔ∏è  Pushing checkpoint-{state.global_step} to Hub...\")\n",
    "            api = HfApi()\n",
    "            api.upload_folder(\n",
    "                folder_path=checkpoint_path,\n",
    "                repo_id=args.hub_model_id,\n",
    "                path_in_repo=f\"checkpoint-{state.global_step}\",\n",
    "                commit_message=f\"Add checkpoint {state.global_step} (EM={metrics.get('exact_match',0)*100:.1f}%, F1={metrics.get('f1',0)*100:.1f}%)\",\n",
    "                repo_type=\"model\"\n",
    "            )\n",
    "            if self.verbose:\n",
    "                print(f\"‚úÖ Pushed checkpoint-{state.global_step} to Hub\")\n",
    "        except Exception as e:\n",
    "            if self.verbose:\n",
    "                print(f\"‚ö†Ô∏è  Warning: Could not push to Hub: {e}\")\n",
    "\n",
    "        return control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-28T11:15:39.234552Z",
     "iopub.status.busy": "2025-11-28T11:15:39.234336Z",
     "iopub.status.idle": "2025-11-28T11:15:40.031517Z",
     "shell.execute_reply": "2025-11-28T11:15:40.030809Z",
     "shell.execute_reply.started": "2025-11-28T11:15:39.234532Z"
    },
    "id": "055f5dda",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer_cb = CustomEvalCallback(evaluate_checkpoint, processed_val, use_in_memory_model=True)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=processed_train,\n",
    "    eval_dataset=processed_val,\n",
    "    callbacks=[trainer_cb],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-11-28T11:15:40.032592Z",
     "iopub.status.busy": "2025-11-28T11:15:40.032362Z",
     "iopub.status.idle": "2025-11-28T11:52:26.051938Z",
     "shell.execute_reply": "2025-11-28T11:52:26.051314Z",
     "shell.execute_reply.started": "2025-11-28T11:15:40.032573Z"
    },
    "id": "TOUimesUX5Re",
    "outputId": "cfa62dcd-8eb4-475a-910b-1c38a3894cc2",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7313' max='7313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7313/7313 36:44, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.917900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.834100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.768900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.677400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.620900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.573700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.491900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.416600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>5.362500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.338000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>5.252800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>5.219900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>5.201900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.129400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>5.079300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.978200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.972300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.917400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.908100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.844900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>4.806900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>4.767800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>4.739300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>4.696400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>4.662600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>4.626400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>4.551700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>4.555400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>4.577600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.547100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>4.548000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>4.437800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>4.446900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>4.452600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>4.389800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>4.282400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>4.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>4.303600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>4.229200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.164500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>4.199300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>4.108200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>4.118300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>4.132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>4.048700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>4.191000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>4.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>3.913200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>4.060900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.961900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>4.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>4.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>4.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>4.063600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>3.935900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>3.915700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>4.001200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>3.923600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>3.857700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.837200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>3.882200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>3.813200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>3.764600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>3.829600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>3.886200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>3.708700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>3.790900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>3.678600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>3.830400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.902300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>3.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>3.871200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>3.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>3.700800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>3.736700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>3.675800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>3.681300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>3.806900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>3.702200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.746000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>3.797000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>3.571500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>3.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>3.729300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>3.704400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>3.669400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>3.585800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>3.543600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4450</td>\n",
       "      <td>3.692900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>3.602200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4550</td>\n",
       "      <td>3.449800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>3.628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4650</td>\n",
       "      <td>3.612100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>3.694300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4750</td>\n",
       "      <td>3.653000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>3.646300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4850</td>\n",
       "      <td>3.503700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>3.569300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4950</td>\n",
       "      <td>3.611200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.613000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5050</td>\n",
       "      <td>3.673900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>3.562100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5150</td>\n",
       "      <td>3.529700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>3.493800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5250</td>\n",
       "      <td>3.345200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>3.587500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5350</td>\n",
       "      <td>3.511200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>3.552200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5450</td>\n",
       "      <td>3.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>3.590900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5550</td>\n",
       "      <td>3.593900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>3.382500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5650</td>\n",
       "      <td>3.412600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>3.553400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5750</td>\n",
       "      <td>3.475400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>3.464700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5850</td>\n",
       "      <td>3.524000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>3.460400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5950</td>\n",
       "      <td>3.502400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.572900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6050</td>\n",
       "      <td>3.583200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>3.445600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6150</td>\n",
       "      <td>3.539700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>3.486400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6250</td>\n",
       "      <td>3.464500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>3.420100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6350</td>\n",
       "      <td>3.423400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>3.419800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6450</td>\n",
       "      <td>3.479500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>3.352500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6550</td>\n",
       "      <td>3.289800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>3.487100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6650</td>\n",
       "      <td>3.433200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>3.583700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6750</td>\n",
       "      <td>3.436800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>3.485400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6850</td>\n",
       "      <td>3.470900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>3.443100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6950</td>\n",
       "      <td>3.479100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.497200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7050</td>\n",
       "      <td>3.414100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>3.391100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7150</td>\n",
       "      <td>3.453800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>3.530500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7250</td>\n",
       "      <td>3.589500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>3.437000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 25.30\n",
      "F1: 26.26\n",
      "Edit Distance (normalized): 28.09\n",
      "‚úÖ Step 500: EM=25.30, F1=26.26, EditDist=28.09\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-500 to Hub...\n",
      "‚úÖ Pushed checkpoint-500 to Hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 1000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 29.95\n",
      "F1: 30.50\n",
      "Edit Distance (normalized): 31.41\n",
      "‚úÖ Step 1000: EM=29.95, F1=30.50, EditDist=31.41\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-1000 to Hub...\n",
      "‚úÖ Pushed checkpoint-1000 to Hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 1500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 30.90\n",
      "F1: 31.27\n",
      "Edit Distance (normalized): 31.92\n",
      "‚úÖ Step 1500: EM=30.90, F1=31.27, EditDist=31.92\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-1500 to Hub...\n",
      "‚úÖ Pushed checkpoint-1500 to Hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 2000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 31.35\n",
      "F1: 31.63\n",
      "Edit Distance (normalized): 32.17\n",
      "‚úÖ Step 2000: EM=31.35, F1=31.63, EditDist=32.17\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-2000 to Hub...\n",
      "‚úÖ Pushed checkpoint-2000 to Hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 2500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 31.75\n",
      "F1: 31.94\n",
      "Edit Distance (normalized): 32.36\n",
      "‚úÖ Step 2500: EM=31.75, F1=31.94, EditDist=32.36\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-2500 to Hub...\n",
      "‚úÖ Pushed checkpoint-2500 to Hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 3000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 32.25\n",
      "F1: 32.46\n",
      "Edit Distance (normalized): 32.87\n",
      "‚úÖ Step 3000: EM=32.25, F1=32.46, EditDist=32.87\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-3000 to Hub...\n",
      "‚úÖ Pushed checkpoint-3000 to Hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 3500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 32.35\n",
      "F1: 32.51\n",
      "Edit Distance (normalized): 32.86\n",
      "‚úÖ Step 3500: EM=32.35, F1=32.51, EditDist=32.86\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-3500 to Hub...\n",
      "‚úÖ Pushed checkpoint-3500 to Hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f77a8601-32db-4ced-a2f7-ce00d8972974)')' thrown while requesting HEAD https://huggingface.co/google/canine-s/resolve/main/config.json\n",
      "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f77a8601-32db-4ced-a2f7-ce00d8972974)')' thrown while requesting HEAD https://huggingface.co/google/canine-s/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 4000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: ea454141-2b46-42a9-82d4-6615effc264f)')' thrown while requesting HEAD https://huggingface.co/google/canine-s/resolve/main/config.json\n",
      "WARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: ea454141-2b46-42a9-82d4-6615effc264f)')' thrown while requesting HEAD https://huggingface.co/google/canine-s/resolve/main/config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "WARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n",
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 32.50\n",
      "F1: 32.66\n",
      "Edit Distance (normalized): 33.01\n",
      "‚úÖ Step 4000: EM=32.50, F1=32.66, EditDist=33.01\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-4000 to Hub...\n",
      "‚úÖ Pushed checkpoint-4000 to Hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 4500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 32.65\n",
      "F1: 32.79\n",
      "Edit Distance (normalized): 33.08\n",
      "‚úÖ Step 4500: EM=32.65, F1=32.79, EditDist=33.08\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-4500 to Hub...\n",
      "‚úÖ Pushed checkpoint-4500 to Hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 5000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 32.75\n",
      "F1: 32.87\n",
      "Edit Distance (normalized): 33.14\n",
      "‚úÖ Step 5000: EM=32.75, F1=32.87, EditDist=33.14\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-5000 to Hub...\n",
      "‚úÖ Pushed checkpoint-5000 to Hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 5500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 32.80\n",
      "F1: 32.92\n",
      "Edit Distance (normalized): 33.19\n",
      "‚úÖ Step 5500: EM=32.80, F1=32.92, EditDist=33.19\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-5500 to Hub...\n",
      "‚úÖ Pushed checkpoint-5500 to Hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 6000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 32.75\n",
      "F1: 32.85\n",
      "Edit Distance (normalized): 33.09\n",
      "‚úÖ Step 6000: EM=32.75, F1=32.85, EditDist=33.09\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-6000 to Hub...\n",
      "‚úÖ Pushed checkpoint-6000 to Hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 6500...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 32.70\n",
      "F1: 32.80\n",
      "Edit Distance (normalized): 33.06\n",
      "‚úÖ Step 6500: EM=32.70, F1=32.80, EditDist=33.06\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-6500 to Hub...\n",
      "‚úÖ Pushed checkpoint-6500 to Hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 7000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 32.70\n",
      "F1: 32.80\n",
      "Edit Distance (normalized): 33.06\n",
      "‚úÖ Step 7000: EM=32.70, F1=32.80, EditDist=33.06\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-7000 to Hub...\n",
      "‚úÖ Pushed checkpoint-7000 to Hub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Running custom evaluation at step 7313...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  eval_trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples evaluated: 2000\n",
      "Exact Match: 32.70\n",
      "F1: 32.80\n",
      "Edit Distance (normalized): 33.06\n",
      "‚úÖ Step 7313: EM=32.70, F1=32.80, EditDist=33.06\n",
      "üíæ Updated trainer_state.json with custom metrics\n",
      "‚òÅÔ∏è  Pushing checkpoint-7313 to Hub...\n",
      "‚úÖ Pushed checkpoint-7313 to Hub\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7313, training_loss=4.007603400027102, metrics={'train_runtime': 2205.5529, 'train_samples_per_second': 53.046, 'train_steps_per_second': 3.316, 'total_flos': 2.9095953406848e+16, 'train_loss': 4.007603400027102, 'epoch': 1.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b41337-dc8a-4b6f-a66a-e409e2dc19ad",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "id": "cc44692c-6652-4cda-9ba4-8a03acdab88d"
   },
   "source": [
    "### Diagnosing Preprocessing Functions!!!\n",
    "\n",
    "These functions are just analysing the preprocessing logic above, they're just using the base model, NOT our trained model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-11-28T11:54:55.505301Z",
     "iopub.status.busy": "2025-11-28T11:54:55.504481Z",
     "iopub.status.idle": "2025-11-28T11:55:21.452459Z",
     "shell.execute_reply": "2025-11-28T11:55:21.451860Z",
     "shell.execute_reply.started": "2025-11-28T11:54:55.505271Z"
    },
    "id": "49f3717d",
    "outputId": "38f435a4-1b55-4c2b-b6a5-86540fc23755",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checked 26317 samples.\n",
      "‚ùå Found 624 cases where Gold was present but Extraction failed.\n",
      "\n",
      "üìä Side-by-Side Comparison (Top 20 Failures):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Gold Answer</th>\n",
       "      <th>Extracted Answer</th>\n",
       "      <th>Split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Close Encounters ŸÜ€í ⁄©ÿ™ŸÜ€í ÿ¢ÿ≥⁄©ÿ± ÿ¨€åÿ™€íÿü</td>\n",
       "      <td>ÿØŸà</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>€å€Å ÿßÿ≥ÿßÿ™ÿ∞€Å ⁄©€í ÿ™ÿßÿ¨ÿ± ÿß⁄©ÿ´ÿ± ⁄©€åÿß ⁄©ÿ±ÿ™€í ÿ™⁄æ€íÿü</td>\n",
       "      <td>ŸÖ€åŸÜ⁄àŸàŸÑ€åŸÜ ÿ¢ÿ±⁄©ÿ≥Ÿπÿ±ÿß</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>ÿ®ÿ±⁄© ⁄©€Åÿß⁄∫ ŸÅ⁄©ÿ± ŸÖŸÜÿØ ÿ™⁄æÿß ⁄©€Å ÿ®ÿ±ÿ∑ÿßŸÜ€å€Å ÿ¨ŸÜ⁄Ø ŸÜ€Å€å⁄∫ ÿ¨€åÿ™ ÿ≥⁄©ÿ™ÿßÿü</td>\n",
       "      <td>ÿßŸÖÿ±€å⁄©€Å</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1964 ŸÖ€å⁄∫ ÿß€åŸÜ ÿß€í ÿß€åŸÖ ⁄©ÿß ÿ±€ÅŸÜŸÖÿß ⁄©ŸàŸÜ ŸÜÿßŸÖÿ≤ÿØ ⁄©€åÿß ⁄Ø€åÿß ÿ™⁄æÿßÿü</td>\n",
       "      <td>ŸÜÿßÿµÿ±</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>ŸæŸÜ⁄©⁄æŸà⁄∫ ŸàÿßŸÑ€í ⁄©€å⁄ëŸà⁄∫ ⁄©Ÿà ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n",
       "      <td>ŸæŸπ€åÿ±⁄ØŸàŸπÿß</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>ÿ®€åŸàŸÜÿ≥€å ŸÜ€í 2006 ŸÖ€å⁄∫ ⁄©ÿ≥ ⁄©Ÿà ÿÆÿ±ÿßÿ¨ ÿ™ÿ≠ÿ≥€åŸÜ Ÿæ€åÿ¥ ⁄©€åÿßÿü</td>\n",
       "      <td>ŸÖÿßÿ¶€å⁄©ŸÑ ÿ¨€å⁄©ÿ≥ŸÜ</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>⁄©ŸàŸÜ ÿ≥ÿß ŸÖŸÑ⁄© Ÿæ€ÅŸÑÿß ŸÖŸÑ⁄© ÿ™⁄æÿß ÿ¨ÿ≥ Ÿæÿ± ÿßŸÖÿ±€å⁄©€Å ŸÜ€í ÿ¨ŸÜ⁄Ø ⁄©ÿß ÿßÿπŸÑÿßŸÜ ⁄©€åÿß ÿ™⁄æÿßÿü</td>\n",
       "      <td>ÿ®ÿ±ÿ∑ÿßŸÜ€å€Å</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>Ÿπ€å ⁄à€å ⁄Øÿßÿ±⁄àŸÜ ⁄©ÿ™ŸÜ€å Ÿπ€åŸÖŸà⁄∫ ⁄©ÿß ⁄Ø⁄æÿ± €Å€íÿü</td>\n",
       "      <td>ÿØŸà</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>€Åÿßÿ¶€å⁄© ŸÜ€í ⁄©€Åÿß ÿ™⁄æÿß ⁄©€Å ŸÖÿπÿßÿ¥ÿ±€í ⁄©€í ŸÑ€å€í ÿ≠ŸÅÿßÿ∏ÿ™€å ÿ¨ÿßŸÑ ⁄©ŸàŸÜ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±€í ⁄Øÿßÿü</td>\n",
       "      <td>ÿ±€åÿßÿ≥ÿ™</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>ÿ±Ÿàÿ≥ ÿßŸàÿ± ÿ™ÿ±⁄©€å ⁄©€í ŸÖÿßÿ®€åŸÜ ÿ™ÿµŸÅ€å€Å ⁄©€í ÿ®ÿπÿØ ÿå ÿ¢ÿ≥Ÿπÿ±€åÿß ŸÜ€í ⁄©ÿ≥ ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ¥ÿßŸÖŸÑ €ÅŸàŸÜ€í ⁄©ÿß ŸÅ€åÿµŸÑ€Å ⁄©€åÿßÿü</td>\n",
       "      <td>ÿ™ÿ±⁄©€å</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>128 kbit / s Ÿæÿ± ⁄©ŸÖŸæÿ±€åÿ≥⁄à ÿß€å⁄© MP3 ⁄©ÿ™ŸÜ€í ⁄©ŸÑ ÿ®Ÿπ / ÿ≥ Ÿæ⁄ë€í ⁄Øÿßÿü</td>\n",
       "      <td>128,000</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>ÿ¨ÿ® ÿØŸàÿ≥ÿ™Ÿà⁄∫ ⁄©Ÿà ÿØŸàÿ≥ÿ±€í ŸÑŸà⁄ØŸà⁄∫ ÿ≥€í ÿ≤€åÿßÿØ€Å Ÿæÿ≥ŸÜÿØ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€í ÿ™Ÿà ÿßÿ≥€í ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n",
       "      <td>⁄©ÿ±ŸàŸÜÿ≤ŸÖ</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>⁄©ŸàŸÜ ÿ≥ÿß ÿ≥€åŸÜÿ≥ÿ± ŸÖŸàÿ¥ŸÜ ÿ≥€åŸÜÿ≥ÿ± ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ±Ÿàÿ¥ŸÜ€å ⁄©Ÿà ⁄©ŸÜŸπÿ±ŸàŸÑ ⁄©ÿ±ÿ™ÿß €Å€íÿü</td>\n",
       "      <td>ŸÇÿ®ÿ∂€Å ÿ≥€åŸÜÿ≥ÿ±</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>ŸÖ€å⁄© ⁄©€í ⁄©ÿ≥ ÿ≠ÿµ€í ŸÖ€å⁄∫ 1984 ŸÖ€å⁄∫ ÿ¢ÿ≥ÿßŸÜ€å ÿ≥€í ÿ™Ÿàÿ≥€åÿπ ŸÜ€Å€å⁄∫ ⁄©€å ÿ¨ÿß ÿ≥⁄©ÿ™€å ÿ™⁄æ€åÿü</td>\n",
       "      <td>ŸÖ€åŸÖŸàÿ±€å</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>ÿ±€å⁄à€åŸà ŸÑ€Åÿ±Ÿà⁄∫ ⁄©Ÿà Ÿæ€åÿØÿß ⁄©ÿ±ŸÜ€í ŸàÿßŸÑ€í ÿπŸÜÿßÿµÿ± ⁄©€í ÿ¨Ÿà⁄ëŸÜ€í ⁄©€í ŸÑÿ¶€í ⁄©€åÿß ÿ∂ÿ±Ÿàÿ±€å €Å€íÿü</td>\n",
       "      <td>ÿß€åŸÜŸπ€åŸÜÿß</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>⁄©ÿ≥ ⁄Øÿ±ŸàŸæ ⁄©€í ÿÆŸÑÿßŸÅ ÿ™ÿ¨ÿßÿ±ÿ™€å Ÿæÿßÿ®ŸÜÿØ€å ÿπÿßÿ¶ÿØ ⁄©€å ⁄Øÿ¶€å ÿ™⁄æ€åÿü</td>\n",
       "      <td>ÿ¥€åŸàŸÜ⁄ØŸÜŸà</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>ŸàÿßŸÜ ŸÜ€åŸàŸÖŸÜ ŸÜ€í ⁄©ŸàŸÜ ÿ≥ÿß ÿ¥ÿπÿ®€Å ŸÇÿßÿ¶ŸÖ ⁄©€åÿßÿü</td>\n",
       "      <td>ŸÖÿ≥ŸÑÿ≥ŸÑ ÿ¨€åŸàŸÖ€åŸπÿ±€å</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>ÿ¨Ÿà Ÿà⁄©ŸπŸàÿ±€åÿß ⁄©€å ÿ≥€å⁄ë⁄æ€åŸà⁄∫ ÿ≥€í ⁄Øÿ±ŸÜ€í ⁄©€í 10 ÿØŸÜ ÿ®ÿπÿØ ŸÖÿ± ⁄Ø€åÿßÿü</td>\n",
       "      <td>ÿ®ÿ±ÿßÿ§ŸÜ</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>ŸÖ€å⁄Ø€å Ÿæ€ÅŸÑ€å ÿ®ÿßÿ± ⁄©ÿ® ÿ¥ÿßÿ¶ÿπ €ÅŸàÿ¶€å ÿ™⁄æ€åÿü</td>\n",
       "      <td>1893</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>ÿ¢ŸÜ€í ŸàÿßŸÑ€í ÿ≥ÿßŸÑŸà⁄∫ ŸÖ€å⁄∫ ÿ™ÿπŸÑ€åŸÖ ⁄©€å ⁄©ŸàŸÜ ÿ≥€å ÿ¥⁄©ŸÑ ÿ∫ÿßŸÑÿ® ŸÜÿ∏ÿ± ÿ¢ÿ™€å €Å€íÿü</td>\n",
       "      <td>ÿßŸàŸæŸÜ ÿß€åÿ¨Ÿà⁄©€åÿ¥ŸÜ</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>⁄©ŸÑÿßÿ±⁄© ÿßŸàÿ± ⁄à€åŸÜ ⁄©€í ÿ®ÿß€Åÿ± ŸÜ⁄©ŸÑŸÜ€í ⁄©€í ÿ®ÿπÿØÿå ⁄©ŸàŸÜ ÿ≥ÿß ÿßŸÖ€åÿØŸàÿßÿ± ⁄©€åÿ±€å ⁄©€í ÿÆŸÑÿßŸÅ Ÿàÿßÿ≠ÿØ ÿ≠ŸÇ€åŸÇ€å ŸÖÿØŸÖŸÇÿßÿ®ŸÑ ÿ≥ŸÖÿ¨⁄æÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿü</td>\n",
       "      <td>ÿß€å⁄àŸàÿ±⁄àÿ≤</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>ÿßŸÖÿ±€å⁄©€Å ŸÖ€å⁄∫ ÿßŸÅÿ±ÿßÿØ ⁄©€å ÿ∑ÿ±ŸÅ ÿ≥€í ÿ¥ÿ±Ÿàÿπ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€í ⁄©€Å SAMs ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n",
       "      <td>ŸÖ€åŸÜ Ÿæ€å⁄àÿ≥</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>€Åÿßÿ±Ÿæÿ± ŸÑ€å ŸÜ€í ÿßŸæŸÜÿß ÿ®⁄ÜŸæŸÜ ⁄©ÿ≥ ÿ±€åÿßÿ≥ÿ™ ŸÖ€å⁄∫ ⁄Øÿ≤ÿßÿ±ÿßÿü</td>\n",
       "      <td>ÿßŸÑÿßÿ®ÿßŸÖÿß</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>⁄©ŸÖ ÿßŸàÿ± ÿßÿπŸÑ€å ⁄Øÿ±€å⁄à ŸÖ€åŸπÿßŸÖŸàÿ±ŸÅ⁄© ⁄ÜŸπÿßŸÜŸà⁄∫ ÿ≥€í ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©€å ÿ™ÿ¥⁄©€åŸÑ ⁄©ÿß ÿßÿ¥ÿßÿ±€Å ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n",
       "      <td>⁄Øÿ±€åŸÜ ÿßÿ≥ŸπŸàŸÜ</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>⁄à€å ⁄ØÿßŸÑ ⁄©€í Ÿæÿßÿ≥ ⁄©€åÿß ÿØÿ±ÿ¨€Å ÿ™⁄æÿßÿü</td>\n",
       "      <td>ÿ¨ŸÜÿ±ŸÑ</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>ŸÖ€åŸÑÿ®Ÿàÿ±ŸÜ ⁄©Ÿæ ⁄©€å Ÿæ€ÅŸÑ€å ÿØŸà⁄ë ⁄©ÿ≥ ÿ≥ÿßŸÑ €ÅŸàÿ¶€å ÿ™⁄æ€åÿü</td>\n",
       "      <td>1861</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>ÿ¨Ÿà ⁄à€åŸà⁄à ÿ®ŸàŸà€å ÿ≥ŸÜ ⁄©ÿ± ŸæŸÑÿß ÿ®⁄ë⁄æÿßÿü</td>\n",
       "      <td>ŸÖ€å⁄àŸàŸÜÿß</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>⁄à⁄Ü ÿßŸàÿ± ÿßŸÜ⁄Øÿ±€åÿ≤€å ⁄©€í ŸÖÿßÿ®€åŸÜ ŸÇÿ±ÿ∂€í ⁄©€í ÿßŸÑŸÅÿßÿ∏ ⁄©€í ÿßÿ¥ÿ™ÿ±ÿß⁄© ŸÖ€å⁄∫ ÿå ⁄©ÿ≥ ÿ≤ÿ®ÿßŸÜ ⁄©Ÿà ŸÇÿ±ÿ∂€í ⁄©€í ÿßŸÑŸÅÿßÿ∏ ⁄©ÿß ÿ≤€åÿßÿØ€Å ŸÅ€åÿµÿØ ŸÖŸÑÿßÿü</td>\n",
       "      <td>⁄à⁄Ü</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>⁄©ŸàŸπ⁄© ⁄©ÿ≥ ⁄©ŸÖŸæŸÜ€å ⁄©ÿß ÿ≥€å ÿß€å ÿßŸà €Å€íÿü</td>\n",
       "      <td>ÿß€å⁄©Ÿπ€åŸà€åÿ¥ŸÜ ÿ®ŸÑ€åÿ≤ÿßÿ±⁄à</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>⁄©ŸàŸÜ ÿ≥Ÿà⁄Üÿ™ÿß ÿ™⁄æÿß ⁄©€Å ŸÅÿß⁄©ÿ≥ ÿßŸàÿ± ÿ®ÿ±⁄© ⁄©€å ÿØŸàÿ≥ÿ™€å ⁄©⁄æŸà ⁄Ø€åÿß ÿ™⁄æÿßÿü</td>\n",
       "      <td>ÿ®ÿ±⁄©</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>⁄©ÿ≥ ÿßŸÜÿØÿ±ŸàŸÜ€å ÿ¨ÿ≤Ÿà ŸÖ€å⁄∫ ⁄©ÿßŸÅ€å ÿ≠ÿØ ÿ™⁄© ŸÜÿ∏ÿ± ÿ´ÿßŸÜ€å ⁄©€å ⁄Øÿ¶€å €Å€íÿü</td>\n",
       "      <td>ÿØÿ±ÿ¨€Å ÿ®ŸÜÿØ€å</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>ŸÜŸÖ€åÿ®€åÿß ŸÖ€å⁄∫ ⁄©ŸàŸÜ ÿ≥€å Ÿàÿ®ÿß ÿß€å⁄© ÿ®⁄ëÿß ŸÖÿ≥ÿ¶ŸÑ€Å €Å€íÿü</td>\n",
       "      <td>ÿß€å⁄àÿ≤</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>ÿßÿ≥ ÿßÿ≥⁄©Ÿàÿ± ⁄©Ÿà ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n",
       "      <td>⁄à€å ÿßÿ≥⁄©Ÿàÿ±</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1740</th>\n",
       "      <td>ÿ¨Ÿà ŸÑÿßÿ¨ÿ≤ ÿ¨€å ÿß€åŸÑ ÿß€å ⁄©€å ÿ™ÿßÿ¶€åÿØ ŸÜ€Å€å⁄∫ ⁄©ÿ± ÿ≥⁄©ÿ™€í ÿ™⁄æ€í ÿßŸÜ€Å€å⁄∫ ÿ®ÿπÿØ ŸÖ€å⁄∫ ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿü</td>\n",
       "      <td>ÿ¨ÿØ€åÿØ</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>ÿ¥ŸàŸæŸÜ ⁄©€í ŸàÿßŸÑÿØ ⁄©ÿß Ÿæ€ÅŸÑÿß ŸÜÿßŸÖ ⁄©€åÿß ÿ™⁄æÿßÿü</td>\n",
       "      <td>ŸÜ⁄©ŸàŸÑÿ≥</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>ŸÖÿ¥ÿ±ŸÇ€å ÿßŸÜ⁄ØŸÑ€åŸÜ⁄à ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ≥ÿßÿ™⁄æ ÿå ÿßŸÜ⁄ØŸÑ€åŸÜ⁄à ⁄©€í ⁄©ÿ≥ ÿ≠ÿµ€í ŸÖ€å⁄∫ ÿßÿ≥⁄©€åŸÜ⁄à€åŸÜ€åŸà€åŸÜ ŸÜ⁄òÿßÿØ ÿ®€Åÿ™ ÿ≥€í ŸÖŸÇÿßŸÖÿßÿ™ ⁄©€í ŸÜÿßŸÖ €Å€å⁄∫ÿü</td>\n",
       "      <td>ÿ¥ŸÖÿßŸÑ€å</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Ÿπ⁄æŸÜ⁄à€å ÿßÿ¥€åÿßÿ° ⁄©€åÿß €Å€å⁄∫ ⁄©€Å ÿßÿ¥€åÿßÿ° ⁄©€í ŸÖŸÇÿßÿ®ŸÑ€í ŸÖ€å⁄∫ ⁄©ŸÖ ⁄ÜŸÖ⁄©ÿü</td>\n",
       "      <td>⁄Øÿ±ŸÖ</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>ÿ¨ÿ≥ ⁄©€í ŸÖÿ∂ÿ®Ÿàÿ∑ ⁄à⁄æÿßŸÜ⁄Ü€í ÿ®ÿßŸæ €åÿß ÿ®€åŸπ€í ⁄©€å ÿ¥⁄©ŸÑ ŸÖ€å⁄∫ €Å€å⁄∫ÿü</td>\n",
       "      <td>ÿ®€åŸπŸà⁄∫</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>ÿ¥ŸàŸæŸÜ ⁄©€Åÿß⁄∫ ŸæŸÑÿß ÿ®⁄ë⁄æÿßÿü</td>\n",
       "      <td>Ÿàÿßÿ±ÿ≥ÿß</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>ŸÇŸàŸÖŸà⁄∫ ⁄©€í ÿ¥€Åÿ±€åŸà⁄∫ ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± ⁄©ÿ≥ ⁄©Ÿà ŸÖŸÇÿ±ÿ± ⁄©€åÿß ⁄Ø€åÿß €Å€íÿü</td>\n",
       "      <td>ÿßÿπÿ≤ÿßÿ≤€å ŸÜÿßÿ¶Ÿπ</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>ÿßÿ≥ ⁄©€å ŸÜÿß⁄©ÿßŸÖ€å ÿ≥€í Ÿæ€ÅŸÑ€íÿå ⁄©ŸàŸÜ ÿ≥ÿß ÿ®⁄Üÿ™ ÿßŸàÿ± ŸÇÿ±ÿ∂ ÿß€åÿ≥Ÿàÿ≥€å ÿß€åÿ¥ŸÜ ÿ±€åÿßÿ≥ÿ™€Åÿßÿ¶€í ŸÖÿ™ÿ≠ÿØ€Å ŸÖ€å⁄∫ ÿ≥ÿßÿ™Ÿà€å⁄∫ ÿ≥ÿ® ÿ≥€í ÿ®⁄ëÿß ÿ±€ÅŸÜ ÿßÿ®ÿ™ÿØÿßÿ¶€å ÿ™⁄æÿßÿü</td>\n",
       "      <td>ÿßŸÜ⁄à€å ŸÖ€å⁄© ÿ®€åŸÜ⁄©</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>ÿØ€å⁄Øÿ± ÿ®ÿ±ÿ∑ÿßŸÜŸà€å ÿ±€åÿßÿ≥ÿ™Ÿà⁄∫ ÿßŸàÿ± ⁄©ÿßŸÑŸàŸÜ€åŸà⁄∫ ŸÜ€í ÿ≥ÿßŸÑ ⁄©€å ÿ¥ÿ±Ÿàÿπÿßÿ™ ⁄©€å ÿ™ÿßÿ±€åÿÆ €å⁄©ŸÖ ÿ¨ŸÜŸàÿ±€å ⁄©ÿ® ŸÖŸÇÿ±ÿ± ⁄©€åÿü</td>\n",
       "      <td>1752</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>⁄©€Åÿß⁄∫ Broz Belousova ÿ≥€í ÿ¥ÿßÿØ€å ⁄©€åÿü</td>\n",
       "      <td>ÿßŸàŸÖÿ≥⁄©</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2207</th>\n",
       "      <td>ÿ®⁄ÜŸà⁄∫ ⁄©€å ŸÖÿ≤ÿØŸàÿ±€å ⁄©€å ŸÅÿ±ÿß€ÅŸÖ€å ÿßŸàÿ± ÿßÿ≥ ⁄©€å ⁄©€åÿß Ÿàÿ¨Ÿà€Åÿßÿ™ €Å€å⁄∫ ÿ¨Ÿà ÿ¢ÿ¨ ÿ®⁄æ€å ŸÖŸàÿ¨ŸàÿØ €Å€å⁄∫ÿü</td>\n",
       "      <td>ÿ∑ŸÑÿ®</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>ÿ∑ÿßŸÑÿ® ÿπŸÑŸÖŸà⁄∫ ⁄©Ÿà ⁄Ü€åŸÜ€å ÿ≠ÿ±ŸàŸÅ ÿ≥⁄©⁄æÿßŸÜ€í ⁄©€í ŸÑ€å€í ÿß⁄©ÿ´ÿ± ⁄©€åÿß ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n",
       "      <td>ÿ®ÿßŸÇÿßÿπÿØ€Å ÿßÿ≥⁄©ÿ±ŸæŸπ ŸÅŸàŸÜŸπ</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2274</th>\n",
       "      <td>€ÅŸÜÿØŸà ÿßÿ≥⁄©ŸàŸÑŸà⁄∫ ŸÖ€å⁄∫ ÿ≥€í ÿ≥ÿ® ÿ≥€í ÿ≤€åÿßÿØ€Å ÿ™ÿ±ŸÇ€å €åÿßŸÅÿ™€Å ÿßŸàÿ± ŸÖÿ¥€ÅŸàÿ± ⁄©ŸàŸÜ ÿ≥ÿß €Å€íÿü</td>\n",
       "      <td>Ÿà€åÿØÿßŸÜÿ™ÿß</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>Ÿæÿ±ŸÜÿØŸà⁄∫ ⁄©€í ⁄©ÿ™ŸÜ€í ÿ®⁄ë€í ŸÅŸÑÿßÿ¶Ÿπ ŸæŸπ⁄æŸà⁄∫ €ÅŸàÿ™€í €Å€å⁄∫ÿü</td>\n",
       "      <td>ÿØŸà</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>⁄©€åŸÜ€í ŸÜ€í ÿ≠ÿßÿØÿ´€í ⁄©€í ÿ®ÿπÿØ ÿ¨Ÿà ⁄©⁄Ü⁄æ €ÅŸàÿß ÿßÿ≥ ⁄©€í ÿ™ÿ¨ÿ±ÿ®€í ⁄©€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫ ⁄©€åÿß ⁄ØÿßŸÜÿß ÿ±€å⁄©ÿßÿ±⁄à ⁄©€åÿßÿü</td>\n",
       "      <td>ÿ™⁄æÿ±Ÿà ÿØ€å Ÿàÿßÿ¶ÿ±</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>ÿß€åŸàÿßŸÜ ŸÖ€å⁄∫ ÿßŸÇŸÑ€åÿ™€å Ÿæÿßÿ±Ÿπ€å ⁄©ÿß ÿ±€ÅŸÜŸÖÿß ⁄©ŸàŸÜ €Å€íÿü</td>\n",
       "      <td>ÿßŸÇŸÑ€åÿ™</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2473</th>\n",
       "      <td>⁄©€åÿß ŸÜŸàÿ¨ŸàÿßŸÜ ÿ®⁄ë€í €åÿß ⁄Ü⁄æŸàŸπ€í Ÿæ€åŸÖÿßŸÜ€í Ÿæÿ± \"⁄©ŸÑ⁄©ÿ≥\" ⁄©€í ÿ≥ÿßÿ™⁄æ ŸÖŸÑÿ™€í €Å€å⁄∫ÿü</td>\n",
       "      <td>⁄Ü⁄æŸàŸπ€í</td>\n",
       "      <td></td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                        Question  \\\n",
       "43                                                                           Close Encounters ŸÜ€í ⁄©ÿ™ŸÜ€í ÿ¢ÿ≥⁄©ÿ± ÿ¨€åÿ™€íÿü   \n",
       "160                                                                         €å€Å ÿßÿ≥ÿßÿ™ÿ∞€Å ⁄©€í ÿ™ÿßÿ¨ÿ± ÿß⁄©ÿ´ÿ± ⁄©€åÿß ⁄©ÿ±ÿ™€í ÿ™⁄æ€íÿü   \n",
       "161                                                           ÿ®ÿ±⁄© ⁄©€Åÿß⁄∫ ŸÅ⁄©ÿ± ŸÖŸÜÿØ ÿ™⁄æÿß ⁄©€Å ÿ®ÿ±ÿ∑ÿßŸÜ€å€Å ÿ¨ŸÜ⁄Ø ŸÜ€Å€å⁄∫ ÿ¨€åÿ™ ÿ≥⁄©ÿ™ÿßÿü   \n",
       "205                                                          1964 ŸÖ€å⁄∫ ÿß€åŸÜ ÿß€í ÿß€åŸÖ ⁄©ÿß ÿ±€ÅŸÜŸÖÿß ⁄©ŸàŸÜ ŸÜÿßŸÖÿ≤ÿØ ⁄©€åÿß ⁄Ø€åÿß ÿ™⁄æÿßÿü   \n",
       "287                                                                        ŸæŸÜ⁄©⁄æŸà⁄∫ ŸàÿßŸÑ€í ⁄©€å⁄ëŸà⁄∫ ⁄©Ÿà ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n",
       "386                                                                 ÿ®€åŸàŸÜÿ≥€å ŸÜ€í 2006 ŸÖ€å⁄∫ ⁄©ÿ≥ ⁄©Ÿà ÿÆÿ±ÿßÿ¨ ÿ™ÿ≠ÿ≥€åŸÜ Ÿæ€åÿ¥ ⁄©€åÿßÿü   \n",
       "465                                                ⁄©ŸàŸÜ ÿ≥ÿß ŸÖŸÑ⁄© Ÿæ€ÅŸÑÿß ŸÖŸÑ⁄© ÿ™⁄æÿß ÿ¨ÿ≥ Ÿæÿ± ÿßŸÖÿ±€å⁄©€Å ŸÜ€í ÿ¨ŸÜ⁄Ø ⁄©ÿß ÿßÿπŸÑÿßŸÜ ⁄©€åÿß ÿ™⁄æÿßÿü   \n",
       "547                                                                            Ÿπ€å ⁄à€å ⁄Øÿßÿ±⁄àŸÜ ⁄©ÿ™ŸÜ€å Ÿπ€åŸÖŸà⁄∫ ⁄©ÿß ⁄Ø⁄æÿ± €Å€íÿü   \n",
       "555                                               €Åÿßÿ¶€å⁄© ŸÜ€í ⁄©€Åÿß ÿ™⁄æÿß ⁄©€Å ŸÖÿπÿßÿ¥ÿ±€í ⁄©€í ŸÑ€å€í ÿ≠ŸÅÿßÿ∏ÿ™€å ÿ¨ÿßŸÑ ⁄©ŸàŸÜ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±€í ⁄Øÿßÿü   \n",
       "562                            ÿ±Ÿàÿ≥ ÿßŸàÿ± ÿ™ÿ±⁄©€å ⁄©€í ŸÖÿßÿ®€åŸÜ ÿ™ÿµŸÅ€å€Å ⁄©€í ÿ®ÿπÿØ ÿå ÿ¢ÿ≥Ÿπÿ±€åÿß ŸÜ€í ⁄©ÿ≥ ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ¥ÿßŸÖŸÑ €ÅŸàŸÜ€í ⁄©ÿß ŸÅ€åÿµŸÑ€Å ⁄©€åÿßÿü   \n",
       "575                                                       128 kbit / s Ÿæÿ± ⁄©ŸÖŸæÿ±€åÿ≥⁄à ÿß€å⁄© MP3 ⁄©ÿ™ŸÜ€í ⁄©ŸÑ ÿ®Ÿπ / ÿ≥ Ÿæ⁄ë€í ⁄Øÿßÿü   \n",
       "589                                   ÿ¨ÿ® ÿØŸàÿ≥ÿ™Ÿà⁄∫ ⁄©Ÿà ÿØŸàÿ≥ÿ±€í ŸÑŸà⁄ØŸà⁄∫ ÿ≥€í ÿ≤€åÿßÿØ€Å Ÿæÿ≥ŸÜÿØ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€í ÿ™Ÿà ÿßÿ≥€í ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n",
       "607                                                     ⁄©ŸàŸÜ ÿ≥ÿß ÿ≥€åŸÜÿ≥ÿ± ŸÖŸàÿ¥ŸÜ ÿ≥€åŸÜÿ≥ÿ± ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ±Ÿàÿ¥ŸÜ€å ⁄©Ÿà ⁄©ŸÜŸπÿ±ŸàŸÑ ⁄©ÿ±ÿ™ÿß €Å€íÿü   \n",
       "634                                               ŸÖ€å⁄© ⁄©€í ⁄©ÿ≥ ÿ≠ÿµ€í ŸÖ€å⁄∫ 1984 ŸÖ€å⁄∫ ÿ¢ÿ≥ÿßŸÜ€å ÿ≥€í ÿ™Ÿàÿ≥€åÿπ ŸÜ€Å€å⁄∫ ⁄©€å ÿ¨ÿß ÿ≥⁄©ÿ™€å ÿ™⁄æ€åÿü   \n",
       "643                                            ÿ±€å⁄à€åŸà ŸÑ€Åÿ±Ÿà⁄∫ ⁄©Ÿà Ÿæ€åÿØÿß ⁄©ÿ±ŸÜ€í ŸàÿßŸÑ€í ÿπŸÜÿßÿµÿ± ⁄©€í ÿ¨Ÿà⁄ëŸÜ€í ⁄©€í ŸÑÿ¶€í ⁄©€åÿß ÿ∂ÿ±Ÿàÿ±€å €Å€íÿü   \n",
       "763                                                               ⁄©ÿ≥ ⁄Øÿ±ŸàŸæ ⁄©€í ÿÆŸÑÿßŸÅ ÿ™ÿ¨ÿßÿ±ÿ™€å Ÿæÿßÿ®ŸÜÿØ€å ÿπÿßÿ¶ÿØ ⁄©€å ⁄Øÿ¶€å ÿ™⁄æ€åÿü   \n",
       "858                                                                           ŸàÿßŸÜ ŸÜ€åŸàŸÖŸÜ ŸÜ€í ⁄©ŸàŸÜ ÿ≥ÿß ÿ¥ÿπÿ®€Å ŸÇÿßÿ¶ŸÖ ⁄©€åÿßÿü   \n",
       "922                                                           ÿ¨Ÿà Ÿà⁄©ŸπŸàÿ±€åÿß ⁄©€å ÿ≥€å⁄ë⁄æ€åŸà⁄∫ ÿ≥€í ⁄Øÿ±ŸÜ€í ⁄©€í 10 ÿØŸÜ ÿ®ÿπÿØ ŸÖÿ± ⁄Ø€åÿßÿü   \n",
       "959                                                                              ŸÖ€å⁄Ø€å Ÿæ€ÅŸÑ€å ÿ®ÿßÿ± ⁄©ÿ® ÿ¥ÿßÿ¶ÿπ €ÅŸàÿ¶€å ÿ™⁄æ€åÿü   \n",
       "974                                                      ÿ¢ŸÜ€í ŸàÿßŸÑ€í ÿ≥ÿßŸÑŸà⁄∫ ŸÖ€å⁄∫ ÿ™ÿπŸÑ€åŸÖ ⁄©€å ⁄©ŸàŸÜ ÿ≥€å ÿ¥⁄©ŸÑ ÿ∫ÿßŸÑÿ® ŸÜÿ∏ÿ± ÿ¢ÿ™€å €Å€íÿü   \n",
       "1037          ⁄©ŸÑÿßÿ±⁄© ÿßŸàÿ± ⁄à€åŸÜ ⁄©€í ÿ®ÿß€Åÿ± ŸÜ⁄©ŸÑŸÜ€í ⁄©€í ÿ®ÿπÿØÿå ⁄©ŸàŸÜ ÿ≥ÿß ÿßŸÖ€åÿØŸàÿßÿ± ⁄©€åÿ±€å ⁄©€í ÿÆŸÑÿßŸÅ Ÿàÿßÿ≠ÿØ ÿ≠ŸÇ€åŸÇ€å ŸÖÿØŸÖŸÇÿßÿ®ŸÑ ÿ≥ŸÖÿ¨⁄æÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿü   \n",
       "1094                                        ÿßŸÖÿ±€å⁄©€Å ŸÖ€å⁄∫ ÿßŸÅÿ±ÿßÿØ ⁄©€å ÿ∑ÿ±ŸÅ ÿ≥€í ÿ¥ÿ±Ÿàÿπ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€í ⁄©€Å SAMs ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n",
       "1097                                                                   €Åÿßÿ±Ÿæÿ± ŸÑ€å ŸÜ€í ÿßŸæŸÜÿß ÿ®⁄ÜŸæŸÜ ⁄©ÿ≥ ÿ±€åÿßÿ≥ÿ™ ŸÖ€å⁄∫ ⁄Øÿ≤ÿßÿ±ÿßÿü   \n",
       "1100                                  ⁄©ŸÖ ÿßŸàÿ± ÿßÿπŸÑ€å ⁄Øÿ±€å⁄à ŸÖ€åŸπÿßŸÖŸàÿ±ŸÅ⁄© ⁄ÜŸπÿßŸÜŸà⁄∫ ÿ≥€í ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©€å ÿ™ÿ¥⁄©€åŸÑ ⁄©ÿß ÿßÿ¥ÿßÿ±€Å ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n",
       "1130                                                                                 ⁄à€å ⁄ØÿßŸÑ ⁄©€í Ÿæÿßÿ≥ ⁄©€åÿß ÿØÿ±ÿ¨€Å ÿ™⁄æÿßÿü   \n",
       "1284                                                                     ŸÖ€åŸÑÿ®Ÿàÿ±ŸÜ ⁄©Ÿæ ⁄©€å Ÿæ€ÅŸÑ€å ÿØŸà⁄ë ⁄©ÿ≥ ÿ≥ÿßŸÑ €ÅŸàÿ¶€å ÿ™⁄æ€åÿü   \n",
       "1315                                                                                ÿ¨Ÿà ⁄à€åŸà⁄à ÿ®ŸàŸà€å ÿ≥ŸÜ ⁄©ÿ± ŸæŸÑÿß ÿ®⁄ë⁄æÿßÿü   \n",
       "1323           ⁄à⁄Ü ÿßŸàÿ± ÿßŸÜ⁄Øÿ±€åÿ≤€å ⁄©€í ŸÖÿßÿ®€åŸÜ ŸÇÿ±ÿ∂€í ⁄©€í ÿßŸÑŸÅÿßÿ∏ ⁄©€í ÿßÿ¥ÿ™ÿ±ÿß⁄© ŸÖ€å⁄∫ ÿå ⁄©ÿ≥ ÿ≤ÿ®ÿßŸÜ ⁄©Ÿà ŸÇÿ±ÿ∂€í ⁄©€í ÿßŸÑŸÅÿßÿ∏ ⁄©ÿß ÿ≤€åÿßÿØ€Å ŸÅ€åÿµÿØ ŸÖŸÑÿßÿü   \n",
       "1399                                                                               ⁄©ŸàŸπ⁄© ⁄©ÿ≥ ⁄©ŸÖŸæŸÜ€å ⁄©ÿß ÿ≥€å ÿß€å ÿßŸà €Å€íÿü   \n",
       "1472                                                         ⁄©ŸàŸÜ ÿ≥Ÿà⁄Üÿ™ÿß ÿ™⁄æÿß ⁄©€Å ŸÅÿß⁄©ÿ≥ ÿßŸàÿ± ÿ®ÿ±⁄© ⁄©€å ÿØŸàÿ≥ÿ™€å ⁄©⁄æŸà ⁄Ø€åÿß ÿ™⁄æÿßÿü   \n",
       "1487                                                           ⁄©ÿ≥ ÿßŸÜÿØÿ±ŸàŸÜ€å ÿ¨ÿ≤Ÿà ŸÖ€å⁄∫ ⁄©ÿßŸÅ€å ÿ≠ÿØ ÿ™⁄© ŸÜÿ∏ÿ± ÿ´ÿßŸÜ€å ⁄©€å ⁄Øÿ¶€å €Å€íÿü   \n",
       "1498                                                                     ŸÜŸÖ€åÿ®€åÿß ŸÖ€å⁄∫ ⁄©ŸàŸÜ ÿ≥€å Ÿàÿ®ÿß ÿß€å⁄© ÿ®⁄ëÿß ŸÖÿ≥ÿ¶ŸÑ€Å €Å€íÿü   \n",
       "1538                                                                                ÿßÿ≥ ÿßÿ≥⁄©Ÿàÿ± ⁄©Ÿà ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n",
       "1740                                 ÿ¨Ÿà ŸÑÿßÿ¨ÿ≤ ÿ¨€å ÿß€åŸÑ ÿß€å ⁄©€å ÿ™ÿßÿ¶€åÿØ ŸÜ€Å€å⁄∫ ⁄©ÿ± ÿ≥⁄©ÿ™€í ÿ™⁄æ€í ÿßŸÜ€Å€å⁄∫ ÿ®ÿπÿØ ŸÖ€å⁄∫ ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿü   \n",
       "1783                                                                           ÿ¥ŸàŸæŸÜ ⁄©€í ŸàÿßŸÑÿØ ⁄©ÿß Ÿæ€ÅŸÑÿß ŸÜÿßŸÖ ⁄©€åÿß ÿ™⁄æÿßÿü   \n",
       "1806              ŸÖÿ¥ÿ±ŸÇ€å ÿßŸÜ⁄ØŸÑ€åŸÜ⁄à ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ≥ÿßÿ™⁄æ ÿå ÿßŸÜ⁄ØŸÑ€åŸÜ⁄à ⁄©€í ⁄©ÿ≥ ÿ≠ÿµ€í ŸÖ€å⁄∫ ÿßÿ≥⁄©€åŸÜ⁄à€åŸÜ€åŸà€åŸÜ ŸÜ⁄òÿßÿØ ÿ®€Åÿ™ ÿ≥€í ŸÖŸÇÿßŸÖÿßÿ™ ⁄©€í ŸÜÿßŸÖ €Å€å⁄∫ÿü   \n",
       "1818                                                          Ÿπ⁄æŸÜ⁄à€å ÿßÿ¥€åÿßÿ° ⁄©€åÿß €Å€å⁄∫ ⁄©€Å ÿßÿ¥€åÿßÿ° ⁄©€í ŸÖŸÇÿßÿ®ŸÑ€í ŸÖ€å⁄∫ ⁄©ŸÖ ⁄ÜŸÖ⁄©ÿü   \n",
       "1824                                                              ÿ¨ÿ≥ ⁄©€í ŸÖÿ∂ÿ®Ÿàÿ∑ ⁄à⁄æÿßŸÜ⁄Ü€í ÿ®ÿßŸæ €åÿß ÿ®€åŸπ€í ⁄©€å ÿ¥⁄©ŸÑ ŸÖ€å⁄∫ €Å€å⁄∫ÿü   \n",
       "1838                                                                                         ÿ¥ŸàŸæŸÜ ⁄©€Åÿß⁄∫ ŸæŸÑÿß ÿ®⁄ë⁄æÿßÿü   \n",
       "1934                                                            ŸÇŸàŸÖŸà⁄∫ ⁄©€í ÿ¥€Åÿ±€åŸà⁄∫ ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± ⁄©ÿ≥ ⁄©Ÿà ŸÖŸÇÿ±ÿ± ⁄©€åÿß ⁄Ø€åÿß €Å€íÿü   \n",
       "2049  ÿßÿ≥ ⁄©€å ŸÜÿß⁄©ÿßŸÖ€å ÿ≥€í Ÿæ€ÅŸÑ€íÿå ⁄©ŸàŸÜ ÿ≥ÿß ÿ®⁄Üÿ™ ÿßŸàÿ± ŸÇÿ±ÿ∂ ÿß€åÿ≥Ÿàÿ≥€å ÿß€åÿ¥ŸÜ ÿ±€åÿßÿ≥ÿ™€Åÿßÿ¶€í ŸÖÿ™ÿ≠ÿØ€Å ŸÖ€å⁄∫ ÿ≥ÿßÿ™Ÿà€å⁄∫ ÿ≥ÿ® ÿ≥€í ÿ®⁄ëÿß ÿ±€ÅŸÜ ÿßÿ®ÿ™ÿØÿßÿ¶€å ÿ™⁄æÿßÿü   \n",
       "2194                           ÿØ€å⁄Øÿ± ÿ®ÿ±ÿ∑ÿßŸÜŸà€å ÿ±€åÿßÿ≥ÿ™Ÿà⁄∫ ÿßŸàÿ± ⁄©ÿßŸÑŸàŸÜ€åŸà⁄∫ ŸÜ€í ÿ≥ÿßŸÑ ⁄©€å ÿ¥ÿ±Ÿàÿπÿßÿ™ ⁄©€å ÿ™ÿßÿ±€åÿÆ €å⁄©ŸÖ ÿ¨ŸÜŸàÿ±€å ⁄©ÿ® ŸÖŸÇÿ±ÿ± ⁄©€åÿü   \n",
       "2197                                                                             ⁄©€Åÿß⁄∫ Broz Belousova ÿ≥€í ÿ¥ÿßÿØ€å ⁄©€åÿü   \n",
       "2207                                      ÿ®⁄ÜŸà⁄∫ ⁄©€å ŸÖÿ≤ÿØŸàÿ±€å ⁄©€å ŸÅÿ±ÿß€ÅŸÖ€å ÿßŸàÿ± ÿßÿ≥ ⁄©€å ⁄©€åÿß Ÿàÿ¨Ÿà€Åÿßÿ™ €Å€å⁄∫ ÿ¨Ÿà ÿ¢ÿ¨ ÿ®⁄æ€å ŸÖŸàÿ¨ŸàÿØ €Å€å⁄∫ÿü   \n",
       "2215                                         ÿ∑ÿßŸÑÿ® ÿπŸÑŸÖŸà⁄∫ ⁄©Ÿà ⁄Ü€åŸÜ€å ÿ≠ÿ±ŸàŸÅ ÿ≥⁄©⁄æÿßŸÜ€í ⁄©€í ŸÑ€å€í ÿß⁄©ÿ´ÿ± ⁄©€åÿß ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n",
       "2274                                             €ÅŸÜÿØŸà ÿßÿ≥⁄©ŸàŸÑŸà⁄∫ ŸÖ€å⁄∫ ÿ≥€í ÿ≥ÿ® ÿ≥€í ÿ≤€åÿßÿØ€Å ÿ™ÿ±ŸÇ€å €åÿßŸÅÿ™€Å ÿßŸàÿ± ŸÖÿ¥€ÅŸàÿ± ⁄©ŸàŸÜ ÿ≥ÿß €Å€íÿü   \n",
       "2401                                                                    Ÿæÿ±ŸÜÿØŸà⁄∫ ⁄©€í ⁄©ÿ™ŸÜ€í ÿ®⁄ë€í ŸÅŸÑÿßÿ¶Ÿπ ŸæŸπ⁄æŸà⁄∫ €ÅŸàÿ™€í €Å€å⁄∫ÿü   \n",
       "2447                                ⁄©€åŸÜ€í ŸÜ€í ÿ≠ÿßÿØÿ´€í ⁄©€í ÿ®ÿπÿØ ÿ¨Ÿà ⁄©⁄Ü⁄æ €ÅŸàÿß ÿßÿ≥ ⁄©€í ÿ™ÿ¨ÿ±ÿ®€í ⁄©€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫ ⁄©€åÿß ⁄ØÿßŸÜÿß ÿ±€å⁄©ÿßÿ±⁄à ⁄©€åÿßÿü   \n",
       "2458                                                                     ÿß€åŸàÿßŸÜ ŸÖ€å⁄∫ ÿßŸÇŸÑ€åÿ™€å Ÿæÿßÿ±Ÿπ€å ⁄©ÿß ÿ±€ÅŸÜŸÖÿß ⁄©ŸàŸÜ €Å€íÿü   \n",
       "2473                                                  ⁄©€åÿß ŸÜŸàÿ¨ŸàÿßŸÜ ÿ®⁄ë€í €åÿß ⁄Ü⁄æŸàŸπ€í Ÿæ€åŸÖÿßŸÜ€í Ÿæÿ± \"⁄©ŸÑ⁄©ÿ≥\" ⁄©€í ÿ≥ÿßÿ™⁄æ ŸÖŸÑÿ™€í €Å€å⁄∫ÿü   \n",
       "\n",
       "              Gold Answer Extracted Answer  Split  \n",
       "43                     ÿØŸà                   train  \n",
       "160      ŸÖ€åŸÜ⁄àŸàŸÑ€åŸÜ ÿ¢ÿ±⁄©ÿ≥Ÿπÿ±ÿß                   train  \n",
       "161                ÿßŸÖÿ±€å⁄©€Å                   train  \n",
       "205                  ŸÜÿßÿµÿ±                   train  \n",
       "287              ŸæŸπ€åÿ±⁄ØŸàŸπÿß                   train  \n",
       "386          ŸÖÿßÿ¶€å⁄©ŸÑ ÿ¨€å⁄©ÿ≥ŸÜ                   train  \n",
       "465               ÿ®ÿ±ÿ∑ÿßŸÜ€å€Å                   train  \n",
       "547                    ÿØŸà                   train  \n",
       "555                 ÿ±€åÿßÿ≥ÿ™                   train  \n",
       "562                  ÿ™ÿ±⁄©€å                   train  \n",
       "575               128,000                   train  \n",
       "589                ⁄©ÿ±ŸàŸÜÿ≤ŸÖ                   train  \n",
       "607            ŸÇÿ®ÿ∂€Å ÿ≥€åŸÜÿ≥ÿ±                   train  \n",
       "634                ŸÖ€åŸÖŸàÿ±€å                   train  \n",
       "643               ÿß€åŸÜŸπ€åŸÜÿß                   train  \n",
       "763               ÿ¥€åŸàŸÜ⁄ØŸÜŸà                   train  \n",
       "858        ŸÖÿ≥ŸÑÿ≥ŸÑ ÿ¨€åŸàŸÖ€åŸπÿ±€å                   train  \n",
       "922                 ÿ®ÿ±ÿßÿ§ŸÜ                   train  \n",
       "959                  1893                   train  \n",
       "974         ÿßŸàŸæŸÜ ÿß€åÿ¨Ÿà⁄©€åÿ¥ŸÜ                   train  \n",
       "1037              ÿß€å⁄àŸàÿ±⁄àÿ≤                   train  \n",
       "1094             ŸÖ€åŸÜ Ÿæ€å⁄àÿ≥                   train  \n",
       "1097              ÿßŸÑÿßÿ®ÿßŸÖÿß                   train  \n",
       "1100           ⁄Øÿ±€åŸÜ ÿßÿ≥ŸπŸàŸÜ                   train  \n",
       "1130                 ÿ¨ŸÜÿ±ŸÑ                   train  \n",
       "1284                 1861                   train  \n",
       "1315               ŸÖ€å⁄àŸàŸÜÿß                   train  \n",
       "1323                   ⁄à⁄Ü                   train  \n",
       "1399    ÿß€å⁄©Ÿπ€åŸà€åÿ¥ŸÜ ÿ®ŸÑ€åÿ≤ÿßÿ±⁄à                   train  \n",
       "1472                  ÿ®ÿ±⁄©                   train  \n",
       "1487            ÿØÿ±ÿ¨€Å ÿ®ŸÜÿØ€å                   train  \n",
       "1498                 ÿß€å⁄àÿ≤                   train  \n",
       "1538             ⁄à€å ÿßÿ≥⁄©Ÿàÿ±                   train  \n",
       "1740                 ÿ¨ÿØ€åÿØ                   train  \n",
       "1783                ŸÜ⁄©ŸàŸÑÿ≥                   train  \n",
       "1806                ÿ¥ŸÖÿßŸÑ€å                   train  \n",
       "1818                  ⁄Øÿ±ŸÖ                   train  \n",
       "1824                ÿ®€åŸπŸà⁄∫                   train  \n",
       "1838                Ÿàÿßÿ±ÿ≥ÿß                   train  \n",
       "1934          ÿßÿπÿ≤ÿßÿ≤€å ŸÜÿßÿ¶Ÿπ                   train  \n",
       "2049        ÿßŸÜ⁄à€å ŸÖ€å⁄© ÿ®€åŸÜ⁄©                   train  \n",
       "2194                 1752                   train  \n",
       "2197                ÿßŸàŸÖÿ≥⁄©                   train  \n",
       "2207                  ÿ∑ŸÑÿ®                   train  \n",
       "2215  ÿ®ÿßŸÇÿßÿπÿØ€Å ÿßÿ≥⁄©ÿ±ŸæŸπ ŸÅŸàŸÜŸπ                   train  \n",
       "2274              Ÿà€åÿØÿßŸÜÿ™ÿß                   train  \n",
       "2401                   ÿØŸà                   train  \n",
       "2447         ÿ™⁄æÿ±Ÿà ÿØ€å Ÿàÿßÿ¶ÿ±                   train  \n",
       "2458                ÿßŸÇŸÑ€åÿ™                   train  \n",
       "2473                ⁄Ü⁄æŸàŸπ€í                   train  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Side-by-Side Comparison (First 10 Rows - Mixed):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Gold Answer</th>\n",
       "      <th>Extracted Answer</th>\n",
       "      <th>Match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>⁄©ÿ≥ ÿ≥ÿßŸÑ ŸÖ€å⁄∫ ⁄à€åŸπŸàŸÜ ⁄©€í ÿÆÿ¥⁄© ÿ≥ÿßŸÖÿßŸÜ ÿ®ŸÜÿØ ⁄©ÿ± ÿØ€åÿß ⁄Ø€åÿß ÿ™⁄æÿßÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>⁄ØŸàÿ±ÿ®ÿß⁄ÜŸàŸÅ ŸÜ€í ⁄©€åÿß ÿ™ÿÆŸÑ€åŸÇ ⁄©ÿ±ŸÜ€í ⁄©€å ÿßŸÖ€åÿØ ⁄©€å ÿ™⁄æ€åÿü</td>\n",
       "      <td>ŸÜ€åÿß ÿ≥Ÿæÿ±€åŸÖ ŸÇÿßŸÜŸàŸÜ ÿ≥ÿßÿ≤ ÿßÿØÿßÿ±€Å</td>\n",
       "      <td>ŸÜ€åÿß ÿ≥Ÿæÿ±€åŸÖ ŸÇÿßŸÜŸàŸÜ ÿ≥ÿßÿ≤ ÿßÿØÿßÿ±€Å</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006 ŸÖ€å⁄∫ ⁄©ŸàŸÜÿ≥ŸÑ ÿ¢ŸÜ ŸÅÿßÿ±ŸÜ ÿ±€åŸÑ€åÿ¥ŸÜÿ≤ ŸÖ€å⁄∫ ŸàÿßŸÜ ŸÜ€åŸàŸÖŸÜ ŸÜ€í ⁄©€åÿß ÿß€åÿ¨ŸÜ⁄àÿß Ÿæ€åÿ¥ ⁄©€åÿß ÿ™⁄æÿßÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>€åÿ≥Ÿàÿπ ⁄©€í ÿ®ÿßŸÑÿ∫ €ÅŸàŸÜ€í ⁄©€å ŸÅŸÜ⁄©ÿßÿ±ÿßŸÜ€Å ÿ™ÿµŸà€åÿ± ⁄©ÿ¥€åŸà⁄∫ ⁄©Ÿà ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UF6 ⁄©ŸàŸÜ ÿ≥ÿß ŸÖÿ±⁄©ÿ® €Å€íÿü</td>\n",
       "      <td>€åŸàÿ±€åŸÜ€åŸÖ €Å€å⁄©ÿ≥ÿßŸÅŸÑŸàŸàÿ±ÿßÿ¶⁄à</td>\n",
       "      <td>€åŸàÿ±€åŸÜ€åŸÖ €Å€å⁄©ÿ≥ÿßŸÅŸÑŸàŸàÿ±ÿßÿ¶⁄à</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>⁄àÿ≥ŸæŸÑ€í ÿ±€åÿ≤ŸàŸÑŸàÿ¥ŸÜ ŸÖÿßÿ±⁄©€åŸπ ŸÖ€å⁄∫ ÿ≤€åÿßÿØ€Å ÿ™ÿ± ÿ≥ŸæŸÑÿßÿ¶ÿ±ÿ≤ ŸÜ€í 2010 ⁄©€å ÿØ€Åÿßÿ¶€å ŸÖ€å⁄∫ ⁄©€åÿß Ÿæ€åÿ¥ ⁄©€åÿßÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Algernon ÿ≥⁄àŸÜ€å ⁄©€åÿß ⁄©€í ŸÑÿ¶€í ÿß€å⁄© ÿÆÿ∑ÿ±€Å ÿ≥ŸÖÿ¨⁄æÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>⁄©Ÿàÿ≤ÿßŸÜ ⁄©ÿ≥ ⁄Ü€åÿ≤ ÿ≥€í ÿ®ŸÜ€í ÿ™⁄æ€íÿü</td>\n",
       "      <td>ŸÑŸà€Å€í €åÿß ⁄ÜŸÖ⁄ë€í</td>\n",
       "      <td>ŸÑŸà€Å€í €åÿß ⁄ÜŸÖ⁄ë€í</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cynanthus latirostris ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©ÿß Ÿæÿ±ŸÜÿØ€Å €Å€íÿü</td>\n",
       "      <td>€ÅŸàŸÖŸÜ⁄Ø ÿ®ÿ±⁄à</td>\n",
       "      <td>€ÅŸàŸÖŸÜ⁄Ø ÿ®ÿ±⁄à</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ÿßÿ≥ ⁄©€å ŸÖŸàÿ™ ⁄©€í ÿ®ÿπÿØ Ÿà€åŸàÿ± ⁄©€í ŸÑÿ¶€í ⁄©ŸàŸÜ ŸÑ€í ŸÑ€åÿßÿü</td>\n",
       "      <td>ÿßŸÑÿ®ÿ±Ÿπ ⁄©€åÿ≥ŸÑŸÜ⁄Ø ÿßŸàÿ± €ÅŸÜÿ≥ ÿ¨Ÿàÿ±⁄ØŸÜ ÿßÿ≥ŸπŸÖŸæŸÅ</td>\n",
       "      <td>ÿßŸÑÿ®ÿ±Ÿπ ⁄©€åÿ≥ŸÑŸÜ⁄Ø ÿßŸàÿ± €ÅŸÜÿ≥ ÿ¨Ÿàÿ±⁄ØŸÜ ÿßÿ≥ŸπŸÖŸæŸÅ</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ÿ®ŸÑŸÇÿßŸÜ ⁄©€å ÿ¨ŸÜ⁄Ø€å⁄∫ ⁄©€Åÿß⁄∫ €ÅŸàÿ¶€å⁄∫ÿü</td>\n",
       "      <td>ÿ¨ŸÜŸàÿ® ŸÖÿ¥ÿ±ŸÇ€å €åŸàÿ±Ÿæ</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ÿ¨ÿ® ÿ¢ÿ±ÿßŸÖ ŸÖ€å⁄∫ÿå ÿß€å⁄© ÿ∑ŸàŸÑ Ÿà ÿπÿ±ÿ∂ ⁄©€å ÿ±ŸÅÿ™ÿßÿ± ⁄©ÿ™ŸÜ€å ÿ™€åÿ≤ €Å€íÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>⁄©ÿ±ŸàŸÖŸàÿ≥ŸàŸÖŸà⁄∫ ⁄©€å ⁄©ŸÑ ⁄ØŸÜÿ™€å ⁄©€í ŸÑÿ¶€í ÿß€å⁄© ÿßŸàÿ± ŸÑŸÅÿ∏ ⁄©€åÿß €Å€íÿü</td>\n",
       "      <td>⁄©€åÿ±ŸàŸπÿßÿ¶Ÿæ</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>813 ŸÖ€å⁄∫ ⁄Üÿßÿ±ŸÑŸÖ€åŸÜ ⁄©ÿß Ÿàÿßÿ≠ÿØ ÿ≤ŸÜÿØ€Å ÿ®€åŸπÿß ⁄©ŸàŸÜ ÿ™⁄æÿßÿü</td>\n",
       "      <td>ŸÑŸàÿ¶€å ÿØ€å Ÿæ€åŸàÿ≥</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ÿ®ÿ±Ÿπ €Å€åŸÖ ⁄©ÿß ŸÖÿßÿ±⁄©€åŸπ ŸÜÿßŸÖ ⁄©€åÿß €Å€íÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>⁄©ÿ≥ ÿ≥ÿßŸÑ ŸÖ€å⁄∫ ÿß€åŸÜ ÿ¢ÿ±ÿ®ÿ± Ÿæÿ®ŸÑ⁄© ÿßÿ≥⁄©ŸàŸÑŸà⁄∫ ŸÖ€å⁄∫ 16ÿå935 ÿ∑ŸÑÿ®ÿßÿ° ÿ±ÿ¨ÿ≥Ÿπÿ±⁄à ÿ™⁄æ€íÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ÿ≥ÿ≥ÿ™€å €ÅŸàŸÜ€í ⁄©€í ÿπŸÑÿßŸà€Å ÿå Ÿæÿ±Ÿàÿ≥€åÿ≥⁄à ŸÅŸà⁄àÿ≤ ⁄©€å ÿß€å⁄© ÿßŸàÿ± ÿß€ÅŸÖ ⁄©ÿ¥ÿ¥ ⁄©€åÿß €Å€íÿü</td>\n",
       "      <td>ÿ≤€åÿßÿØ€Å ÿ¢ÿ≥ÿßŸÜ</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>⁄©ÿ≥ ÿ≥ÿßŸÑ ŸÖ€å⁄∫ ŸÅÿ±€å⁄à€å ÿßŸàÿ± ÿÆŸàÿßÿ® ÿØ€å⁄©⁄æŸÜ€í ŸàÿßŸÑŸà⁄∫ ⁄©Ÿà ÿßŸÜ ⁄©€å Ÿæ€ÅŸÑ€å €ÅŸπ ŸÖŸÑ ⁄Øÿ¶€åÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ŸÜÿ¶€í ÿ≥€å Ÿæ€å €åŸà ŸÅŸÜ ÿ™ÿπŸÖ€åÿ± ŸÖ€å⁄∫ ⁄©ÿßŸÖ€åÿßÿ®€å ⁄©€í ÿ≥ÿßÿ™⁄æ ŸÖŸÜÿ™ŸÇŸÑ€å ⁄©€í ŸÑÿ¶€í Ÿàÿßÿ≠ÿØ ŸÖÿ±⁄©ÿ≤€å ÿØ⁄æÿßÿ±€í ⁄©€í ⁄©ŸÖŸæ€åŸàŸπÿ± ŸæŸÑ€åŸπ ŸÅÿßÿ±ŸÖ ⁄©€åÿß €Å€íÿü</td>\n",
       "      <td>ŸÖ€å⁄©ŸÜŸπŸàÿ¥</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ÿ≥€åÿß€Å ŸÅÿßŸÖ ÿßŸàÿ± ÿß€åÿ¥€åÿßÿ¶€å ÿßÿ≥⁄©ŸàŸÑ ⁄©€í ÿ®⁄ÜŸà⁄∫ ⁄©ÿß ÿ≥ŸÅ€åÿØ ŸÅÿßŸÖ ÿßÿ≥⁄©ŸàŸÑ ⁄©€í ÿ®⁄ÜŸà⁄∫ ⁄©€í ŸÖŸÇÿßÿ®ŸÑ€í ŸÖ€å⁄∫ ⁄©€åÿß ÿ™ŸÜÿßÿ≥ÿ® €Å€íÿü</td>\n",
       "      <td>ÿ™ŸÇÿ±€åÿ®ÿß ⁄Ü⁄æ ÿ≥€í ⁄Üÿßÿ±</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ÿπÿ∑€åÿßÿ™ Ÿæÿ± ÿßŸÜÿ≠ÿµÿßÿ± ⁄©ÿ±ŸÜ€í ŸàÿßŸÑ€å ÿ¨ŸÖÿßÿπÿ™Ÿà⁄∫ ⁄©Ÿà ⁄©ÿ® ŸÖÿ≥ÿßÿ¶ŸÑ ⁄©ÿß ÿ≥ÿßŸÖŸÜÿß ⁄©ÿ±ŸÜÿß Ÿæ⁄ëÿßÿü</td>\n",
       "      <td>ÿ®€åÿ≥Ÿà€å⁄∫ ÿµÿØ€å ⁄©€í ÿØŸàÿ≥ÿ±€í ŸÜÿµŸÅ ÿ≥€í</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ÿ≥ÿ≥ŸÑ€å ÿ≥€í ŸæÿßŸÑÿ±ŸÖŸà ÿ™⁄© Ÿæ€ÅŸÜ⁄ÜŸÜÿß ⁄©€åŸà⁄∫ ŸÖÿ¥⁄©ŸÑ €Å€íÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>⁄©ŸàŸÜ ÿ≥ÿß€åŸÜŸπŸàŸÑŸàÿ¨€å ŸÖ€å⁄∫ ÿßÿµŸÑÿßÿ≠ÿßÿ™ ŸÑÿß€åÿß ÿ¨ÿ≥ ÿ≥€í ÿπŸÑ€åÿ≠ÿØ€Å ⁄Øÿ±Ÿà€ÅŸà⁄∫ ⁄©Ÿà ÿ®ÿØÿπÿ™ ŸÇÿ±ÿßÿ± ÿØ€åÿß ⁄Ø€åÿßÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ŸÖÿßÿ§ ⁄©Ÿà ÿ¨ŸÜŸàÿ®€å ⁄©Ÿàÿ±€åÿß ⁄©€í ÿ≠ŸÖŸÑ€í ⁄©€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫ ⁄©€åÿß ÿ™ÿ¥Ÿà€åÿ¥ ÿ™⁄æ€åÿü</td>\n",
       "      <td>ÿßŸÖÿ±€å⁄©€å ŸÖÿØÿßÿÆŸÑÿ™ ⁄©ÿ±€å⁄∫ ⁄Ø€í</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ÿ±ÿßÿ¶ŸÑ ÿßŸÜÿ≥Ÿπ€å Ÿπ€åŸàŸπ ⁄©€í ⁄©ÿßÿ±Ÿàÿ®ÿßÿ±€å ÿ¢Ÿæÿ±€åÿ¥ŸÜ ⁄©ÿß ŸÜÿßŸÖ ⁄©€åÿß €Å€íÿü</td>\n",
       "      <td>RIBA ÿßŸÜŸπÿ±Ÿæÿ±ÿßÿ¶ÿ≤ÿ≤</td>\n",
       "      <td>RIBA ÿßŸÜŸπÿ±Ÿæÿ±ÿßÿ¶ÿ≤ÿ≤</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ÿ¢ÿÆÿ±€å ŸæŸàŸæ ŸÜ€í ⁄©ÿ≥ ÿ™ÿßÿ±€åÿÆ ⁄©Ÿà ÿß€åÿ®€å ŸÖ€å⁄∫ ŸÇÿØŸÖ ÿ±⁄©⁄æÿß ÿ™⁄æÿßÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>⁄©ŸÑŸàÿ±ŸàŸÅŸÑ ⁄©ÿ≥ ⁄Ü€åÿ≤ ⁄©Ÿà ÿ™Ÿà⁄ëŸÜ€í ŸÖ€å⁄∫ ÿß€ÅŸÖ ⁄©ÿ±ÿØÿßÿ± ÿßÿØÿß ⁄©ÿ±ÿ™ÿß €Å€íÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>⁄©ÿ≥ ŸÅ€åÿµŸÑ€í ŸÜ€í ŸÇÿ∞ÿßŸÅ€å ⁄©Ÿà ŸÑ€åÿ®€åÿß ⁄©Ÿà ÿ≥Ÿàÿ¥ŸÑÿ≤ŸÖ ⁄©€í ŸÇÿ±€åÿ® ŸÑ€í ÿ¨ÿßŸÜ€í ⁄©€å ÿßÿ¨ÿßÿ≤ÿ™ ÿØ€åÿü</td>\n",
       "      <td>ÿ≥ÿ™ŸÖÿ®ÿ± 1973 ŸÖ€å⁄∫ ÿå €å€Å ÿßÿπŸÑÿßŸÜ ⁄©€åÿß ⁄Ø€åÿß ⁄©€Å ŸÑ€åÿ®€åÿß ŸÖ€å⁄∫ ÿ≥ÿ±⁄Øÿ±ŸÖ ÿ™ŸÖÿßŸÖ ÿ∫€åÿ± ŸÖŸÑ⁄©€å ÿ™€åŸÑ Ÿæÿ±Ÿà⁄à€åŸàÿ≥ÿ±Ÿà⁄∫ ⁄©Ÿà ŸÇŸàŸÖ€å ÿ®ŸÜÿß€åÿß ÿ¨ÿßÿ¶€í ⁄Øÿß€î</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ÿ≠ÿ±€åŸÅ ŸÅÿßÿ¶ŸÜŸÑ ŸÖ€å⁄∫ ÿßÿ®ÿ™ÿØÿßÿ¶€å ÿ∑Ÿàÿ± Ÿæÿ± ⁄©ÿ™ŸÜ€í ⁄ØÿßŸÜ€í ⁄Øÿßÿ™€í €Å€å⁄∫ÿü</td>\n",
       "      <td>ÿß€å⁄©</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ÿ¨ÿ∞ÿ®ÿßÿ™€å ŸÖÿ≤ÿßÿ¨ ⁄©ÿ≥ ÿØŸàÿ≥ÿ±€å ÿÆÿµŸàÿµ€åÿ™ ÿ≥€í ŸÖÿ¥ÿßÿ®€Åÿ™ ŸÜ€Å€å⁄∫ ÿ±⁄©⁄æÿ™ÿßÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ÿ®ÿ±ŸÖŸàÿØÿß ŸÖ€å⁄∫ ÿ≥€åÿß€Å ŸÅÿßŸÖ ŸÑŸà⁄ØŸà⁄∫ ⁄©€å ÿß⁄©ÿ´ÿ±€åÿ™ ⁄©ÿß ÿ≠ŸàÿßŸÑ€Å ÿØ€åŸÜ€í ⁄©€í ŸÑÿ¶€í ⁄©ÿ≥ ÿßÿµÿ∑ŸÑÿßÿ≠ ⁄©ÿß ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n",
       "      <td>ÿ®ÿ±ŸÖŸà⁄à€åŸÜ ÿ≥€åÿß€Å ŸÅÿßŸÖ</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ŸπŸà⁄à€í ⁄àÿßŸπ ⁄©ÿßŸÖ Ÿæÿ± ÿå ŸÖ€åŸπ ÿ≤ŸàŸÑÿ± ÿ≥€åŸπÿ≤ ŸÜ€í ŸÅŸÑŸÖ ⁄©Ÿà ⁄©ÿ™ŸÜ€í ÿ≥ÿ™ÿßÿ±€í ÿØ€åÿ¶€íÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ÿ≥ŸÑÿ∑ŸÜÿ™ ÿπÿ´ŸÖÿßŸÜ€å€Å ⁄©€í ÿØŸàÿ±ÿßŸÜÿå ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©€í ÿßÿ≥⁄©ŸàŸÑ ÿ∫€åÿ± ŸÖÿπŸÖŸàŸÑ€å ÿ™⁄æ€íÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2008 ⁄©€í Ÿàÿ≥ÿ∑ ŸÖ€å⁄∫ ÿ±€åÿßÿ≥ÿ™€Åÿßÿ¶€í ŸÖÿ™ÿ≠ÿØ€Å ŸÖ€å⁄∫ ⁄Ø⁄æÿ± ⁄©€å ÿß€å⁄©Ÿà€åŸπ€å ⁄©€å ŸÇ€åŸÖÿ™ ⁄©ÿ™ŸÜ€å ÿ™⁄æ€åÿü</td>\n",
       "      <td>8.8 Ÿπÿ±€åŸÑ€åŸÜ ⁄àÿßŸÑÿ±</td>\n",
       "      <td>8.8 Ÿπÿ±€åŸÑ€åŸÜ ⁄àÿßŸÑÿ±</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ŸÜÿßÿ±ŸÖŸÜ ŸÜ€í ÿßŸæŸÜ€í ⁄©ÿßŸÖ ⁄©Ÿà ⁄©ÿ≥ ŸÖ€å⁄Øÿ≤€åŸÜ ŸÖ€å⁄∫ ÿ¥ÿßÿ¶ÿπ ⁄©€åÿßÿü</td>\n",
       "      <td>ÿ≥⁄©ÿ±€åÿ®ŸÜÿ±ÿ≤ ŸÖ€å⁄Øÿ≤€åŸÜ</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ÿ¥ŸàŸæŸÜ ŸÜ€í ⁄©ŸàŸÜ ÿ≥ÿß ÿ™ÿµŸàÿ± ÿ™ÿÆŸÑ€åŸÇ ⁄©€åÿßÿü</td>\n",
       "      <td>ÿßŸÜÿ≥Ÿπÿ±ŸàŸÖŸÜŸπŸÑ ÿ®€åŸÑ⁄à</td>\n",
       "      <td>ÿßŸÜÿ≥Ÿπÿ±ŸàŸÖŸÜŸπŸÑ ÿ®€åŸÑ⁄à</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ÿ™⁄©ŸÜ€å⁄©€å ÿ™ÿ®ÿØ€åŸÑ€å ⁄©€í ŸÜÿ™€åÿ¨€í ŸÖ€å⁄∫ ⁄©€åÿß ÿ≤€åÿßÿØ€Å ŸÖ€ÅŸÜ⁄Øÿß €ÅŸà ÿ±€Åÿß €Å€íÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ŸÖ€å⁄àŸàŸÜÿß ŸÜ€í ÿßŸæŸÜ€å ÿØŸàÿ≥ÿ±€å ⁄©Ÿæ⁄ë€í ⁄©€å ŸÑÿßÿ¶ŸÜ ⁄©ÿ® ÿ¨ÿßÿ±€å ⁄©€åÿü</td>\n",
       "      <td>ŸÜŸàŸÖÿ®ÿ± 2011</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>De Re Aedificatoria ⁄©ÿ≥ ŸÜ€í ŸÑ⁄©⁄æÿßÿü</td>\n",
       "      <td>ŸÑ€åŸàŸÜ ÿ®Ÿπ€åÿ≥Ÿπÿß ÿßŸÑÿ®ÿ±Ÿπ€å</td>\n",
       "      <td>ŸÑ€åŸàŸÜ ÿ®Ÿπ€åÿ≥Ÿπÿß ÿßŸÑÿ®ÿ±Ÿπ€å</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ÿµÿßÿ±ŸÅ€åŸÜ ⁄©Ÿà ÿßŸæŸÜ€å ŸÖŸàÿ≥€åŸÇ€å ⁄©Ÿà ÿßŸÜ⁄©Ÿà⁄à ⁄©ÿ±ÿ™€í ŸàŸÇÿ™ ⁄©€åÿß ŸÇÿØÿ± ÿ¨ÿßŸÜŸÜ€í ⁄©€å ÿ∂ÿ±Ÿàÿ±ÿ™ €Å€í ÿ™ÿß⁄©€Å ÿßŸÜ€Å€å⁄∫ €Åÿ± ŸÖŸàÿ≥€åŸÇ€å ⁄©€í Ÿπ⁄©⁄ë€í Ÿæÿ± Ÿπ€åÿ≥Ÿπ ⁄©ÿ±ŸÜ€í ÿ≥€í ÿ®⁄ÜŸÜ€í ŸÖ€å⁄∫ ŸÖÿØÿØ ŸÖŸÑ€íÿü</td>\n",
       "      <td>ŸÖÿπ€åÿßÿ± ⁄©€å ÿ™ÿ±ÿ™€åÿ®</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ÿßŸÖÿßÿ≥€åÿß ⁄©€å ÿßŸÖŸÜ ⁄©ÿ® ÿ™⁄æ€åÿü</td>\n",
       "      <td>16 Ÿà€å⁄∫ ÿµÿØ€å ⁄©€í Ÿàÿ≥ÿ∑</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Ÿà€å⁄à€åŸà ŸÑÿß ÿß€åÿ≥Ÿπÿß ÿ®ŸàŸÜŸπÿß ⁄©€í ŸÑÿ¶€í ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©€í €Åÿ≥ŸæÿßŸÜŸà€å ⁄©Ÿæ⁄ë€í Ÿæ€ÅŸÜ€í ⁄Øÿ¶€í ÿ™⁄æ€íÿü</td>\n",
       "      <td>ÿ®ŸàŸÑ€åÿ±Ÿàÿ≥ ÿßŸàÿ± Ÿæÿ±ÿ™Ÿà⁄∫ ŸàÿßŸÑ€å ÿ≥⁄©ÿ±Ÿπ</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>19 Ÿà€å⁄∫ ÿµÿØ€å ⁄©€í ÿ¢ÿÆÿ± ŸÖ€å⁄∫ ⁄©ÿ≥ ÿ¨ÿßÿ¶€åÿØÿßÿØ ⁄©€í ÿ™ÿßÿ¨ÿ± ŸÜ€í ÿ¨ÿßÿ¶€åÿØÿßÿØ ⁄©Ÿà Ÿàÿ±ÿßÿ´ÿ™ ŸÖ€å⁄∫ ÿ≠ÿßÿµŸÑ ⁄©€åÿßÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Close Encounters ŸÜ€í ⁄©ÿ™ŸÜ€í ÿ¢ÿ≥⁄©ÿ± ÿ¨€åÿ™€íÿü</td>\n",
       "      <td>ÿØŸà</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2005 ÿ™⁄© ŸÅÿßÿ±ŸÖŸàŸÑÿß ŸÅŸàÿ±⁄à ⁄Ü€åŸÖŸæÿ¶ŸÜ ÿ¥Ÿæ ŸÖ€å⁄∫ ⁄©ÿ≥ ŸÜ€í ÿØŸà⁄ë ŸÑ⁄Øÿßÿ¶€åÿü</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>\"Ÿæ€åŸÜÿ≥€åŸÑ Ÿπ€åÿ≥Ÿπ\" ⁄©ÿ≥ ŸÜ€í ⁄©€åÿßÿü</td>\n",
       "      <td>ŸÖÿπŸÖŸàŸÑ€å ÿπ€ÅÿØ€åÿØÿßÿ±Ÿà⁄∫</td>\n",
       "      <td>ŸÖÿπŸÖŸàŸÑ€å ÿπ€ÅÿØ€åÿØÿßÿ±Ÿà⁄∫</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ŸÖÿßŸÅŸàŸÇ ÿßŸÑŸÅÿ∑ÿ±ÿ™ ŸÖŸàÿ¨ŸàÿØÿßÿ™ ⁄©€åÿ≥€í ⁄©ÿßŸÖ ⁄©ÿ±ÿ™€í €Å€å⁄∫ÿü</td>\n",
       "      <td>ŸÑŸà⁄ØŸà⁄∫ ⁄©€å ÿ∑ÿ±ÿ≠</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>⁄©ŸÑŸÜŸπŸÜ ⁄©€å ŸÖÿØÿ™ ⁄©€í ÿØŸàÿ±ÿßŸÜ ⁄©ŸàŸÜ ÿ≥ÿß ÿÆŸàŸÅŸÜÿß⁄© ŸàÿßŸÇÿπ€Å ÿ¨ÿßÿ±€å ÿ™⁄æÿß ÿ¨ÿ≥ ŸÜ€í ŸÑŸà⁄ØŸà⁄∫ ⁄©Ÿà Ÿæÿ±€åÿ¥ÿßŸÜ ⁄©ÿ±ÿØ€åÿßÿü</td>\n",
       "      <td>ÿ±ŸàÿßŸÜ⁄àÿß ŸÜÿ≥ŸÑ ⁄©ÿ¥€å</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>⁄©ŸàŸÜ ÿ≥ÿß ŸÅŸÜ⁄©ÿßÿ± ÿ®€åŸàŸÜÿ≥€í ⁄©€å Ÿæÿ±€åŸÖ€åÿ¶ÿ± ÿ≥ŸàŸÑŸà ÿ±€å⁄©ÿßÿ±⁄àŸÜ⁄Ø ⁄©€í ÿ≥ÿßÿ™⁄æ ŸÖŸÜÿ≥ŸÑ⁄© ⁄©€åÿß ⁄Ø€åÿß ÿ™⁄æÿßÿü</td>\n",
       "      <td>ÿ¨€í ÿ≤€å</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>⁄©ÿßÿ±ÿ®ŸàŸÜ€åŸÅ€åÿ±ÿ≥ ⁄©€í ÿπŸÑÿßŸà€Å ÿå ⁄©ŸàŸÜ ÿ≥ÿß ÿØŸàÿ≥ÿ±ÿß ⁄©€å⁄ë€í ⁄©ÿß ÿ¢ÿ±⁄àÿ± ŸÖŸàÿ¨ŸàÿØ€Å ⁄Øÿ±Ÿà€ÅŸà⁄∫ ÿå ÿßÿ≥Ÿπ€åŸÖ ⁄Øÿ±Ÿà€ÅŸà⁄∫ ÿßŸàÿ± Ÿæ€åŸÑ€åŸàÿ≤Ÿà⁄© ⁄Øÿ±Ÿà€ÅŸà⁄∫ ⁄©Ÿà ÿ¥ÿßŸÖŸÑ ⁄©ÿ±ÿ™ÿß €Å€íÿü</td>\n",
       "      <td>ÿßÿ®ÿ™ÿØÿßÿ¶€å Ÿæÿ±ŸÖ€åŸÜ</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                            Question  \\\n",
       "0                                                                                  ⁄©ÿ≥ ÿ≥ÿßŸÑ ŸÖ€å⁄∫ ⁄à€åŸπŸàŸÜ ⁄©€í ÿÆÿ¥⁄© ÿ≥ÿßŸÖÿßŸÜ ÿ®ŸÜÿØ ⁄©ÿ± ÿØ€åÿß ⁄Ø€åÿß ÿ™⁄æÿßÿü   \n",
       "1                                                                                         ⁄ØŸàÿ±ÿ®ÿß⁄ÜŸàŸÅ ŸÜ€í ⁄©€åÿß ÿ™ÿÆŸÑ€åŸÇ ⁄©ÿ±ŸÜ€í ⁄©€å ÿßŸÖ€åÿØ ⁄©€å ÿ™⁄æ€åÿü   \n",
       "2                                                            2006 ŸÖ€å⁄∫ ⁄©ŸàŸÜÿ≥ŸÑ ÿ¢ŸÜ ŸÅÿßÿ±ŸÜ ÿ±€åŸÑ€åÿ¥ŸÜÿ≤ ŸÖ€å⁄∫ ŸàÿßŸÜ ŸÜ€åŸàŸÖŸÜ ŸÜ€í ⁄©€åÿß ÿß€åÿ¨ŸÜ⁄àÿß Ÿæ€åÿ¥ ⁄©€åÿß ÿ™⁄æÿßÿü   \n",
       "3                                                                      €åÿ≥Ÿàÿπ ⁄©€í ÿ®ÿßŸÑÿ∫ €ÅŸàŸÜ€í ⁄©€å ŸÅŸÜ⁄©ÿßÿ±ÿßŸÜ€Å ÿ™ÿµŸà€åÿ± ⁄©ÿ¥€åŸà⁄∫ ⁄©Ÿà ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n",
       "4                                                                                                                UF6 ⁄©ŸàŸÜ ÿ≥ÿß ŸÖÿ±⁄©ÿ® €Å€íÿü   \n",
       "5                                                       ⁄àÿ≥ŸæŸÑ€í ÿ±€åÿ≤ŸàŸÑŸàÿ¥ŸÜ ŸÖÿßÿ±⁄©€åŸπ ŸÖ€å⁄∫ ÿ≤€åÿßÿØ€Å ÿ™ÿ± ÿ≥ŸæŸÑÿßÿ¶ÿ±ÿ≤ ŸÜ€í 2010 ⁄©€å ÿØ€Åÿßÿ¶€å ŸÖ€å⁄∫ ⁄©€åÿß Ÿæ€åÿ¥ ⁄©€åÿßÿü   \n",
       "6                                                                                  Algernon ÿ≥⁄àŸÜ€å ⁄©€åÿß ⁄©€í ŸÑÿ¶€í ÿß€å⁄© ÿÆÿ∑ÿ±€Å ÿ≥ŸÖÿ¨⁄æÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿü   \n",
       "7                                                                                                           ⁄©Ÿàÿ≤ÿßŸÜ ⁄©ÿ≥ ⁄Ü€åÿ≤ ÿ≥€í ÿ®ŸÜ€í ÿ™⁄æ€íÿü   \n",
       "8                                                                                          Cynanthus latirostris ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©ÿß Ÿæÿ±ŸÜÿØ€Å €Å€íÿü   \n",
       "9                                                                                           ÿßÿ≥ ⁄©€å ŸÖŸàÿ™ ⁄©€í ÿ®ÿπÿØ Ÿà€åŸàÿ± ⁄©€í ŸÑÿ¶€í ⁄©ŸàŸÜ ŸÑ€í ŸÑ€åÿßÿü   \n",
       "10                                                                                                        ÿ®ŸÑŸÇÿßŸÜ ⁄©€å ÿ¨ŸÜ⁄Ø€å⁄∫ ⁄©€Åÿß⁄∫ €ÅŸàÿ¶€å⁄∫ÿü   \n",
       "11                                                                                  ÿ¨ÿ® ÿ¢ÿ±ÿßŸÖ ŸÖ€å⁄∫ÿå ÿß€å⁄© ÿ∑ŸàŸÑ Ÿà ÿπÿ±ÿ∂ ⁄©€å ÿ±ŸÅÿ™ÿßÿ± ⁄©ÿ™ŸÜ€å ÿ™€åÿ≤ €Å€íÿü   \n",
       "12                                                                                  ⁄©ÿ±ŸàŸÖŸàÿ≥ŸàŸÖŸà⁄∫ ⁄©€å ⁄©ŸÑ ⁄ØŸÜÿ™€å ⁄©€í ŸÑÿ¶€í ÿß€å⁄© ÿßŸàÿ± ŸÑŸÅÿ∏ ⁄©€åÿß €Å€íÿü   \n",
       "13                                                                                        813 ŸÖ€å⁄∫ ⁄Üÿßÿ±ŸÑŸÖ€åŸÜ ⁄©ÿß Ÿàÿßÿ≠ÿØ ÿ≤ŸÜÿØ€Å ÿ®€åŸπÿß ⁄©ŸàŸÜ ÿ™⁄æÿßÿü   \n",
       "14                                                                                                     ÿ®ÿ±Ÿπ €Å€åŸÖ ⁄©ÿß ŸÖÿßÿ±⁄©€åŸπ ŸÜÿßŸÖ ⁄©€åÿß €Å€íÿü   \n",
       "15                                                                     ⁄©ÿ≥ ÿ≥ÿßŸÑ ŸÖ€å⁄∫ ÿß€åŸÜ ÿ¢ÿ±ÿ®ÿ± Ÿæÿ®ŸÑ⁄© ÿßÿ≥⁄©ŸàŸÑŸà⁄∫ ŸÖ€å⁄∫ 16ÿå935 ÿ∑ŸÑÿ®ÿßÿ° ÿ±ÿ¨ÿ≥Ÿπÿ±⁄à ÿ™⁄æ€íÿü   \n",
       "16                                                                      ÿ≥ÿ≥ÿ™€å €ÅŸàŸÜ€í ⁄©€í ÿπŸÑÿßŸà€Å ÿå Ÿæÿ±Ÿàÿ≥€åÿ≥⁄à ŸÅŸà⁄àÿ≤ ⁄©€å ÿß€å⁄© ÿßŸàÿ± ÿß€ÅŸÖ ⁄©ÿ¥ÿ¥ ⁄©€åÿß €Å€íÿü   \n",
       "17                                                                   ⁄©ÿ≥ ÿ≥ÿßŸÑ ŸÖ€å⁄∫ ŸÅÿ±€å⁄à€å ÿßŸàÿ± ÿÆŸàÿßÿ® ÿØ€å⁄©⁄æŸÜ€í ŸàÿßŸÑŸà⁄∫ ⁄©Ÿà ÿßŸÜ ⁄©€å Ÿæ€ÅŸÑ€å €ÅŸπ ŸÖŸÑ ⁄Øÿ¶€åÿü   \n",
       "18                             ŸÜÿ¶€í ÿ≥€å Ÿæ€å €åŸà ŸÅŸÜ ÿ™ÿπŸÖ€åÿ± ŸÖ€å⁄∫ ⁄©ÿßŸÖ€åÿßÿ®€å ⁄©€í ÿ≥ÿßÿ™⁄æ ŸÖŸÜÿ™ŸÇŸÑ€å ⁄©€í ŸÑÿ¶€í Ÿàÿßÿ≠ÿØ ŸÖÿ±⁄©ÿ≤€å ÿØ⁄æÿßÿ±€í ⁄©€í ⁄©ŸÖŸæ€åŸàŸπÿ± ŸæŸÑ€åŸπ ŸÅÿßÿ±ŸÖ ⁄©€åÿß €Å€íÿü   \n",
       "19                                          ÿ≥€åÿß€Å ŸÅÿßŸÖ ÿßŸàÿ± ÿß€åÿ¥€åÿßÿ¶€å ÿßÿ≥⁄©ŸàŸÑ ⁄©€í ÿ®⁄ÜŸà⁄∫ ⁄©ÿß ÿ≥ŸÅ€åÿØ ŸÅÿßŸÖ ÿßÿ≥⁄©ŸàŸÑ ⁄©€í ÿ®⁄ÜŸà⁄∫ ⁄©€í ŸÖŸÇÿßÿ®ŸÑ€í ŸÖ€å⁄∫ ⁄©€åÿß ÿ™ŸÜÿßÿ≥ÿ® €Å€íÿü   \n",
       "20                                                                  ÿπÿ∑€åÿßÿ™ Ÿæÿ± ÿßŸÜÿ≠ÿµÿßÿ± ⁄©ÿ±ŸÜ€í ŸàÿßŸÑ€å ÿ¨ŸÖÿßÿπÿ™Ÿà⁄∫ ⁄©Ÿà ⁄©ÿ® ŸÖÿ≥ÿßÿ¶ŸÑ ⁄©ÿß ÿ≥ÿßŸÖŸÜÿß ⁄©ÿ±ŸÜÿß Ÿæ⁄ëÿßÿü   \n",
       "21                                                                                            ÿ≥ÿ≥ŸÑ€å ÿ≥€í ŸæÿßŸÑÿ±ŸÖŸà ÿ™⁄© Ÿæ€ÅŸÜ⁄ÜŸÜÿß ⁄©€åŸà⁄∫ ŸÖÿ¥⁄©ŸÑ €Å€íÿü   \n",
       "22                                                         ⁄©ŸàŸÜ ÿ≥ÿß€åŸÜŸπŸàŸÑŸàÿ¨€å ŸÖ€å⁄∫ ÿßÿµŸÑÿßÿ≠ÿßÿ™ ŸÑÿß€åÿß ÿ¨ÿ≥ ÿ≥€í ÿπŸÑ€åÿ≠ÿØ€Å ⁄Øÿ±Ÿà€ÅŸà⁄∫ ⁄©Ÿà ÿ®ÿØÿπÿ™ ŸÇÿ±ÿßÿ± ÿØ€åÿß ⁄Ø€åÿßÿü   \n",
       "23                                                                             ŸÖÿßÿ§ ⁄©Ÿà ÿ¨ŸÜŸàÿ®€å ⁄©Ÿàÿ±€åÿß ⁄©€í ÿ≠ŸÖŸÑ€í ⁄©€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫ ⁄©€åÿß ÿ™ÿ¥Ÿà€åÿ¥ ÿ™⁄æ€åÿü   \n",
       "24                                                                                 ÿ±ÿßÿ¶ŸÑ ÿßŸÜÿ≥Ÿπ€å Ÿπ€åŸàŸπ ⁄©€í ⁄©ÿßÿ±Ÿàÿ®ÿßÿ±€å ÿ¢Ÿæÿ±€åÿ¥ŸÜ ⁄©ÿß ŸÜÿßŸÖ ⁄©€åÿß €Å€íÿü   \n",
       "25                                                                                    ÿ¢ÿÆÿ±€å ŸæŸàŸæ ŸÜ€í ⁄©ÿ≥ ÿ™ÿßÿ±€åÿÆ ⁄©Ÿà ÿß€åÿ®€å ŸÖ€å⁄∫ ŸÇÿØŸÖ ÿ±⁄©⁄æÿß ÿ™⁄æÿßÿü   \n",
       "26                                                                                ⁄©ŸÑŸàÿ±ŸàŸÅŸÑ ⁄©ÿ≥ ⁄Ü€åÿ≤ ⁄©Ÿà ÿ™Ÿà⁄ëŸÜ€í ŸÖ€å⁄∫ ÿß€ÅŸÖ ⁄©ÿ±ÿØÿßÿ± ÿßÿØÿß ⁄©ÿ±ÿ™ÿß €Å€íÿü   \n",
       "27                                                                 ⁄©ÿ≥ ŸÅ€åÿµŸÑ€í ŸÜ€í ŸÇÿ∞ÿßŸÅ€å ⁄©Ÿà ŸÑ€åÿ®€åÿß ⁄©Ÿà ÿ≥Ÿàÿ¥ŸÑÿ≤ŸÖ ⁄©€í ŸÇÿ±€åÿ® ŸÑ€í ÿ¨ÿßŸÜ€í ⁄©€å ÿßÿ¨ÿßÿ≤ÿ™ ÿØ€åÿü   \n",
       "28                                                                                 ÿ≠ÿ±€åŸÅ ŸÅÿßÿ¶ŸÜŸÑ ŸÖ€å⁄∫ ÿßÿ®ÿ™ÿØÿßÿ¶€å ÿ∑Ÿàÿ± Ÿæÿ± ⁄©ÿ™ŸÜ€í ⁄ØÿßŸÜ€í ⁄Øÿßÿ™€í €Å€å⁄∫ÿü   \n",
       "29                                                                                 ÿ¨ÿ∞ÿ®ÿßÿ™€å ŸÖÿ≤ÿßÿ¨ ⁄©ÿ≥ ÿØŸàÿ≥ÿ±€å ÿÆÿµŸàÿµ€åÿ™ ÿ≥€í ŸÖÿ¥ÿßÿ®€Åÿ™ ŸÜ€Å€å⁄∫ ÿ±⁄©⁄æÿ™ÿßÿü   \n",
       "30                                        ÿ®ÿ±ŸÖŸàÿØÿß ŸÖ€å⁄∫ ÿ≥€åÿß€Å ŸÅÿßŸÖ ŸÑŸà⁄ØŸà⁄∫ ⁄©€å ÿß⁄©ÿ´ÿ±€åÿ™ ⁄©ÿß ÿ≠ŸàÿßŸÑ€Å ÿØ€åŸÜ€í ⁄©€í ŸÑÿ¶€í ⁄©ÿ≥ ÿßÿµÿ∑ŸÑÿßÿ≠ ⁄©ÿß ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n",
       "31                                                                        ŸπŸà⁄à€í ⁄àÿßŸπ ⁄©ÿßŸÖ Ÿæÿ± ÿå ŸÖ€åŸπ ÿ≤ŸàŸÑÿ± ÿ≥€åŸπÿ≤ ŸÜ€í ŸÅŸÑŸÖ ⁄©Ÿà ⁄©ÿ™ŸÜ€í ÿ≥ÿ™ÿßÿ±€í ÿØ€åÿ¶€íÿü   \n",
       "32                                                                           ÿ≥ŸÑÿ∑ŸÜÿ™ ÿπÿ´ŸÖÿßŸÜ€å€Å ⁄©€í ÿØŸàÿ±ÿßŸÜÿå ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©€í ÿßÿ≥⁄©ŸàŸÑ ÿ∫€åÿ± ŸÖÿπŸÖŸàŸÑ€å ÿ™⁄æ€íÿü   \n",
       "33                                                              2008 ⁄©€í Ÿàÿ≥ÿ∑ ŸÖ€å⁄∫ ÿ±€åÿßÿ≥ÿ™€Åÿßÿ¶€í ŸÖÿ™ÿ≠ÿØ€Å ŸÖ€å⁄∫ ⁄Ø⁄æÿ± ⁄©€å ÿß€å⁄©Ÿà€åŸπ€å ⁄©€å ŸÇ€åŸÖÿ™ ⁄©ÿ™ŸÜ€å ÿ™⁄æ€åÿü   \n",
       "34                                                                                      ŸÜÿßÿ±ŸÖŸÜ ŸÜ€í ÿßŸæŸÜ€í ⁄©ÿßŸÖ ⁄©Ÿà ⁄©ÿ≥ ŸÖ€å⁄Øÿ≤€åŸÜ ŸÖ€å⁄∫ ÿ¥ÿßÿ¶ÿπ ⁄©€åÿßÿü   \n",
       "35                                                                                                    ÿ¥ŸàŸæŸÜ ŸÜ€í ⁄©ŸàŸÜ ÿ≥ÿß ÿ™ÿµŸàÿ± ÿ™ÿÆŸÑ€åŸÇ ⁄©€åÿßÿü   \n",
       "36                                                                             ÿ™⁄©ŸÜ€å⁄©€å ÿ™ÿ®ÿØ€åŸÑ€å ⁄©€í ŸÜÿ™€åÿ¨€í ŸÖ€å⁄∫ ⁄©€åÿß ÿ≤€åÿßÿØ€Å ŸÖ€ÅŸÜ⁄Øÿß €ÅŸà ÿ±€Åÿß €Å€íÿü   \n",
       "37                                                                                     ŸÖ€å⁄àŸàŸÜÿß ŸÜ€í ÿßŸæŸÜ€å ÿØŸàÿ≥ÿ±€å ⁄©Ÿæ⁄ë€í ⁄©€å ŸÑÿßÿ¶ŸÜ ⁄©ÿ® ÿ¨ÿßÿ±€å ⁄©€åÿü   \n",
       "38                                                                                                   De Re Aedificatoria ⁄©ÿ≥ ŸÜ€í ŸÑ⁄©⁄æÿßÿü   \n",
       "39  ÿµÿßÿ±ŸÅ€åŸÜ ⁄©Ÿà ÿßŸæŸÜ€å ŸÖŸàÿ≥€åŸÇ€å ⁄©Ÿà ÿßŸÜ⁄©Ÿà⁄à ⁄©ÿ±ÿ™€í ŸàŸÇÿ™ ⁄©€åÿß ŸÇÿØÿ± ÿ¨ÿßŸÜŸÜ€í ⁄©€å ÿ∂ÿ±Ÿàÿ±ÿ™ €Å€í ÿ™ÿß⁄©€Å ÿßŸÜ€Å€å⁄∫ €Åÿ± ŸÖŸàÿ≥€åŸÇ€å ⁄©€í Ÿπ⁄©⁄ë€í Ÿæÿ± Ÿπ€åÿ≥Ÿπ ⁄©ÿ±ŸÜ€í ÿ≥€í ÿ®⁄ÜŸÜ€í ŸÖ€å⁄∫ ŸÖÿØÿØ ŸÖŸÑ€íÿü   \n",
       "40                                                                                                             ÿßŸÖÿßÿ≥€åÿß ⁄©€å ÿßŸÖŸÜ ⁄©ÿ® ÿ™⁄æ€åÿü   \n",
       "41                                                                  Ÿà€å⁄à€åŸà ŸÑÿß ÿß€åÿ≥Ÿπÿß ÿ®ŸàŸÜŸπÿß ⁄©€í ŸÑÿ¶€í ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©€í €Åÿ≥ŸæÿßŸÜŸà€å ⁄©Ÿæ⁄ë€í Ÿæ€ÅŸÜ€í ⁄Øÿ¶€í ÿ™⁄æ€íÿü   \n",
       "42                                                        19 Ÿà€å⁄∫ ÿµÿØ€å ⁄©€í ÿ¢ÿÆÿ± ŸÖ€å⁄∫ ⁄©ÿ≥ ÿ¨ÿßÿ¶€åÿØÿßÿØ ⁄©€í ÿ™ÿßÿ¨ÿ± ŸÜ€í ÿ¨ÿßÿ¶€åÿØÿßÿØ ⁄©Ÿà Ÿàÿ±ÿßÿ´ÿ™ ŸÖ€å⁄∫ ÿ≠ÿßÿµŸÑ ⁄©€åÿßÿü   \n",
       "43                                                                                               Close Encounters ŸÜ€í ⁄©ÿ™ŸÜ€í ÿ¢ÿ≥⁄©ÿ± ÿ¨€åÿ™€íÿü   \n",
       "44                                                                               2005 ÿ™⁄© ŸÅÿßÿ±ŸÖŸàŸÑÿß ŸÅŸàÿ±⁄à ⁄Ü€åŸÖŸæÿ¶ŸÜ ÿ¥Ÿæ ŸÖ€å⁄∫ ⁄©ÿ≥ ŸÜ€í ÿØŸà⁄ë ŸÑ⁄Øÿßÿ¶€åÿü   \n",
       "45                                                                                                          \"Ÿæ€åŸÜÿ≥€åŸÑ Ÿπ€åÿ≥Ÿπ\" ⁄©ÿ≥ ŸÜ€í ⁄©€åÿßÿü   \n",
       "46                                                                                           ŸÖÿßŸÅŸàŸÇ ÿßŸÑŸÅÿ∑ÿ±ÿ™ ŸÖŸàÿ¨ŸàÿØÿßÿ™ ⁄©€åÿ≥€í ⁄©ÿßŸÖ ⁄©ÿ±ÿ™€í €Å€å⁄∫ÿü   \n",
       "47                                                   ⁄©ŸÑŸÜŸπŸÜ ⁄©€å ŸÖÿØÿ™ ⁄©€í ÿØŸàÿ±ÿßŸÜ ⁄©ŸàŸÜ ÿ≥ÿß ÿÆŸàŸÅŸÜÿß⁄© ŸàÿßŸÇÿπ€Å ÿ¨ÿßÿ±€å ÿ™⁄æÿß ÿ¨ÿ≥ ŸÜ€í ŸÑŸà⁄ØŸà⁄∫ ⁄©Ÿà Ÿæÿ±€åÿ¥ÿßŸÜ ⁄©ÿ±ÿØ€åÿßÿü   \n",
       "48                                                           ⁄©ŸàŸÜ ÿ≥ÿß ŸÅŸÜ⁄©ÿßÿ± ÿ®€åŸàŸÜÿ≥€í ⁄©€å Ÿæÿ±€åŸÖ€åÿ¶ÿ± ÿ≥ŸàŸÑŸà ÿ±€å⁄©ÿßÿ±⁄àŸÜ⁄Ø ⁄©€í ÿ≥ÿßÿ™⁄æ ŸÖŸÜÿ≥ŸÑ⁄© ⁄©€åÿß ⁄Ø€åÿß ÿ™⁄æÿßÿü   \n",
       "49                ⁄©ÿßÿ±ÿ®ŸàŸÜ€åŸÅ€åÿ±ÿ≥ ⁄©€í ÿπŸÑÿßŸà€Å ÿå ⁄©ŸàŸÜ ÿ≥ÿß ÿØŸàÿ≥ÿ±ÿß ⁄©€å⁄ë€í ⁄©ÿß ÿ¢ÿ±⁄àÿ± ŸÖŸàÿ¨ŸàÿØ€Å ⁄Øÿ±Ÿà€ÅŸà⁄∫ ÿå ÿßÿ≥Ÿπ€åŸÖ ⁄Øÿ±Ÿà€ÅŸà⁄∫ ÿßŸàÿ± Ÿæ€åŸÑ€åŸàÿ≤Ÿà⁄© ⁄Øÿ±Ÿà€ÅŸà⁄∫ ⁄©Ÿà ÿ¥ÿßŸÖŸÑ ⁄©ÿ±ÿ™ÿß €Å€íÿü   \n",
       "\n",
       "                                                                                                 Gold Answer  \\\n",
       "0                                                                                                              \n",
       "1                                                                                  ŸÜ€åÿß ÿ≥Ÿæÿ±€åŸÖ ŸÇÿßŸÜŸàŸÜ ÿ≥ÿßÿ≤ ÿßÿØÿßÿ±€Å   \n",
       "2                                                                                                              \n",
       "3                                                                                                              \n",
       "4                                                                                      €åŸàÿ±€åŸÜ€åŸÖ €Å€å⁄©ÿ≥ÿßŸÅŸÑŸàŸàÿ±ÿßÿ¶⁄à   \n",
       "5                                                                                                              \n",
       "6                                                                                                              \n",
       "7                                                                                               ŸÑŸà€Å€í €åÿß ⁄ÜŸÖ⁄ë€í   \n",
       "8                                                                                                  €ÅŸàŸÖŸÜ⁄Ø ÿ®ÿ±⁄à   \n",
       "9                                                                          ÿßŸÑÿ®ÿ±Ÿπ ⁄©€åÿ≥ŸÑŸÜ⁄Ø ÿßŸàÿ± €ÅŸÜÿ≥ ÿ¨Ÿàÿ±⁄ØŸÜ ÿßÿ≥ŸπŸÖŸæŸÅ   \n",
       "10                                                                                           ÿ¨ŸÜŸàÿ® ŸÖÿ¥ÿ±ŸÇ€å €åŸàÿ±Ÿæ   \n",
       "11                                                                                                             \n",
       "12                                                                                                  ⁄©€åÿ±ŸàŸπÿßÿ¶Ÿæ   \n",
       "13                                                                                              ŸÑŸàÿ¶€å ÿØ€å Ÿæ€åŸàÿ≥   \n",
       "14                                                                                                             \n",
       "15                                                                                                             \n",
       "16                                                                                                ÿ≤€åÿßÿØ€Å ÿ¢ÿ≥ÿßŸÜ   \n",
       "17                                                                                                             \n",
       "18                                                                                                   ŸÖ€å⁄©ŸÜŸπŸàÿ¥   \n",
       "19                                                                                          ÿ™ŸÇÿ±€åÿ®ÿß ⁄Ü⁄æ ÿ≥€í ⁄Üÿßÿ±   \n",
       "20                                                                                ÿ®€åÿ≥Ÿà€å⁄∫ ÿµÿØ€å ⁄©€í ÿØŸàÿ≥ÿ±€í ŸÜÿµŸÅ ÿ≥€í   \n",
       "21                                                                                                             \n",
       "22                                                                                                             \n",
       "23                                                                                     ÿßŸÖÿ±€å⁄©€å ŸÖÿØÿßÿÆŸÑÿ™ ⁄©ÿ±€å⁄∫ ⁄Ø€í   \n",
       "24                                                                                           RIBA ÿßŸÜŸπÿ±Ÿæÿ±ÿßÿ¶ÿ≤ÿ≤   \n",
       "25                                                                                                             \n",
       "26                                                                                                             \n",
       "27  ÿ≥ÿ™ŸÖÿ®ÿ± 1973 ŸÖ€å⁄∫ ÿå €å€Å ÿßÿπŸÑÿßŸÜ ⁄©€åÿß ⁄Ø€åÿß ⁄©€Å ŸÑ€åÿ®€åÿß ŸÖ€å⁄∫ ÿ≥ÿ±⁄Øÿ±ŸÖ ÿ™ŸÖÿßŸÖ ÿ∫€åÿ± ŸÖŸÑ⁄©€å ÿ™€åŸÑ Ÿæÿ±Ÿà⁄à€åŸàÿ≥ÿ±Ÿà⁄∫ ⁄©Ÿà ŸÇŸàŸÖ€å ÿ®ŸÜÿß€åÿß ÿ¨ÿßÿ¶€í ⁄Øÿß€î   \n",
       "28                                                                                                       ÿß€å⁄©   \n",
       "29                                                                                                             \n",
       "30                                                                                          ÿ®ÿ±ŸÖŸà⁄à€åŸÜ ÿ≥€åÿß€Å ŸÅÿßŸÖ   \n",
       "31                                                                                                             \n",
       "32                                                                                                             \n",
       "33                                                                                           8.8 Ÿπÿ±€åŸÑ€åŸÜ ⁄àÿßŸÑÿ±   \n",
       "34                                                                                           ÿ≥⁄©ÿ±€åÿ®ŸÜÿ±ÿ≤ ŸÖ€å⁄Øÿ≤€åŸÜ   \n",
       "35                                                                                           ÿßŸÜÿ≥Ÿπÿ±ŸàŸÖŸÜŸπŸÑ ÿ®€åŸÑ⁄à   \n",
       "36                                                                                                             \n",
       "37                                                                                                ŸÜŸàŸÖÿ®ÿ± 2011   \n",
       "38                                                                                        ŸÑ€åŸàŸÜ ÿ®Ÿπ€åÿ≥Ÿπÿß ÿßŸÑÿ®ÿ±Ÿπ€å   \n",
       "39                                                                                            ŸÖÿπ€åÿßÿ± ⁄©€å ÿ™ÿ±ÿ™€åÿ®   \n",
       "40                                                                                         16 Ÿà€å⁄∫ ÿµÿØ€å ⁄©€í Ÿàÿ≥ÿ∑   \n",
       "41                                                                               ÿ®ŸàŸÑ€åÿ±Ÿàÿ≥ ÿßŸàÿ± Ÿæÿ±ÿ™Ÿà⁄∫ ŸàÿßŸÑ€å ÿ≥⁄©ÿ±Ÿπ   \n",
       "42                                                                                                             \n",
       "43                                                                                                        ÿØŸà   \n",
       "44                                                                                                             \n",
       "45                                                                                          ŸÖÿπŸÖŸàŸÑ€å ÿπ€ÅÿØ€åÿØÿßÿ±Ÿà⁄∫   \n",
       "46                                                                                              ŸÑŸà⁄ØŸà⁄∫ ⁄©€å ÿ∑ÿ±ÿ≠   \n",
       "47                                                                                            ÿ±ŸàÿßŸÜ⁄àÿß ŸÜÿ≥ŸÑ ⁄©ÿ¥€å   \n",
       "48                                                                                                     ÿ¨€í ÿ≤€å   \n",
       "49                                                                                             ÿßÿ®ÿ™ÿØÿßÿ¶€å Ÿæÿ±ŸÖ€åŸÜ   \n",
       "\n",
       "                     Extracted Answer  Match  \n",
       "0                                       True  \n",
       "1           ŸÜ€åÿß ÿ≥Ÿæÿ±€åŸÖ ŸÇÿßŸÜŸàŸÜ ÿ≥ÿßÿ≤ ÿßÿØÿßÿ±€Å   True  \n",
       "2                                       True  \n",
       "3                                       True  \n",
       "4               €åŸàÿ±€åŸÜ€åŸÖ €Å€å⁄©ÿ≥ÿßŸÅŸÑŸàŸàÿ±ÿßÿ¶⁄à   True  \n",
       "5                                       True  \n",
       "6                                       True  \n",
       "7                        ŸÑŸà€Å€í €åÿß ⁄ÜŸÖ⁄ë€í   True  \n",
       "8                           €ÅŸàŸÖŸÜ⁄Ø ÿ®ÿ±⁄à   True  \n",
       "9   ÿßŸÑÿ®ÿ±Ÿπ ⁄©€åÿ≥ŸÑŸÜ⁄Ø ÿßŸàÿ± €ÅŸÜÿ≥ ÿ¨Ÿàÿ±⁄ØŸÜ ÿßÿ≥ŸπŸÖŸæŸÅ   True  \n",
       "10                                     False  \n",
       "11                                      True  \n",
       "12                                     False  \n",
       "13                                     False  \n",
       "14                                      True  \n",
       "15                                      True  \n",
       "16                                     False  \n",
       "17                                      True  \n",
       "18                                     False  \n",
       "19                                     False  \n",
       "20                                     False  \n",
       "21                                      True  \n",
       "22                                      True  \n",
       "23                                     False  \n",
       "24                    RIBA ÿßŸÜŸπÿ±Ÿæÿ±ÿßÿ¶ÿ≤ÿ≤   True  \n",
       "25                                      True  \n",
       "26                                      True  \n",
       "27                                     False  \n",
       "28                                     False  \n",
       "29                                      True  \n",
       "30                                     False  \n",
       "31                                      True  \n",
       "32                                      True  \n",
       "33                    8.8 Ÿπÿ±€åŸÑ€åŸÜ ⁄àÿßŸÑÿ±   True  \n",
       "34                                     False  \n",
       "35                    ÿßŸÜÿ≥Ÿπÿ±ŸàŸÖŸÜŸπŸÑ ÿ®€åŸÑ⁄à   True  \n",
       "36                                      True  \n",
       "37                                     False  \n",
       "38                 ŸÑ€åŸàŸÜ ÿ®Ÿπ€åÿ≥Ÿπÿß ÿßŸÑÿ®ÿ±Ÿπ€å   True  \n",
       "39                                     False  \n",
       "40                                     False  \n",
       "41                                     False  \n",
       "42                                      True  \n",
       "43                                     False  \n",
       "44                                      True  \n",
       "45                   ŸÖÿπŸÖŸàŸÑ€å ÿπ€ÅÿØ€åÿØÿßÿ±Ÿà⁄∫   True  \n",
       "46                                     False  \n",
       "47                                     False  \n",
       "48                                     False  \n",
       "49                                     False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Diagnostic cell (fixed): Investigate preprocessing and truncation for many samples\n",
    "import random\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Set display options to see full Urdu text\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"google/canine-s\")\n",
    "except Exception:\n",
    "    tokenizer = None\n",
    "\n",
    "num_samples = 20000  # Number of samples to check\n",
    "results = []\n",
    "\n",
    "for split_name, orig_data, proc_data in [\n",
    "    (\"train\", uqa_train, processed_train),\n",
    "    (\"val\", uqa_val, processed_val)\n",
    "]:\n",
    "    # Sample random indices\n",
    "    if len(proc_data) < num_samples:\n",
    "        current_indices = range(len(proc_data))\n",
    "    else:\n",
    "        current_indices = random.sample(range(len(proc_data)), num_samples)\n",
    "\n",
    "    for idx in current_indices:\n",
    "        proc = proc_data[idx]\n",
    "        # Use overflow_to_sample_mapping to get the correct original index\n",
    "        orig_idx = proc[\"overflow_to_sample_mapping\"]\n",
    "        orig = orig_data[orig_idx]\n",
    "\n",
    "        input_ids = proc[\"input_ids\"]\n",
    "        start_pos = proc[\"start_positions\"]\n",
    "        end_pos = proc[\"end_positions\"]\n",
    "\n",
    "        gold_answer = orig.get(\"gold_answer\", orig.get(\"answer\", \"\"))\n",
    "        question = orig.get(\"question\", \"\")\n",
    "\n",
    "        # Decode input_ids to text (for debugging context)\n",
    "        if tokenizer:\n",
    "            decoded_text = tokenizer.decode(input_ids, skip_special_tokens=False)\n",
    "        else:\n",
    "            decoded_text = str(input_ids)\n",
    "\n",
    "        # Extract predicted answer span\n",
    "        if 0 <= start_pos < len(input_ids) and 0 <= end_pos < len(input_ids):\n",
    "            if tokenizer:\n",
    "                pred_span = tokenizer.decode(input_ids[start_pos:end_pos+1], skip_special_tokens=True)\n",
    "            else:\n",
    "                pred_span = str(input_ids[start_pos:end_pos+1])\n",
    "        else:\n",
    "            pred_span = \"[CLS]\" # Represents no answer found in this chunk or invalid\n",
    "\n",
    "        # Check if pred_span matches gold answer\n",
    "        # We strip() to ignore minor whitespace differences\n",
    "        pred_matches_gold = pred_span.strip() == gold_answer.strip()\n",
    "\n",
    "        # Check if gold is even reachable in this chunk\n",
    "        gold_in_decoded = gold_answer in decoded_text\n",
    "\n",
    "        results.append({\n",
    "            \"Split\": split_name,\n",
    "            \"Question\": question,\n",
    "            \"Gold Answer\": gold_answer,\n",
    "            \"Extracted Answer\": pred_span,\n",
    "            \"Match\": pred_matches_gold,\n",
    "            \"Gold Reachable\": gold_in_decoded,\n",
    "            \"orig_idx\": orig_idx\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# --- SIDE BY SIDE COMPARISON ---\n",
    "\n",
    "# 1. Filter for Solvable Mismatches (Gold was there, but we predicted wrong)\n",
    "problem_cases = results_df[\n",
    "    (results_df[\"Gold Reachable\"] == True) &\n",
    "    (results_df[\"Match\"] == False)\n",
    "][[\"Question\", \"Gold Answer\", \"Extracted Answer\", \"Split\"]]\n",
    "\n",
    "print(f\"üîç Checked {len(results_df)} samples.\")\n",
    "print(f\"‚ùå Found {len(problem_cases)} cases where Gold was present but Extraction failed.\")\n",
    "\n",
    "print(\"\\nüìä Side-by-Side Comparison (Top 20 Failures):\")\n",
    "display(problem_cases.head(50))\n",
    "\n",
    "print(\"\\n‚úÖ Side-by-Side Comparison (First 10 Rows - Mixed):\")\n",
    "display(results_df[[\"Question\", \"Gold Answer\", \"Extracted Answer\", \"Match\"]].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-11-28T11:53:41.757695Z",
     "iopub.status.busy": "2025-11-28T11:53:41.757195Z",
     "iopub.status.idle": "2025-11-28T11:53:41.771566Z",
     "shell.execute_reply": "2025-11-28T11:53:41.770634Z",
     "shell.execute_reply.started": "2025-11-28T11:53:41.757667Z"
    },
    "id": "e67abc12",
    "outputId": "c597ec41-a56e-4e5d-9eb6-e71bd0eafd38",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.583\n",
      "Precision: 1.000\n"
     ]
    }
   ],
   "source": [
    "# Accuracy: fraction of rows where extracted answer matches gold answer\n",
    "accuracy = (results_df[\"Match\"]).mean()\n",
    "\n",
    "# Precision: among rows where extracted answer is non-empty, fraction that matches gold\n",
    "# We filter out cases where the model predicted nothing (empty string) or just whitespace\n",
    "non_empty_pred = results_df[\"Extracted Answer\"].str.strip() != \"\"\n",
    "\n",
    "# Avoid division by zero if no predictions were made\n",
    "if non_empty_pred.sum() > 0:\n",
    "    precision = (results_df[\"Match\"] & non_empty_pred).sum() / non_empty_pred.sum()\n",
    "else:\n",
    "    precision = 0.0\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.3f}\")\n",
    "print(f\"Precision: {precision:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6eba58",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìã Hybrid Training Summary\n",
    "\n",
    "**This notebook implements a cost-optimized hybrid training approach:**\n",
    "\n",
    "### Changes from LoRA-Only Notebook:\n",
    "1. ‚úÖ **Architecture Inspection Cell** - Discovers CANINE-S layer count programmatically\n",
    "2. ‚úÖ **Hybrid Model Building** - LoRA adapters + last encoder layer fully unfrozen\n",
    "3. ‚úÖ **Updated Evaluation** - Applies same unfreezing logic during checkpoint evaluation\n",
    "4. ‚úÖ **Adjusted Hyperparameters:**\n",
    "   - Learning rate: 5e-5 ‚Üí 4e-5 (20% reduction for stability)\n",
    "   - Warmup: 0% ‚Üí 6% (~420 steps for smooth start)\n",
    "5. ‚úÖ **Updated Paths:**\n",
    "   - Output: `outputs/canine-s-uqa-hybrid`\n",
    "   - Hub: `VohraAK/canine-s-uqa-hybrid`\n",
    "\n",
    "### Expected Results:\n",
    "- **Trainable Parameters:** ~6-8M (vs ~1M LoRA-only)\n",
    "- **Training Time:** +25% (acceptable trade-off)\n",
    "- **Memory:** Minimal increase (fp16 + gradient checkpointing)\n",
    "- **Target Metrics:** EM/F1 > 40% (breaking through 33% plateau)\n",
    "\n",
    "### Cost-Benefit Analysis:\n",
    "| Approach | Params | Time | Memory | Expected EM/F1 |\n",
    "|----------|--------|------|--------|----------------|\n",
    "| LoRA Only | 1M | 1.0x | 1.0x | 33% ‚ùå |\n",
    "| **Hybrid (1 layer)** | **6-8M** | **1.25x** | **1.1x** | **40-55% ‚úÖ** |\n",
    "| Hybrid (2 layers) | 11-16M | 1.60x | 1.3x | 45-60% (risky) |\n",
    "\n",
    "**Ready to train! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
