{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"0","cell_type":"code","source":"# %pip install peft evaluate transformers Levenshtein ipywidgets\n# %pip install protobuf==3.20.3\n# !rm -rf /kaggle/working/cache","metadata":{"id":"c186240c","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:11:48.242413Z","iopub.execute_input":"2025-11-28T11:11:48.243073Z","iopub.status.idle":"2025-11-28T11:11:48.246594Z","shell.execute_reply.started":"2025-11-28T11:11:48.243045Z","shell.execute_reply":"2025-11-28T11:11:48.245793Z"}},"outputs":[],"execution_count":4},{"id":"1","cell_type":"code","source":"# X\n\nimport os\nos.environ[\"TRANSFORMERS_DISABLE_CHAT_TEMPLATES\"] = \"1\"\nos.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\nos.environ[\"TRANSFORMERS_NO_ADDITIONAL_CHAT_TEMPLATES\"] = \"1\"","metadata":{"id":"cd8da8ab","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:11:48.247517Z","iopub.execute_input":"2025-11-28T11:11:48.247828Z","iopub.status.idle":"2025-11-28T11:11:48.263852Z","shell.execute_reply.started":"2025-11-28T11:11:48.247808Z","shell.execute_reply":"2025-11-28T11:11:48.263227Z"}},"outputs":[],"execution_count":5},{"id":"2","cell_type":"code","source":"from datasets import load_dataset, load_from_disk\n# from UQA.canine_utils import preprocess_uqa, lora_config, print_trainable_parameters, normalize_answer, exact_match_score, f1_score, edit_distance_score, gold_answer, decode_prediction\nfrom transformers import CanineTokenizer\nfrom peft import LoraConfig, TaskType, get_peft_model\nimport re\nimport string\nfrom collections import Counter\nimport numpy as np\nimport Levenshtein\n\nfrom transformers import TrainingArguments, Trainer, TrainerCallback\nimport json\nfrom huggingface_hub import HfApi, notebook_login, whoami","metadata":{"id":"d87eba82","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:11:48.264845Z","iopub.execute_input":"2025-11-28T11:11:48.265048Z","iopub.status.idle":"2025-11-28T11:11:48.280590Z","shell.execute_reply.started":"2025-11-28T11:11:48.265031Z","shell.execute_reply":"2025-11-28T11:11:48.279966Z"}},"outputs":[],"execution_count":6},{"id":"3","cell_type":"code","source":"# notebook_login()\n# whoami()","metadata":{"id":"0e98cebe-4c08-4850-b3c1-1529564fdb1b","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:11:48.281234Z","iopub.execute_input":"2025-11-28T11:11:48.281454Z","iopub.status.idle":"2025-11-28T11:11:48.293889Z","shell.execute_reply.started":"2025-11-28T11:11:48.281436Z","shell.execute_reply":"2025-11-28T11:11:48.293246Z"}},"outputs":[],"execution_count":7},{"id":"4","cell_type":"code","source":"from transformers import CanineTokenizer, CanineForQuestionAnswering\nimport torch\nmodel_name = 'google/canine-s'\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n\ntokenizer = CanineTokenizer.from_pretrained(model_name, use_fast=False, trust_remote_code=False)\nmodel = CanineForQuestionAnswering.from_pretrained(model_name, trust_remote_code=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f2dd5a40","outputId":"140c30ea-575d-45cd-ea54-7818cdfe6bf5","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:11:48.294982Z","iopub.execute_input":"2025-11-28T11:11:48.295278Z","iopub.status.idle":"2025-11-28T11:11:54.546342Z","shell.execute_reply.started":"2025-11-28T11:11:48.295257Z","shell.execute_reply":"2025-11-28T11:11:54.545465Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/854 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef83badc19d342b29d393ed515680f87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/657 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa501ee0d4134901a8b3ad1feaa9e6f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/670 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71a7c5c531e944d49da401bac6d2e79d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/528M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab6662eec4af418f94ca2659464619c2"}},"metadata":{}},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":8},{"id":"5","cell_type":"code","source":"uqa_dataset = load_dataset(\"uqa/UQA\")\nuqa_train = uqa_dataset[\"train\"].shuffle(seed=42).select(range(40000))\nuqa_val = uqa_dataset[\"validation\"].shuffle(seed=42).select(range(2000))","metadata":{"id":"d474e2e8","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:11:54.547289Z","iopub.execute_input":"2025-11-28T11:11:54.547715Z","iopub.status.idle":"2025-11-28T11:11:58.228385Z","shell.execute_reply.started":"2025-11-28T11:11:54.547689Z","shell.execute_reply":"2025-11-28T11:11:58.227799Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/898 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4bf08b13dc9404b88eceac9291d80cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001-bac007e8ca7192(‚Ä¶):   0%|          | 0.00/30.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b1fa97bea2c4e548544cd15fbc0f5ac"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/validation-00000-of-00001-cf8a6960d(‚Ä¶):   0%|          | 0.00/2.92M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"454e6291b615412aa3369d0b7f21eaad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/124745 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b9ceba9de34443797aa8ce5370150a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/16824 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c280fa0cc371413bb18072c97b50a75f"}},"metadata":{}}],"execution_count":9},{"id":"6","cell_type":"markdown","source":"---","metadata":{"id":"89c472d5"}},{"id":"7","cell_type":"markdown","source":"## Updated preprocessors!\n\nPreviously, we tried to apply the same approach we used in TYDIQA on UQA, the problem was the preprocessors were aligning the answer spans in units of **byte-level spans** instead of **character-level spans**. The calculations were adding byte-level offsets to the answer lengths, and since Urdu characters may be quantified in multiple bytes, the model was being fed the wrong spans -> GIGO!","metadata":{"id":"6e80a8d3"}},{"id":"8","cell_type":"code","source":"MAX_SEQ_LENGTH = 384\nDOC_STRIDE = 64\n\ndef preprocess_uqa(examples, tokenizer, max_length=MAX_SEQ_LENGTH, doc_stride=DOC_STRIDE, model_obj=None, indices=None):\n    # Handle tokenizer/model limits safely\n    tokenizer_max = getattr(tokenizer, \"model_max_length\", max_length)\n    model_max = getattr(model_obj.config, \"max_position_embeddings\", None) if model_obj is not None else None\n    max_allowed = max_length\n    if tokenizer_max is not None and tokenizer_max > 0:\n        max_allowed = min(max_allowed, tokenizer_max)\n    if model_max is not None and model_max > 0:\n        max_allowed = min(max_allowed, model_max)\n\n    questions = [q.strip() for q in examples[\"question\"]]\n    contexts = examples[\"context\"]\n    answers = examples[\"answer\"]\n    answer_starts = examples[\"answer_start\"]\n\n    encoded = {\n        \"input_ids\": [],\n        \"attention_mask\": [],\n        \"token_type_ids\": [],\n        \"start_positions\": [],\n        \"end_positions\": [],\n        \"overflow_to_sample_mapping\": []\n    }\n\n    for i, (question, context, answer, answer_start) in enumerate(zip(questions, contexts, answers, answer_starts)):\n        example_idx = indices[i] if indices is not None else i\n\n        # CANINE encodes to characters directly.\n        # add_special_tokens=False gives us raw character IDs.\n        question_ids = tokenizer.encode(question, add_special_tokens=False)\n        context_ids = tokenizer.encode(context, add_special_tokens=False)\n\n        # 1. Setup Targets (DIRECT MAPPING)\n        # UQA answer_start is a CHARACTER index. CANINE tokens are CHARACTERS.\n        # Therefore, answer_start maps 1:1 to the context_ids index.\n        if answer and answer_start != -1:\n            gold_char_start = answer_start\n            gold_char_end = answer_start + len(answer) # Points to char AFTER the answer\n        else:\n            gold_char_start = -1\n            gold_char_end = -1\n\n        # 2. Calculate Window Size\n        # [CLS] + Question + [SEP] + Context + [SEP]\n        special_tokens_count = tokenizer.num_special_tokens_to_add(pair=True)\n        max_context_length = max_allowed - len(question_ids) - special_tokens_count\n\n        if max_context_length <= 0:\n            # Edge case: Question is too long, skip or truncate question (skipping here for safety)\n            continue\n\n        # 3. Sliding Window Loop\n        stride_step = max_context_length - doc_stride\n        if stride_step <= 0: stride_step = max_context_length # Fallback if doc_stride is too big\n\n        for chunk_start_idx in range(0, len(context_ids), stride_step):\n            chunk_end_idx = min(chunk_start_idx + max_context_length, len(context_ids))\n            context_chunk = context_ids[chunk_start_idx:chunk_end_idx]\n\n            # Build inputs using tokenizer utility to handle special tokens correctly\n            input_ids = tokenizer.build_inputs_with_special_tokens(question_ids, context_chunk)\n            token_type_ids = tokenizer.create_token_type_ids_from_sequences(question_ids, context_chunk)\n            attention_mask = [1] * len(input_ids)\n\n            # Calculate Offset: Where does the context actually start in input_ids?\n            # Typically: [CLS] (1) + Q_Len + [SEP] (1) = Start of Context\n            # We calculate this dynamically to be safe:\n            sep_indices = [k for k, x in enumerate(input_ids) if x == tokenizer.sep_token_id]\n            if not sep_indices:\n                continue # Should not happen\n            context_offset_in_input = sep_indices[0] + 1\n\n            # 4. Label Assignment\n            # Check if the answer lies ENTIRELY within this specific chunk\n            is_answer_in_chunk = (\n                gold_char_start >= chunk_start_idx and\n                gold_char_end <= chunk_end_idx and\n                gold_char_start != -1\n            )\n\n            if is_answer_in_chunk:\n                # Map global context index to local window index\n                start_pos = context_offset_in_input + (gold_char_start - chunk_start_idx)\n                # -1 because end_positions is usually inclusive in HF Trainers\n                end_pos = context_offset_in_input + (gold_char_end - chunk_start_idx) - 1\n            else:\n                # Label as [CLS] (index 0) if answer is not here\n                start_pos = 0\n                end_pos = 0\n\n            # 5. Padding\n            pad_len = max_allowed - len(input_ids)\n            if pad_len > 0:\n                input_ids += [tokenizer.pad_token_id] * pad_len\n                attention_mask += [0] * pad_len\n                token_type_ids += [0] * pad_len\n\n            # 6. Final Safety Truncation (just in case)\n            if len(input_ids) > max_allowed:\n                input_ids = input_ids[:max_allowed]\n                attention_mask = attention_mask[:max_allowed]\n                token_type_ids = token_type_ids[:max_allowed]\n                # If labels were pushed out by truncation, reset to 0\n                if start_pos >= max_allowed or end_pos >= max_allowed:\n                    start_pos = 0\n                    end_pos = 0\n\n            encoded[\"input_ids\"].append(input_ids)\n            encoded[\"attention_mask\"].append(attention_mask)\n            encoded[\"token_type_ids\"].append(token_type_ids)\n            encoded[\"start_positions\"].append(start_pos)\n            encoded[\"end_positions\"].append(end_pos)\n            encoded[\"overflow_to_sample_mapping\"].append(example_idx)\n\n            # Break loop if this chunk reached the end of the context\n            if chunk_end_idx >= len(context_ids):\n                break\n\n    return encoded\n","metadata":{"id":"438d8765","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:11:58.230039Z","iopub.execute_input":"2025-11-28T11:11:58.230277Z","iopub.status.idle":"2025-11-28T11:11:58.242318Z","shell.execute_reply.started":"2025-11-28T11:11:58.230260Z","shell.execute_reply":"2025-11-28T11:11:58.241585Z"}},"outputs":[],"execution_count":10},{"id":"9","cell_type":"code","source":"# LoRA config\nlora_config = LoraConfig(\n    task_type=TaskType.QUESTION_ANS,\n    r=16,   # changed from 8\n    lora_alpha=32,\n    lora_dropout=0.1,\n    target_modules=[\"query\", \"value\", \"key\"],\n    bias=\"none\",\n    modules_to_save=[\"qa_outputs\"],\n)\n\ndef print_trainable_parameters(model):\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n","metadata":{"id":"a3e95eec","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:11:58.242997Z","iopub.execute_input":"2025-11-28T11:11:58.243268Z","iopub.status.idle":"2025-11-28T11:11:58.268086Z","shell.execute_reply.started":"2025-11-28T11:11:58.243244Z","shell.execute_reply":"2025-11-28T11:11:58.267273Z"}},"outputs":[],"execution_count":11},{"id":"10","cell_type":"code","source":"# preprocess the train and val splits\nprocessed_train = uqa_train.map(lambda examples, indices: preprocess_uqa(examples, tokenizer, indices=indices), batched=True, remove_columns=uqa_train.column_names, with_indices=True)\nprocessed_val = uqa_val.map(lambda examples, indices: preprocess_uqa(examples, tokenizer, indices=indices), batched=True, remove_columns=uqa_val.column_names, with_indices=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["b1984a6d29864e2d940119370816a37e","a307de6c263a4c20a6418344cbd98c0c","1db208af0dbc4f2facee78148266a207","d44d38a959ec44aa90e91c15a83abbd6","527baa5fc421480da4d2dc7041e19b1f","d398c81b546d4527a41dd97bd87ad7d8","ab4047c7f0144667857fe835d452f6c7","0120d513dd4d4fccac2d528eb7ff4696","c3e0981c2924416fbdf9ceab3e6b04ab","bc970c64373f4f69b6c6936087ed978a","4a74d22a2c334fbda54a95c5e29e712a"]},"id":"d11807b9","outputId":"64fc2534-2871-4bd2-b3fa-4b37973486e2","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:11:58.268995Z","iopub.execute_input":"2025-11-28T11:11:58.269233Z","iopub.status.idle":"2025-11-28T11:15:38.690199Z","shell.execute_reply.started":"2025-11-28T11:11:58.269210Z","shell.execute_reply":"2025-11-28T11:15:38.689310Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/40000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1b0de37122a498f8a276ebcc1b2cc6e"}},"metadata":{}},{"name":"stderr","text":"Token indices sequence length is longer than the specified maximum sequence length for this model (3179 > 2048). Running this sequence through the model will result in indexing errors\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"325528da1bc44de381a5065221eb8e8d"}},"metadata":{}}],"execution_count":12},{"id":"11","cell_type":"code","source":"# processed_train","metadata":{"id":"D-emFQTIaZRL","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:15:38.691302Z","iopub.execute_input":"2025-11-28T11:15:38.691596Z","iopub.status.idle":"2025-11-28T11:15:38.695246Z","shell.execute_reply.started":"2025-11-28T11:15:38.691576Z","shell.execute_reply":"2025-11-28T11:15:38.694441Z"}},"outputs":[],"execution_count":13},{"id":"12","cell_type":"code","source":"# processed_val","metadata":{"id":"Yy3SiWwCabEi","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:15:38.695967Z","iopub.execute_input":"2025-11-28T11:15:38.696219Z","iopub.status.idle":"2025-11-28T11:15:38.723658Z","shell.execute_reply.started":"2025-11-28T11:15:38.696195Z","shell.execute_reply":"2025-11-28T11:15:38.722762Z"}},"outputs":[],"execution_count":14},{"id":"13","cell_type":"code","source":"processed_train.save_to_disk(\"/kaggle/working/cache/processed_train_uqa\")\nprocessed_val.save_to_disk(\"/kaggle/working/cache/processed_val_uqa\")   # cached it\n\n\nprocessed_train = load_from_disk(\"/kaggle/working/cache/processed_train_uqa\")\nprocessed_val = load_from_disk(\"/kaggle/working/cache/processed_val_uqa\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["05d936e2dc9d412b8637c174a3c0be64","7e0b41aa16f241a4ba3bb8a2f3525984","2bebe7e1f3f341dfaabf29963d2c5995","41b300b02ed2413ba80865aaa99ece2a","b4740a7137e742d687e2075b60d2be8a","80132c8e4fa743fca850936ecfebc7f7","303bb3d75f7d4e94aeb60c5491ea6e61","d7463faafecf4e46a87dc6863a646cea","bc199cddba714aeda650d97fef015a14","1a508a6457bb460ba17d5adb0a9e9f85","3aac2656907a416291a622717ccaf929","fa1af70d9c95443c9f09666359ba3769","ddb717fd4dbc40c6bd8422a02f925060","6d1342eeaf4f4f0489fe0746ceaaeb09","a10683e5c1164f349cbdc75b1567994c","71cfe2c8df474badb255d7d28da04348","077fbb403e5f4069841e558a3cc0c065","b068b9fac9f24eca9bd430bab30ea70c","8cbfc6f4ec434674ac59d3fbdbddcd3b","4d675a6788b641c6a09604ef17514dec","bd9b9f21be9744c49d99ac4bc76f11e1","89469ab4bd6f48d8b9aa369473c7230f"]},"id":"77ecdd17","outputId":"602e648b-4a75-424b-da09-d58f3295a65e","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:15:38.725685Z","iopub.execute_input":"2025-11-28T11:15:38.725954Z","iopub.status.idle":"2025-11-28T11:15:39.084734Z","shell.execute_reply.started":"2025-11-28T11:15:38.725934Z","shell.execute_reply":"2025-11-28T11:15:39.083979Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/116995 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6c4669494c145109fb6b11aac1fdfc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Saving the dataset (0/1 shards):   0%|          | 0/6317 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ce0807ce4424724ad7a0e788bbc7764"}},"metadata":{}}],"execution_count":15},{"id":"14","cell_type":"code","source":"def print_trainable_parameters(model):\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\")\n\n","metadata":{"id":"c0e06e6b","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:15:39.085698Z","iopub.execute_input":"2025-11-28T11:15:39.085972Z","iopub.status.idle":"2025-11-28T11:15:39.090479Z","shell.execute_reply.started":"2025-11-28T11:15:39.085946Z","shell.execute_reply":"2025-11-28T11:15:39.089509Z"}},"outputs":[],"execution_count":16},{"id":"15","cell_type":"code","source":"# build LoRA model\n\npeft_model = get_peft_model(model, lora_config)\npeft_model.gradient_checkpointing_enable()\nprint_trainable_parameters(peft_model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ba9eeeed","outputId":"27071b6e-b703-4b47-9288-9a1c6f3eba55","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:15:39.091280Z","iopub.execute_input":"2025-11-28T11:15:39.091567Z","iopub.status.idle":"2025-11-28T11:15:39.168406Z","shell.execute_reply.started":"2025-11-28T11:15:39.091542Z","shell.execute_reply":"2025-11-28T11:15:39.167781Z"}},"outputs":[{"name":"stdout","text":"trainable params: 1033730 || all params: 133118212 || trainable%: 0.7765503941714602\n","output_type":"stream"}],"execution_count":17},{"id":"16","cell_type":"code","source":"def normalize_answer(text):\n    text = (text or \"\").lower()\n    def remove_articles(s):\n        return re.sub(r\"\\b(a|an|the)\\b\", \" \", s)\n    def remove_punctuation(s):\n        return \"\".join(ch for ch in s if ch not in string.punctuation)\n    def white_space_fix(s):\n        return \" \".join(s.split())\n    return white_space_fix(remove_articles(remove_punctuation(text)))\n\ndef exact_match_score(prediction, ground_truth):\n    return float(normalize_answer(prediction) == normalize_answer(ground_truth))\n\ndef f1_score(prediction, ground_truth):\n    pred_tokens = normalize_answer(prediction).split()\n    gold_tokens = normalize_answer(ground_truth).split()\n    if not gold_tokens:\n        return 1.0 if not pred_tokens else 0.0\n    if not pred_tokens:\n        return 0.0\n    common = Counter(pred_tokens) & Counter(gold_tokens)\n    num_same = sum(common.values())\n    if num_same == 0:\n        return 0.0\n    precision = num_same / len(pred_tokens)\n    recall = num_same / len(gold_tokens)\n    return 2 * precision * recall / (precision + recall)\n\ndef decode_prediction(input_ids, start_idx, end_idx, tokenizer):\n    cls_index = input_ids.index(tokenizer.cls_token_id)\n    if start_idx == cls_index and end_idx == cls_index:\n        return \"\" # Empty answer\n    if start_idx > end_idx:\n        return \"\" # Invalid range -> Empty answer\n    \n    # Ensure indices are within bounds\n    start_idx = max(start_idx, 0)\n    end_idx = min(end_idx, len(input_ids) - 1)\n    \n    text = tokenizer.decode(input_ids[start_idx:end_idx + 1], skip_special_tokens=True)\n    return text.strip()\n\ndef gold_answer(example):\n    if example[\"answer_start\"] == -1:\n        return \"\"\n    return example[\"answer\"]\n\ndef edit_distance_score(prediction, ground_truth):\n    return Levenshtein.ratio(normalize_answer(prediction), normalize_answer(ground_truth))\n\n\ndef evaluate_checkpoint(checkpoint_path=None, model_instance=None, eval_dataset=None):\n    \"\"\"Evaluate either a checkpoint path (loads model) or a provided model instance.\n\n    - checkpoint_path: path to checkpoint folder\n    - model_instance: an in-memory model (preferably a PeftModel or CanineForQuestionAnswering)\n    - eval_dataset: optional dataset to evaluate; if None the default processed_val will be used\n    \"\"\"\n    if eval_dataset is None:\n        eval_dataset = processed_val\n\n    # If a model_instance is given, use it directly (avoid re-loading a fresh base model)\n    if model_instance is not None:\n        eval_model = model_instance\n    else:\n        base_model = CanineForQuestionAnswering.from_pretrained(model_name, trust_remote_code=False)\n        eval_model = get_peft_model(base_model, lora_config)\n        # Try loading adapter weights; fall back to PeftModel.from_pretrained if needed\n        try:\n            eval_model.load_adapter(checkpoint_path)\n        except Exception:\n            from peft import PeftModel\n            eval_model = PeftModel.from_pretrained(base_model, checkpoint_path)\n\n    eval_model.to(device)\n\n    eval_args = TrainingArguments(\n        # Small evaluation config; uses cpu/mps if no gpu during eval\n        output_dir=\"outputs/canine-s-uqa\",\n        per_device_eval_batch_size=16,\n        dataloader_drop_last=False,\n        fp16=True,\n        bf16=False,\n        report_to=\"none\",\n    )\n\n    # Run evaluation via a lightweight Trainer so prediction loop is standard\n    eval_trainer = Trainer(\n        model=eval_model,\n        args=eval_args,\n        eval_dataset=eval_dataset,\n        tokenizer=tokenizer,\n    )\n\n    predictions = eval_trainer.predict(eval_dataset)\n    start_logits, end_logits = predictions.predictions\n    best_predictions = {}\n    for feature_index, feature in enumerate(eval_dataset):\n        sample_idx = int(feature[\"overflow_to_sample_mapping\"])\n        input_ids = feature[\"input_ids\"]\n        start_idx = int(np.argmax(start_logits[feature_index]))\n        end_idx = int(np.argmax(end_logits[feature_index]))\n        score = float(start_logits[feature_index][start_idx] + end_logits[feature_index][end_idx])\n        prediction_text = decode_prediction(input_ids, start_idx, end_idx, tokenizer=tokenizer)\n        stored = best_predictions.get(sample_idx)\n        if stored is None or score > stored[0]:\n            best_predictions[sample_idx] = (score, prediction_text)\n\n    em_scores = []\n    f1_scores = []\n    edit_dist_scores = []\n    for sample_idx, (_, prediction_text) in best_predictions.items():\n        reference = gold_answer(uqa_val[int(sample_idx)])\n        em_scores.append(exact_match_score(prediction_text, reference))\n        f1_scores.append(f1_score(prediction_text, reference))\n        edit_dist_scores.append(edit_distance_score(prediction_text, reference))\n\n    em = float(np.mean(em_scores)) if em_scores else 0.0\n    f1 = float(np.mean(f1_scores)) if f1_scores else 0.0\n    edit_dist = float(np.mean(edit_dist_scores)) if edit_dist_scores else 0.0\n    print(f\"Examples evaluated: {len(em_scores)}\")\n    print(f\"Exact Match: {em * 100:.2f}\")\n    print(f\"F1: {f1 * 100:.2f}\")\n    print(f\"Edit Distance (normalized): {edit_dist * 100:.2f}\")\n    return {\"exact_match\": em, \"f1\": f1, \"edit_distance\": edit_dist}\n","metadata":{"id":"61c5c7a7","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:15:39.169086Z","iopub.execute_input":"2025-11-28T11:15:39.169259Z","iopub.status.idle":"2025-11-28T11:15:39.183325Z","shell.execute_reply.started":"2025-11-28T11:15:39.169245Z","shell.execute_reply":"2025-11-28T11:15:39.182637Z"}},"outputs":[],"execution_count":18},{"id":"17","cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"outputs/canine-s-uqa\",\n\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=16,\n\n    gradient_accumulation_steps=4,\n    gradient_checkpointing=True,\n\n    num_train_epochs=1,\n    learning_rate=5e-5,     # changed from 3e-4\n    weight_decay=0.01,\n    eval_strategy=\"no\",\n    eval_steps=500,\n    save_strategy=\"steps\",\n    save_steps=500,\n    logging_steps=50,\n    fp16=True,\n    bf16=False,\n    report_to=\"none\",\n    push_to_hub=True,\n    hub_model_id=\"VohraAK/canine-s-uqa\",\n    hub_strategy=\"checkpoint\",\n    )\n\nclass CustomEvalCallback(TrainerCallback):\n    def __init__(self, eval_func, eval_dataset, use_in_memory_model=True, verbose=True):\n        self.eval_func = eval_func\n        self.eval_dataset = eval_dataset\n        self.use_in_memory_model = use_in_memory_model\n        self.verbose = verbose\n        # trainer reference (set after trainer exists)\n        self.trainer = None\n\n    def on_save(self, args, state, control, model=None, **kwargs):\n        checkpoint_path = f\"{args.output_dir}/checkpoint-{state.global_step}\"\n        if self.verbose:\n            print(f\"\\nüîç Running custom evaluation at step {state.global_step}...\")\n\n        # Prefer evaluating the in-memory trainer model (fast + avoids re-loading)\n        if self.use_in_memory_model and self.trainer is not None:\n            if self.verbose:\n                print(\"Using in-memory model for evaluation (no reloading).\")\n            try:\n                metrics = self.eval_func(checkpoint_path=None, model_instance=self.trainer.model, eval_dataset=self.eval_dataset)\n            except Exception as e:\n                print(\"‚ö†Ô∏è in-memory evaluation failed, falling back to checkpoint load:\", e)\n                metrics = self.eval_func(checkpoint_path)\n        else:\n            metrics = self.eval_func(checkpoint_path)\n\n        # record metrics in state.log_history\n        state.log_history.append({\n            \"step\": state.global_step,\n            \"eval_exact_match\": metrics.get(\"exact_match\"),\n            \"eval_f1\": metrics.get(\"f1\"),\n            \"eval_edit_distance\": metrics.get(\"edit_distance\"),\n        })\n\n        if self.verbose:\n            print(f\"‚úÖ Step {state.global_step}: EM={metrics.get('exact_match',0)*100:.2f}, F1={metrics.get('f1',0)*100:.2f}, EditDist={metrics.get('edit_distance',0)*100:.2f}\")\n\n        # Update trainer_state.json to include custom metrics\n        state_path = f\"{checkpoint_path}/trainer_state.json\"\n        try:\n            with open(state_path, 'r') as f:\n                state_dict = json.load(f)\n            state_dict['log_history'] = state.log_history\n            with open(state_path, 'w') as f:\n                json.dump(state_dict, f, indent=2)\n            if self.verbose:\n                print(f\"üíæ Updated trainer_state.json with custom metrics\")\n        except Exception as e:\n            if self.verbose:\n                print(f\"‚ö†Ô∏è  Warning: Could not update trainer_state.json: {e}\")\n\n        try:\n            if self.verbose:\n                print(f\"‚òÅÔ∏è  Pushing checkpoint-{state.global_step} to Hub...\")\n            api = HfApi()\n            api.upload_folder(\n                folder_path=checkpoint_path,\n                repo_id=args.hub_model_id,\n                path_in_repo=f\"checkpoint-{state.global_step}\",\n                commit_message=f\"Add checkpoint {state.global_step} (EM={metrics.get('exact_match',0)*100:.1f}%, F1={metrics.get('f1',0)*100:.1f}%)\",\n                repo_type=\"model\"\n            )\n            if self.verbose:\n                print(f\"‚úÖ Pushed checkpoint-{state.global_step} to Hub\")\n        except Exception as e:\n            if self.verbose:\n                print(f\"‚ö†Ô∏è  Warning: Could not push to Hub: {e}\")\n\n        return control","metadata":{"id":"c4abaaab","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:15:39.184799Z","iopub.execute_input":"2025-11-28T11:15:39.185061Z","iopub.status.idle":"2025-11-28T11:15:39.233564Z","shell.execute_reply.started":"2025-11-28T11:15:39.185044Z","shell.execute_reply":"2025-11-28T11:15:39.232990Z"}},"outputs":[],"execution_count":19},{"id":"18","cell_type":"code","source":"trainer_cb = CustomEvalCallback(evaluate_checkpoint, processed_val, use_in_memory_model=True)\n\ntrainer = Trainer(\n    model=peft_model,\n    args=training_args,\n    train_dataset=processed_train,\n    eval_dataset=processed_val,\n    callbacks=[trainer_cb],\n)\n","metadata":{"id":"055f5dda","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:15:39.234336Z","iopub.execute_input":"2025-11-28T11:15:39.234552Z","iopub.status.idle":"2025-11-28T11:15:40.031517Z","shell.execute_reply.started":"2025-11-28T11:15:39.234532Z","shell.execute_reply":"2025-11-28T11:15:40.030809Z"}},"outputs":[{"name":"stderr","text":"No label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"}],"execution_count":20},{"id":"19","cell_type":"code","source":"trainer.train()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TOUimesUX5Re","outputId":"cfa62dcd-8eb4-475a-910b-1c38a3894cc2","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:15:40.032362Z","iopub.execute_input":"2025-11-28T11:15:40.032592Z","iopub.status.idle":"2025-11-28T11:52:26.051938Z","shell.execute_reply.started":"2025-11-28T11:15:40.032573Z","shell.execute_reply":"2025-11-28T11:52:26.051314Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7313' max='7313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [7313/7313 36:44, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>5.917900</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>5.834100</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>5.768900</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>5.677400</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>5.620900</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>5.573700</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>5.491900</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>5.416600</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>5.362500</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>5.338000</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>5.252800</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>5.219900</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>5.201900</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>5.129400</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>5.079300</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>4.978200</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>4.972300</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>4.917400</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>4.908100</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>4.844900</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>4.806900</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>4.767800</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>4.739300</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>4.696400</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>4.662600</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>4.626400</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>4.551700</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>4.555400</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>4.577600</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>4.547100</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>4.548000</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>4.437800</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>4.446900</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>4.452600</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>4.389800</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>4.282400</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>4.344000</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>4.303600</td>\n    </tr>\n    <tr>\n      <td>1950</td>\n      <td>4.229200</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>4.164500</td>\n    </tr>\n    <tr>\n      <td>2050</td>\n      <td>4.199300</td>\n    </tr>\n    <tr>\n      <td>2100</td>\n      <td>4.108200</td>\n    </tr>\n    <tr>\n      <td>2150</td>\n      <td>4.118300</td>\n    </tr>\n    <tr>\n      <td>2200</td>\n      <td>4.132800</td>\n    </tr>\n    <tr>\n      <td>2250</td>\n      <td>4.048700</td>\n    </tr>\n    <tr>\n      <td>2300</td>\n      <td>4.191000</td>\n    </tr>\n    <tr>\n      <td>2350</td>\n      <td>4.134700</td>\n    </tr>\n    <tr>\n      <td>2400</td>\n      <td>3.913200</td>\n    </tr>\n    <tr>\n      <td>2450</td>\n      <td>4.060900</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>3.961900</td>\n    </tr>\n    <tr>\n      <td>2550</td>\n      <td>4.006000</td>\n    </tr>\n    <tr>\n      <td>2600</td>\n      <td>4.023600</td>\n    </tr>\n    <tr>\n      <td>2650</td>\n      <td>4.017400</td>\n    </tr>\n    <tr>\n      <td>2700</td>\n      <td>4.063600</td>\n    </tr>\n    <tr>\n      <td>2750</td>\n      <td>3.935900</td>\n    </tr>\n    <tr>\n      <td>2800</td>\n      <td>3.915700</td>\n    </tr>\n    <tr>\n      <td>2850</td>\n      <td>4.001200</td>\n    </tr>\n    <tr>\n      <td>2900</td>\n      <td>3.923600</td>\n    </tr>\n    <tr>\n      <td>2950</td>\n      <td>3.857700</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>3.837200</td>\n    </tr>\n    <tr>\n      <td>3050</td>\n      <td>3.882200</td>\n    </tr>\n    <tr>\n      <td>3100</td>\n      <td>3.813200</td>\n    </tr>\n    <tr>\n      <td>3150</td>\n      <td>3.764600</td>\n    </tr>\n    <tr>\n      <td>3200</td>\n      <td>3.829600</td>\n    </tr>\n    <tr>\n      <td>3250</td>\n      <td>3.886200</td>\n    </tr>\n    <tr>\n      <td>3300</td>\n      <td>3.708700</td>\n    </tr>\n    <tr>\n      <td>3350</td>\n      <td>3.790900</td>\n    </tr>\n    <tr>\n      <td>3400</td>\n      <td>3.678600</td>\n    </tr>\n    <tr>\n      <td>3450</td>\n      <td>3.830400</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>3.902300</td>\n    </tr>\n    <tr>\n      <td>3550</td>\n      <td>3.692000</td>\n    </tr>\n    <tr>\n      <td>3600</td>\n      <td>3.871200</td>\n    </tr>\n    <tr>\n      <td>3650</td>\n      <td>3.745000</td>\n    </tr>\n    <tr>\n      <td>3700</td>\n      <td>3.700800</td>\n    </tr>\n    <tr>\n      <td>3750</td>\n      <td>3.736700</td>\n    </tr>\n    <tr>\n      <td>3800</td>\n      <td>3.675800</td>\n    </tr>\n    <tr>\n      <td>3850</td>\n      <td>3.681300</td>\n    </tr>\n    <tr>\n      <td>3900</td>\n      <td>3.806900</td>\n    </tr>\n    <tr>\n      <td>3950</td>\n      <td>3.702200</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>3.746000</td>\n    </tr>\n    <tr>\n      <td>4050</td>\n      <td>3.797000</td>\n    </tr>\n    <tr>\n      <td>4100</td>\n      <td>3.571500</td>\n    </tr>\n    <tr>\n      <td>4150</td>\n      <td>3.550000</td>\n    </tr>\n    <tr>\n      <td>4200</td>\n      <td>3.729300</td>\n    </tr>\n    <tr>\n      <td>4250</td>\n      <td>3.704400</td>\n    </tr>\n    <tr>\n      <td>4300</td>\n      <td>3.669400</td>\n    </tr>\n    <tr>\n      <td>4350</td>\n      <td>3.585800</td>\n    </tr>\n    <tr>\n      <td>4400</td>\n      <td>3.543600</td>\n    </tr>\n    <tr>\n      <td>4450</td>\n      <td>3.692900</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>3.602200</td>\n    </tr>\n    <tr>\n      <td>4550</td>\n      <td>3.449800</td>\n    </tr>\n    <tr>\n      <td>4600</td>\n      <td>3.628000</td>\n    </tr>\n    <tr>\n      <td>4650</td>\n      <td>3.612100</td>\n    </tr>\n    <tr>\n      <td>4700</td>\n      <td>3.694300</td>\n    </tr>\n    <tr>\n      <td>4750</td>\n      <td>3.653000</td>\n    </tr>\n    <tr>\n      <td>4800</td>\n      <td>3.646300</td>\n    </tr>\n    <tr>\n      <td>4850</td>\n      <td>3.503700</td>\n    </tr>\n    <tr>\n      <td>4900</td>\n      <td>3.569300</td>\n    </tr>\n    <tr>\n      <td>4950</td>\n      <td>3.611200</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>3.613000</td>\n    </tr>\n    <tr>\n      <td>5050</td>\n      <td>3.673900</td>\n    </tr>\n    <tr>\n      <td>5100</td>\n      <td>3.562100</td>\n    </tr>\n    <tr>\n      <td>5150</td>\n      <td>3.529700</td>\n    </tr>\n    <tr>\n      <td>5200</td>\n      <td>3.493800</td>\n    </tr>\n    <tr>\n      <td>5250</td>\n      <td>3.345200</td>\n    </tr>\n    <tr>\n      <td>5300</td>\n      <td>3.587500</td>\n    </tr>\n    <tr>\n      <td>5350</td>\n      <td>3.511200</td>\n    </tr>\n    <tr>\n      <td>5400</td>\n      <td>3.552200</td>\n    </tr>\n    <tr>\n      <td>5450</td>\n      <td>3.510000</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>3.590900</td>\n    </tr>\n    <tr>\n      <td>5550</td>\n      <td>3.593900</td>\n    </tr>\n    <tr>\n      <td>5600</td>\n      <td>3.382500</td>\n    </tr>\n    <tr>\n      <td>5650</td>\n      <td>3.412600</td>\n    </tr>\n    <tr>\n      <td>5700</td>\n      <td>3.553400</td>\n    </tr>\n    <tr>\n      <td>5750</td>\n      <td>3.475400</td>\n    </tr>\n    <tr>\n      <td>5800</td>\n      <td>3.464700</td>\n    </tr>\n    <tr>\n      <td>5850</td>\n      <td>3.524000</td>\n    </tr>\n    <tr>\n      <td>5900</td>\n      <td>3.460400</td>\n    </tr>\n    <tr>\n      <td>5950</td>\n      <td>3.502400</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>3.572900</td>\n    </tr>\n    <tr>\n      <td>6050</td>\n      <td>3.583200</td>\n    </tr>\n    <tr>\n      <td>6100</td>\n      <td>3.445600</td>\n    </tr>\n    <tr>\n      <td>6150</td>\n      <td>3.539700</td>\n    </tr>\n    <tr>\n      <td>6200</td>\n      <td>3.486400</td>\n    </tr>\n    <tr>\n      <td>6250</td>\n      <td>3.464500</td>\n    </tr>\n    <tr>\n      <td>6300</td>\n      <td>3.420100</td>\n    </tr>\n    <tr>\n      <td>6350</td>\n      <td>3.423400</td>\n    </tr>\n    <tr>\n      <td>6400</td>\n      <td>3.419800</td>\n    </tr>\n    <tr>\n      <td>6450</td>\n      <td>3.479500</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>3.352500</td>\n    </tr>\n    <tr>\n      <td>6550</td>\n      <td>3.289800</td>\n    </tr>\n    <tr>\n      <td>6600</td>\n      <td>3.487100</td>\n    </tr>\n    <tr>\n      <td>6650</td>\n      <td>3.433200</td>\n    </tr>\n    <tr>\n      <td>6700</td>\n      <td>3.583700</td>\n    </tr>\n    <tr>\n      <td>6750</td>\n      <td>3.436800</td>\n    </tr>\n    <tr>\n      <td>6800</td>\n      <td>3.485400</td>\n    </tr>\n    <tr>\n      <td>6850</td>\n      <td>3.470900</td>\n    </tr>\n    <tr>\n      <td>6900</td>\n      <td>3.443100</td>\n    </tr>\n    <tr>\n      <td>6950</td>\n      <td>3.479100</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>3.497200</td>\n    </tr>\n    <tr>\n      <td>7050</td>\n      <td>3.414100</td>\n    </tr>\n    <tr>\n      <td>7100</td>\n      <td>3.391100</td>\n    </tr>\n    <tr>\n      <td>7150</td>\n      <td>3.453800</td>\n    </tr>\n    <tr>\n      <td>7200</td>\n      <td>3.530500</td>\n    </tr>\n    <tr>\n      <td>7250</td>\n      <td>3.589500</td>\n    </tr>\n    <tr>\n      <td>7300</td>\n      <td>3.437000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nüîç Running custom evaluation at step 500...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 25.30\nF1: 26.26\nEdit Distance (normalized): 28.09\n‚úÖ Step 500: EM=25.30, F1=26.26, EditDist=28.09\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-500 to Hub...\n‚úÖ Pushed checkpoint-500 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 1000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 29.95\nF1: 30.50\nEdit Distance (normalized): 31.41\n‚úÖ Step 1000: EM=29.95, F1=30.50, EditDist=31.41\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-1000 to Hub...\n‚úÖ Pushed checkpoint-1000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 1500...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 30.90\nF1: 31.27\nEdit Distance (normalized): 31.92\n‚úÖ Step 1500: EM=30.90, F1=31.27, EditDist=31.92\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-1500 to Hub...\n‚úÖ Pushed checkpoint-1500 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 2000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 31.35\nF1: 31.63\nEdit Distance (normalized): 32.17\n‚úÖ Step 2000: EM=31.35, F1=31.63, EditDist=32.17\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-2000 to Hub...\n‚úÖ Pushed checkpoint-2000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 2500...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 31.75\nF1: 31.94\nEdit Distance (normalized): 32.36\n‚úÖ Step 2500: EM=31.75, F1=31.94, EditDist=32.36\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-2500 to Hub...\n‚úÖ Pushed checkpoint-2500 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 3000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 32.25\nF1: 32.46\nEdit Distance (normalized): 32.87\n‚úÖ Step 3000: EM=32.25, F1=32.46, EditDist=32.87\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-3000 to Hub...\n‚úÖ Pushed checkpoint-3000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 3500...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 32.35\nF1: 32.51\nEdit Distance (normalized): 32.86\n‚úÖ Step 3500: EM=32.35, F1=32.51, EditDist=32.86\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-3500 to Hub...\n‚úÖ Pushed checkpoint-3500 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f77a8601-32db-4ced-a2f7-ce00d8972974)')' thrown while requesting HEAD https://huggingface.co/google/canine-s/resolve/main/config.json\nWARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: f77a8601-32db-4ced-a2f7-ce00d8972974)')' thrown while requesting HEAD https://huggingface.co/google/canine-s/resolve/main/config.json\nRetrying in 1s [Retry 1/5].\nWARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 4000...\n","output_type":"stream"},{"name":"stderr","text":"'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: ea454141-2b46-42a9-82d4-6615effc264f)')' thrown while requesting HEAD https://huggingface.co/google/canine-s/resolve/main/config.json\nWARNING:huggingface_hub.utils._http:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: ea454141-2b46-42a9-82d4-6615effc264f)')' thrown while requesting HEAD https://huggingface.co/google/canine-s/resolve/main/config.json\nRetrying in 1s [Retry 1/5].\nWARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\nSome weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 32.50\nF1: 32.66\nEdit Distance (normalized): 33.01\n‚úÖ Step 4000: EM=32.50, F1=32.66, EditDist=33.01\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-4000 to Hub...\n‚úÖ Pushed checkpoint-4000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 4500...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 32.65\nF1: 32.79\nEdit Distance (normalized): 33.08\n‚úÖ Step 4500: EM=32.65, F1=32.79, EditDist=33.08\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-4500 to Hub...\n‚úÖ Pushed checkpoint-4500 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 5000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 32.75\nF1: 32.87\nEdit Distance (normalized): 33.14\n‚úÖ Step 5000: EM=32.75, F1=32.87, EditDist=33.14\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-5000 to Hub...\n‚úÖ Pushed checkpoint-5000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 5500...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 32.80\nF1: 32.92\nEdit Distance (normalized): 33.19\n‚úÖ Step 5500: EM=32.80, F1=32.92, EditDist=33.19\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-5500 to Hub...\n‚úÖ Pushed checkpoint-5500 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 6000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 32.75\nF1: 32.85\nEdit Distance (normalized): 33.09\n‚úÖ Step 6000: EM=32.75, F1=32.85, EditDist=33.09\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-6000 to Hub...\n‚úÖ Pushed checkpoint-6000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 6500...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 32.70\nF1: 32.80\nEdit Distance (normalized): 33.06\n‚úÖ Step 6500: EM=32.70, F1=32.80, EditDist=33.06\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-6500 to Hub...\n‚úÖ Pushed checkpoint-6500 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 7000...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 32.70\nF1: 32.80\nEdit Distance (normalized): 33.06\n‚úÖ Step 7000: EM=32.70, F1=32.80, EditDist=33.06\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-7000 to Hub...\n‚úÖ Pushed checkpoint-7000 to Hub\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nüîç Running custom evaluation at step 7313...\n","output_type":"stream"},{"name":"stderr","text":"Some weights of CanineForQuestionAnswering were not initialized from the model checkpoint at google/canine-s and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:190: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n  warnings.warn(\n/tmp/ipykernel_120/2231442091.py:88: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  eval_trainer = Trainer(\nNo label_names provided for model class `PeftModelForQuestionAnswering`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Examples evaluated: 2000\nExact Match: 32.70\nF1: 32.80\nEdit Distance (normalized): 33.06\n‚úÖ Step 7313: EM=32.70, F1=32.80, EditDist=33.06\nüíæ Updated trainer_state.json with custom metrics\n‚òÅÔ∏è  Pushing checkpoint-7313 to Hub...\n‚úÖ Pushed checkpoint-7313 to Hub\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=7313, training_loss=4.007603400027102, metrics={'train_runtime': 2205.5529, 'train_samples_per_second': 53.046, 'train_steps_per_second': 3.316, 'total_flos': 2.9095953406848e+16, 'train_loss': 4.007603400027102, 'epoch': 1.0})"},"metadata":{}}],"execution_count":21},{"id":"28b41337-dc8a-4b6f-a66a-e409e2dc19ad","cell_type":"markdown","source":"---","metadata":{}},{"id":"20","cell_type":"markdown","source":"### Diagnosing Preprocessing Functions!!!\n\nThese functions are just analysing the preprocessing logic above, they're just using the base model, NOT our trained model...","metadata":{"id":"cc44692c-6652-4cda-9ba4-8a03acdab88d"}},{"id":"21","cell_type":"code","source":"# Diagnostic cell (fixed): Investigate preprocessing and truncation for many samples\nimport random\nimport pandas as pd\nfrom transformers import AutoTokenizer\n\n# Set display options to see full Urdu text\npd.set_option('display.max_colwidth', None)\n\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(\"google/canine-s\")\nexcept Exception:\n    tokenizer = None\n\nnum_samples = 20000  # Number of samples to check\nresults = []\n\nfor split_name, orig_data, proc_data in [\n    (\"train\", uqa_train, processed_train),\n    (\"val\", uqa_val, processed_val)\n]:\n    # Sample random indices\n    if len(proc_data) < num_samples:\n        current_indices = range(len(proc_data))\n    else:\n        current_indices = random.sample(range(len(proc_data)), num_samples)\n\n    for idx in current_indices:\n        proc = proc_data[idx]\n        # Use overflow_to_sample_mapping to get the correct original index\n        orig_idx = proc[\"overflow_to_sample_mapping\"]\n        orig = orig_data[orig_idx]\n\n        input_ids = proc[\"input_ids\"]\n        start_pos = proc[\"start_positions\"]\n        end_pos = proc[\"end_positions\"]\n\n        gold_answer = orig.get(\"gold_answer\", orig.get(\"answer\", \"\"))\n        question = orig.get(\"question\", \"\")\n\n        # Decode input_ids to text (for debugging context)\n        if tokenizer:\n            decoded_text = tokenizer.decode(input_ids, skip_special_tokens=False)\n        else:\n            decoded_text = str(input_ids)\n\n        # Extract predicted answer span\n        if 0 <= start_pos < len(input_ids) and 0 <= end_pos < len(input_ids):\n            if tokenizer:\n                pred_span = tokenizer.decode(input_ids[start_pos:end_pos+1], skip_special_tokens=True)\n            else:\n                pred_span = str(input_ids[start_pos:end_pos+1])\n        else:\n            pred_span = \"[CLS]\" # Represents no answer found in this chunk or invalid\n\n        # Check if pred_span matches gold answer\n        # We strip() to ignore minor whitespace differences\n        pred_matches_gold = pred_span.strip() == gold_answer.strip()\n\n        # Check if gold is even reachable in this chunk\n        gold_in_decoded = gold_answer in decoded_text\n\n        results.append({\n            \"Split\": split_name,\n            \"Question\": question,\n            \"Gold Answer\": gold_answer,\n            \"Extracted Answer\": pred_span,\n            \"Match\": pred_matches_gold,\n            \"Gold Reachable\": gold_in_decoded,\n            \"orig_idx\": orig_idx\n        })\n\n# Create DataFrame\nresults_df = pd.DataFrame(results)\n\n# --- SIDE BY SIDE COMPARISON ---\n\n# 1. Filter for Solvable Mismatches (Gold was there, but we predicted wrong)\nproblem_cases = results_df[\n    (results_df[\"Gold Reachable\"] == True) &\n    (results_df[\"Match\"] == False)\n][[\"Question\", \"Gold Answer\", \"Extracted Answer\", \"Split\"]]\n\nprint(f\"üîç Checked {len(results_df)} samples.\")\nprint(f\"‚ùå Found {len(problem_cases)} cases where Gold was present but Extraction failed.\")\n\nprint(\"\\nüìä Side-by-Side Comparison (Top 20 Failures):\")\ndisplay(problem_cases.head(50))\n\nprint(\"\\n‚úÖ Side-by-Side Comparison (First 10 Rows - Mixed):\")\ndisplay(results_df[[\"Question\", \"Gold Answer\", \"Extracted Answer\", \"Match\"]].head(50))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"49f3717d","outputId":"38f435a4-1b55-4c2b-b6a5-86540fc23755","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:54:55.504481Z","iopub.execute_input":"2025-11-28T11:54:55.505301Z","iopub.status.idle":"2025-11-28T11:55:21.452459Z","shell.execute_reply.started":"2025-11-28T11:54:55.505271Z","shell.execute_reply":"2025-11-28T11:55:21.451860Z"}},"outputs":[{"name":"stdout","text":"üîç Checked 26317 samples.\n‚ùå Found 624 cases where Gold was present but Extraction failed.\n\nüìä Side-by-Side Comparison (Top 20 Failures):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                                                                        Question  \\\n43                                                                           Close Encounters ŸÜ€í ⁄©ÿ™ŸÜ€í ÿ¢ÿ≥⁄©ÿ± ÿ¨€åÿ™€íÿü   \n160                                                                         €å€Å ÿßÿ≥ÿßÿ™ÿ∞€Å ⁄©€í ÿ™ÿßÿ¨ÿ± ÿß⁄©ÿ´ÿ± ⁄©€åÿß ⁄©ÿ±ÿ™€í ÿ™⁄æ€íÿü   \n161                                                           ÿ®ÿ±⁄© ⁄©€Åÿß⁄∫ ŸÅ⁄©ÿ± ŸÖŸÜÿØ ÿ™⁄æÿß ⁄©€Å ÿ®ÿ±ÿ∑ÿßŸÜ€å€Å ÿ¨ŸÜ⁄Ø ŸÜ€Å€å⁄∫ ÿ¨€åÿ™ ÿ≥⁄©ÿ™ÿßÿü   \n205                                                          1964 ŸÖ€å⁄∫ ÿß€åŸÜ ÿß€í ÿß€åŸÖ ⁄©ÿß ÿ±€ÅŸÜŸÖÿß ⁄©ŸàŸÜ ŸÜÿßŸÖÿ≤ÿØ ⁄©€åÿß ⁄Ø€åÿß ÿ™⁄æÿßÿü   \n287                                                                        ŸæŸÜ⁄©⁄æŸà⁄∫ ŸàÿßŸÑ€í ⁄©€å⁄ëŸà⁄∫ ⁄©Ÿà ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n386                                                                 ÿ®€åŸàŸÜÿ≥€å ŸÜ€í 2006 ŸÖ€å⁄∫ ⁄©ÿ≥ ⁄©Ÿà ÿÆÿ±ÿßÿ¨ ÿ™ÿ≠ÿ≥€åŸÜ Ÿæ€åÿ¥ ⁄©€åÿßÿü   \n465                                                ⁄©ŸàŸÜ ÿ≥ÿß ŸÖŸÑ⁄© Ÿæ€ÅŸÑÿß ŸÖŸÑ⁄© ÿ™⁄æÿß ÿ¨ÿ≥ Ÿæÿ± ÿßŸÖÿ±€å⁄©€Å ŸÜ€í ÿ¨ŸÜ⁄Ø ⁄©ÿß ÿßÿπŸÑÿßŸÜ ⁄©€åÿß ÿ™⁄æÿßÿü   \n547                                                                            Ÿπ€å ⁄à€å ⁄Øÿßÿ±⁄àŸÜ ⁄©ÿ™ŸÜ€å Ÿπ€åŸÖŸà⁄∫ ⁄©ÿß ⁄Ø⁄æÿ± €Å€íÿü   \n555                                               €Åÿßÿ¶€å⁄© ŸÜ€í ⁄©€Åÿß ÿ™⁄æÿß ⁄©€Å ŸÖÿπÿßÿ¥ÿ±€í ⁄©€í ŸÑ€å€í ÿ≠ŸÅÿßÿ∏ÿ™€å ÿ¨ÿßŸÑ ⁄©ŸàŸÜ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±€í ⁄Øÿßÿü   \n562                            ÿ±Ÿàÿ≥ ÿßŸàÿ± ÿ™ÿ±⁄©€å ⁄©€í ŸÖÿßÿ®€åŸÜ ÿ™ÿµŸÅ€å€Å ⁄©€í ÿ®ÿπÿØ ÿå ÿ¢ÿ≥Ÿπÿ±€åÿß ŸÜ€í ⁄©ÿ≥ ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ¥ÿßŸÖŸÑ €ÅŸàŸÜ€í ⁄©ÿß ŸÅ€åÿµŸÑ€Å ⁄©€åÿßÿü   \n575                                                       128 kbit / s Ÿæÿ± ⁄©ŸÖŸæÿ±€åÿ≥⁄à ÿß€å⁄© MP3 ⁄©ÿ™ŸÜ€í ⁄©ŸÑ ÿ®Ÿπ / ÿ≥ Ÿæ⁄ë€í ⁄Øÿßÿü   \n589                                   ÿ¨ÿ® ÿØŸàÿ≥ÿ™Ÿà⁄∫ ⁄©Ÿà ÿØŸàÿ≥ÿ±€í ŸÑŸà⁄ØŸà⁄∫ ÿ≥€í ÿ≤€åÿßÿØ€Å Ÿæÿ≥ŸÜÿØ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€í ÿ™Ÿà ÿßÿ≥€í ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n607                                                     ⁄©ŸàŸÜ ÿ≥ÿß ÿ≥€åŸÜÿ≥ÿ± ŸÖŸàÿ¥ŸÜ ÿ≥€åŸÜÿ≥ÿ± ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ±Ÿàÿ¥ŸÜ€å ⁄©Ÿà ⁄©ŸÜŸπÿ±ŸàŸÑ ⁄©ÿ±ÿ™ÿß €Å€íÿü   \n634                                               ŸÖ€å⁄© ⁄©€í ⁄©ÿ≥ ÿ≠ÿµ€í ŸÖ€å⁄∫ 1984 ŸÖ€å⁄∫ ÿ¢ÿ≥ÿßŸÜ€å ÿ≥€í ÿ™Ÿàÿ≥€åÿπ ŸÜ€Å€å⁄∫ ⁄©€å ÿ¨ÿß ÿ≥⁄©ÿ™€å ÿ™⁄æ€åÿü   \n643                                            ÿ±€å⁄à€åŸà ŸÑ€Åÿ±Ÿà⁄∫ ⁄©Ÿà Ÿæ€åÿØÿß ⁄©ÿ±ŸÜ€í ŸàÿßŸÑ€í ÿπŸÜÿßÿµÿ± ⁄©€í ÿ¨Ÿà⁄ëŸÜ€í ⁄©€í ŸÑÿ¶€í ⁄©€åÿß ÿ∂ÿ±Ÿàÿ±€å €Å€íÿü   \n763                                                               ⁄©ÿ≥ ⁄Øÿ±ŸàŸæ ⁄©€í ÿÆŸÑÿßŸÅ ÿ™ÿ¨ÿßÿ±ÿ™€å Ÿæÿßÿ®ŸÜÿØ€å ÿπÿßÿ¶ÿØ ⁄©€å ⁄Øÿ¶€å ÿ™⁄æ€åÿü   \n858                                                                           ŸàÿßŸÜ ŸÜ€åŸàŸÖŸÜ ŸÜ€í ⁄©ŸàŸÜ ÿ≥ÿß ÿ¥ÿπÿ®€Å ŸÇÿßÿ¶ŸÖ ⁄©€åÿßÿü   \n922                                                           ÿ¨Ÿà Ÿà⁄©ŸπŸàÿ±€åÿß ⁄©€å ÿ≥€å⁄ë⁄æ€åŸà⁄∫ ÿ≥€í ⁄Øÿ±ŸÜ€í ⁄©€í 10 ÿØŸÜ ÿ®ÿπÿØ ŸÖÿ± ⁄Ø€åÿßÿü   \n959                                                                              ŸÖ€å⁄Ø€å Ÿæ€ÅŸÑ€å ÿ®ÿßÿ± ⁄©ÿ® ÿ¥ÿßÿ¶ÿπ €ÅŸàÿ¶€å ÿ™⁄æ€åÿü   \n974                                                      ÿ¢ŸÜ€í ŸàÿßŸÑ€í ÿ≥ÿßŸÑŸà⁄∫ ŸÖ€å⁄∫ ÿ™ÿπŸÑ€åŸÖ ⁄©€å ⁄©ŸàŸÜ ÿ≥€å ÿ¥⁄©ŸÑ ÿ∫ÿßŸÑÿ® ŸÜÿ∏ÿ± ÿ¢ÿ™€å €Å€íÿü   \n1037          ⁄©ŸÑÿßÿ±⁄© ÿßŸàÿ± ⁄à€åŸÜ ⁄©€í ÿ®ÿß€Åÿ± ŸÜ⁄©ŸÑŸÜ€í ⁄©€í ÿ®ÿπÿØÿå ⁄©ŸàŸÜ ÿ≥ÿß ÿßŸÖ€åÿØŸàÿßÿ± ⁄©€åÿ±€å ⁄©€í ÿÆŸÑÿßŸÅ Ÿàÿßÿ≠ÿØ ÿ≠ŸÇ€åŸÇ€å ŸÖÿØŸÖŸÇÿßÿ®ŸÑ ÿ≥ŸÖÿ¨⁄æÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿü   \n1094                                        ÿßŸÖÿ±€å⁄©€Å ŸÖ€å⁄∫ ÿßŸÅÿ±ÿßÿØ ⁄©€å ÿ∑ÿ±ŸÅ ÿ≥€í ÿ¥ÿ±Ÿàÿπ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€í ⁄©€Å SAMs ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n1097                                                                   €Åÿßÿ±Ÿæÿ± ŸÑ€å ŸÜ€í ÿßŸæŸÜÿß ÿ®⁄ÜŸæŸÜ ⁄©ÿ≥ ÿ±€åÿßÿ≥ÿ™ ŸÖ€å⁄∫ ⁄Øÿ≤ÿßÿ±ÿßÿü   \n1100                                  ⁄©ŸÖ ÿßŸàÿ± ÿßÿπŸÑ€å ⁄Øÿ±€å⁄à ŸÖ€åŸπÿßŸÖŸàÿ±ŸÅ⁄© ⁄ÜŸπÿßŸÜŸà⁄∫ ÿ≥€í ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©€å ÿ™ÿ¥⁄©€åŸÑ ⁄©ÿß ÿßÿ¥ÿßÿ±€Å ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n1130                                                                                 ⁄à€å ⁄ØÿßŸÑ ⁄©€í Ÿæÿßÿ≥ ⁄©€åÿß ÿØÿ±ÿ¨€Å ÿ™⁄æÿßÿü   \n1284                                                                     ŸÖ€åŸÑÿ®Ÿàÿ±ŸÜ ⁄©Ÿæ ⁄©€å Ÿæ€ÅŸÑ€å ÿØŸà⁄ë ⁄©ÿ≥ ÿ≥ÿßŸÑ €ÅŸàÿ¶€å ÿ™⁄æ€åÿü   \n1315                                                                                ÿ¨Ÿà ⁄à€åŸà⁄à ÿ®ŸàŸà€å ÿ≥ŸÜ ⁄©ÿ± ŸæŸÑÿß ÿ®⁄ë⁄æÿßÿü   \n1323           ⁄à⁄Ü ÿßŸàÿ± ÿßŸÜ⁄Øÿ±€åÿ≤€å ⁄©€í ŸÖÿßÿ®€åŸÜ ŸÇÿ±ÿ∂€í ⁄©€í ÿßŸÑŸÅÿßÿ∏ ⁄©€í ÿßÿ¥ÿ™ÿ±ÿß⁄© ŸÖ€å⁄∫ ÿå ⁄©ÿ≥ ÿ≤ÿ®ÿßŸÜ ⁄©Ÿà ŸÇÿ±ÿ∂€í ⁄©€í ÿßŸÑŸÅÿßÿ∏ ⁄©ÿß ÿ≤€åÿßÿØ€Å ŸÅ€åÿµÿØ ŸÖŸÑÿßÿü   \n1399                                                                               ⁄©ŸàŸπ⁄© ⁄©ÿ≥ ⁄©ŸÖŸæŸÜ€å ⁄©ÿß ÿ≥€å ÿß€å ÿßŸà €Å€íÿü   \n1472                                                         ⁄©ŸàŸÜ ÿ≥Ÿà⁄Üÿ™ÿß ÿ™⁄æÿß ⁄©€Å ŸÅÿß⁄©ÿ≥ ÿßŸàÿ± ÿ®ÿ±⁄© ⁄©€å ÿØŸàÿ≥ÿ™€å ⁄©⁄æŸà ⁄Ø€åÿß ÿ™⁄æÿßÿü   \n1487                                                           ⁄©ÿ≥ ÿßŸÜÿØÿ±ŸàŸÜ€å ÿ¨ÿ≤Ÿà ŸÖ€å⁄∫ ⁄©ÿßŸÅ€å ÿ≠ÿØ ÿ™⁄© ŸÜÿ∏ÿ± ÿ´ÿßŸÜ€å ⁄©€å ⁄Øÿ¶€å €Å€íÿü   \n1498                                                                     ŸÜŸÖ€åÿ®€åÿß ŸÖ€å⁄∫ ⁄©ŸàŸÜ ÿ≥€å Ÿàÿ®ÿß ÿß€å⁄© ÿ®⁄ëÿß ŸÖÿ≥ÿ¶ŸÑ€Å €Å€íÿü   \n1538                                                                                ÿßÿ≥ ÿßÿ≥⁄©Ÿàÿ± ⁄©Ÿà ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n1740                                 ÿ¨Ÿà ŸÑÿßÿ¨ÿ≤ ÿ¨€å ÿß€åŸÑ ÿß€å ⁄©€å ÿ™ÿßÿ¶€åÿØ ŸÜ€Å€å⁄∫ ⁄©ÿ± ÿ≥⁄©ÿ™€í ÿ™⁄æ€í ÿßŸÜ€Å€å⁄∫ ÿ®ÿπÿØ ŸÖ€å⁄∫ ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿü   \n1783                                                                           ÿ¥ŸàŸæŸÜ ⁄©€í ŸàÿßŸÑÿØ ⁄©ÿß Ÿæ€ÅŸÑÿß ŸÜÿßŸÖ ⁄©€åÿß ÿ™⁄æÿßÿü   \n1806              ŸÖÿ¥ÿ±ŸÇ€å ÿßŸÜ⁄ØŸÑ€åŸÜ⁄à ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ≥ÿßÿ™⁄æ ÿå ÿßŸÜ⁄ØŸÑ€åŸÜ⁄à ⁄©€í ⁄©ÿ≥ ÿ≠ÿµ€í ŸÖ€å⁄∫ ÿßÿ≥⁄©€åŸÜ⁄à€åŸÜ€åŸà€åŸÜ ŸÜ⁄òÿßÿØ ÿ®€Åÿ™ ÿ≥€í ŸÖŸÇÿßŸÖÿßÿ™ ⁄©€í ŸÜÿßŸÖ €Å€å⁄∫ÿü   \n1818                                                          Ÿπ⁄æŸÜ⁄à€å ÿßÿ¥€åÿßÿ° ⁄©€åÿß €Å€å⁄∫ ⁄©€Å ÿßÿ¥€åÿßÿ° ⁄©€í ŸÖŸÇÿßÿ®ŸÑ€í ŸÖ€å⁄∫ ⁄©ŸÖ ⁄ÜŸÖ⁄©ÿü   \n1824                                                              ÿ¨ÿ≥ ⁄©€í ŸÖÿ∂ÿ®Ÿàÿ∑ ⁄à⁄æÿßŸÜ⁄Ü€í ÿ®ÿßŸæ €åÿß ÿ®€åŸπ€í ⁄©€å ÿ¥⁄©ŸÑ ŸÖ€å⁄∫ €Å€å⁄∫ÿü   \n1838                                                                                         ÿ¥ŸàŸæŸÜ ⁄©€Åÿß⁄∫ ŸæŸÑÿß ÿ®⁄ë⁄æÿßÿü   \n1934                                                            ŸÇŸàŸÖŸà⁄∫ ⁄©€í ÿ¥€Åÿ±€åŸà⁄∫ ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± ⁄©ÿ≥ ⁄©Ÿà ŸÖŸÇÿ±ÿ± ⁄©€åÿß ⁄Ø€åÿß €Å€íÿü   \n2049  ÿßÿ≥ ⁄©€å ŸÜÿß⁄©ÿßŸÖ€å ÿ≥€í Ÿæ€ÅŸÑ€íÿå ⁄©ŸàŸÜ ÿ≥ÿß ÿ®⁄Üÿ™ ÿßŸàÿ± ŸÇÿ±ÿ∂ ÿß€åÿ≥Ÿàÿ≥€å ÿß€åÿ¥ŸÜ ÿ±€åÿßÿ≥ÿ™€Åÿßÿ¶€í ŸÖÿ™ÿ≠ÿØ€Å ŸÖ€å⁄∫ ÿ≥ÿßÿ™Ÿà€å⁄∫ ÿ≥ÿ® ÿ≥€í ÿ®⁄ëÿß ÿ±€ÅŸÜ ÿßÿ®ÿ™ÿØÿßÿ¶€å ÿ™⁄æÿßÿü   \n2194                           ÿØ€å⁄Øÿ± ÿ®ÿ±ÿ∑ÿßŸÜŸà€å ÿ±€åÿßÿ≥ÿ™Ÿà⁄∫ ÿßŸàÿ± ⁄©ÿßŸÑŸàŸÜ€åŸà⁄∫ ŸÜ€í ÿ≥ÿßŸÑ ⁄©€å ÿ¥ÿ±Ÿàÿπÿßÿ™ ⁄©€å ÿ™ÿßÿ±€åÿÆ €å⁄©ŸÖ ÿ¨ŸÜŸàÿ±€å ⁄©ÿ® ŸÖŸÇÿ±ÿ± ⁄©€åÿü   \n2197                                                                             ⁄©€Åÿß⁄∫ Broz Belousova ÿ≥€í ÿ¥ÿßÿØ€å ⁄©€åÿü   \n2207                                      ÿ®⁄ÜŸà⁄∫ ⁄©€å ŸÖÿ≤ÿØŸàÿ±€å ⁄©€å ŸÅÿ±ÿß€ÅŸÖ€å ÿßŸàÿ± ÿßÿ≥ ⁄©€å ⁄©€åÿß Ÿàÿ¨Ÿà€Åÿßÿ™ €Å€å⁄∫ ÿ¨Ÿà ÿ¢ÿ¨ ÿ®⁄æ€å ŸÖŸàÿ¨ŸàÿØ €Å€å⁄∫ÿü   \n2215                                         ÿ∑ÿßŸÑÿ® ÿπŸÑŸÖŸà⁄∫ ⁄©Ÿà ⁄Ü€åŸÜ€å ÿ≠ÿ±ŸàŸÅ ÿ≥⁄©⁄æÿßŸÜ€í ⁄©€í ŸÑ€å€í ÿß⁄©ÿ´ÿ± ⁄©€åÿß ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n2274                                             €ÅŸÜÿØŸà ÿßÿ≥⁄©ŸàŸÑŸà⁄∫ ŸÖ€å⁄∫ ÿ≥€í ÿ≥ÿ® ÿ≥€í ÿ≤€åÿßÿØ€Å ÿ™ÿ±ŸÇ€å €åÿßŸÅÿ™€Å ÿßŸàÿ± ŸÖÿ¥€ÅŸàÿ± ⁄©ŸàŸÜ ÿ≥ÿß €Å€íÿü   \n2401                                                                    Ÿæÿ±ŸÜÿØŸà⁄∫ ⁄©€í ⁄©ÿ™ŸÜ€í ÿ®⁄ë€í ŸÅŸÑÿßÿ¶Ÿπ ŸæŸπ⁄æŸà⁄∫ €ÅŸàÿ™€í €Å€å⁄∫ÿü   \n2447                                ⁄©€åŸÜ€í ŸÜ€í ÿ≠ÿßÿØÿ´€í ⁄©€í ÿ®ÿπÿØ ÿ¨Ÿà ⁄©⁄Ü⁄æ €ÅŸàÿß ÿßÿ≥ ⁄©€í ÿ™ÿ¨ÿ±ÿ®€í ⁄©€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫ ⁄©€åÿß ⁄ØÿßŸÜÿß ÿ±€å⁄©ÿßÿ±⁄à ⁄©€åÿßÿü   \n2458                                                                     ÿß€åŸàÿßŸÜ ŸÖ€å⁄∫ ÿßŸÇŸÑ€åÿ™€å Ÿæÿßÿ±Ÿπ€å ⁄©ÿß ÿ±€ÅŸÜŸÖÿß ⁄©ŸàŸÜ €Å€íÿü   \n2473                                                  ⁄©€åÿß ŸÜŸàÿ¨ŸàÿßŸÜ ÿ®⁄ë€í €åÿß ⁄Ü⁄æŸàŸπ€í Ÿæ€åŸÖÿßŸÜ€í Ÿæÿ± \"⁄©ŸÑ⁄©ÿ≥\" ⁄©€í ÿ≥ÿßÿ™⁄æ ŸÖŸÑÿ™€í €Å€å⁄∫ÿü   \n\n              Gold Answer Extracted Answer  Split  \n43                     ÿØŸà                   train  \n160      ŸÖ€åŸÜ⁄àŸàŸÑ€åŸÜ ÿ¢ÿ±⁄©ÿ≥Ÿπÿ±ÿß                   train  \n161                ÿßŸÖÿ±€å⁄©€Å                   train  \n205                  ŸÜÿßÿµÿ±                   train  \n287              ŸæŸπ€åÿ±⁄ØŸàŸπÿß                   train  \n386          ŸÖÿßÿ¶€å⁄©ŸÑ ÿ¨€å⁄©ÿ≥ŸÜ                   train  \n465               ÿ®ÿ±ÿ∑ÿßŸÜ€å€Å                   train  \n547                    ÿØŸà                   train  \n555                 ÿ±€åÿßÿ≥ÿ™                   train  \n562                  ÿ™ÿ±⁄©€å                   train  \n575               128,000                   train  \n589                ⁄©ÿ±ŸàŸÜÿ≤ŸÖ                   train  \n607            ŸÇÿ®ÿ∂€Å ÿ≥€åŸÜÿ≥ÿ±                   train  \n634                ŸÖ€åŸÖŸàÿ±€å                   train  \n643               ÿß€åŸÜŸπ€åŸÜÿß                   train  \n763               ÿ¥€åŸàŸÜ⁄ØŸÜŸà                   train  \n858        ŸÖÿ≥ŸÑÿ≥ŸÑ ÿ¨€åŸàŸÖ€åŸπÿ±€å                   train  \n922                 ÿ®ÿ±ÿßÿ§ŸÜ                   train  \n959                  1893                   train  \n974         ÿßŸàŸæŸÜ ÿß€åÿ¨Ÿà⁄©€åÿ¥ŸÜ                   train  \n1037              ÿß€å⁄àŸàÿ±⁄àÿ≤                   train  \n1094             ŸÖ€åŸÜ Ÿæ€å⁄àÿ≥                   train  \n1097              ÿßŸÑÿßÿ®ÿßŸÖÿß                   train  \n1100           ⁄Øÿ±€åŸÜ ÿßÿ≥ŸπŸàŸÜ                   train  \n1130                 ÿ¨ŸÜÿ±ŸÑ                   train  \n1284                 1861                   train  \n1315               ŸÖ€å⁄àŸàŸÜÿß                   train  \n1323                   ⁄à⁄Ü                   train  \n1399    ÿß€å⁄©Ÿπ€åŸà€åÿ¥ŸÜ ÿ®ŸÑ€åÿ≤ÿßÿ±⁄à                   train  \n1472                  ÿ®ÿ±⁄©                   train  \n1487            ÿØÿ±ÿ¨€Å ÿ®ŸÜÿØ€å                   train  \n1498                 ÿß€å⁄àÿ≤                   train  \n1538             ⁄à€å ÿßÿ≥⁄©Ÿàÿ±                   train  \n1740                 ÿ¨ÿØ€åÿØ                   train  \n1783                ŸÜ⁄©ŸàŸÑÿ≥                   train  \n1806                ÿ¥ŸÖÿßŸÑ€å                   train  \n1818                  ⁄Øÿ±ŸÖ                   train  \n1824                ÿ®€åŸπŸà⁄∫                   train  \n1838                Ÿàÿßÿ±ÿ≥ÿß                   train  \n1934          ÿßÿπÿ≤ÿßÿ≤€å ŸÜÿßÿ¶Ÿπ                   train  \n2049        ÿßŸÜ⁄à€å ŸÖ€å⁄© ÿ®€åŸÜ⁄©                   train  \n2194                 1752                   train  \n2197                ÿßŸàŸÖÿ≥⁄©                   train  \n2207                  ÿ∑ŸÑÿ®                   train  \n2215  ÿ®ÿßŸÇÿßÿπÿØ€Å ÿßÿ≥⁄©ÿ±ŸæŸπ ŸÅŸàŸÜŸπ                   train  \n2274              Ÿà€åÿØÿßŸÜÿ™ÿß                   train  \n2401                   ÿØŸà                   train  \n2447         ÿ™⁄æÿ±Ÿà ÿØ€å Ÿàÿßÿ¶ÿ±                   train  \n2458                ÿßŸÇŸÑ€åÿ™                   train  \n2473                ⁄Ü⁄æŸàŸπ€í                   train  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Gold Answer</th>\n      <th>Extracted Answer</th>\n      <th>Split</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>43</th>\n      <td>Close Encounters ŸÜ€í ⁄©ÿ™ŸÜ€í ÿ¢ÿ≥⁄©ÿ± ÿ¨€åÿ™€íÿü</td>\n      <td>ÿØŸà</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>160</th>\n      <td>€å€Å ÿßÿ≥ÿßÿ™ÿ∞€Å ⁄©€í ÿ™ÿßÿ¨ÿ± ÿß⁄©ÿ´ÿ± ⁄©€åÿß ⁄©ÿ±ÿ™€í ÿ™⁄æ€íÿü</td>\n      <td>ŸÖ€åŸÜ⁄àŸàŸÑ€åŸÜ ÿ¢ÿ±⁄©ÿ≥Ÿπÿ±ÿß</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>161</th>\n      <td>ÿ®ÿ±⁄© ⁄©€Åÿß⁄∫ ŸÅ⁄©ÿ± ŸÖŸÜÿØ ÿ™⁄æÿß ⁄©€Å ÿ®ÿ±ÿ∑ÿßŸÜ€å€Å ÿ¨ŸÜ⁄Ø ŸÜ€Å€å⁄∫ ÿ¨€åÿ™ ÿ≥⁄©ÿ™ÿßÿü</td>\n      <td>ÿßŸÖÿ±€å⁄©€Å</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>205</th>\n      <td>1964 ŸÖ€å⁄∫ ÿß€åŸÜ ÿß€í ÿß€åŸÖ ⁄©ÿß ÿ±€ÅŸÜŸÖÿß ⁄©ŸàŸÜ ŸÜÿßŸÖÿ≤ÿØ ⁄©€åÿß ⁄Ø€åÿß ÿ™⁄æÿßÿü</td>\n      <td>ŸÜÿßÿµÿ±</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>287</th>\n      <td>ŸæŸÜ⁄©⁄æŸà⁄∫ ŸàÿßŸÑ€í ⁄©€å⁄ëŸà⁄∫ ⁄©Ÿà ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n      <td>ŸæŸπ€åÿ±⁄ØŸàŸπÿß</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>386</th>\n      <td>ÿ®€åŸàŸÜÿ≥€å ŸÜ€í 2006 ŸÖ€å⁄∫ ⁄©ÿ≥ ⁄©Ÿà ÿÆÿ±ÿßÿ¨ ÿ™ÿ≠ÿ≥€åŸÜ Ÿæ€åÿ¥ ⁄©€åÿßÿü</td>\n      <td>ŸÖÿßÿ¶€å⁄©ŸÑ ÿ¨€å⁄©ÿ≥ŸÜ</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>465</th>\n      <td>⁄©ŸàŸÜ ÿ≥ÿß ŸÖŸÑ⁄© Ÿæ€ÅŸÑÿß ŸÖŸÑ⁄© ÿ™⁄æÿß ÿ¨ÿ≥ Ÿæÿ± ÿßŸÖÿ±€å⁄©€Å ŸÜ€í ÿ¨ŸÜ⁄Ø ⁄©ÿß ÿßÿπŸÑÿßŸÜ ⁄©€åÿß ÿ™⁄æÿßÿü</td>\n      <td>ÿ®ÿ±ÿ∑ÿßŸÜ€å€Å</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>547</th>\n      <td>Ÿπ€å ⁄à€å ⁄Øÿßÿ±⁄àŸÜ ⁄©ÿ™ŸÜ€å Ÿπ€åŸÖŸà⁄∫ ⁄©ÿß ⁄Ø⁄æÿ± €Å€íÿü</td>\n      <td>ÿØŸà</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>555</th>\n      <td>€Åÿßÿ¶€å⁄© ŸÜ€í ⁄©€Åÿß ÿ™⁄æÿß ⁄©€Å ŸÖÿπÿßÿ¥ÿ±€í ⁄©€í ŸÑ€å€í ÿ≠ŸÅÿßÿ∏ÿ™€å ÿ¨ÿßŸÑ ⁄©ŸàŸÜ ŸÅÿ±ÿß€ÅŸÖ ⁄©ÿ±€í ⁄Øÿßÿü</td>\n      <td>ÿ±€åÿßÿ≥ÿ™</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>562</th>\n      <td>ÿ±Ÿàÿ≥ ÿßŸàÿ± ÿ™ÿ±⁄©€å ⁄©€í ŸÖÿßÿ®€åŸÜ ÿ™ÿµŸÅ€å€Å ⁄©€í ÿ®ÿπÿØ ÿå ÿ¢ÿ≥Ÿπÿ±€åÿß ŸÜ€í ⁄©ÿ≥ ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ¥ÿßŸÖŸÑ €ÅŸàŸÜ€í ⁄©ÿß ŸÅ€åÿµŸÑ€Å ⁄©€åÿßÿü</td>\n      <td>ÿ™ÿ±⁄©€å</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>575</th>\n      <td>128 kbit / s Ÿæÿ± ⁄©ŸÖŸæÿ±€åÿ≥⁄à ÿß€å⁄© MP3 ⁄©ÿ™ŸÜ€í ⁄©ŸÑ ÿ®Ÿπ / ÿ≥ Ÿæ⁄ë€í ⁄Øÿßÿü</td>\n      <td>128,000</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>589</th>\n      <td>ÿ¨ÿ® ÿØŸàÿ≥ÿ™Ÿà⁄∫ ⁄©Ÿà ÿØŸàÿ≥ÿ±€í ŸÑŸà⁄ØŸà⁄∫ ÿ≥€í ÿ≤€åÿßÿØ€Å Ÿæÿ≥ŸÜÿØ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€í ÿ™Ÿà ÿßÿ≥€í ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n      <td>⁄©ÿ±ŸàŸÜÿ≤ŸÖ</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>607</th>\n      <td>⁄©ŸàŸÜ ÿ≥ÿß ÿ≥€åŸÜÿ≥ÿ± ŸÖŸàÿ¥ŸÜ ÿ≥€åŸÜÿ≥ÿ± ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ±Ÿàÿ¥ŸÜ€å ⁄©Ÿà ⁄©ŸÜŸπÿ±ŸàŸÑ ⁄©ÿ±ÿ™ÿß €Å€íÿü</td>\n      <td>ŸÇÿ®ÿ∂€Å ÿ≥€åŸÜÿ≥ÿ±</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>634</th>\n      <td>ŸÖ€å⁄© ⁄©€í ⁄©ÿ≥ ÿ≠ÿµ€í ŸÖ€å⁄∫ 1984 ŸÖ€å⁄∫ ÿ¢ÿ≥ÿßŸÜ€å ÿ≥€í ÿ™Ÿàÿ≥€åÿπ ŸÜ€Å€å⁄∫ ⁄©€å ÿ¨ÿß ÿ≥⁄©ÿ™€å ÿ™⁄æ€åÿü</td>\n      <td>ŸÖ€åŸÖŸàÿ±€å</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>643</th>\n      <td>ÿ±€å⁄à€åŸà ŸÑ€Åÿ±Ÿà⁄∫ ⁄©Ÿà Ÿæ€åÿØÿß ⁄©ÿ±ŸÜ€í ŸàÿßŸÑ€í ÿπŸÜÿßÿµÿ± ⁄©€í ÿ¨Ÿà⁄ëŸÜ€í ⁄©€í ŸÑÿ¶€í ⁄©€åÿß ÿ∂ÿ±Ÿàÿ±€å €Å€íÿü</td>\n      <td>ÿß€åŸÜŸπ€åŸÜÿß</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>⁄©ÿ≥ ⁄Øÿ±ŸàŸæ ⁄©€í ÿÆŸÑÿßŸÅ ÿ™ÿ¨ÿßÿ±ÿ™€å Ÿæÿßÿ®ŸÜÿØ€å ÿπÿßÿ¶ÿØ ⁄©€å ⁄Øÿ¶€å ÿ™⁄æ€åÿü</td>\n      <td>ÿ¥€åŸàŸÜ⁄ØŸÜŸà</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>858</th>\n      <td>ŸàÿßŸÜ ŸÜ€åŸàŸÖŸÜ ŸÜ€í ⁄©ŸàŸÜ ÿ≥ÿß ÿ¥ÿπÿ®€Å ŸÇÿßÿ¶ŸÖ ⁄©€åÿßÿü</td>\n      <td>ŸÖÿ≥ŸÑÿ≥ŸÑ ÿ¨€åŸàŸÖ€åŸπÿ±€å</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>922</th>\n      <td>ÿ¨Ÿà Ÿà⁄©ŸπŸàÿ±€åÿß ⁄©€å ÿ≥€å⁄ë⁄æ€åŸà⁄∫ ÿ≥€í ⁄Øÿ±ŸÜ€í ⁄©€í 10 ÿØŸÜ ÿ®ÿπÿØ ŸÖÿ± ⁄Ø€åÿßÿü</td>\n      <td>ÿ®ÿ±ÿßÿ§ŸÜ</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>959</th>\n      <td>ŸÖ€å⁄Ø€å Ÿæ€ÅŸÑ€å ÿ®ÿßÿ± ⁄©ÿ® ÿ¥ÿßÿ¶ÿπ €ÅŸàÿ¶€å ÿ™⁄æ€åÿü</td>\n      <td>1893</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>974</th>\n      <td>ÿ¢ŸÜ€í ŸàÿßŸÑ€í ÿ≥ÿßŸÑŸà⁄∫ ŸÖ€å⁄∫ ÿ™ÿπŸÑ€åŸÖ ⁄©€å ⁄©ŸàŸÜ ÿ≥€å ÿ¥⁄©ŸÑ ÿ∫ÿßŸÑÿ® ŸÜÿ∏ÿ± ÿ¢ÿ™€å €Å€íÿü</td>\n      <td>ÿßŸàŸæŸÜ ÿß€åÿ¨Ÿà⁄©€åÿ¥ŸÜ</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1037</th>\n      <td>⁄©ŸÑÿßÿ±⁄© ÿßŸàÿ± ⁄à€åŸÜ ⁄©€í ÿ®ÿß€Åÿ± ŸÜ⁄©ŸÑŸÜ€í ⁄©€í ÿ®ÿπÿØÿå ⁄©ŸàŸÜ ÿ≥ÿß ÿßŸÖ€åÿØŸàÿßÿ± ⁄©€åÿ±€å ⁄©€í ÿÆŸÑÿßŸÅ Ÿàÿßÿ≠ÿØ ÿ≠ŸÇ€åŸÇ€å ŸÖÿØŸÖŸÇÿßÿ®ŸÑ ÿ≥ŸÖÿ¨⁄æÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿü</td>\n      <td>ÿß€å⁄àŸàÿ±⁄àÿ≤</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1094</th>\n      <td>ÿßŸÖÿ±€å⁄©€Å ŸÖ€å⁄∫ ÿßŸÅÿ±ÿßÿØ ⁄©€å ÿ∑ÿ±ŸÅ ÿ≥€í ÿ¥ÿ±Ÿàÿπ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€í ⁄©€Å SAMs ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n      <td>ŸÖ€åŸÜ Ÿæ€å⁄àÿ≥</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1097</th>\n      <td>€Åÿßÿ±Ÿæÿ± ŸÑ€å ŸÜ€í ÿßŸæŸÜÿß ÿ®⁄ÜŸæŸÜ ⁄©ÿ≥ ÿ±€åÿßÿ≥ÿ™ ŸÖ€å⁄∫ ⁄Øÿ≤ÿßÿ±ÿßÿü</td>\n      <td>ÿßŸÑÿßÿ®ÿßŸÖÿß</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1100</th>\n      <td>⁄©ŸÖ ÿßŸàÿ± ÿßÿπŸÑ€å ⁄Øÿ±€å⁄à ŸÖ€åŸπÿßŸÖŸàÿ±ŸÅ⁄© ⁄ÜŸπÿßŸÜŸà⁄∫ ÿ≥€í ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©€å ÿ™ÿ¥⁄©€åŸÑ ⁄©ÿß ÿßÿ¥ÿßÿ±€Å ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n      <td>⁄Øÿ±€åŸÜ ÿßÿ≥ŸπŸàŸÜ</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1130</th>\n      <td>⁄à€å ⁄ØÿßŸÑ ⁄©€í Ÿæÿßÿ≥ ⁄©€åÿß ÿØÿ±ÿ¨€Å ÿ™⁄æÿßÿü</td>\n      <td>ÿ¨ŸÜÿ±ŸÑ</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1284</th>\n      <td>ŸÖ€åŸÑÿ®Ÿàÿ±ŸÜ ⁄©Ÿæ ⁄©€å Ÿæ€ÅŸÑ€å ÿØŸà⁄ë ⁄©ÿ≥ ÿ≥ÿßŸÑ €ÅŸàÿ¶€å ÿ™⁄æ€åÿü</td>\n      <td>1861</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1315</th>\n      <td>ÿ¨Ÿà ⁄à€åŸà⁄à ÿ®ŸàŸà€å ÿ≥ŸÜ ⁄©ÿ± ŸæŸÑÿß ÿ®⁄ë⁄æÿßÿü</td>\n      <td>ŸÖ€å⁄àŸàŸÜÿß</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1323</th>\n      <td>⁄à⁄Ü ÿßŸàÿ± ÿßŸÜ⁄Øÿ±€åÿ≤€å ⁄©€í ŸÖÿßÿ®€åŸÜ ŸÇÿ±ÿ∂€í ⁄©€í ÿßŸÑŸÅÿßÿ∏ ⁄©€í ÿßÿ¥ÿ™ÿ±ÿß⁄© ŸÖ€å⁄∫ ÿå ⁄©ÿ≥ ÿ≤ÿ®ÿßŸÜ ⁄©Ÿà ŸÇÿ±ÿ∂€í ⁄©€í ÿßŸÑŸÅÿßÿ∏ ⁄©ÿß ÿ≤€åÿßÿØ€Å ŸÅ€åÿµÿØ ŸÖŸÑÿßÿü</td>\n      <td>⁄à⁄Ü</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1399</th>\n      <td>⁄©ŸàŸπ⁄© ⁄©ÿ≥ ⁄©ŸÖŸæŸÜ€å ⁄©ÿß ÿ≥€å ÿß€å ÿßŸà €Å€íÿü</td>\n      <td>ÿß€å⁄©Ÿπ€åŸà€åÿ¥ŸÜ ÿ®ŸÑ€åÿ≤ÿßÿ±⁄à</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1472</th>\n      <td>⁄©ŸàŸÜ ÿ≥Ÿà⁄Üÿ™ÿß ÿ™⁄æÿß ⁄©€Å ŸÅÿß⁄©ÿ≥ ÿßŸàÿ± ÿ®ÿ±⁄© ⁄©€å ÿØŸàÿ≥ÿ™€å ⁄©⁄æŸà ⁄Ø€åÿß ÿ™⁄æÿßÿü</td>\n      <td>ÿ®ÿ±⁄©</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1487</th>\n      <td>⁄©ÿ≥ ÿßŸÜÿØÿ±ŸàŸÜ€å ÿ¨ÿ≤Ÿà ŸÖ€å⁄∫ ⁄©ÿßŸÅ€å ÿ≠ÿØ ÿ™⁄© ŸÜÿ∏ÿ± ÿ´ÿßŸÜ€å ⁄©€å ⁄Øÿ¶€å €Å€íÿü</td>\n      <td>ÿØÿ±ÿ¨€Å ÿ®ŸÜÿØ€å</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1498</th>\n      <td>ŸÜŸÖ€åÿ®€åÿß ŸÖ€å⁄∫ ⁄©ŸàŸÜ ÿ≥€å Ÿàÿ®ÿß ÿß€å⁄© ÿ®⁄ëÿß ŸÖÿ≥ÿ¶ŸÑ€Å €Å€íÿü</td>\n      <td>ÿß€å⁄àÿ≤</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1538</th>\n      <td>ÿßÿ≥ ÿßÿ≥⁄©Ÿàÿ± ⁄©Ÿà ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n      <td>⁄à€å ÿßÿ≥⁄©Ÿàÿ±</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1740</th>\n      <td>ÿ¨Ÿà ŸÑÿßÿ¨ÿ≤ ÿ¨€å ÿß€åŸÑ ÿß€å ⁄©€å ÿ™ÿßÿ¶€åÿØ ŸÜ€Å€å⁄∫ ⁄©ÿ± ÿ≥⁄©ÿ™€í ÿ™⁄æ€í ÿßŸÜ€Å€å⁄∫ ÿ®ÿπÿØ ŸÖ€å⁄∫ ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿü</td>\n      <td>ÿ¨ÿØ€åÿØ</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1783</th>\n      <td>ÿ¥ŸàŸæŸÜ ⁄©€í ŸàÿßŸÑÿØ ⁄©ÿß Ÿæ€ÅŸÑÿß ŸÜÿßŸÖ ⁄©€åÿß ÿ™⁄æÿßÿü</td>\n      <td>ŸÜ⁄©ŸàŸÑÿ≥</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1806</th>\n      <td>ŸÖÿ¥ÿ±ŸÇ€å ÿßŸÜ⁄ØŸÑ€åŸÜ⁄à ⁄©€í ÿ≥ÿßÿ™⁄æ ÿ≥ÿßÿ™⁄æ ÿå ÿßŸÜ⁄ØŸÑ€åŸÜ⁄à ⁄©€í ⁄©ÿ≥ ÿ≠ÿµ€í ŸÖ€å⁄∫ ÿßÿ≥⁄©€åŸÜ⁄à€åŸÜ€åŸà€åŸÜ ŸÜ⁄òÿßÿØ ÿ®€Åÿ™ ÿ≥€í ŸÖŸÇÿßŸÖÿßÿ™ ⁄©€í ŸÜÿßŸÖ €Å€å⁄∫ÿü</td>\n      <td>ÿ¥ŸÖÿßŸÑ€å</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1818</th>\n      <td>Ÿπ⁄æŸÜ⁄à€å ÿßÿ¥€åÿßÿ° ⁄©€åÿß €Å€å⁄∫ ⁄©€Å ÿßÿ¥€åÿßÿ° ⁄©€í ŸÖŸÇÿßÿ®ŸÑ€í ŸÖ€å⁄∫ ⁄©ŸÖ ⁄ÜŸÖ⁄©ÿü</td>\n      <td>⁄Øÿ±ŸÖ</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1824</th>\n      <td>ÿ¨ÿ≥ ⁄©€í ŸÖÿ∂ÿ®Ÿàÿ∑ ⁄à⁄æÿßŸÜ⁄Ü€í ÿ®ÿßŸæ €åÿß ÿ®€åŸπ€í ⁄©€å ÿ¥⁄©ŸÑ ŸÖ€å⁄∫ €Å€å⁄∫ÿü</td>\n      <td>ÿ®€åŸπŸà⁄∫</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1838</th>\n      <td>ÿ¥ŸàŸæŸÜ ⁄©€Åÿß⁄∫ ŸæŸÑÿß ÿ®⁄ë⁄æÿßÿü</td>\n      <td>Ÿàÿßÿ±ÿ≥ÿß</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1934</th>\n      <td>ŸÇŸàŸÖŸà⁄∫ ⁄©€í ÿ¥€Åÿ±€åŸà⁄∫ ⁄©€í ÿ∑Ÿàÿ± Ÿæÿ± ⁄©ÿ≥ ⁄©Ÿà ŸÖŸÇÿ±ÿ± ⁄©€åÿß ⁄Ø€åÿß €Å€íÿü</td>\n      <td>ÿßÿπÿ≤ÿßÿ≤€å ŸÜÿßÿ¶Ÿπ</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2049</th>\n      <td>ÿßÿ≥ ⁄©€å ŸÜÿß⁄©ÿßŸÖ€å ÿ≥€í Ÿæ€ÅŸÑ€íÿå ⁄©ŸàŸÜ ÿ≥ÿß ÿ®⁄Üÿ™ ÿßŸàÿ± ŸÇÿ±ÿ∂ ÿß€åÿ≥Ÿàÿ≥€å ÿß€åÿ¥ŸÜ ÿ±€åÿßÿ≥ÿ™€Åÿßÿ¶€í ŸÖÿ™ÿ≠ÿØ€Å ŸÖ€å⁄∫ ÿ≥ÿßÿ™Ÿà€å⁄∫ ÿ≥ÿ® ÿ≥€í ÿ®⁄ëÿß ÿ±€ÅŸÜ ÿßÿ®ÿ™ÿØÿßÿ¶€å ÿ™⁄æÿßÿü</td>\n      <td>ÿßŸÜ⁄à€å ŸÖ€å⁄© ÿ®€åŸÜ⁄©</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2194</th>\n      <td>ÿØ€å⁄Øÿ± ÿ®ÿ±ÿ∑ÿßŸÜŸà€å ÿ±€åÿßÿ≥ÿ™Ÿà⁄∫ ÿßŸàÿ± ⁄©ÿßŸÑŸàŸÜ€åŸà⁄∫ ŸÜ€í ÿ≥ÿßŸÑ ⁄©€å ÿ¥ÿ±Ÿàÿπÿßÿ™ ⁄©€å ÿ™ÿßÿ±€åÿÆ €å⁄©ŸÖ ÿ¨ŸÜŸàÿ±€å ⁄©ÿ® ŸÖŸÇÿ±ÿ± ⁄©€åÿü</td>\n      <td>1752</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2197</th>\n      <td>⁄©€Åÿß⁄∫ Broz Belousova ÿ≥€í ÿ¥ÿßÿØ€å ⁄©€åÿü</td>\n      <td>ÿßŸàŸÖÿ≥⁄©</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2207</th>\n      <td>ÿ®⁄ÜŸà⁄∫ ⁄©€å ŸÖÿ≤ÿØŸàÿ±€å ⁄©€å ŸÅÿ±ÿß€ÅŸÖ€å ÿßŸàÿ± ÿßÿ≥ ⁄©€å ⁄©€åÿß Ÿàÿ¨Ÿà€Åÿßÿ™ €Å€å⁄∫ ÿ¨Ÿà ÿ¢ÿ¨ ÿ®⁄æ€å ŸÖŸàÿ¨ŸàÿØ €Å€å⁄∫ÿü</td>\n      <td>ÿ∑ŸÑÿ®</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2215</th>\n      <td>ÿ∑ÿßŸÑÿ® ÿπŸÑŸÖŸà⁄∫ ⁄©Ÿà ⁄Ü€åŸÜ€å ÿ≠ÿ±ŸàŸÅ ÿ≥⁄©⁄æÿßŸÜ€í ⁄©€í ŸÑ€å€í ÿß⁄©ÿ´ÿ± ⁄©€åÿß ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n      <td>ÿ®ÿßŸÇÿßÿπÿØ€Å ÿßÿ≥⁄©ÿ±ŸæŸπ ŸÅŸàŸÜŸπ</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2274</th>\n      <td>€ÅŸÜÿØŸà ÿßÿ≥⁄©ŸàŸÑŸà⁄∫ ŸÖ€å⁄∫ ÿ≥€í ÿ≥ÿ® ÿ≥€í ÿ≤€åÿßÿØ€Å ÿ™ÿ±ŸÇ€å €åÿßŸÅÿ™€Å ÿßŸàÿ± ŸÖÿ¥€ÅŸàÿ± ⁄©ŸàŸÜ ÿ≥ÿß €Å€íÿü</td>\n      <td>Ÿà€åÿØÿßŸÜÿ™ÿß</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2401</th>\n      <td>Ÿæÿ±ŸÜÿØŸà⁄∫ ⁄©€í ⁄©ÿ™ŸÜ€í ÿ®⁄ë€í ŸÅŸÑÿßÿ¶Ÿπ ŸæŸπ⁄æŸà⁄∫ €ÅŸàÿ™€í €Å€å⁄∫ÿü</td>\n      <td>ÿØŸà</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2447</th>\n      <td>⁄©€åŸÜ€í ŸÜ€í ÿ≠ÿßÿØÿ´€í ⁄©€í ÿ®ÿπÿØ ÿ¨Ÿà ⁄©⁄Ü⁄æ €ÅŸàÿß ÿßÿ≥ ⁄©€í ÿ™ÿ¨ÿ±ÿ®€í ⁄©€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫ ⁄©€åÿß ⁄ØÿßŸÜÿß ÿ±€å⁄©ÿßÿ±⁄à ⁄©€åÿßÿü</td>\n      <td>ÿ™⁄æÿ±Ÿà ÿØ€å Ÿàÿßÿ¶ÿ±</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2458</th>\n      <td>ÿß€åŸàÿßŸÜ ŸÖ€å⁄∫ ÿßŸÇŸÑ€åÿ™€å Ÿæÿßÿ±Ÿπ€å ⁄©ÿß ÿ±€ÅŸÜŸÖÿß ⁄©ŸàŸÜ €Å€íÿü</td>\n      <td>ÿßŸÇŸÑ€åÿ™</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2473</th>\n      <td>⁄©€åÿß ŸÜŸàÿ¨ŸàÿßŸÜ ÿ®⁄ë€í €åÿß ⁄Ü⁄æŸàŸπ€í Ÿæ€åŸÖÿßŸÜ€í Ÿæÿ± \"⁄©ŸÑ⁄©ÿ≥\" ⁄©€í ÿ≥ÿßÿ™⁄æ ŸÖŸÑÿ™€í €Å€å⁄∫ÿü</td>\n      <td>⁄Ü⁄æŸàŸπ€í</td>\n      <td></td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"\n‚úÖ Side-by-Side Comparison (First 10 Rows - Mixed):\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                                                                                            Question  \\\n0                                                                                  ⁄©ÿ≥ ÿ≥ÿßŸÑ ŸÖ€å⁄∫ ⁄à€åŸπŸàŸÜ ⁄©€í ÿÆÿ¥⁄© ÿ≥ÿßŸÖÿßŸÜ ÿ®ŸÜÿØ ⁄©ÿ± ÿØ€åÿß ⁄Ø€åÿß ÿ™⁄æÿßÿü   \n1                                                                                         ⁄ØŸàÿ±ÿ®ÿß⁄ÜŸàŸÅ ŸÜ€í ⁄©€åÿß ÿ™ÿÆŸÑ€åŸÇ ⁄©ÿ±ŸÜ€í ⁄©€å ÿßŸÖ€åÿØ ⁄©€å ÿ™⁄æ€åÿü   \n2                                                            2006 ŸÖ€å⁄∫ ⁄©ŸàŸÜÿ≥ŸÑ ÿ¢ŸÜ ŸÅÿßÿ±ŸÜ ÿ±€åŸÑ€åÿ¥ŸÜÿ≤ ŸÖ€å⁄∫ ŸàÿßŸÜ ŸÜ€åŸàŸÖŸÜ ŸÜ€í ⁄©€åÿß ÿß€åÿ¨ŸÜ⁄àÿß Ÿæ€åÿ¥ ⁄©€åÿß ÿ™⁄æÿßÿü   \n3                                                                      €åÿ≥Ÿàÿπ ⁄©€í ÿ®ÿßŸÑÿ∫ €ÅŸàŸÜ€í ⁄©€å ŸÅŸÜ⁄©ÿßÿ±ÿßŸÜ€Å ÿ™ÿµŸà€åÿ± ⁄©ÿ¥€åŸà⁄∫ ⁄©Ÿà ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n4                                                                                                                UF6 ⁄©ŸàŸÜ ÿ≥ÿß ŸÖÿ±⁄©ÿ® €Å€íÿü   \n5                                                       ⁄àÿ≥ŸæŸÑ€í ÿ±€åÿ≤ŸàŸÑŸàÿ¥ŸÜ ŸÖÿßÿ±⁄©€åŸπ ŸÖ€å⁄∫ ÿ≤€åÿßÿØ€Å ÿ™ÿ± ÿ≥ŸæŸÑÿßÿ¶ÿ±ÿ≤ ŸÜ€í 2010 ⁄©€å ÿØ€Åÿßÿ¶€å ŸÖ€å⁄∫ ⁄©€åÿß Ÿæ€åÿ¥ ⁄©€åÿßÿü   \n6                                                                                  Algernon ÿ≥⁄àŸÜ€å ⁄©€åÿß ⁄©€í ŸÑÿ¶€í ÿß€å⁄© ÿÆÿ∑ÿ±€Å ÿ≥ŸÖÿ¨⁄æÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿü   \n7                                                                                                           ⁄©Ÿàÿ≤ÿßŸÜ ⁄©ÿ≥ ⁄Ü€åÿ≤ ÿ≥€í ÿ®ŸÜ€í ÿ™⁄æ€íÿü   \n8                                                                                          Cynanthus latirostris ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©ÿß Ÿæÿ±ŸÜÿØ€Å €Å€íÿü   \n9                                                                                           ÿßÿ≥ ⁄©€å ŸÖŸàÿ™ ⁄©€í ÿ®ÿπÿØ Ÿà€åŸàÿ± ⁄©€í ŸÑÿ¶€í ⁄©ŸàŸÜ ŸÑ€í ŸÑ€åÿßÿü   \n10                                                                                                        ÿ®ŸÑŸÇÿßŸÜ ⁄©€å ÿ¨ŸÜ⁄Ø€å⁄∫ ⁄©€Åÿß⁄∫ €ÅŸàÿ¶€å⁄∫ÿü   \n11                                                                                  ÿ¨ÿ® ÿ¢ÿ±ÿßŸÖ ŸÖ€å⁄∫ÿå ÿß€å⁄© ÿ∑ŸàŸÑ Ÿà ÿπÿ±ÿ∂ ⁄©€å ÿ±ŸÅÿ™ÿßÿ± ⁄©ÿ™ŸÜ€å ÿ™€åÿ≤ €Å€íÿü   \n12                                                                                  ⁄©ÿ±ŸàŸÖŸàÿ≥ŸàŸÖŸà⁄∫ ⁄©€å ⁄©ŸÑ ⁄ØŸÜÿ™€å ⁄©€í ŸÑÿ¶€í ÿß€å⁄© ÿßŸàÿ± ŸÑŸÅÿ∏ ⁄©€åÿß €Å€íÿü   \n13                                                                                        813 ŸÖ€å⁄∫ ⁄Üÿßÿ±ŸÑŸÖ€åŸÜ ⁄©ÿß Ÿàÿßÿ≠ÿØ ÿ≤ŸÜÿØ€Å ÿ®€åŸπÿß ⁄©ŸàŸÜ ÿ™⁄æÿßÿü   \n14                                                                                                     ÿ®ÿ±Ÿπ €Å€åŸÖ ⁄©ÿß ŸÖÿßÿ±⁄©€åŸπ ŸÜÿßŸÖ ⁄©€åÿß €Å€íÿü   \n15                                                                     ⁄©ÿ≥ ÿ≥ÿßŸÑ ŸÖ€å⁄∫ ÿß€åŸÜ ÿ¢ÿ±ÿ®ÿ± Ÿæÿ®ŸÑ⁄© ÿßÿ≥⁄©ŸàŸÑŸà⁄∫ ŸÖ€å⁄∫ 16ÿå935 ÿ∑ŸÑÿ®ÿßÿ° ÿ±ÿ¨ÿ≥Ÿπÿ±⁄à ÿ™⁄æ€íÿü   \n16                                                                      ÿ≥ÿ≥ÿ™€å €ÅŸàŸÜ€í ⁄©€í ÿπŸÑÿßŸà€Å ÿå Ÿæÿ±Ÿàÿ≥€åÿ≥⁄à ŸÅŸà⁄àÿ≤ ⁄©€å ÿß€å⁄© ÿßŸàÿ± ÿß€ÅŸÖ ⁄©ÿ¥ÿ¥ ⁄©€åÿß €Å€íÿü   \n17                                                                   ⁄©ÿ≥ ÿ≥ÿßŸÑ ŸÖ€å⁄∫ ŸÅÿ±€å⁄à€å ÿßŸàÿ± ÿÆŸàÿßÿ® ÿØ€å⁄©⁄æŸÜ€í ŸàÿßŸÑŸà⁄∫ ⁄©Ÿà ÿßŸÜ ⁄©€å Ÿæ€ÅŸÑ€å €ÅŸπ ŸÖŸÑ ⁄Øÿ¶€åÿü   \n18                             ŸÜÿ¶€í ÿ≥€å Ÿæ€å €åŸà ŸÅŸÜ ÿ™ÿπŸÖ€åÿ± ŸÖ€å⁄∫ ⁄©ÿßŸÖ€åÿßÿ®€å ⁄©€í ÿ≥ÿßÿ™⁄æ ŸÖŸÜÿ™ŸÇŸÑ€å ⁄©€í ŸÑÿ¶€í Ÿàÿßÿ≠ÿØ ŸÖÿ±⁄©ÿ≤€å ÿØ⁄æÿßÿ±€í ⁄©€í ⁄©ŸÖŸæ€åŸàŸπÿ± ŸæŸÑ€åŸπ ŸÅÿßÿ±ŸÖ ⁄©€åÿß €Å€íÿü   \n19                                          ÿ≥€åÿß€Å ŸÅÿßŸÖ ÿßŸàÿ± ÿß€åÿ¥€åÿßÿ¶€å ÿßÿ≥⁄©ŸàŸÑ ⁄©€í ÿ®⁄ÜŸà⁄∫ ⁄©ÿß ÿ≥ŸÅ€åÿØ ŸÅÿßŸÖ ÿßÿ≥⁄©ŸàŸÑ ⁄©€í ÿ®⁄ÜŸà⁄∫ ⁄©€í ŸÖŸÇÿßÿ®ŸÑ€í ŸÖ€å⁄∫ ⁄©€åÿß ÿ™ŸÜÿßÿ≥ÿ® €Å€íÿü   \n20                                                                  ÿπÿ∑€åÿßÿ™ Ÿæÿ± ÿßŸÜÿ≠ÿµÿßÿ± ⁄©ÿ±ŸÜ€í ŸàÿßŸÑ€å ÿ¨ŸÖÿßÿπÿ™Ÿà⁄∫ ⁄©Ÿà ⁄©ÿ® ŸÖÿ≥ÿßÿ¶ŸÑ ⁄©ÿß ÿ≥ÿßŸÖŸÜÿß ⁄©ÿ±ŸÜÿß Ÿæ⁄ëÿßÿü   \n21                                                                                            ÿ≥ÿ≥ŸÑ€å ÿ≥€í ŸæÿßŸÑÿ±ŸÖŸà ÿ™⁄© Ÿæ€ÅŸÜ⁄ÜŸÜÿß ⁄©€åŸà⁄∫ ŸÖÿ¥⁄©ŸÑ €Å€íÿü   \n22                                                         ⁄©ŸàŸÜ ÿ≥ÿß€åŸÜŸπŸàŸÑŸàÿ¨€å ŸÖ€å⁄∫ ÿßÿµŸÑÿßÿ≠ÿßÿ™ ŸÑÿß€åÿß ÿ¨ÿ≥ ÿ≥€í ÿπŸÑ€åÿ≠ÿØ€Å ⁄Øÿ±Ÿà€ÅŸà⁄∫ ⁄©Ÿà ÿ®ÿØÿπÿ™ ŸÇÿ±ÿßÿ± ÿØ€åÿß ⁄Ø€åÿßÿü   \n23                                                                             ŸÖÿßÿ§ ⁄©Ÿà ÿ¨ŸÜŸàÿ®€å ⁄©Ÿàÿ±€åÿß ⁄©€í ÿ≠ŸÖŸÑ€í ⁄©€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫ ⁄©€åÿß ÿ™ÿ¥Ÿà€åÿ¥ ÿ™⁄æ€åÿü   \n24                                                                                 ÿ±ÿßÿ¶ŸÑ ÿßŸÜÿ≥Ÿπ€å Ÿπ€åŸàŸπ ⁄©€í ⁄©ÿßÿ±Ÿàÿ®ÿßÿ±€å ÿ¢Ÿæÿ±€åÿ¥ŸÜ ⁄©ÿß ŸÜÿßŸÖ ⁄©€åÿß €Å€íÿü   \n25                                                                                    ÿ¢ÿÆÿ±€å ŸæŸàŸæ ŸÜ€í ⁄©ÿ≥ ÿ™ÿßÿ±€åÿÆ ⁄©Ÿà ÿß€åÿ®€å ŸÖ€å⁄∫ ŸÇÿØŸÖ ÿ±⁄©⁄æÿß ÿ™⁄æÿßÿü   \n26                                                                                ⁄©ŸÑŸàÿ±ŸàŸÅŸÑ ⁄©ÿ≥ ⁄Ü€åÿ≤ ⁄©Ÿà ÿ™Ÿà⁄ëŸÜ€í ŸÖ€å⁄∫ ÿß€ÅŸÖ ⁄©ÿ±ÿØÿßÿ± ÿßÿØÿß ⁄©ÿ±ÿ™ÿß €Å€íÿü   \n27                                                                 ⁄©ÿ≥ ŸÅ€åÿµŸÑ€í ŸÜ€í ŸÇÿ∞ÿßŸÅ€å ⁄©Ÿà ŸÑ€åÿ®€åÿß ⁄©Ÿà ÿ≥Ÿàÿ¥ŸÑÿ≤ŸÖ ⁄©€í ŸÇÿ±€åÿ® ŸÑ€í ÿ¨ÿßŸÜ€í ⁄©€å ÿßÿ¨ÿßÿ≤ÿ™ ÿØ€åÿü   \n28                                                                                 ÿ≠ÿ±€åŸÅ ŸÅÿßÿ¶ŸÜŸÑ ŸÖ€å⁄∫ ÿßÿ®ÿ™ÿØÿßÿ¶€å ÿ∑Ÿàÿ± Ÿæÿ± ⁄©ÿ™ŸÜ€í ⁄ØÿßŸÜ€í ⁄Øÿßÿ™€í €Å€å⁄∫ÿü   \n29                                                                                 ÿ¨ÿ∞ÿ®ÿßÿ™€å ŸÖÿ≤ÿßÿ¨ ⁄©ÿ≥ ÿØŸàÿ≥ÿ±€å ÿÆÿµŸàÿµ€åÿ™ ÿ≥€í ŸÖÿ¥ÿßÿ®€Åÿ™ ŸÜ€Å€å⁄∫ ÿ±⁄©⁄æÿ™ÿßÿü   \n30                                        ÿ®ÿ±ŸÖŸàÿØÿß ŸÖ€å⁄∫ ÿ≥€åÿß€Å ŸÅÿßŸÖ ŸÑŸà⁄ØŸà⁄∫ ⁄©€å ÿß⁄©ÿ´ÿ±€åÿ™ ⁄©ÿß ÿ≠ŸàÿßŸÑ€Å ÿØ€åŸÜ€í ⁄©€í ŸÑÿ¶€í ⁄©ÿ≥ ÿßÿµÿ∑ŸÑÿßÿ≠ ⁄©ÿß ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü   \n31                                                                        ŸπŸà⁄à€í ⁄àÿßŸπ ⁄©ÿßŸÖ Ÿæÿ± ÿå ŸÖ€åŸπ ÿ≤ŸàŸÑÿ± ÿ≥€åŸπÿ≤ ŸÜ€í ŸÅŸÑŸÖ ⁄©Ÿà ⁄©ÿ™ŸÜ€í ÿ≥ÿ™ÿßÿ±€í ÿØ€åÿ¶€íÿü   \n32                                                                           ÿ≥ŸÑÿ∑ŸÜÿ™ ÿπÿ´ŸÖÿßŸÜ€å€Å ⁄©€í ÿØŸàÿ±ÿßŸÜÿå ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©€í ÿßÿ≥⁄©ŸàŸÑ ÿ∫€åÿ± ŸÖÿπŸÖŸàŸÑ€å ÿ™⁄æ€íÿü   \n33                                                              2008 ⁄©€í Ÿàÿ≥ÿ∑ ŸÖ€å⁄∫ ÿ±€åÿßÿ≥ÿ™€Åÿßÿ¶€í ŸÖÿ™ÿ≠ÿØ€Å ŸÖ€å⁄∫ ⁄Ø⁄æÿ± ⁄©€å ÿß€å⁄©Ÿà€åŸπ€å ⁄©€å ŸÇ€åŸÖÿ™ ⁄©ÿ™ŸÜ€å ÿ™⁄æ€åÿü   \n34                                                                                      ŸÜÿßÿ±ŸÖŸÜ ŸÜ€í ÿßŸæŸÜ€í ⁄©ÿßŸÖ ⁄©Ÿà ⁄©ÿ≥ ŸÖ€å⁄Øÿ≤€åŸÜ ŸÖ€å⁄∫ ÿ¥ÿßÿ¶ÿπ ⁄©€åÿßÿü   \n35                                                                                                    ÿ¥ŸàŸæŸÜ ŸÜ€í ⁄©ŸàŸÜ ÿ≥ÿß ÿ™ÿµŸàÿ± ÿ™ÿÆŸÑ€åŸÇ ⁄©€åÿßÿü   \n36                                                                             ÿ™⁄©ŸÜ€å⁄©€å ÿ™ÿ®ÿØ€åŸÑ€å ⁄©€í ŸÜÿ™€åÿ¨€í ŸÖ€å⁄∫ ⁄©€åÿß ÿ≤€åÿßÿØ€Å ŸÖ€ÅŸÜ⁄Øÿß €ÅŸà ÿ±€Åÿß €Å€íÿü   \n37                                                                                     ŸÖ€å⁄àŸàŸÜÿß ŸÜ€í ÿßŸæŸÜ€å ÿØŸàÿ≥ÿ±€å ⁄©Ÿæ⁄ë€í ⁄©€å ŸÑÿßÿ¶ŸÜ ⁄©ÿ® ÿ¨ÿßÿ±€å ⁄©€åÿü   \n38                                                                                                   De Re Aedificatoria ⁄©ÿ≥ ŸÜ€í ŸÑ⁄©⁄æÿßÿü   \n39  ÿµÿßÿ±ŸÅ€åŸÜ ⁄©Ÿà ÿßŸæŸÜ€å ŸÖŸàÿ≥€åŸÇ€å ⁄©Ÿà ÿßŸÜ⁄©Ÿà⁄à ⁄©ÿ±ÿ™€í ŸàŸÇÿ™ ⁄©€åÿß ŸÇÿØÿ± ÿ¨ÿßŸÜŸÜ€í ⁄©€å ÿ∂ÿ±Ÿàÿ±ÿ™ €Å€í ÿ™ÿß⁄©€Å ÿßŸÜ€Å€å⁄∫ €Åÿ± ŸÖŸàÿ≥€åŸÇ€å ⁄©€í Ÿπ⁄©⁄ë€í Ÿæÿ± Ÿπ€åÿ≥Ÿπ ⁄©ÿ±ŸÜ€í ÿ≥€í ÿ®⁄ÜŸÜ€í ŸÖ€å⁄∫ ŸÖÿØÿØ ŸÖŸÑ€íÿü   \n40                                                                                                             ÿßŸÖÿßÿ≥€åÿß ⁄©€å ÿßŸÖŸÜ ⁄©ÿ® ÿ™⁄æ€åÿü   \n41                                                                  Ÿà€å⁄à€åŸà ŸÑÿß ÿß€åÿ≥Ÿπÿß ÿ®ŸàŸÜŸπÿß ⁄©€í ŸÑÿ¶€í ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©€í €Åÿ≥ŸæÿßŸÜŸà€å ⁄©Ÿæ⁄ë€í Ÿæ€ÅŸÜ€í ⁄Øÿ¶€í ÿ™⁄æ€íÿü   \n42                                                        19 Ÿà€å⁄∫ ÿµÿØ€å ⁄©€í ÿ¢ÿÆÿ± ŸÖ€å⁄∫ ⁄©ÿ≥ ÿ¨ÿßÿ¶€åÿØÿßÿØ ⁄©€í ÿ™ÿßÿ¨ÿ± ŸÜ€í ÿ¨ÿßÿ¶€åÿØÿßÿØ ⁄©Ÿà Ÿàÿ±ÿßÿ´ÿ™ ŸÖ€å⁄∫ ÿ≠ÿßÿµŸÑ ⁄©€åÿßÿü   \n43                                                                                               Close Encounters ŸÜ€í ⁄©ÿ™ŸÜ€í ÿ¢ÿ≥⁄©ÿ± ÿ¨€åÿ™€íÿü   \n44                                                                               2005 ÿ™⁄© ŸÅÿßÿ±ŸÖŸàŸÑÿß ŸÅŸàÿ±⁄à ⁄Ü€åŸÖŸæÿ¶ŸÜ ÿ¥Ÿæ ŸÖ€å⁄∫ ⁄©ÿ≥ ŸÜ€í ÿØŸà⁄ë ŸÑ⁄Øÿßÿ¶€åÿü   \n45                                                                                                          \"Ÿæ€åŸÜÿ≥€åŸÑ Ÿπ€åÿ≥Ÿπ\" ⁄©ÿ≥ ŸÜ€í ⁄©€åÿßÿü   \n46                                                                                           ŸÖÿßŸÅŸàŸÇ ÿßŸÑŸÅÿ∑ÿ±ÿ™ ŸÖŸàÿ¨ŸàÿØÿßÿ™ ⁄©€åÿ≥€í ⁄©ÿßŸÖ ⁄©ÿ±ÿ™€í €Å€å⁄∫ÿü   \n47                                                   ⁄©ŸÑŸÜŸπŸÜ ⁄©€å ŸÖÿØÿ™ ⁄©€í ÿØŸàÿ±ÿßŸÜ ⁄©ŸàŸÜ ÿ≥ÿß ÿÆŸàŸÅŸÜÿß⁄© ŸàÿßŸÇÿπ€Å ÿ¨ÿßÿ±€å ÿ™⁄æÿß ÿ¨ÿ≥ ŸÜ€í ŸÑŸà⁄ØŸà⁄∫ ⁄©Ÿà Ÿæÿ±€åÿ¥ÿßŸÜ ⁄©ÿ±ÿØ€åÿßÿü   \n48                                                           ⁄©ŸàŸÜ ÿ≥ÿß ŸÅŸÜ⁄©ÿßÿ± ÿ®€åŸàŸÜÿ≥€í ⁄©€å Ÿæÿ±€åŸÖ€åÿ¶ÿ± ÿ≥ŸàŸÑŸà ÿ±€å⁄©ÿßÿ±⁄àŸÜ⁄Ø ⁄©€í ÿ≥ÿßÿ™⁄æ ŸÖŸÜÿ≥ŸÑ⁄© ⁄©€åÿß ⁄Ø€åÿß ÿ™⁄æÿßÿü   \n49                ⁄©ÿßÿ±ÿ®ŸàŸÜ€åŸÅ€åÿ±ÿ≥ ⁄©€í ÿπŸÑÿßŸà€Å ÿå ⁄©ŸàŸÜ ÿ≥ÿß ÿØŸàÿ≥ÿ±ÿß ⁄©€å⁄ë€í ⁄©ÿß ÿ¢ÿ±⁄àÿ± ŸÖŸàÿ¨ŸàÿØ€Å ⁄Øÿ±Ÿà€ÅŸà⁄∫ ÿå ÿßÿ≥Ÿπ€åŸÖ ⁄Øÿ±Ÿà€ÅŸà⁄∫ ÿßŸàÿ± Ÿæ€åŸÑ€åŸàÿ≤Ÿà⁄© ⁄Øÿ±Ÿà€ÅŸà⁄∫ ⁄©Ÿà ÿ¥ÿßŸÖŸÑ ⁄©ÿ±ÿ™ÿß €Å€íÿü   \n\n                                                                                                 Gold Answer  \\\n0                                                                                                              \n1                                                                                  ŸÜ€åÿß ÿ≥Ÿæÿ±€åŸÖ ŸÇÿßŸÜŸàŸÜ ÿ≥ÿßÿ≤ ÿßÿØÿßÿ±€Å   \n2                                                                                                              \n3                                                                                                              \n4                                                                                      €åŸàÿ±€åŸÜ€åŸÖ €Å€å⁄©ÿ≥ÿßŸÅŸÑŸàŸàÿ±ÿßÿ¶⁄à   \n5                                                                                                              \n6                                                                                                              \n7                                                                                               ŸÑŸà€Å€í €åÿß ⁄ÜŸÖ⁄ë€í   \n8                                                                                                  €ÅŸàŸÖŸÜ⁄Ø ÿ®ÿ±⁄à   \n9                                                                          ÿßŸÑÿ®ÿ±Ÿπ ⁄©€åÿ≥ŸÑŸÜ⁄Ø ÿßŸàÿ± €ÅŸÜÿ≥ ÿ¨Ÿàÿ±⁄ØŸÜ ÿßÿ≥ŸπŸÖŸæŸÅ   \n10                                                                                           ÿ¨ŸÜŸàÿ® ŸÖÿ¥ÿ±ŸÇ€å €åŸàÿ±Ÿæ   \n11                                                                                                             \n12                                                                                                  ⁄©€åÿ±ŸàŸπÿßÿ¶Ÿæ   \n13                                                                                              ŸÑŸàÿ¶€å ÿØ€å Ÿæ€åŸàÿ≥   \n14                                                                                                             \n15                                                                                                             \n16                                                                                                ÿ≤€åÿßÿØ€Å ÿ¢ÿ≥ÿßŸÜ   \n17                                                                                                             \n18                                                                                                   ŸÖ€å⁄©ŸÜŸπŸàÿ¥   \n19                                                                                          ÿ™ŸÇÿ±€åÿ®ÿß ⁄Ü⁄æ ÿ≥€í ⁄Üÿßÿ±   \n20                                                                                ÿ®€åÿ≥Ÿà€å⁄∫ ÿµÿØ€å ⁄©€í ÿØŸàÿ≥ÿ±€í ŸÜÿµŸÅ ÿ≥€í   \n21                                                                                                             \n22                                                                                                             \n23                                                                                     ÿßŸÖÿ±€å⁄©€å ŸÖÿØÿßÿÆŸÑÿ™ ⁄©ÿ±€å⁄∫ ⁄Ø€í   \n24                                                                                           RIBA ÿßŸÜŸπÿ±Ÿæÿ±ÿßÿ¶ÿ≤ÿ≤   \n25                                                                                                             \n26                                                                                                             \n27  ÿ≥ÿ™ŸÖÿ®ÿ± 1973 ŸÖ€å⁄∫ ÿå €å€Å ÿßÿπŸÑÿßŸÜ ⁄©€åÿß ⁄Ø€åÿß ⁄©€Å ŸÑ€åÿ®€åÿß ŸÖ€å⁄∫ ÿ≥ÿ±⁄Øÿ±ŸÖ ÿ™ŸÖÿßŸÖ ÿ∫€åÿ± ŸÖŸÑ⁄©€å ÿ™€åŸÑ Ÿæÿ±Ÿà⁄à€åŸàÿ≥ÿ±Ÿà⁄∫ ⁄©Ÿà ŸÇŸàŸÖ€å ÿ®ŸÜÿß€åÿß ÿ¨ÿßÿ¶€í ⁄Øÿß€î   \n28                                                                                                       ÿß€å⁄©   \n29                                                                                                             \n30                                                                                          ÿ®ÿ±ŸÖŸà⁄à€åŸÜ ÿ≥€åÿß€Å ŸÅÿßŸÖ   \n31                                                                                                             \n32                                                                                                             \n33                                                                                           8.8 Ÿπÿ±€åŸÑ€åŸÜ ⁄àÿßŸÑÿ±   \n34                                                                                           ÿ≥⁄©ÿ±€åÿ®ŸÜÿ±ÿ≤ ŸÖ€å⁄Øÿ≤€åŸÜ   \n35                                                                                           ÿßŸÜÿ≥Ÿπÿ±ŸàŸÖŸÜŸπŸÑ ÿ®€åŸÑ⁄à   \n36                                                                                                             \n37                                                                                                ŸÜŸàŸÖÿ®ÿ± 2011   \n38                                                                                        ŸÑ€åŸàŸÜ ÿ®Ÿπ€åÿ≥Ÿπÿß ÿßŸÑÿ®ÿ±Ÿπ€å   \n39                                                                                            ŸÖÿπ€åÿßÿ± ⁄©€å ÿ™ÿ±ÿ™€åÿ®   \n40                                                                                         16 Ÿà€å⁄∫ ÿµÿØ€å ⁄©€í Ÿàÿ≥ÿ∑   \n41                                                                               ÿ®ŸàŸÑ€åÿ±Ÿàÿ≥ ÿßŸàÿ± Ÿæÿ±ÿ™Ÿà⁄∫ ŸàÿßŸÑ€å ÿ≥⁄©ÿ±Ÿπ   \n42                                                                                                             \n43                                                                                                        ÿØŸà   \n44                                                                                                             \n45                                                                                          ŸÖÿπŸÖŸàŸÑ€å ÿπ€ÅÿØ€åÿØÿßÿ±Ÿà⁄∫   \n46                                                                                              ŸÑŸà⁄ØŸà⁄∫ ⁄©€å ÿ∑ÿ±ÿ≠   \n47                                                                                            ÿ±ŸàÿßŸÜ⁄àÿß ŸÜÿ≥ŸÑ ⁄©ÿ¥€å   \n48                                                                                                     ÿ¨€í ÿ≤€å   \n49                                                                                             ÿßÿ®ÿ™ÿØÿßÿ¶€å Ÿæÿ±ŸÖ€åŸÜ   \n\n                     Extracted Answer  Match  \n0                                       True  \n1           ŸÜ€åÿß ÿ≥Ÿæÿ±€åŸÖ ŸÇÿßŸÜŸàŸÜ ÿ≥ÿßÿ≤ ÿßÿØÿßÿ±€Å   True  \n2                                       True  \n3                                       True  \n4               €åŸàÿ±€åŸÜ€åŸÖ €Å€å⁄©ÿ≥ÿßŸÅŸÑŸàŸàÿ±ÿßÿ¶⁄à   True  \n5                                       True  \n6                                       True  \n7                        ŸÑŸà€Å€í €åÿß ⁄ÜŸÖ⁄ë€í   True  \n8                           €ÅŸàŸÖŸÜ⁄Ø ÿ®ÿ±⁄à   True  \n9   ÿßŸÑÿ®ÿ±Ÿπ ⁄©€åÿ≥ŸÑŸÜ⁄Ø ÿßŸàÿ± €ÅŸÜÿ≥ ÿ¨Ÿàÿ±⁄ØŸÜ ÿßÿ≥ŸπŸÖŸæŸÅ   True  \n10                                     False  \n11                                      True  \n12                                     False  \n13                                     False  \n14                                      True  \n15                                      True  \n16                                     False  \n17                                      True  \n18                                     False  \n19                                     False  \n20                                     False  \n21                                      True  \n22                                      True  \n23                                     False  \n24                    RIBA ÿßŸÜŸπÿ±Ÿæÿ±ÿßÿ¶ÿ≤ÿ≤   True  \n25                                      True  \n26                                      True  \n27                                     False  \n28                                     False  \n29                                      True  \n30                                     False  \n31                                      True  \n32                                      True  \n33                    8.8 Ÿπÿ±€åŸÑ€åŸÜ ⁄àÿßŸÑÿ±   True  \n34                                     False  \n35                    ÿßŸÜÿ≥Ÿπÿ±ŸàŸÖŸÜŸπŸÑ ÿ®€åŸÑ⁄à   True  \n36                                      True  \n37                                     False  \n38                 ŸÑ€åŸàŸÜ ÿ®Ÿπ€åÿ≥Ÿπÿß ÿßŸÑÿ®ÿ±Ÿπ€å   True  \n39                                     False  \n40                                     False  \n41                                     False  \n42                                      True  \n43                                     False  \n44                                      True  \n45                   ŸÖÿπŸÖŸàŸÑ€å ÿπ€ÅÿØ€åÿØÿßÿ±Ÿà⁄∫   True  \n46                                     False  \n47                                     False  \n48                                     False  \n49                                     False  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Question</th>\n      <th>Gold Answer</th>\n      <th>Extracted Answer</th>\n      <th>Match</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>⁄©ÿ≥ ÿ≥ÿßŸÑ ŸÖ€å⁄∫ ⁄à€åŸπŸàŸÜ ⁄©€í ÿÆÿ¥⁄© ÿ≥ÿßŸÖÿßŸÜ ÿ®ŸÜÿØ ⁄©ÿ± ÿØ€åÿß ⁄Ø€åÿß ÿ™⁄æÿßÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>⁄ØŸàÿ±ÿ®ÿß⁄ÜŸàŸÅ ŸÜ€í ⁄©€åÿß ÿ™ÿÆŸÑ€åŸÇ ⁄©ÿ±ŸÜ€í ⁄©€å ÿßŸÖ€åÿØ ⁄©€å ÿ™⁄æ€åÿü</td>\n      <td>ŸÜ€åÿß ÿ≥Ÿæÿ±€åŸÖ ŸÇÿßŸÜŸàŸÜ ÿ≥ÿßÿ≤ ÿßÿØÿßÿ±€Å</td>\n      <td>ŸÜ€åÿß ÿ≥Ÿæÿ±€åŸÖ ŸÇÿßŸÜŸàŸÜ ÿ≥ÿßÿ≤ ÿßÿØÿßÿ±€Å</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2006 ŸÖ€å⁄∫ ⁄©ŸàŸÜÿ≥ŸÑ ÿ¢ŸÜ ŸÅÿßÿ±ŸÜ ÿ±€åŸÑ€åÿ¥ŸÜÿ≤ ŸÖ€å⁄∫ ŸàÿßŸÜ ŸÜ€åŸàŸÖŸÜ ŸÜ€í ⁄©€åÿß ÿß€åÿ¨ŸÜ⁄àÿß Ÿæ€åÿ¥ ⁄©€åÿß ÿ™⁄æÿßÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>€åÿ≥Ÿàÿπ ⁄©€í ÿ®ÿßŸÑÿ∫ €ÅŸàŸÜ€í ⁄©€å ŸÅŸÜ⁄©ÿßÿ±ÿßŸÜ€Å ÿ™ÿµŸà€åÿ± ⁄©ÿ¥€åŸà⁄∫ ⁄©Ÿà ⁄©€åÿß ⁄©€Åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>UF6 ⁄©ŸàŸÜ ÿ≥ÿß ŸÖÿ±⁄©ÿ® €Å€íÿü</td>\n      <td>€åŸàÿ±€åŸÜ€åŸÖ €Å€å⁄©ÿ≥ÿßŸÅŸÑŸàŸàÿ±ÿßÿ¶⁄à</td>\n      <td>€åŸàÿ±€åŸÜ€åŸÖ €Å€å⁄©ÿ≥ÿßŸÅŸÑŸàŸàÿ±ÿßÿ¶⁄à</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>⁄àÿ≥ŸæŸÑ€í ÿ±€åÿ≤ŸàŸÑŸàÿ¥ŸÜ ŸÖÿßÿ±⁄©€åŸπ ŸÖ€å⁄∫ ÿ≤€åÿßÿØ€Å ÿ™ÿ± ÿ≥ŸæŸÑÿßÿ¶ÿ±ÿ≤ ŸÜ€í 2010 ⁄©€å ÿØ€Åÿßÿ¶€å ŸÖ€å⁄∫ ⁄©€åÿß Ÿæ€åÿ¥ ⁄©€åÿßÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Algernon ÿ≥⁄àŸÜ€å ⁄©€åÿß ⁄©€í ŸÑÿ¶€í ÿß€å⁄© ÿÆÿ∑ÿ±€Å ÿ≥ŸÖÿ¨⁄æÿß ÿ¨ÿßÿ™ÿß ÿ™⁄æÿßÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>⁄©Ÿàÿ≤ÿßŸÜ ⁄©ÿ≥ ⁄Ü€åÿ≤ ÿ≥€í ÿ®ŸÜ€í ÿ™⁄æ€íÿü</td>\n      <td>ŸÑŸà€Å€í €åÿß ⁄ÜŸÖ⁄ë€í</td>\n      <td>ŸÑŸà€Å€í €åÿß ⁄ÜŸÖ⁄ë€í</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Cynanthus latirostris ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©ÿß Ÿæÿ±ŸÜÿØ€Å €Å€íÿü</td>\n      <td>€ÅŸàŸÖŸÜ⁄Ø ÿ®ÿ±⁄à</td>\n      <td>€ÅŸàŸÖŸÜ⁄Ø ÿ®ÿ±⁄à</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>ÿßÿ≥ ⁄©€å ŸÖŸàÿ™ ⁄©€í ÿ®ÿπÿØ Ÿà€åŸàÿ± ⁄©€í ŸÑÿ¶€í ⁄©ŸàŸÜ ŸÑ€í ŸÑ€åÿßÿü</td>\n      <td>ÿßŸÑÿ®ÿ±Ÿπ ⁄©€åÿ≥ŸÑŸÜ⁄Ø ÿßŸàÿ± €ÅŸÜÿ≥ ÿ¨Ÿàÿ±⁄ØŸÜ ÿßÿ≥ŸπŸÖŸæŸÅ</td>\n      <td>ÿßŸÑÿ®ÿ±Ÿπ ⁄©€åÿ≥ŸÑŸÜ⁄Ø ÿßŸàÿ± €ÅŸÜÿ≥ ÿ¨Ÿàÿ±⁄ØŸÜ ÿßÿ≥ŸπŸÖŸæŸÅ</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>ÿ®ŸÑŸÇÿßŸÜ ⁄©€å ÿ¨ŸÜ⁄Ø€å⁄∫ ⁄©€Åÿß⁄∫ €ÅŸàÿ¶€å⁄∫ÿü</td>\n      <td>ÿ¨ŸÜŸàÿ® ŸÖÿ¥ÿ±ŸÇ€å €åŸàÿ±Ÿæ</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>ÿ¨ÿ® ÿ¢ÿ±ÿßŸÖ ŸÖ€å⁄∫ÿå ÿß€å⁄© ÿ∑ŸàŸÑ Ÿà ÿπÿ±ÿ∂ ⁄©€å ÿ±ŸÅÿ™ÿßÿ± ⁄©ÿ™ŸÜ€å ÿ™€åÿ≤ €Å€íÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>⁄©ÿ±ŸàŸÖŸàÿ≥ŸàŸÖŸà⁄∫ ⁄©€å ⁄©ŸÑ ⁄ØŸÜÿ™€å ⁄©€í ŸÑÿ¶€í ÿß€å⁄© ÿßŸàÿ± ŸÑŸÅÿ∏ ⁄©€åÿß €Å€íÿü</td>\n      <td>⁄©€åÿ±ŸàŸπÿßÿ¶Ÿæ</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>813 ŸÖ€å⁄∫ ⁄Üÿßÿ±ŸÑŸÖ€åŸÜ ⁄©ÿß Ÿàÿßÿ≠ÿØ ÿ≤ŸÜÿØ€Å ÿ®€åŸπÿß ⁄©ŸàŸÜ ÿ™⁄æÿßÿü</td>\n      <td>ŸÑŸàÿ¶€å ÿØ€å Ÿæ€åŸàÿ≥</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>ÿ®ÿ±Ÿπ €Å€åŸÖ ⁄©ÿß ŸÖÿßÿ±⁄©€åŸπ ŸÜÿßŸÖ ⁄©€åÿß €Å€íÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>⁄©ÿ≥ ÿ≥ÿßŸÑ ŸÖ€å⁄∫ ÿß€åŸÜ ÿ¢ÿ±ÿ®ÿ± Ÿæÿ®ŸÑ⁄© ÿßÿ≥⁄©ŸàŸÑŸà⁄∫ ŸÖ€å⁄∫ 16ÿå935 ÿ∑ŸÑÿ®ÿßÿ° ÿ±ÿ¨ÿ≥Ÿπÿ±⁄à ÿ™⁄æ€íÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>ÿ≥ÿ≥ÿ™€å €ÅŸàŸÜ€í ⁄©€í ÿπŸÑÿßŸà€Å ÿå Ÿæÿ±Ÿàÿ≥€åÿ≥⁄à ŸÅŸà⁄àÿ≤ ⁄©€å ÿß€å⁄© ÿßŸàÿ± ÿß€ÅŸÖ ⁄©ÿ¥ÿ¥ ⁄©€åÿß €Å€íÿü</td>\n      <td>ÿ≤€åÿßÿØ€Å ÿ¢ÿ≥ÿßŸÜ</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>⁄©ÿ≥ ÿ≥ÿßŸÑ ŸÖ€å⁄∫ ŸÅÿ±€å⁄à€å ÿßŸàÿ± ÿÆŸàÿßÿ® ÿØ€å⁄©⁄æŸÜ€í ŸàÿßŸÑŸà⁄∫ ⁄©Ÿà ÿßŸÜ ⁄©€å Ÿæ€ÅŸÑ€å €ÅŸπ ŸÖŸÑ ⁄Øÿ¶€åÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ŸÜÿ¶€í ÿ≥€å Ÿæ€å €åŸà ŸÅŸÜ ÿ™ÿπŸÖ€åÿ± ŸÖ€å⁄∫ ⁄©ÿßŸÖ€åÿßÿ®€å ⁄©€í ÿ≥ÿßÿ™⁄æ ŸÖŸÜÿ™ŸÇŸÑ€å ⁄©€í ŸÑÿ¶€í Ÿàÿßÿ≠ÿØ ŸÖÿ±⁄©ÿ≤€å ÿØ⁄æÿßÿ±€í ⁄©€í ⁄©ŸÖŸæ€åŸàŸπÿ± ŸæŸÑ€åŸπ ŸÅÿßÿ±ŸÖ ⁄©€åÿß €Å€íÿü</td>\n      <td>ŸÖ€å⁄©ŸÜŸπŸàÿ¥</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>ÿ≥€åÿß€Å ŸÅÿßŸÖ ÿßŸàÿ± ÿß€åÿ¥€åÿßÿ¶€å ÿßÿ≥⁄©ŸàŸÑ ⁄©€í ÿ®⁄ÜŸà⁄∫ ⁄©ÿß ÿ≥ŸÅ€åÿØ ŸÅÿßŸÖ ÿßÿ≥⁄©ŸàŸÑ ⁄©€í ÿ®⁄ÜŸà⁄∫ ⁄©€í ŸÖŸÇÿßÿ®ŸÑ€í ŸÖ€å⁄∫ ⁄©€åÿß ÿ™ŸÜÿßÿ≥ÿ® €Å€íÿü</td>\n      <td>ÿ™ŸÇÿ±€åÿ®ÿß ⁄Ü⁄æ ÿ≥€í ⁄Üÿßÿ±</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>ÿπÿ∑€åÿßÿ™ Ÿæÿ± ÿßŸÜÿ≠ÿµÿßÿ± ⁄©ÿ±ŸÜ€í ŸàÿßŸÑ€å ÿ¨ŸÖÿßÿπÿ™Ÿà⁄∫ ⁄©Ÿà ⁄©ÿ® ŸÖÿ≥ÿßÿ¶ŸÑ ⁄©ÿß ÿ≥ÿßŸÖŸÜÿß ⁄©ÿ±ŸÜÿß Ÿæ⁄ëÿßÿü</td>\n      <td>ÿ®€åÿ≥Ÿà€å⁄∫ ÿµÿØ€å ⁄©€í ÿØŸàÿ≥ÿ±€í ŸÜÿµŸÅ ÿ≥€í</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ÿ≥ÿ≥ŸÑ€å ÿ≥€í ŸæÿßŸÑÿ±ŸÖŸà ÿ™⁄© Ÿæ€ÅŸÜ⁄ÜŸÜÿß ⁄©€åŸà⁄∫ ŸÖÿ¥⁄©ŸÑ €Å€íÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>⁄©ŸàŸÜ ÿ≥ÿß€åŸÜŸπŸàŸÑŸàÿ¨€å ŸÖ€å⁄∫ ÿßÿµŸÑÿßÿ≠ÿßÿ™ ŸÑÿß€åÿß ÿ¨ÿ≥ ÿ≥€í ÿπŸÑ€åÿ≠ÿØ€Å ⁄Øÿ±Ÿà€ÅŸà⁄∫ ⁄©Ÿà ÿ®ÿØÿπÿ™ ŸÇÿ±ÿßÿ± ÿØ€åÿß ⁄Ø€åÿßÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>ŸÖÿßÿ§ ⁄©Ÿà ÿ¨ŸÜŸàÿ®€å ⁄©Ÿàÿ±€åÿß ⁄©€í ÿ≠ŸÖŸÑ€í ⁄©€í ÿ®ÿßÿ±€í ŸÖ€å⁄∫ ⁄©€åÿß ÿ™ÿ¥Ÿà€åÿ¥ ÿ™⁄æ€åÿü</td>\n      <td>ÿßŸÖÿ±€å⁄©€å ŸÖÿØÿßÿÆŸÑÿ™ ⁄©ÿ±€å⁄∫ ⁄Ø€í</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>ÿ±ÿßÿ¶ŸÑ ÿßŸÜÿ≥Ÿπ€å Ÿπ€åŸàŸπ ⁄©€í ⁄©ÿßÿ±Ÿàÿ®ÿßÿ±€å ÿ¢Ÿæÿ±€åÿ¥ŸÜ ⁄©ÿß ŸÜÿßŸÖ ⁄©€åÿß €Å€íÿü</td>\n      <td>RIBA ÿßŸÜŸπÿ±Ÿæÿ±ÿßÿ¶ÿ≤ÿ≤</td>\n      <td>RIBA ÿßŸÜŸπÿ±Ÿæÿ±ÿßÿ¶ÿ≤ÿ≤</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>ÿ¢ÿÆÿ±€å ŸæŸàŸæ ŸÜ€í ⁄©ÿ≥ ÿ™ÿßÿ±€åÿÆ ⁄©Ÿà ÿß€åÿ®€å ŸÖ€å⁄∫ ŸÇÿØŸÖ ÿ±⁄©⁄æÿß ÿ™⁄æÿßÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>⁄©ŸÑŸàÿ±ŸàŸÅŸÑ ⁄©ÿ≥ ⁄Ü€åÿ≤ ⁄©Ÿà ÿ™Ÿà⁄ëŸÜ€í ŸÖ€å⁄∫ ÿß€ÅŸÖ ⁄©ÿ±ÿØÿßÿ± ÿßÿØÿß ⁄©ÿ±ÿ™ÿß €Å€íÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>⁄©ÿ≥ ŸÅ€åÿµŸÑ€í ŸÜ€í ŸÇÿ∞ÿßŸÅ€å ⁄©Ÿà ŸÑ€åÿ®€åÿß ⁄©Ÿà ÿ≥Ÿàÿ¥ŸÑÿ≤ŸÖ ⁄©€í ŸÇÿ±€åÿ® ŸÑ€í ÿ¨ÿßŸÜ€í ⁄©€å ÿßÿ¨ÿßÿ≤ÿ™ ÿØ€åÿü</td>\n      <td>ÿ≥ÿ™ŸÖÿ®ÿ± 1973 ŸÖ€å⁄∫ ÿå €å€Å ÿßÿπŸÑÿßŸÜ ⁄©€åÿß ⁄Ø€åÿß ⁄©€Å ŸÑ€åÿ®€åÿß ŸÖ€å⁄∫ ÿ≥ÿ±⁄Øÿ±ŸÖ ÿ™ŸÖÿßŸÖ ÿ∫€åÿ± ŸÖŸÑ⁄©€å ÿ™€åŸÑ Ÿæÿ±Ÿà⁄à€åŸàÿ≥ÿ±Ÿà⁄∫ ⁄©Ÿà ŸÇŸàŸÖ€å ÿ®ŸÜÿß€åÿß ÿ¨ÿßÿ¶€í ⁄Øÿß€î</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>ÿ≠ÿ±€åŸÅ ŸÅÿßÿ¶ŸÜŸÑ ŸÖ€å⁄∫ ÿßÿ®ÿ™ÿØÿßÿ¶€å ÿ∑Ÿàÿ± Ÿæÿ± ⁄©ÿ™ŸÜ€í ⁄ØÿßŸÜ€í ⁄Øÿßÿ™€í €Å€å⁄∫ÿü</td>\n      <td>ÿß€å⁄©</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>ÿ¨ÿ∞ÿ®ÿßÿ™€å ŸÖÿ≤ÿßÿ¨ ⁄©ÿ≥ ÿØŸàÿ≥ÿ±€å ÿÆÿµŸàÿµ€åÿ™ ÿ≥€í ŸÖÿ¥ÿßÿ®€Åÿ™ ŸÜ€Å€å⁄∫ ÿ±⁄©⁄æÿ™ÿßÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>ÿ®ÿ±ŸÖŸàÿØÿß ŸÖ€å⁄∫ ÿ≥€åÿß€Å ŸÅÿßŸÖ ŸÑŸà⁄ØŸà⁄∫ ⁄©€å ÿß⁄©ÿ´ÿ±€åÿ™ ⁄©ÿß ÿ≠ŸàÿßŸÑ€Å ÿØ€åŸÜ€í ⁄©€í ŸÑÿ¶€í ⁄©ÿ≥ ÿßÿµÿ∑ŸÑÿßÿ≠ ⁄©ÿß ÿßÿ≥ÿ™ÿπŸÖÿßŸÑ ⁄©€åÿß ÿ¨ÿßÿ™ÿß €Å€íÿü</td>\n      <td>ÿ®ÿ±ŸÖŸà⁄à€åŸÜ ÿ≥€åÿß€Å ŸÅÿßŸÖ</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>ŸπŸà⁄à€í ⁄àÿßŸπ ⁄©ÿßŸÖ Ÿæÿ± ÿå ŸÖ€åŸπ ÿ≤ŸàŸÑÿ± ÿ≥€åŸπÿ≤ ŸÜ€í ŸÅŸÑŸÖ ⁄©Ÿà ⁄©ÿ™ŸÜ€í ÿ≥ÿ™ÿßÿ±€í ÿØ€åÿ¶€íÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>ÿ≥ŸÑÿ∑ŸÜÿ™ ÿπÿ´ŸÖÿßŸÜ€å€Å ⁄©€í ÿØŸàÿ±ÿßŸÜÿå ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©€í ÿßÿ≥⁄©ŸàŸÑ ÿ∫€åÿ± ŸÖÿπŸÖŸàŸÑ€å ÿ™⁄æ€íÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>2008 ⁄©€í Ÿàÿ≥ÿ∑ ŸÖ€å⁄∫ ÿ±€åÿßÿ≥ÿ™€Åÿßÿ¶€í ŸÖÿ™ÿ≠ÿØ€Å ŸÖ€å⁄∫ ⁄Ø⁄æÿ± ⁄©€å ÿß€å⁄©Ÿà€åŸπ€å ⁄©€å ŸÇ€åŸÖÿ™ ⁄©ÿ™ŸÜ€å ÿ™⁄æ€åÿü</td>\n      <td>8.8 Ÿπÿ±€åŸÑ€åŸÜ ⁄àÿßŸÑÿ±</td>\n      <td>8.8 Ÿπÿ±€åŸÑ€åŸÜ ⁄àÿßŸÑÿ±</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>ŸÜÿßÿ±ŸÖŸÜ ŸÜ€í ÿßŸæŸÜ€í ⁄©ÿßŸÖ ⁄©Ÿà ⁄©ÿ≥ ŸÖ€å⁄Øÿ≤€åŸÜ ŸÖ€å⁄∫ ÿ¥ÿßÿ¶ÿπ ⁄©€åÿßÿü</td>\n      <td>ÿ≥⁄©ÿ±€åÿ®ŸÜÿ±ÿ≤ ŸÖ€å⁄Øÿ≤€åŸÜ</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>ÿ¥ŸàŸæŸÜ ŸÜ€í ⁄©ŸàŸÜ ÿ≥ÿß ÿ™ÿµŸàÿ± ÿ™ÿÆŸÑ€åŸÇ ⁄©€åÿßÿü</td>\n      <td>ÿßŸÜÿ≥Ÿπÿ±ŸàŸÖŸÜŸπŸÑ ÿ®€åŸÑ⁄à</td>\n      <td>ÿßŸÜÿ≥Ÿπÿ±ŸàŸÖŸÜŸπŸÑ ÿ®€åŸÑ⁄à</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>ÿ™⁄©ŸÜ€å⁄©€å ÿ™ÿ®ÿØ€åŸÑ€å ⁄©€í ŸÜÿ™€åÿ¨€í ŸÖ€å⁄∫ ⁄©€åÿß ÿ≤€åÿßÿØ€Å ŸÖ€ÅŸÜ⁄Øÿß €ÅŸà ÿ±€Åÿß €Å€íÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>ŸÖ€å⁄àŸàŸÜÿß ŸÜ€í ÿßŸæŸÜ€å ÿØŸàÿ≥ÿ±€å ⁄©Ÿæ⁄ë€í ⁄©€å ŸÑÿßÿ¶ŸÜ ⁄©ÿ® ÿ¨ÿßÿ±€å ⁄©€åÿü</td>\n      <td>ŸÜŸàŸÖÿ®ÿ± 2011</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>De Re Aedificatoria ⁄©ÿ≥ ŸÜ€í ŸÑ⁄©⁄æÿßÿü</td>\n      <td>ŸÑ€åŸàŸÜ ÿ®Ÿπ€åÿ≥Ÿπÿß ÿßŸÑÿ®ÿ±Ÿπ€å</td>\n      <td>ŸÑ€åŸàŸÜ ÿ®Ÿπ€åÿ≥Ÿπÿß ÿßŸÑÿ®ÿ±Ÿπ€å</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>ÿµÿßÿ±ŸÅ€åŸÜ ⁄©Ÿà ÿßŸæŸÜ€å ŸÖŸàÿ≥€åŸÇ€å ⁄©Ÿà ÿßŸÜ⁄©Ÿà⁄à ⁄©ÿ±ÿ™€í ŸàŸÇÿ™ ⁄©€åÿß ŸÇÿØÿ± ÿ¨ÿßŸÜŸÜ€í ⁄©€å ÿ∂ÿ±Ÿàÿ±ÿ™ €Å€í ÿ™ÿß⁄©€Å ÿßŸÜ€Å€å⁄∫ €Åÿ± ŸÖŸàÿ≥€åŸÇ€å ⁄©€í Ÿπ⁄©⁄ë€í Ÿæÿ± Ÿπ€åÿ≥Ÿπ ⁄©ÿ±ŸÜ€í ÿ≥€í ÿ®⁄ÜŸÜ€í ŸÖ€å⁄∫ ŸÖÿØÿØ ŸÖŸÑ€íÿü</td>\n      <td>ŸÖÿπ€åÿßÿ± ⁄©€å ÿ™ÿ±ÿ™€åÿ®</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>ÿßŸÖÿßÿ≥€åÿß ⁄©€å ÿßŸÖŸÜ ⁄©ÿ® ÿ™⁄æ€åÿü</td>\n      <td>16 Ÿà€å⁄∫ ÿµÿØ€å ⁄©€í Ÿàÿ≥ÿ∑</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>Ÿà€å⁄à€åŸà ŸÑÿß ÿß€åÿ≥Ÿπÿß ÿ®ŸàŸÜŸπÿß ⁄©€í ŸÑÿ¶€í ⁄©ÿ≥ ŸÇÿ≥ŸÖ ⁄©€í €Åÿ≥ŸæÿßŸÜŸà€å ⁄©Ÿæ⁄ë€í Ÿæ€ÅŸÜ€í ⁄Øÿ¶€í ÿ™⁄æ€íÿü</td>\n      <td>ÿ®ŸàŸÑ€åÿ±Ÿàÿ≥ ÿßŸàÿ± Ÿæÿ±ÿ™Ÿà⁄∫ ŸàÿßŸÑ€å ÿ≥⁄©ÿ±Ÿπ</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>19 Ÿà€å⁄∫ ÿµÿØ€å ⁄©€í ÿ¢ÿÆÿ± ŸÖ€å⁄∫ ⁄©ÿ≥ ÿ¨ÿßÿ¶€åÿØÿßÿØ ⁄©€í ÿ™ÿßÿ¨ÿ± ŸÜ€í ÿ¨ÿßÿ¶€åÿØÿßÿØ ⁄©Ÿà Ÿàÿ±ÿßÿ´ÿ™ ŸÖ€å⁄∫ ÿ≠ÿßÿµŸÑ ⁄©€åÿßÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>Close Encounters ŸÜ€í ⁄©ÿ™ŸÜ€í ÿ¢ÿ≥⁄©ÿ± ÿ¨€åÿ™€íÿü</td>\n      <td>ÿØŸà</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>2005 ÿ™⁄© ŸÅÿßÿ±ŸÖŸàŸÑÿß ŸÅŸàÿ±⁄à ⁄Ü€åŸÖŸæÿ¶ŸÜ ÿ¥Ÿæ ŸÖ€å⁄∫ ⁄©ÿ≥ ŸÜ€í ÿØŸà⁄ë ŸÑ⁄Øÿßÿ¶€åÿü</td>\n      <td></td>\n      <td></td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>\"Ÿæ€åŸÜÿ≥€åŸÑ Ÿπ€åÿ≥Ÿπ\" ⁄©ÿ≥ ŸÜ€í ⁄©€åÿßÿü</td>\n      <td>ŸÖÿπŸÖŸàŸÑ€å ÿπ€ÅÿØ€åÿØÿßÿ±Ÿà⁄∫</td>\n      <td>ŸÖÿπŸÖŸàŸÑ€å ÿπ€ÅÿØ€åÿØÿßÿ±Ÿà⁄∫</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>ŸÖÿßŸÅŸàŸÇ ÿßŸÑŸÅÿ∑ÿ±ÿ™ ŸÖŸàÿ¨ŸàÿØÿßÿ™ ⁄©€åÿ≥€í ⁄©ÿßŸÖ ⁄©ÿ±ÿ™€í €Å€å⁄∫ÿü</td>\n      <td>ŸÑŸà⁄ØŸà⁄∫ ⁄©€å ÿ∑ÿ±ÿ≠</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>⁄©ŸÑŸÜŸπŸÜ ⁄©€å ŸÖÿØÿ™ ⁄©€í ÿØŸàÿ±ÿßŸÜ ⁄©ŸàŸÜ ÿ≥ÿß ÿÆŸàŸÅŸÜÿß⁄© ŸàÿßŸÇÿπ€Å ÿ¨ÿßÿ±€å ÿ™⁄æÿß ÿ¨ÿ≥ ŸÜ€í ŸÑŸà⁄ØŸà⁄∫ ⁄©Ÿà Ÿæÿ±€åÿ¥ÿßŸÜ ⁄©ÿ±ÿØ€åÿßÿü</td>\n      <td>ÿ±ŸàÿßŸÜ⁄àÿß ŸÜÿ≥ŸÑ ⁄©ÿ¥€å</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>⁄©ŸàŸÜ ÿ≥ÿß ŸÅŸÜ⁄©ÿßÿ± ÿ®€åŸàŸÜÿ≥€í ⁄©€å Ÿæÿ±€åŸÖ€åÿ¶ÿ± ÿ≥ŸàŸÑŸà ÿ±€å⁄©ÿßÿ±⁄àŸÜ⁄Ø ⁄©€í ÿ≥ÿßÿ™⁄æ ŸÖŸÜÿ≥ŸÑ⁄© ⁄©€åÿß ⁄Ø€åÿß ÿ™⁄æÿßÿü</td>\n      <td>ÿ¨€í ÿ≤€å</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>⁄©ÿßÿ±ÿ®ŸàŸÜ€åŸÅ€åÿ±ÿ≥ ⁄©€í ÿπŸÑÿßŸà€Å ÿå ⁄©ŸàŸÜ ÿ≥ÿß ÿØŸàÿ≥ÿ±ÿß ⁄©€å⁄ë€í ⁄©ÿß ÿ¢ÿ±⁄àÿ± ŸÖŸàÿ¨ŸàÿØ€Å ⁄Øÿ±Ÿà€ÅŸà⁄∫ ÿå ÿßÿ≥Ÿπ€åŸÖ ⁄Øÿ±Ÿà€ÅŸà⁄∫ ÿßŸàÿ± Ÿæ€åŸÑ€åŸàÿ≤Ÿà⁄© ⁄Øÿ±Ÿà€ÅŸà⁄∫ ⁄©Ÿà ÿ¥ÿßŸÖŸÑ ⁄©ÿ±ÿ™ÿß €Å€íÿü</td>\n      <td>ÿßÿ®ÿ™ÿØÿßÿ¶€å Ÿæÿ±ŸÖ€åŸÜ</td>\n      <td></td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":26},{"id":"22","cell_type":"code","source":"# Accuracy: fraction of rows where extracted answer matches gold answer\naccuracy = (results_df[\"Match\"]).mean()\n\n# Precision: among rows where extracted answer is non-empty, fraction that matches gold\n# We filter out cases where the model predicted nothing (empty string) or just whitespace\nnon_empty_pred = results_df[\"Extracted Answer\"].str.strip() != \"\"\n\n# Avoid division by zero if no predictions were made\nif non_empty_pred.sum() > 0:\n    precision = (results_df[\"Match\"] & non_empty_pred).sum() / non_empty_pred.sum()\nelse:\n    precision = 0.0\n\nprint(f\"Accuracy: {accuracy:.3f}\")\nprint(f\"Precision: {precision:.3f}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e67abc12","outputId":"c597ec41-a56e-4e5d-9eb6-e71bd0eafd38","trusted":true,"execution":{"iopub.status.busy":"2025-11-28T11:53:41.757195Z","iopub.execute_input":"2025-11-28T11:53:41.757695Z","iopub.status.idle":"2025-11-28T11:53:41.771566Z","shell.execute_reply.started":"2025-11-28T11:53:41.757667Z","shell.execute_reply":"2025-11-28T11:53:41.770634Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.583\nPrecision: 1.000\n","output_type":"stream"}],"execution_count":24}]}